var THREE = require("./three.js");
global.THREE = THREE;
var WGS = require("./wgs.js");
global.WGS = WGS;/** @license zlib.js 2012 - imaya [ https://github.com/imaya/zlib.js ] The MIT License */(function() {'use strict';function n(e){throw e;}var p=void 0,aa=this;function r(e,c){var d=e.split("."),b=aa;!(d[0]in b)&&b.execScript&&b.execScript("var "+d[0]);for(var a;d.length&&(a=d.shift());)!d.length&&c!==p?b[a]=c:b=b[a]?b[a]:b[a]={}};var u="undefined"!==typeof Uint8Array&&"undefined"!==typeof Uint16Array&&"undefined"!==typeof Uint32Array;new (u?Uint8Array:Array)(256);var v;for(v=0;256>v;++v)for(var w=v,ba=7,w=w>>>1;w;w>>>=1)--ba;function x(e,c,d){var b,a="number"===typeof c?c:c=0,f="number"===typeof d?d:e.length;b=-1;for(a=f&7;a--;++c)b=b>>>8^y[(b^e[c])&255];for(a=f>>3;a--;c+=8)b=b>>>8^y[(b^e[c])&255],b=b>>>8^y[(b^e[c+1])&255],b=b>>>8^y[(b^e[c+2])&255],b=b>>>8^y[(b^e[c+3])&255],b=b>>>8^y[(b^e[c+4])&255],b=b>>>8^y[(b^e[c+5])&255],b=b>>>8^y[(b^e[c+6])&255],b=b>>>8^y[(b^e[c+7])&255];return(b^4294967295)>>>0}
var z=[0,1996959894,3993919788,2567524794,124634137,1886057615,3915621685,2657392035,249268274,2044508324,3772115230,2547177864,162941995,2125561021,3887607047,2428444049,498536548,1789927666,4089016648,2227061214,450548861,1843258603,4107580753,2211677639,325883990,1684777152,4251122042,2321926636,335633487,1661365465,4195302755,2366115317,997073096,1281953886,3579855332,2724688242,1006888145,1258607687,3524101629,2768942443,901097722,1119000684,3686517206,2898065728,853044451,1172266101,3705015759,
2882616665,651767980,1373503546,3369554304,3218104598,565507253,1454621731,3485111705,3099436303,671266974,1594198024,3322730930,2970347812,795835527,1483230225,3244367275,3060149565,1994146192,31158534,2563907772,4023717930,1907459465,112637215,2680153253,3904427059,2013776290,251722036,2517215374,3775830040,2137656763,141376813,2439277719,3865271297,1802195444,476864866,2238001368,4066508878,1812370925,453092731,2181625025,4111451223,1706088902,314042704,2344532202,4240017532,1658658271,366619977,
2362670323,4224994405,1303535960,984961486,2747007092,3569037538,1256170817,1037604311,2765210733,3554079995,1131014506,879679996,2909243462,3663771856,1141124467,855842277,2852801631,3708648649,1342533948,654459306,3188396048,3373015174,1466479909,544179635,3110523913,3462522015,1591671054,702138776,2966460450,3352799412,1504918807,783551873,3082640443,3233442989,3988292384,2596254646,62317068,1957810842,3939845945,2647816111,81470997,1943803523,3814918930,2489596804,225274430,2053790376,3826175755,
2466906013,167816743,2097651377,4027552580,2265490386,503444072,1762050814,4150417245,2154129355,426522225,1852507879,4275313526,2312317920,282753626,1742555852,4189708143,2394877945,397917763,1622183637,3604390888,2714866558,953729732,1340076626,3518719985,2797360999,1068828381,1219638859,3624741850,2936675148,906185462,1090812512,3747672003,2825379669,829329135,1181335161,3412177804,3160834842,628085408,1382605366,3423369109,3138078467,570562233,1426400815,3317316542,2998733608,733239954,1555261956,
3268935591,3050360625,752459403,1541320221,2607071920,3965973030,1969922972,40735498,2617837225,3943577151,1913087877,83908371,2512341634,3803740692,2075208622,213261112,2463272603,3855990285,2094854071,198958881,2262029012,4057260610,1759359992,534414190,2176718541,4139329115,1873836001,414664567,2282248934,4279200368,1711684554,285281116,2405801727,4167216745,1634467795,376229701,2685067896,3608007406,1308918612,956543938,2808555105,3495958263,1231636301,1047427035,2932959818,3654703836,1088359270,
936918E3,2847714899,3736837829,1202900863,817233897,3183342108,3401237130,1404277552,615818150,3134207493,3453421203,1423857449,601450431,3009837614,3294710456,1567103746,711928724,3020668471,3272380065,1510334235,755167117],y=u?new Uint32Array(z):z;function A(){}A.prototype.getName=function(){return this.name};A.prototype.getData=function(){return this.data};A.prototype.G=function(){return this.H};r("Zlib.GunzipMember",A);r("Zlib.GunzipMember.prototype.getName",A.prototype.getName);r("Zlib.GunzipMember.prototype.getData",A.prototype.getData);r("Zlib.GunzipMember.prototype.getMtime",A.prototype.G);function C(e){var c=e.length,d=0,b=Number.POSITIVE_INFINITY,a,f,g,k,m,q,t,h,l;for(h=0;h<c;++h)e[h]>d&&(d=e[h]),e[h]<b&&(b=e[h]);a=1<<d;f=new (u?Uint32Array:Array)(a);g=1;k=0;for(m=2;g<=d;){for(h=0;h<c;++h)if(e[h]===g){q=0;t=k;for(l=0;l<g;++l)q=q<<1|t&1,t>>=1;for(l=q;l<a;l+=m)f[l]=g<<16|h;++k}++g;k<<=1;m<<=1}return[f,d,b]};var D=[],E;for(E=0;288>E;E++)switch(!0){case 143>=E:D.push([E+48,8]);break;case 255>=E:D.push([E-144+400,9]);break;case 279>=E:D.push([E-256+0,7]);break;case 287>=E:D.push([E-280+192,8]);break;default:n("invalid literal: "+E)}
var ca=function(){function e(a){switch(!0){case 3===a:return[257,a-3,0];case 4===a:return[258,a-4,0];case 5===a:return[259,a-5,0];case 6===a:return[260,a-6,0];case 7===a:return[261,a-7,0];case 8===a:return[262,a-8,0];case 9===a:return[263,a-9,0];case 10===a:return[264,a-10,0];case 12>=a:return[265,a-11,1];case 14>=a:return[266,a-13,1];case 16>=a:return[267,a-15,1];case 18>=a:return[268,a-17,1];case 22>=a:return[269,a-19,2];case 26>=a:return[270,a-23,2];case 30>=a:return[271,a-27,2];case 34>=a:return[272,
a-31,2];case 42>=a:return[273,a-35,3];case 50>=a:return[274,a-43,3];case 58>=a:return[275,a-51,3];case 66>=a:return[276,a-59,3];case 82>=a:return[277,a-67,4];case 98>=a:return[278,a-83,4];case 114>=a:return[279,a-99,4];case 130>=a:return[280,a-115,4];case 162>=a:return[281,a-131,5];case 194>=a:return[282,a-163,5];case 226>=a:return[283,a-195,5];case 257>=a:return[284,a-227,5];case 258===a:return[285,a-258,0];default:n("invalid length: "+a)}}var c=[],d,b;for(d=3;258>=d;d++)b=e(d),c[d]=b[2]<<24|b[1]<<
16|b[0];return c}();u&&new Uint32Array(ca);function G(e,c){this.i=[];this.j=32768;this.d=this.f=this.c=this.n=0;this.input=u?new Uint8Array(e):e;this.o=!1;this.k=H;this.w=!1;if(c||!(c={}))c.index&&(this.c=c.index),c.bufferSize&&(this.j=c.bufferSize),c.bufferType&&(this.k=c.bufferType),c.resize&&(this.w=c.resize);switch(this.k){case I:this.a=32768;this.b=new (u?Uint8Array:Array)(32768+this.j+258);break;case H:this.a=0;this.b=new (u?Uint8Array:Array)(this.j);this.e=this.D;this.q=this.A;this.l=this.C;break;default:n(Error("invalid inflate mode"))}}
var I=0,H=1;
G.prototype.g=function(){for(;!this.o;){var e=J(this,3);e&1&&(this.o=!0);e>>>=1;switch(e){case 0:var c=this.input,d=this.c,b=this.b,a=this.a,f=p,g=p,k=p,m=b.length,q=p;this.d=this.f=0;f=c[d++];f===p&&n(Error("invalid uncompressed block header: LEN (first byte)"));g=f;f=c[d++];f===p&&n(Error("invalid uncompressed block header: LEN (second byte)"));g|=f<<8;f=c[d++];f===p&&n(Error("invalid uncompressed block header: NLEN (first byte)"));k=f;f=c[d++];f===p&&n(Error("invalid uncompressed block header: NLEN (second byte)"));k|=
f<<8;g===~k&&n(Error("invalid uncompressed block header: length verify"));d+g>c.length&&n(Error("input buffer is broken"));switch(this.k){case I:for(;a+g>b.length;){q=m-a;g-=q;if(u)b.set(c.subarray(d,d+q),a),a+=q,d+=q;else for(;q--;)b[a++]=c[d++];this.a=a;b=this.e();a=this.a}break;case H:for(;a+g>b.length;)b=this.e({t:2});break;default:n(Error("invalid inflate mode"))}if(u)b.set(c.subarray(d,d+g),a),a+=g,d+=g;else for(;g--;)b[a++]=c[d++];this.c=d;this.a=a;this.b=b;break;case 1:this.l(da,ea);break;
case 2:fa(this);break;default:n(Error("unknown BTYPE: "+e))}}return this.q()};
var K=[16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15],L=u?new Uint16Array(K):K,N=[3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,258,258],O=u?new Uint16Array(N):N,P=[0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0,0,0],Q=u?new Uint8Array(P):P,T=[1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577],ga=u?new Uint16Array(T):T,ha=[0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,
13,13],U=u?new Uint8Array(ha):ha,V=new (u?Uint8Array:Array)(288),W,ia;W=0;for(ia=V.length;W<ia;++W)V[W]=143>=W?8:255>=W?9:279>=W?7:8;var da=C(V),X=new (u?Uint8Array:Array)(30),Y,ja;Y=0;for(ja=X.length;Y<ja;++Y)X[Y]=5;var ea=C(X);function J(e,c){for(var d=e.f,b=e.d,a=e.input,f=e.c,g;b<c;)g=a[f++],g===p&&n(Error("input buffer is broken")),d|=g<<b,b+=8;g=d&(1<<c)-1;e.f=d>>>c;e.d=b-c;e.c=f;return g}
function Z(e,c){for(var d=e.f,b=e.d,a=e.input,f=e.c,g=c[0],k=c[1],m,q,t;b<k;){m=a[f++];if(m===p)break;d|=m<<b;b+=8}q=g[d&(1<<k)-1];t=q>>>16;e.f=d>>t;e.d=b-t;e.c=f;return q&65535}
function fa(e){function c(a,c,b){var d,e,f,g;for(g=0;g<a;)switch(d=Z(this,c),d){case 16:for(f=3+J(this,2);f--;)b[g++]=e;break;case 17:for(f=3+J(this,3);f--;)b[g++]=0;e=0;break;case 18:for(f=11+J(this,7);f--;)b[g++]=0;e=0;break;default:e=b[g++]=d}return b}var d=J(e,5)+257,b=J(e,5)+1,a=J(e,4)+4,f=new (u?Uint8Array:Array)(L.length),g,k,m,q;for(q=0;q<a;++q)f[L[q]]=J(e,3);g=C(f);k=new (u?Uint8Array:Array)(d);m=new (u?Uint8Array:Array)(b);e.l(C(c.call(e,d,g,k)),C(c.call(e,b,g,m)))}
G.prototype.l=function(e,c){var d=this.b,b=this.a;this.r=e;for(var a=d.length-258,f,g,k,m;256!==(f=Z(this,e));)if(256>f)b>=a&&(this.a=b,d=this.e(),b=this.a),d[b++]=f;else{g=f-257;m=O[g];0<Q[g]&&(m+=J(this,Q[g]));f=Z(this,c);k=ga[f];0<U[f]&&(k+=J(this,U[f]));b>=a&&(this.a=b,d=this.e(),b=this.a);for(;m--;)d[b]=d[b++-k]}for(;8<=this.d;)this.d-=8,this.c--;this.a=b};
G.prototype.C=function(e,c){var d=this.b,b=this.a;this.r=e;for(var a=d.length,f,g,k,m;256!==(f=Z(this,e));)if(256>f)b>=a&&(d=this.e(),a=d.length),d[b++]=f;else{g=f-257;m=O[g];0<Q[g]&&(m+=J(this,Q[g]));f=Z(this,c);k=ga[f];0<U[f]&&(k+=J(this,U[f]));b+m>a&&(d=this.e(),a=d.length);for(;m--;)d[b]=d[b++-k]}for(;8<=this.d;)this.d-=8,this.c--;this.a=b};
G.prototype.e=function(){var e=new (u?Uint8Array:Array)(this.a-32768),c=this.a-32768,d,b,a=this.b;if(u)e.set(a.subarray(32768,e.length));else{d=0;for(b=e.length;d<b;++d)e[d]=a[d+32768]}this.i.push(e);this.n+=e.length;if(u)a.set(a.subarray(c,c+32768));else for(d=0;32768>d;++d)a[d]=a[c+d];this.a=32768;return a};
G.prototype.D=function(e){var c,d=this.input.length/this.c+1|0,b,a,f,g=this.input,k=this.b;e&&("number"===typeof e.t&&(d=e.t),"number"===typeof e.z&&(d+=e.z));2>d?(b=(g.length-this.c)/this.r[2],f=258*(b/2)|0,a=f<k.length?k.length+f:k.length<<1):a=k.length*d;u?(c=new Uint8Array(a),c.set(k)):c=k;return this.b=c};
G.prototype.q=function(){var e=0,c=this.b,d=this.i,b,a=new (u?Uint8Array:Array)(this.n+(this.a-32768)),f,g,k,m;if(0===d.length)return u?this.b.subarray(32768,this.a):this.b.slice(32768,this.a);f=0;for(g=d.length;f<g;++f){b=d[f];k=0;for(m=b.length;k<m;++k)a[e++]=b[k]}f=32768;for(g=this.a;f<g;++f)a[e++]=c[f];this.i=[];return this.buffer=a};
G.prototype.A=function(){var e,c=this.a;u?this.w?(e=new Uint8Array(c),e.set(this.b.subarray(0,c))):e=this.b.subarray(0,c):(this.b.length>c&&(this.b.length=c),e=this.b);return this.buffer=e};function $(e){this.input=e;this.c=0;this.m=[];this.s=!1}$.prototype.F=function(){this.s||this.g();return this.m.slice()};
$.prototype.g=function(){for(var e=this.input.length;this.c<e;){var c=new A,d=p,b=p,a=p,f=p,g=p,k=p,m=p,q=p,t=p,h=this.input,l=this.c;c.u=h[l++];c.v=h[l++];(31!==c.u||139!==c.v)&&n(Error("invalid file signature:"+c.u+","+c.v));c.p=h[l++];switch(c.p){case 8:break;default:n(Error("unknown compression method: "+c.p))}c.h=h[l++];q=h[l++]|h[l++]<<8|h[l++]<<16|h[l++]<<24;c.H=new Date(1E3*q);c.N=h[l++];c.M=h[l++];0<(c.h&4)&&(c.I=h[l++]|h[l++]<<8,l+=c.I);if(0<(c.h&8)){m=[];for(k=0;0<(g=h[l++]);)m[k++]=String.fromCharCode(g);
c.name=m.join("")}if(0<(c.h&16)){m=[];for(k=0;0<(g=h[l++]);)m[k++]=String.fromCharCode(g);c.J=m.join("")}0<(c.h&2)&&(c.B=x(h,0,l)&65535,c.B!==(h[l++]|h[l++]<<8)&&n(Error("invalid header crc16")));d=h[h.length-4]|h[h.length-3]<<8|h[h.length-2]<<16|h[h.length-1]<<24;h.length-l-4-4<512*d&&(f=d);b=new G(h,{index:l,bufferSize:f});c.data=a=b.g();l=b.c;c.K=t=(h[l++]|h[l++]<<8|h[l++]<<16|h[l++]<<24)>>>0;x(a,p,p)!==t&&n(Error("invalid CRC-32 checksum: 0x"+x(a,p,p).toString(16)+" / 0x"+t.toString(16)));c.L=
d=(h[l++]|h[l++]<<8|h[l++]<<16|h[l++]<<24)>>>0;(a.length&4294967295)!==d&&n(Error("invalid input size: "+(a.length&4294967295)+" / "+d));this.m.push(c);this.c=l}this.s=!0;var F=this.m,s,M,R=0,S=0,B;s=0;for(M=F.length;s<M;++s)S+=F[s].data.length;if(u){B=new Uint8Array(S);for(s=0;s<M;++s)B.set(F[s].data,R),R+=F[s].data.length}else{B=[];for(s=0;s<M;++s)B[s]=F[s].data;B=Array.prototype.concat.apply([],B)}return B};r("Zlib.Gunzip",$);r("Zlib.Gunzip.prototype.decompress",$.prototype.g);r("Zlib.Gunzip.prototype.getMembers",$.prototype.F);}).call(this);
;
/** @license zlib.js 2012 - imaya [ https://github.com/imaya/zlib.js ] The MIT License */(function() {'use strict';function m(a){throw a;}var p=void 0,t,aa=this;function v(a,b){var c=a.split("."),d=aa;!(c[0]in d)&&d.execScript&&d.execScript("var "+c[0]);for(var g;c.length&&(g=c.shift());)!c.length&&b!==p?d[g]=b:d=d[g]?d[g]:d[g]={}};var w="undefined"!==typeof Uint8Array&&"undefined"!==typeof Uint16Array&&"undefined"!==typeof Uint32Array;new (w?Uint8Array:Array)(256);var x;for(x=0;256>x;++x)for(var y=x,ba=7,y=y>>>1;y;y>>>=1)--ba;var z=[0,1996959894,3993919788,2567524794,124634137,1886057615,3915621685,2657392035,249268274,2044508324,3772115230,2547177864,162941995,2125561021,3887607047,2428444049,498536548,1789927666,4089016648,2227061214,450548861,1843258603,4107580753,2211677639,325883990,1684777152,4251122042,2321926636,335633487,1661365465,4195302755,2366115317,997073096,1281953886,3579855332,2724688242,1006888145,1258607687,3524101629,2768942443,901097722,1119000684,3686517206,2898065728,853044451,1172266101,3705015759,
2882616665,651767980,1373503546,3369554304,3218104598,565507253,1454621731,3485111705,3099436303,671266974,1594198024,3322730930,2970347812,795835527,1483230225,3244367275,3060149565,1994146192,31158534,2563907772,4023717930,1907459465,112637215,2680153253,3904427059,2013776290,251722036,2517215374,3775830040,2137656763,141376813,2439277719,3865271297,1802195444,476864866,2238001368,4066508878,1812370925,453092731,2181625025,4111451223,1706088902,314042704,2344532202,4240017532,1658658271,366619977,
2362670323,4224994405,1303535960,984961486,2747007092,3569037538,1256170817,1037604311,2765210733,3554079995,1131014506,879679996,2909243462,3663771856,1141124467,855842277,2852801631,3708648649,1342533948,654459306,3188396048,3373015174,1466479909,544179635,3110523913,3462522015,1591671054,702138776,2966460450,3352799412,1504918807,783551873,3082640443,3233442989,3988292384,2596254646,62317068,1957810842,3939845945,2647816111,81470997,1943803523,3814918930,2489596804,225274430,2053790376,3826175755,
2466906013,167816743,2097651377,4027552580,2265490386,503444072,1762050814,4150417245,2154129355,426522225,1852507879,4275313526,2312317920,282753626,1742555852,4189708143,2394877945,397917763,1622183637,3604390888,2714866558,953729732,1340076626,3518719985,2797360999,1068828381,1219638859,3624741850,2936675148,906185462,1090812512,3747672003,2825379669,829329135,1181335161,3412177804,3160834842,628085408,1382605366,3423369109,3138078467,570562233,1426400815,3317316542,2998733608,733239954,1555261956,
3268935591,3050360625,752459403,1541320221,2607071920,3965973030,1969922972,40735498,2617837225,3943577151,1913087877,83908371,2512341634,3803740692,2075208622,213261112,2463272603,3855990285,2094854071,198958881,2262029012,4057260610,1759359992,534414190,2176718541,4139329115,1873836001,414664567,2282248934,4279200368,1711684554,285281116,2405801727,4167216745,1634467795,376229701,2685067896,3608007406,1308918612,956543938,2808555105,3495958263,1231636301,1047427035,2932959818,3654703836,1088359270,
936918E3,2847714899,3736837829,1202900863,817233897,3183342108,3401237130,1404277552,615818150,3134207493,3453421203,1423857449,601450431,3009837614,3294710456,1567103746,711928724,3020668471,3272380065,1510334235,755167117],A=w?new Uint32Array(z):z;function B(a){var b=a.length,c=0,d=Number.POSITIVE_INFINITY,g,f,h,e,k,l,q,s,r;for(s=0;s<b;++s)a[s]>c&&(c=a[s]),a[s]<d&&(d=a[s]);g=1<<c;f=new (w?Uint32Array:Array)(g);h=1;e=0;for(k=2;h<=c;){for(s=0;s<b;++s)if(a[s]===h){l=0;q=e;for(r=0;r<h;++r)l=l<<1|q&1,q>>=1;for(r=l;r<g;r+=k)f[r]=h<<16|s;++e}++h;e<<=1;k<<=1}return[f,c,d]};var C=[],D;for(D=0;288>D;D++)switch(!0){case 143>=D:C.push([D+48,8]);break;case 255>=D:C.push([D-144+400,9]);break;case 279>=D:C.push([D-256+0,7]);break;case 287>=D:C.push([D-280+192,8]);break;default:m("invalid literal: "+D)}
var ca=function(){function a(a){switch(!0){case 3===a:return[257,a-3,0];case 4===a:return[258,a-4,0];case 5===a:return[259,a-5,0];case 6===a:return[260,a-6,0];case 7===a:return[261,a-7,0];case 8===a:return[262,a-8,0];case 9===a:return[263,a-9,0];case 10===a:return[264,a-10,0];case 12>=a:return[265,a-11,1];case 14>=a:return[266,a-13,1];case 16>=a:return[267,a-15,1];case 18>=a:return[268,a-17,1];case 22>=a:return[269,a-19,2];case 26>=a:return[270,a-23,2];case 30>=a:return[271,a-27,2];case 34>=a:return[272,
a-31,2];case 42>=a:return[273,a-35,3];case 50>=a:return[274,a-43,3];case 58>=a:return[275,a-51,3];case 66>=a:return[276,a-59,3];case 82>=a:return[277,a-67,4];case 98>=a:return[278,a-83,4];case 114>=a:return[279,a-99,4];case 130>=a:return[280,a-115,4];case 162>=a:return[281,a-131,5];case 194>=a:return[282,a-163,5];case 226>=a:return[283,a-195,5];case 257>=a:return[284,a-227,5];case 258===a:return[285,a-258,0];default:m("invalid length: "+a)}}var b=[],c,d;for(c=3;258>=c;c++)d=a(c),b[c]=d[2]<<24|d[1]<<
16|d[0];return b}();w&&new Uint32Array(ca);function E(a,b){this.l=[];this.m=32768;this.d=this.f=this.c=this.t=0;this.input=w?new Uint8Array(a):a;this.u=!1;this.n=F;this.K=!1;if(b||!(b={}))b.index&&(this.c=b.index),b.bufferSize&&(this.m=b.bufferSize),b.bufferType&&(this.n=b.bufferType),b.resize&&(this.K=b.resize);switch(this.n){case G:this.a=32768;this.b=new (w?Uint8Array:Array)(32768+this.m+258);break;case F:this.a=0;this.b=new (w?Uint8Array:Array)(this.m);this.e=this.W;this.B=this.R;this.q=this.V;break;default:m(Error("invalid inflate mode"))}}
var G=0,F=1;
E.prototype.r=function(){for(;!this.u;){var a=H(this,3);a&1&&(this.u=!0);a>>>=1;switch(a){case 0:var b=this.input,c=this.c,d=this.b,g=this.a,f=p,h=p,e=p,k=d.length,l=p;this.d=this.f=0;f=b[c++];f===p&&m(Error("invalid uncompressed block header: LEN (first byte)"));h=f;f=b[c++];f===p&&m(Error("invalid uncompressed block header: LEN (second byte)"));h|=f<<8;f=b[c++];f===p&&m(Error("invalid uncompressed block header: NLEN (first byte)"));e=f;f=b[c++];f===p&&m(Error("invalid uncompressed block header: NLEN (second byte)"));e|=
f<<8;h===~e&&m(Error("invalid uncompressed block header: length verify"));c+h>b.length&&m(Error("input buffer is broken"));switch(this.n){case G:for(;g+h>d.length;){l=k-g;h-=l;if(w)d.set(b.subarray(c,c+l),g),g+=l,c+=l;else for(;l--;)d[g++]=b[c++];this.a=g;d=this.e();g=this.a}break;case F:for(;g+h>d.length;)d=this.e({H:2});break;default:m(Error("invalid inflate mode"))}if(w)d.set(b.subarray(c,c+h),g),g+=h,c+=h;else for(;h--;)d[g++]=b[c++];this.c=c;this.a=g;this.b=d;break;case 1:this.q(da,ea);break;
case 2:fa(this);break;default:m(Error("unknown BTYPE: "+a))}}return this.B()};
var I=[16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15],J=w?new Uint16Array(I):I,K=[3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,258,258],L=w?new Uint16Array(K):K,ga=[0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0,0,0],O=w?new Uint8Array(ga):ga,ha=[1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577],ia=w?new Uint16Array(ha):ha,ja=[0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,
12,12,13,13],P=w?new Uint8Array(ja):ja,Q=new (w?Uint8Array:Array)(288),R,la;R=0;for(la=Q.length;R<la;++R)Q[R]=143>=R?8:255>=R?9:279>=R?7:8;var da=B(Q),S=new (w?Uint8Array:Array)(30),T,ma;T=0;for(ma=S.length;T<ma;++T)S[T]=5;var ea=B(S);function H(a,b){for(var c=a.f,d=a.d,g=a.input,f=a.c,h;d<b;)h=g[f++],h===p&&m(Error("input buffer is broken")),c|=h<<d,d+=8;h=c&(1<<b)-1;a.f=c>>>b;a.d=d-b;a.c=f;return h}
function U(a,b){for(var c=a.f,d=a.d,g=a.input,f=a.c,h=b[0],e=b[1],k,l,q;d<e;){k=g[f++];if(k===p)break;c|=k<<d;d+=8}l=h[c&(1<<e)-1];q=l>>>16;a.f=c>>q;a.d=d-q;a.c=f;return l&65535}
function fa(a){function b(a,b,c){var d,e,f,g;for(g=0;g<a;)switch(d=U(this,b),d){case 16:for(f=3+H(this,2);f--;)c[g++]=e;break;case 17:for(f=3+H(this,3);f--;)c[g++]=0;e=0;break;case 18:for(f=11+H(this,7);f--;)c[g++]=0;e=0;break;default:e=c[g++]=d}return c}var c=H(a,5)+257,d=H(a,5)+1,g=H(a,4)+4,f=new (w?Uint8Array:Array)(J.length),h,e,k,l;for(l=0;l<g;++l)f[J[l]]=H(a,3);h=B(f);e=new (w?Uint8Array:Array)(c);k=new (w?Uint8Array:Array)(d);a.q(B(b.call(a,c,h,e)),B(b.call(a,d,h,k)))}t=E.prototype;
t.q=function(a,b){var c=this.b,d=this.a;this.C=a;for(var g=c.length-258,f,h,e,k;256!==(f=U(this,a));)if(256>f)d>=g&&(this.a=d,c=this.e(),d=this.a),c[d++]=f;else{h=f-257;k=L[h];0<O[h]&&(k+=H(this,O[h]));f=U(this,b);e=ia[f];0<P[f]&&(e+=H(this,P[f]));d>=g&&(this.a=d,c=this.e(),d=this.a);for(;k--;)c[d]=c[d++-e]}for(;8<=this.d;)this.d-=8,this.c--;this.a=d};
t.V=function(a,b){var c=this.b,d=this.a;this.C=a;for(var g=c.length,f,h,e,k;256!==(f=U(this,a));)if(256>f)d>=g&&(c=this.e(),g=c.length),c[d++]=f;else{h=f-257;k=L[h];0<O[h]&&(k+=H(this,O[h]));f=U(this,b);e=ia[f];0<P[f]&&(e+=H(this,P[f]));d+k>g&&(c=this.e(),g=c.length);for(;k--;)c[d]=c[d++-e]}for(;8<=this.d;)this.d-=8,this.c--;this.a=d};
t.e=function(){var a=new (w?Uint8Array:Array)(this.a-32768),b=this.a-32768,c,d,g=this.b;if(w)a.set(g.subarray(32768,a.length));else{c=0;for(d=a.length;c<d;++c)a[c]=g[c+32768]}this.l.push(a);this.t+=a.length;if(w)g.set(g.subarray(b,b+32768));else for(c=0;32768>c;++c)g[c]=g[b+c];this.a=32768;return g};
t.W=function(a){var b,c=this.input.length/this.c+1|0,d,g,f,h=this.input,e=this.b;a&&("number"===typeof a.H&&(c=a.H),"number"===typeof a.P&&(c+=a.P));2>c?(d=(h.length-this.c)/this.C[2],f=258*(d/2)|0,g=f<e.length?e.length+f:e.length<<1):g=e.length*c;w?(b=new Uint8Array(g),b.set(e)):b=e;return this.b=b};
t.B=function(){var a=0,b=this.b,c=this.l,d,g=new (w?Uint8Array:Array)(this.t+(this.a-32768)),f,h,e,k;if(0===c.length)return w?this.b.subarray(32768,this.a):this.b.slice(32768,this.a);f=0;for(h=c.length;f<h;++f){d=c[f];e=0;for(k=d.length;e<k;++e)g[a++]=d[e]}f=32768;for(h=this.a;f<h;++f)g[a++]=b[f];this.l=[];return this.buffer=g};
t.R=function(){var a,b=this.a;w?this.K?(a=new Uint8Array(b),a.set(this.b.subarray(0,b))):a=this.b.subarray(0,b):(this.b.length>b&&(this.b.length=b),a=this.b);return this.buffer=a};function V(a){a=a||{};this.files=[];this.v=a.comment}V.prototype.L=function(a){this.j=a};V.prototype.s=function(a){var b=a[2]&65535|2;return b*(b^1)>>8&255};V.prototype.k=function(a,b){a[0]=(A[(a[0]^b)&255]^a[0]>>>8)>>>0;a[1]=(6681*(20173*(a[1]+(a[0]&255))>>>0)>>>0)+1>>>0;a[2]=(A[(a[2]^a[1]>>>24)&255]^a[2]>>>8)>>>0};V.prototype.T=function(a){var b=[305419896,591751049,878082192],c,d;w&&(b=new Uint32Array(b));c=0;for(d=a.length;c<d;++c)this.k(b,a[c]&255);return b};function W(a,b){b=b||{};this.input=w&&a instanceof Array?new Uint8Array(a):a;this.c=0;this.ba=b.verify||!1;this.j=b.password}var na={O:0,M:8},X=[80,75,1,2],Y=[80,75,3,4],Z=[80,75,5,6];function oa(a,b){this.input=a;this.offset=b}
oa.prototype.parse=function(){var a=this.input,b=this.offset;(a[b++]!==X[0]||a[b++]!==X[1]||a[b++]!==X[2]||a[b++]!==X[3])&&m(Error("invalid file header signature"));this.version=a[b++];this.ia=a[b++];this.Z=a[b++]|a[b++]<<8;this.I=a[b++]|a[b++]<<8;this.A=a[b++]|a[b++]<<8;this.time=a[b++]|a[b++]<<8;this.U=a[b++]|a[b++]<<8;this.p=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.z=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.J=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.h=a[b++]|a[b++]<<
8;this.g=a[b++]|a[b++]<<8;this.F=a[b++]|a[b++]<<8;this.ea=a[b++]|a[b++]<<8;this.ga=a[b++]|a[b++]<<8;this.fa=a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24;this.$=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.filename=String.fromCharCode.apply(null,w?a.subarray(b,b+=this.h):a.slice(b,b+=this.h));this.X=w?a.subarray(b,b+=this.g):a.slice(b,b+=this.g);this.v=w?a.subarray(b,b+this.F):a.slice(b,b+this.F);this.length=b-this.offset};function pa(a,b){this.input=a;this.offset=b}var qa={N:1,ca:8,da:2048};
pa.prototype.parse=function(){var a=this.input,b=this.offset;(a[b++]!==Y[0]||a[b++]!==Y[1]||a[b++]!==Y[2]||a[b++]!==Y[3])&&m(Error("invalid local file header signature"));this.Z=a[b++]|a[b++]<<8;this.I=a[b++]|a[b++]<<8;this.A=a[b++]|a[b++]<<8;this.time=a[b++]|a[b++]<<8;this.U=a[b++]|a[b++]<<8;this.p=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.z=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.J=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.h=a[b++]|a[b++]<<8;this.g=a[b++]|a[b++]<<8;this.filename=
String.fromCharCode.apply(null,w?a.subarray(b,b+=this.h):a.slice(b,b+=this.h));this.X=w?a.subarray(b,b+=this.g):a.slice(b,b+=this.g);this.length=b-this.offset};
function $(a){var b=[],c={},d,g,f,h;if(!a.i){if(a.o===p){var e=a.input,k;if(!a.D)a:{var l=a.input,q;for(q=l.length-12;0<q;--q)if(l[q]===Z[0]&&l[q+1]===Z[1]&&l[q+2]===Z[2]&&l[q+3]===Z[3]){a.D=q;break a}m(Error("End of Central Directory Record not found"))}k=a.D;(e[k++]!==Z[0]||e[k++]!==Z[1]||e[k++]!==Z[2]||e[k++]!==Z[3])&&m(Error("invalid signature"));a.ha=e[k++]|e[k++]<<8;a.ja=e[k++]|e[k++]<<8;a.ka=e[k++]|e[k++]<<8;a.aa=e[k++]|e[k++]<<8;a.Q=(e[k++]|e[k++]<<8|e[k++]<<16|e[k++]<<24)>>>0;a.o=(e[k++]|
e[k++]<<8|e[k++]<<16|e[k++]<<24)>>>0;a.w=e[k++]|e[k++]<<8;a.v=w?e.subarray(k,k+a.w):e.slice(k,k+a.w)}d=a.o;f=0;for(h=a.aa;f<h;++f)g=new oa(a.input,d),g.parse(),d+=g.length,b[f]=g,c[g.filename]=f;a.Q<d-a.o&&m(Error("invalid file header size"));a.i=b;a.G=c}}t=W.prototype;t.Y=function(){var a=[],b,c,d;this.i||$(this);d=this.i;b=0;for(c=d.length;b<c;++b)a[b]=d[b].filename;return a};
t.r=function(a,b){var c;this.G||$(this);c=this.G[a];c===p&&m(Error(a+" not found"));var d;d=b||{};var g=this.input,f=this.i,h,e,k,l,q,s,r,M;f||$(this);f[c]===p&&m(Error("wrong index"));e=f[c].$;h=new pa(this.input,e);h.parse();e+=h.length;k=h.z;if(0!==(h.I&qa.N)){!d.password&&!this.j&&m(Error("please set password"));s=this.S(d.password||this.j);r=e;for(M=e+12;r<M;++r)ra(this,s,g[r]);e+=12;k-=12;r=e;for(M=e+k;r<M;++r)g[r]=ra(this,s,g[r])}switch(h.A){case na.O:l=w?this.input.subarray(e,e+k):this.input.slice(e,
e+k);break;case na.M:l=(new E(this.input,{index:e,bufferSize:h.J})).r();break;default:m(Error("unknown compression type"))}if(this.ba){var u=p,n,N="number"===typeof u?u:u=0,ka=l.length;n=-1;for(N=ka&7;N--;++u)n=n>>>8^A[(n^l[u])&255];for(N=ka>>3;N--;u+=8)n=n>>>8^A[(n^l[u])&255],n=n>>>8^A[(n^l[u+1])&255],n=n>>>8^A[(n^l[u+2])&255],n=n>>>8^A[(n^l[u+3])&255],n=n>>>8^A[(n^l[u+4])&255],n=n>>>8^A[(n^l[u+5])&255],n=n>>>8^A[(n^l[u+6])&255],n=n>>>8^A[(n^l[u+7])&255];q=(n^4294967295)>>>0;h.p!==q&&m(Error("wrong crc: file=0x"+
h.p.toString(16)+", data=0x"+q.toString(16)))}return l};t.L=function(a){this.j=a};function ra(a,b,c){c^=a.s(b);a.k(b,c);return c}t.k=V.prototype.k;t.S=V.prototype.T;t.s=V.prototype.s;v("Zlib.Unzip",W);v("Zlib.Unzip.prototype.decompress",W.prototype.r);v("Zlib.Unzip.prototype.getFilenames",W.prototype.Y);v("Zlib.Unzip.prototype.setPassword",W.prototype.L);}).call(this);
;
/** @license zlib.js 2012 - imaya [ https://github.com/imaya/zlib.js ] The MIT License */(function() {'use strict';function m(b){throw b;}var n=void 0,r=this;function s(b,d){var a=b.split("."),c=r;!(a[0]in c)&&c.execScript&&c.execScript("var "+a[0]);for(var f;a.length&&(f=a.shift());)!a.length&&d!==n?c[f]=d:c=c[f]?c[f]:c[f]={}};var u="undefined"!==typeof Uint8Array&&"undefined"!==typeof Uint16Array&&"undefined"!==typeof Uint32Array;function v(b){var d=b.length,a=0,c=Number.POSITIVE_INFINITY,f,e,g,h,k,l,q,p,t;for(p=0;p<d;++p)b[p]>a&&(a=b[p]),b[p]<c&&(c=b[p]);f=1<<a;e=new (u?Uint32Array:Array)(f);g=1;h=0;for(k=2;g<=a;){for(p=0;p<d;++p)if(b[p]===g){l=0;q=h;for(t=0;t<g;++t)l=l<<1|q&1,q>>=1;for(t=l;t<f;t+=k)e[t]=g<<16|p;++h}++g;h<<=1;k<<=1}return[e,a,c]};function w(b,d){this.g=[];this.h=32768;this.d=this.f=this.a=this.l=0;this.input=u?new Uint8Array(b):b;this.m=!1;this.i=x;this.r=!1;if(d||!(d={}))d.index&&(this.a=d.index),d.bufferSize&&(this.h=d.bufferSize),d.bufferType&&(this.i=d.bufferType),d.resize&&(this.r=d.resize);switch(this.i){case y:this.b=32768;this.c=new (u?Uint8Array:Array)(32768+this.h+258);break;case x:this.b=0;this.c=new (u?Uint8Array:Array)(this.h);this.e=this.z;this.n=this.v;this.j=this.w;break;default:m(Error("invalid inflate mode"))}}
var y=0,x=1,z={t:y,s:x};
w.prototype.k=function(){for(;!this.m;){var b=A(this,3);b&1&&(this.m=!0);b>>>=1;switch(b){case 0:var d=this.input,a=this.a,c=this.c,f=this.b,e=n,g=n,h=n,k=c.length,l=n;this.d=this.f=0;e=d[a++];e===n&&m(Error("invalid uncompressed block header: LEN (first byte)"));g=e;e=d[a++];e===n&&m(Error("invalid uncompressed block header: LEN (second byte)"));g|=e<<8;e=d[a++];e===n&&m(Error("invalid uncompressed block header: NLEN (first byte)"));h=e;e=d[a++];e===n&&m(Error("invalid uncompressed block header: NLEN (second byte)"));h|=
e<<8;g===~h&&m(Error("invalid uncompressed block header: length verify"));a+g>d.length&&m(Error("input buffer is broken"));switch(this.i){case y:for(;f+g>c.length;){l=k-f;g-=l;if(u)c.set(d.subarray(a,a+l),f),f+=l,a+=l;else for(;l--;)c[f++]=d[a++];this.b=f;c=this.e();f=this.b}break;case x:for(;f+g>c.length;)c=this.e({p:2});break;default:m(Error("invalid inflate mode"))}if(u)c.set(d.subarray(a,a+g),f),f+=g,a+=g;else for(;g--;)c[f++]=d[a++];this.a=a;this.b=f;this.c=c;break;case 1:this.j(B,C);break;case 2:aa(this);
break;default:m(Error("unknown BTYPE: "+b))}}return this.n()};
var D=[16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15],E=u?new Uint16Array(D):D,F=[3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,258,258],G=u?new Uint16Array(F):F,H=[0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0,0,0],I=u?new Uint8Array(H):H,J=[1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577],K=u?new Uint16Array(J):J,L=[0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,
13],M=u?new Uint8Array(L):L,N=new (u?Uint8Array:Array)(288),O,P;O=0;for(P=N.length;O<P;++O)N[O]=143>=O?8:255>=O?9:279>=O?7:8;var B=v(N),Q=new (u?Uint8Array:Array)(30),R,S;R=0;for(S=Q.length;R<S;++R)Q[R]=5;var C=v(Q);function A(b,d){for(var a=b.f,c=b.d,f=b.input,e=b.a,g;c<d;)g=f[e++],g===n&&m(Error("input buffer is broken")),a|=g<<c,c+=8;g=a&(1<<d)-1;b.f=a>>>d;b.d=c-d;b.a=e;return g}
function T(b,d){for(var a=b.f,c=b.d,f=b.input,e=b.a,g=d[0],h=d[1],k,l,q;c<h;){k=f[e++];if(k===n)break;a|=k<<c;c+=8}l=g[a&(1<<h)-1];q=l>>>16;b.f=a>>q;b.d=c-q;b.a=e;return l&65535}
function aa(b){function d(a,b,c){var d,e,f,g;for(g=0;g<a;)switch(d=T(this,b),d){case 16:for(f=3+A(this,2);f--;)c[g++]=e;break;case 17:for(f=3+A(this,3);f--;)c[g++]=0;e=0;break;case 18:for(f=11+A(this,7);f--;)c[g++]=0;e=0;break;default:e=c[g++]=d}return c}var a=A(b,5)+257,c=A(b,5)+1,f=A(b,4)+4,e=new (u?Uint8Array:Array)(E.length),g,h,k,l;for(l=0;l<f;++l)e[E[l]]=A(b,3);g=v(e);h=new (u?Uint8Array:Array)(a);k=new (u?Uint8Array:Array)(c);b.j(v(d.call(b,a,g,h)),v(d.call(b,c,g,k)))}
w.prototype.j=function(b,d){var a=this.c,c=this.b;this.o=b;for(var f=a.length-258,e,g,h,k;256!==(e=T(this,b));)if(256>e)c>=f&&(this.b=c,a=this.e(),c=this.b),a[c++]=e;else{g=e-257;k=G[g];0<I[g]&&(k+=A(this,I[g]));e=T(this,d);h=K[e];0<M[e]&&(h+=A(this,M[e]));c>=f&&(this.b=c,a=this.e(),c=this.b);for(;k--;)a[c]=a[c++-h]}for(;8<=this.d;)this.d-=8,this.a--;this.b=c};
w.prototype.w=function(b,d){var a=this.c,c=this.b;this.o=b;for(var f=a.length,e,g,h,k;256!==(e=T(this,b));)if(256>e)c>=f&&(a=this.e(),f=a.length),a[c++]=e;else{g=e-257;k=G[g];0<I[g]&&(k+=A(this,I[g]));e=T(this,d);h=K[e];0<M[e]&&(h+=A(this,M[e]));c+k>f&&(a=this.e(),f=a.length);for(;k--;)a[c]=a[c++-h]}for(;8<=this.d;)this.d-=8,this.a--;this.b=c};
w.prototype.e=function(){var b=new (u?Uint8Array:Array)(this.b-32768),d=this.b-32768,a,c,f=this.c;if(u)b.set(f.subarray(32768,b.length));else{a=0;for(c=b.length;a<c;++a)b[a]=f[a+32768]}this.g.push(b);this.l+=b.length;if(u)f.set(f.subarray(d,d+32768));else for(a=0;32768>a;++a)f[a]=f[d+a];this.b=32768;return f};
w.prototype.z=function(b){var d,a=this.input.length/this.a+1|0,c,f,e,g=this.input,h=this.c;b&&("number"===typeof b.p&&(a=b.p),"number"===typeof b.u&&(a+=b.u));2>a?(c=(g.length-this.a)/this.o[2],e=258*(c/2)|0,f=e<h.length?h.length+e:h.length<<1):f=h.length*a;u?(d=new Uint8Array(f),d.set(h)):d=h;return this.c=d};
w.prototype.n=function(){var b=0,d=this.c,a=this.g,c,f=new (u?Uint8Array:Array)(this.l+(this.b-32768)),e,g,h,k;if(0===a.length)return u?this.c.subarray(32768,this.b):this.c.slice(32768,this.b);e=0;for(g=a.length;e<g;++e){c=a[e];h=0;for(k=c.length;h<k;++h)f[b++]=c[h]}e=32768;for(g=this.b;e<g;++e)f[b++]=d[e];this.g=[];return this.buffer=f};
w.prototype.v=function(){var b,d=this.b;u?this.r?(b=new Uint8Array(d),b.set(this.c.subarray(0,d))):b=this.c.subarray(0,d):(this.c.length>d&&(this.c.length=d),b=this.c);return this.buffer=b};function U(b,d){var a,c;this.input=b;this.a=0;if(d||!(d={}))d.index&&(this.a=d.index),d.verify&&(this.A=d.verify);a=b[this.a++];c=b[this.a++];switch(a&15){case V:this.method=V;break;default:m(Error("unsupported compression method"))}0!==((a<<8)+c)%31&&m(Error("invalid fcheck flag:"+((a<<8)+c)%31));c&32&&m(Error("fdict flag is not supported"));this.q=new w(b,{index:this.a,bufferSize:d.bufferSize,bufferType:d.bufferType,resize:d.resize})}
U.prototype.k=function(){var b=this.input,d,a;d=this.q.k();this.a=this.q.a;if(this.A){a=(b[this.a++]<<24|b[this.a++]<<16|b[this.a++]<<8|b[this.a++])>>>0;var c=d;if("string"===typeof c){var f=c.split(""),e,g;e=0;for(g=f.length;e<g;e++)f[e]=(f[e].charCodeAt(0)&255)>>>0;c=f}for(var h=1,k=0,l=c.length,q,p=0;0<l;){q=1024<l?1024:l;l-=q;do h+=c[p++],k+=h;while(--q);h%=65521;k%=65521}a!==(k<<16|h)>>>0&&m(Error("invalid adler-32 checksum"))}return d};var V=8;s("Zlib.Inflate",U);s("Zlib.Inflate.prototype.decompress",U.prototype.k);var W={ADAPTIVE:z.s,BLOCK:z.t},X,Y,Z,$;if(Object.keys)X=Object.keys(W);else for(Y in X=[],Z=0,W)X[Z++]=Y;Z=0;for($=X.length;Z<$;++Z)Y=X[Z],s("Zlib.Inflate.BufferType."+Y,W[Y]);}).call(this);
;
global.Autodesk = {
   Viewing: { isNodeJS: true },
   LMVTK: { isNodeJS: true }
};
var Zlib = exports.Zlib;
function getGlobal() {
    return (typeof window !== "undefined" && window !== null)
            ? window
            : (typeof self !== "undefined" && self !== null)
                ? self
                : global;
}

/**
 * Create namespace
 * @param {string} s - namespace (e.g. 'Autodesk.Viewing')
 * @return {Object} namespace
 */
var AutodeskNamespace = function (s) {
    var ns = getGlobal();

    var parts = s.split('.');
    for (var i = 0; i < parts.length; ++i) {
        ns[parts[i]] = ns[parts[i]] || {};
        ns = ns[parts[i]];
    }

    return ns;
};

// Define the most often used ones
AutodeskNamespace("Autodesk.Viewing.Private");

AutodeskNamespace("Autodesk.Viewing.Extensions");

AutodeskNamespace("Autodesk.Viewing.Shaders");

AutodeskNamespace('Autodesk.Viewing.UI');

AutodeskNamespace('Autodesk.LMVTK');

Autodesk.Viewing.getGlobal = getGlobal;
Autodesk.Viewing.AutodeskNamespace = AutodeskNamespace;
;
// Map wgs.js symbols back to Autodesk namespaces for backwards compatibility.
// If the worker parameter is true, only worker-specific symbols are mapped.
Autodesk.Viewing.Private.initializeLegacyNamespaces = function(worker) {
    var av = Autodesk.Viewing;
    var avs = av.Shaders;
    var avp = av.Private;

    avp.InstanceTreeStorage = WGS.InstanceTreeStorage;
	avp.InstanceTreeAccess = WGS.InstanceTreeAccess;
    avp.BVHBuilder = WGS.BVHBuilder;
    avp.NodeArray = WGS.NodeArray;

    if (worker)
        return;

    avs.PackDepthShaderChunk = WGS.PackDepthShaderChunk;
    avs.TonemapShaderChunk = WGS.TonemapShaderChunk;
    avs.OrderedDitheringShaderChunk = WGS.OrderedDitheringShaderChunk;
    avs.CutPlanesUniforms = WGS.CutPlanesUniforms;
    avs.CutPlanesShaderChunk = WGS.CutPlanesShaderChunk;
    avs.PackNormalsShaderChunk = WGS.PackNormalsShaderChunk;
    avs.HatchPatternShaderChunk = WGS.HatchPatternShaderChunk;
    avs.EnvSamplingShaderChunk = WGS.EnvSamplingShaderChunk;
    avs.IdUniforms = WGS.IdUniforms;
    avs.IdFragmentDeclaration = WGS.IdFragmentDeclaration;
    avs.IdOutputShaderChunk = WGS.IdOutputShaderChunk;
    avs.FinalOutputShaderChunk = WGS.FinalOutputShaderChunk;
    avs.ThemingUniform = WGS.ThemingUniform;
    avs.ThemingFragmentDeclaration = WGS.ThemingFragmentDeclaration;
    avs.ThemingFragmentShaderChunk = WGS.ThemingFragmentShaderChunk;

    avs.BackgroundShader = WGS.BackgroundShader;

    avs.BlendShader = WGS.BlendShader;

    avs.CelShader = WGS.CelShader;

    avs.CopyShader = WGS.CopyShader;

    avs.FXAAShader = WGS.FXAAShader;

    avs.SAOBlurShader = WGS.SAOBlurShader;

    avs.SAOMinifyFirstShader = WGS.SAOMinifyFirstShader;
    avs.SAOMinifyShader = WGS.SAOMinifyShader;

    avs.SAOShader = WGS.SAOShader;

    avs.NormalsShader = WGS.NormalsShader;

    avs.LineShader = WGS.LineShader;

    avp.LineStyleDefs = WGS.LineStyleDefs;
    avp.CreateLinePatternTexture = WGS.CreateLinePatternTexture;

    avp.FloatToHalf = WGS.FloatToHalf;
    avp.HalfToFloat = WGS.HalfToFloat;
    avp.IntToHalf = WGS.IntToHalf;
    avp.HalfToInt = WGS.HalfToInt;
    avp.HalfTest = WGS.HalfTest;

    avs.createShaderMaterial = WGS.createShaderMaterial;
    avs.setMacro = WGS.setMacro;
    avs.removeMacro = WGS.removeMacro;

    avs.LmvShaderPass = WGS.ShaderPass;

    avs.GaussianPass = WGS.GaussianPass;

    avs.GroundShadow = WGS.GroundShadow;
    avs.createGroundShape = WGS.createGroundShape;
    avs.setGroundShapeTransform = WGS.setGroundShapeTransform;

    avs.GroundReflection = WGS.GroundReflection;

    avp.FireflyWebGLShader = WGS.WebGLShader;

    avp.PrismMaps = WGS.PrismMaps;
    avp.GetPrismMapChunk = WGS.GetPrismMapChunk;
    avp.FireflyWebGLProgram = WGS.WebGLProgram;

    avs.ShadowMapCommonUniforms = WGS.ShadowMapCommonUniforms;
    avs.ShadowMapUniforms = WGS.ShadowMapUniforms;
    avs.ShadowMapDeclareCommonUniforms = WGS.ShadowMapDeclareCommonUniforms;
    avs.ShadowMapVertexDeclaration = WGS.ShadowMapVertexDeclaration;
    avs.ShadowMapVertexShaderChunk = WGS.ShadowMapVertexShaderChunk;
    avs.ShadowMapFragmentDeclaration = WGS.ShadowMapFragmentDeclaration;

    avs.FireflyPhongShader = WGS.PhongShader;

    avs.PrismShader = WGS.PrismShader;
    avs.GetPrismMapUniforms = WGS.GetPrismMapUniforms;
    avs.GetPrismMapSampleChunk = WGS.GetPrismMapSampleChunk;
    avs.GetPrismMapUniformChunk = WGS.GetPrismMapUniformChunk;
    avs.AverageOfFloat3 = WGS.AverageOfFloat3;
    avp.createPrismMaterial = WGS.createPrismMaterial;
    avp.clonePrismMaterial = WGS.clonePrismMaterial;

    avp.ShadowMapShader = WGS.ShadowMapShader;
    avp.GroundShadowShader = WGS.GroundShadowShader;
    avp.ShadowMapOverrideMaterials = WGS.ShadowMapOverrideMaterials;
    avp.SHADOWMAP_NEEDS_UPDATE = WGS.SHADOWMAP_NEEDS_UPDATE;
    avp.SHADOWMAP_INCOMPLETE = WGS.SHADOWMAP_INCOMPLETE;
    avp.SHADOWMAP_VALID = WGS.SHADOWMAP_VALID;
    avp.ShadowConfig = WGS.ShadowConfig;
    avp.ShadowRender = WGS.ShadowRender;
    avp.ShadowMaps = WGS.ShadowMaps;

    avp.FrustumIntersector = WGS.FrustumIntersector;
    avp.OUTSIDE = WGS.OUTSIDE;
    avp.INTERSECTS = WGS.INTERSECTS;
    avp.CONTAINS = WGS.CONTAINS;

    avp.VBIntersector = WGS.VBIntersector;

    avp.memoryOptimizedLoading = WGS.memoryOptimizedLoading;
    avp.GPU_MEMORY_LIMIT = WGS.GPU_MEMORY_LIMIT;
    avp.GPU_OBJECT_LIMIT = WGS.GPU_OBJECT_LIMIT;
    avp.FRAGS_PERSISTENT_COUNT = WGS.FRAGS_PERSISTENT_COUNT;
    avp.FRAGS_PERSISTENT_MAX_COUNT = WGS.FRAGS_PERSISTENT_MAX_COUNT;
    avp.MAX_2D_PERSISTENT_BUFFER_COUNT = WGS.MAX_2D_PERSISTENT_BUFFER_COUNT;
    avp.PAGE_OUT_COUNT_2D = WGS.PAGE_OUT_COUNT_2D;
    avp.PAGE_OUT_GOAL_2D = WGS.PAGE_OUT_GOAL_2D;
    avp.GEOMS_COUNT_LIMIT = WGS.GEOMS_COUNT_LIMIT;
    avp.onDemandLoading = WGS.onDemandLoading;
    avp.cullGeometryOnLoading = WGS.cullGeometryOnLoading;
    avp.pageOutGeometryEnabled = WGS.pageOutGeometryEnabled;
    avp.PAGEOUT_SUCCESS = WGS.PAGEOUT_SUCCESS;
    avp.PAGEOUT_FAIL = WGS.PAGEOUT_FAIL;
    avp.PAGEOUT_NONE = WGS.PAGEOUT_NONE;
    avp.PAGEOUT_PERCENTAGE = WGS.PAGEOUT_PERCENTAGE;
    avp.GEOMS_PAGEOUT_COUNT = WGS.GEOMS_PAGEOUT_COUNT;

    avp.GeometryList = WGS.GeometryList;

    avp.MESH_VISIBLE = WGS.MESH_VISIBLE;
    avp.MESH_HIGHLIGHTED = WGS.MESH_HIGHLIGHTED;
    avp.MESH_HIDE = WGS.MESH_HIDE;
    avp.MESH_ISLINE = WGS.MESH_ISLINE;
    avp.MESH_ISPOINT = WGS.MESH_ISPOINT;
    avp.MESH_MOVED = WGS.MESH_MOVED;
    avp.MESH_TRAVERSED = WGS.MESH_TRAVERSED;
    avp.MESH_DRAWN = WGS.MESH_DRAWN;
    avp.MESH_RENDERFLAG = WGS.MESH_RENDERFLAG;
    avp.FragmentPointer = WGS.FragmentPointer;
    avp.FragmentList = WGS.FragmentList;

    avp.RENDER_NORMAL = WGS.RENDER_NORMAL;
    avp.RENDER_HIGHLIGHTED = WGS.RENDER_HIGHLIGHTED;
    avp.RENDER_HIDDEN = WGS.RENDER_HIDDEN;
    avp.RENDER_SHADOWMAP = WGS.RENDER_SHADOWMAP;
    avp.RENDER_FINISHED = WGS.RENDER_FINISHED;

    avp.RenderBatch = WGS.RenderBatch;

    av.rescueFromPolymer = WGS.rescueFromPolymer;

    avp.FireflyWebGLRenderer = WGS.WebGLRenderer;

    avp.ModelIteratorLinear = WGS.ModelIteratorLinear;
    avp.ModelIteratorBVH = WGS.ModelIteratorBVH;

    avp.BufferGeometryUtils = WGS.BufferGeometry;

    avp.RenderScene = WGS.RenderScene;

    avp.SortedList = WGS.SortedList;

    avp.ModelIteratorTexQuad = WGS.ModelIteratorTexQuad;
    avp.TexQuadConfig = WGS.TexQuadConfig;

    avp.InstanceTree = WGS.InstanceTree;
    av.SelectionMode = WGS.SelectionMode;

    avp.MaterialConverter = WGS.MaterialConverter;
};
;

function getGlobal() {
    return (typeof window !== "undefined" && window !== null)
            ? window
            : (typeof self !== "undefined" && self !== null)
                ? self
                : global;
}

var av = Autodesk.Viewing,
    avp = av.Private;

av.getGlobal = getGlobal;

var isBrowser = av.isBrowser = (typeof navigator !== "undefined");

var isIE11 = av.isIE11 = isBrowser && !!navigator.userAgent.match(/Trident\/7\./);

// fix IE events
if(typeof window !== "undefined" && isIE11){
    (function () {
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: undefined };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        };

        CustomEvent.prototype = window.CustomEvent.prototype;

        window.CustomEvent = CustomEvent;
    })();
}

// IE does not implement ArrayBuffer slice. Handy!
if (!ArrayBuffer.prototype.slice) {
    ArrayBuffer.prototype.slice = function(start, end) {
        // Normalize start/end values
        if (!end || end > this.byteLength) {
            end = this.byteLength;
        }
        else if (end < 0) {
            end = this.byteLength + end;
            if (end < 0) end = 0;
        }
        if (start < 0) {
            start = this.byteLength + start;
            if (start < 0) start = 0;
        }

        if (end <= start) {
            return new ArrayBuffer();
        }

        // Bytewise copy- this will not be fast, but what choice do we have?
        var len = end - start;
        var view = new Uint8Array(this, start, len);
        var out = new Uint8Array(len);
        for (var i = 0; i < len; i++) {
            out[i] = view[i];
        }
        return out.buffer;
    }
}

// IE doesn't implement Math.log2
(function(){
    Math.log2 = Math.log2 || function(x) {
        return Math.log(x) / Math.LN2;
    };
})();

//The BlobBuilder object
if (typeof window !== "undefined")
    window.BlobBuilder = window.BlobBuilder || window.WebKitBlobBuilder || window.MozBlobBuilder || window.MSBlobBuilder;


// Launch full screen on the given element with the available method
var launchFullscreen = av.launchFullscreen = function(element, options) {
    if (element.requestFullscreen) {
        element.requestFullscreen(options);
    } else if (element.mozRequestFullScreen) {
        element.mozRequestFullScreen(options);
    } else if (element.webkitRequestFullscreen) {
        element.webkitRequestFullscreen(options);
    } else if (element.msRequestFullscreen) {
        element.msRequestFullscreen(options);
    }
}

// Exit full screen with the available method
var exitFullscreen = av.exitFullscreen = function() {
    if (document.exitFullscreen) {
        document.exitFullscreen();
    } else if (document.mozCancelFullScreen) {
        document.mozCancelFullScreen();
    } else if (document.webkitExitFullscreen) {
        document.webkitExitFullscreen();
    } else if (document.msExitFullscreen) {
        document.msExitFullscreen();
    }
}

// Determines if the browser is in full screen
var inFullscreen = av.inFullscreen = function(){

    // Special case for Ms-Edge that has webkitIsFullScreen with correct value
    // and fullscreenEnabled with wrong value (thanks MS)
    if ("webkitIsFullScreen" in document) return document.webkitIsFullScreen;
    return !!(document.mozFullScreenElement ||
        document.msFullscreenElement ||
        document.fullscreenElement ||
        document.querySelector(".viewer-fill-browser")); // Fallback for iPad
}

var fullscreenElement = av.fullscreenElement = function() {
    return document.fullscreenElement || document.mozFullScreenElement || document.webkitFullscreenElement || document.msFullscreenElement;
}

var isFullscreenAvailable = av.isFullscreenAvailable = function(element) {
    return element.requestFullscreen || element.mozRequestFullScreen || element.webkitRequestFullscreen || element.msRequestFullscreen;
}

// Get the version of the android device through user agent.
// Return the version string of android device, e.g. 4.4, 5.0...
var getAndroidVersion = av.getAndroidVersion = function(ua) {
    var ua = ua || navigator.userAgent;
    var match = ua.match(/Android\s([0-9\.]*)/);
    return match ? match[1] : false;
};

// Determine if this is a touch or notouch device.
var isTouchDevice = av.isTouchDevice = function() {
    /*
    // Temporarily disable touch support through hammer on Android 5, to debug
    // some specific gesture issue with Chromium WebView when loading viewer3D.js.
    if (parseInt(getAndroidVersion()) == 5) {
        return false;
    }
    */

    return (typeof window !== "undefined" &&  "ontouchstart" in window);
}

av.isIOSDevice = function() {
    if (!isBrowser) return false;
    return /ip(ad|hone|od)/.test(navigator.userAgent.toLowerCase());
};

av.isAndroidDevice = function() {
    if (!isBrowser) return false;
    return (navigator.userAgent.toLowerCase().indexOf('android') !== -1);
};

av.isMobileDevice = function() {
    if (!isBrowser) return false;
    return av.isIOSDevice() || av.isAndroidDevice();
};

av.isSafari = function() {
    if (!isBrowser) return false;
    var _ua = navigator.userAgent.toLowerCase();
    return (_ua.indexOf("safari") !== -1) && (_ua.indexOf("chrome") === -1);
};

av.isFirefox = function() {
    if (!isBrowser) return false;
    var _ua = navigator.userAgent.toLowerCase();
    return (_ua.indexOf("firefox") !== -1);
};

av.isMac = function() {
    if (!isBrowser) return false;
    var _ua = navigator.userAgent.toLowerCase();
    return  (_ua.indexOf("mac os") !== -1);
};

av.isWindows = function() {
    if (!isBrowser) return false;
    var _ua = navigator.userAgent.toLowerCase();
    return  (_ua.indexOf("win32") !== -1 || _ua.indexOf("windows") !== -1);
};

/**
 * Detects if WebGL is enabled.
 *
 * @return { number } -1 for not Supported,
 *                    0 for disabled
 *                    1 for enabled
 */
var detectWebGL = av.detectWebGL = function()
{
    // Check for the webgl rendering context
    if ( !! window.WebGLRenderingContext) {
        var canvas = document.createElement("canvas"),
            names = ["webgl", "experimental-webgl", "moz-webgl", "webkit-3d"],
            context = false;

        for (var i = 0; i < 4; i++) {
            try {
                context = canvas.getContext(names[i]);
                context = rescueFromPolymer(context);
                if (context && typeof context.getParameter === "function") {
                    // WebGL is enabled.
                    //
                    return 1;
                }
            } catch (e) {}
        }

        // WebGL is supported, but disabled.
        //
        return 0;
    }

    // WebGL not supported.
    //
    return -1;
};


// Convert touchstart event to click to remove the delay between the touch and
// the click event which is sent after touchstart with about 300ms deley.
// Should be used in UI elements on touch devices.
var touchStartToClick = av.touchStartToClick = function(e) {
    e.preventDefault();  // Stops the firing of delayed click event.
    e.stopPropagation();
    e.target.click();    // Maps to immediate click.
};

//Safari doesn't have the Performance object
//We only need the now() function, so that's easy to emulate.
(function() {
    var global = getGlobal();
    if (!global.performance)
        global.performance = Date;
})();

// Polyfill for IE and Safari
// https://developer.mozilla.org/de/docs/Web/JavaScript/Reference/Global_Objects/Number/isInteger
Number.isInteger = Number.isInteger || function(value) {
    return typeof value === "number" &&
        isFinite(value) &&
        Math.floor(value) === value;
};

// Polyfill for IE
String.prototype.repeat = String.prototype.repeat || function(count) {
    if (count < 1) return '';
    var result = '', pattern = this.valueOf();
    while (count > 1) {
        if (count & 1) result += pattern;
        count >>= 1, pattern += pattern;
    }
    return result + pattern;
};
;

//This file is the first one when creating minified build
//and is used to set certain flags that are needed
//for the concatenated build.

var av = Autodesk.Viewing;
var avp = Autodesk.Viewing.Private;

//avp.IS_CONCAT_BUILD = true; // Debugging source files without concatenation is no longer supported

/** @define {string} */
avp.BUILD_LMV_WORKER_URL = "lmvworker.js";
avp.LMV_WORKER_URL = avp.BUILD_LMV_WORKER_URL;

avp.ENABLE_DEBUG = avp.ENABLE_DEBUG || false;
avp.ENABLE_TRACE = avp.ENABLE_TRACE || false;
//avp.DEBUG_SHADERS = avp.DEBUG_SHADERS || false; // will be moved to wgs.js
avp.ENABLE_INLINE_WORKER = true;
;

var av = Autodesk.Viewing;

/**
 * Error code constants
 *
 * These constants will be used in `onErrorCallback` functions.
 *
 * @enum {number}
 * @readonly
 * @alias Autodesk.Viewing.ErrorCodes
 * @category Core
 */
av.ErrorCodes = {
    /** An unknown failure has occurred. */
    UNKNOWN_FAILURE: 1,

    /** Bad data (corrupted or malformed) was encountered. */
    BAD_DATA: 2,

    /** A network failure was encountered. */
    NETWORK_FAILURE: 3,

    /** Access was denied to a network resource (HTTP 403) */
    NETWORK_ACCESS_DENIED: 4,

    /** A network resource could not be found (HTTP 404) */
    NETWORK_FILE_NOT_FOUND: 5,

    /** A server error was returned when accessing a network resource (HTTP 5xx) */
    NETWORK_SERVER_ERROR: 6,

    /** An unhandled response code was returned when accessing a network resource (HTTP 'everything else') */
    NETWORK_UNHANDLED_RESPONSE_CODE: 7,

    /** Browser error: webGL is not supported by the current browser */
    BROWSER_WEBGL_NOT_SUPPORTED: 8,

    /** There is nothing viewable in the fetched document */
    BAD_DATA_NO_VIEWABLE_CONTENT: 9,

    /** Browser error: webGL is supported, but not enabled */
    BROWSER_WEBGL_DISABLED: 10,

    /** There is no geomtry in loaded model */
    BAD_DATA_MODEL_IS_EMPTY: 11,

    /** Collaboration server error */
    RTC_ERROR: 12,

    /** The extension of the loaded file is not supported */
    UNSUPORTED_FILE_EXTENSION: 13

};
;

(function() {

"use strict";

var av = Autodesk.Viewing;
var avp = Autodesk.Viewing.Private;

/**
 * Logging levels. Higher number means more verbose logs,
 * for example, with level 3, `info`, `warn`, or `error`
 * logs will show up in the console but `debug` and `log` won't.
 *
 * Semantics of specific levels:
 *  - debug: low-level debugging logs
 *  - log: common, higher-level debugging logs
 *  - info: helpful runtime information (even for stag/prod environments)
 *  - warn: potentially problematic situations; handled exceptions
 *  - error: definitely problematic situations; unhandled exceptions
 * @readonly
 * @enum {number}
 */
avp.LogLevels = {
    DEBUG: 5,
    LOG: 4,
    INFO: 3,
    WARNING: 2,
    ERROR: 1,
    NONE: 0
};

function Logger() {
    this.adp = null;
    this.runtimeStats = {};
    this.level = -1;
    this.setLevel(avp.ENABLE_TRACE ? avp.LogLevels.DEBUG : avp.LogLevels.ERROR);
}

Logger.prototype.initialize = function(options) {

    if (options.eventCallback)
        this.callback = options.eventCallback;

    this.sessionId = options.sessionId;
    if (!this.sessionId) {
        var now = Date.now() + "";
        this.sessionId = parseFloat(((Math.random() * 10000) | 0) + "" + now.substring(4));
    }

    this.environmentInfo = {
        touch: av.isTouchDevice(),
        env: avp.env,
        referer: getReferer(),
        version: LMV_VIEWER_VERSION,
        patch: LMV_VIEWER_PATCH,
        build_type: LMV_BUILD_TYPE
    };

    //Kick off with a viewer start event
    var startEvent = {
        category: "viewer_start",
        touch: this.environmentInfo.touch,
        env: this.environmentInfo.env,
        referer: this.environmentInfo.referer,
        version: this.environmentInfo.version,
        patch: this.environmentInfo.patch,
        build_type: this.environmentInfo.build_type
    };
    this.track(startEvent);

    var _this = this;
    this.interval = setInterval(function() {
        _this.reportRuntimeStats();
    }, 60000);
};

Logger.prototype.shutdown = function() {
    clearInterval(this.interval);
    this.interval = undefined;
};

Logger.prototype.track = function (entry) {
    this.updateRuntimeStats(entry);

    if (avp.offline || !this.sessionId) {
        return;
    }

    entry.timestamp = Date.now();
    entry.sessionId = this.sessionId;

    var sent = this.logToADP(entry);

    if (this.callback) {
        this.callback(entry, {
            adp: sent
        });
    }
};

Logger.prototype.logToADP = function(entry) {
    if (!this.adp) {
        return false;
    }

    // Map & log legacy events to ADP
    // TODO: move away from the legacy naming and avoid the awkward switch below
    var evType = '';
    var opType = '';
    switch (entry.category) {
        case 'tool_changed':
        case 'pref_changed':
            evType = 'CLICK_OPERATION';
            opType = entry.category + '/' + entry.name;
            break;
        case 'screen_mode':
            evType = 'CLICK_OPERATION';
            opType = 'pref_changed/' + entry.category;
            break;
        case 'metadata_load_stats':
            evType = 'DOCUMENT_START';
            opType = 'stats';
            entry.full_url = getReferer();
            break;
        case 'model_load_stats':
            evType = 'DOCUMENT_FULL';
            opType = 'stats';
            break;
        case 'error':
            evType = 'BACKGROUND_CALL';
            opType = 'error';
            break;
    }

    if (!evType)
        return false;

    this.adp.trackEvent(evType, {
        operation: {
            id: entry.sessionId,
            type: opType,
            stage: '',
            status: 'C',
            meta: entry
        }
    });
    return true;
};

Logger.prototype.updateRuntimeStats = function(entry) {
    if (entry.hasOwnProperty('aggregate')) {
        switch (entry.aggregate) {
            case 'count':
                if (this.runtimeStats[entry.name] > 0) {
                    this.runtimeStats[entry.name]++;
                } else {
                    this.runtimeStats[entry.name] = 1;
                }
                this.runtimeStats._nonempty = true;
                break;
            case 'last':
                this.runtimeStats[entry.name] = entry.value;
                this.runtimeStats._nonempty = true;
                break;
            default:
                this.warn('unknown log aggregate type');
        }
    }
};

Logger.prototype.reportRuntimeStats = function() {
    if (this.runtimeStats._nonempty) {
        delete this.runtimeStats._nonempty;

        if (this.adp) {
            this.adp.trackEvent('BACKGROUND_CALL', {
                operation: {
                    id: this.sessionId,
                    type: 'stats',
                    stage: '',
                    status: 'C',
                    meta: this.runtimeStats
                }
            });
        }

        this.runtimeStats.category = 'misc_stats';
        this.track(this.runtimeStats);
        this.runtimeStats = {};
    }
};

Logger.prototype.setLevel = function(level) {
    if (this.level === level)
        return;

    this.level = level;

    var nullFn = function(){};
    var avpl = avp.LogLevels;
    var self = this;

    var reportError = function() {
        if (self.callback) {
            var msg = Array.prototype.slice.call(arguments).join(' ');
            self.callback({ category: 'error', message: msg }, { adp: false });
        }
        console.error.apply(console, arguments);
    };

    // Bind to console
    this.debug = level >= avpl.DEBUG   ? console.log.bind(console) : nullFn;
    this.log   = level >= avpl.LOG     ? console.log.bind(console)   : nullFn;
    this.info  = level >= avpl.INFO    ? console.info.bind(console)  : nullFn;
    this.warn  = level >= avpl.WARNING ? console.warn.bind(console)  : nullFn;
    this.error = level >= avpl.ERROR   ? reportError : nullFn;
};

/**
 * @private
 */
function getReferer(){
    // Wrapping href retrieval due to Fortify complains
    if (typeof window !== 'undefined') {
        return encodeURI(window.location.href);
    }
    return '';
}

Autodesk.Viewing.Private.logger = new Logger();

})();
;
/**
 * @author mrdoob / http://mrdoob.com/
 * @author supereggbert / http://www.paulbrunt.co.uk/
 * @author philogb / http://blog.thejit.org/
 * @author jordi_ros / http://plattsoft.com
 * @author D1plo1d / http://github.com/D1plo1d
 * @author alteredq / http://alteredqualia.com/
 * @author mikael emtinger / http://gomo.se/
 * @author timknip / http://www.floorplanner.com/
 * @author bhouston / http://exocortex.com
 * @author WestLangley / http://github.com/WestLangley
 */
/* Pruned version of THREE.Matrix4, for use in the LMV web worker */

LmvMatrix4 = function (useDoublePrecision) {

	if (useDoublePrecision) {

		this.elements = new Float64Array( [

			1, 0, 0, 0,
			0, 1, 0, 0,
			0, 0, 1, 0,
			0, 0, 0, 1

		] );

	} else {

		this.elements = new Float32Array( [

			1, 0, 0, 0,
			0, 1, 0, 0,
			0, 0, 1, 0,
			0, 0, 0, 1

		] );

	}

};

LmvMatrix4.prototype = {

	constructor: LmvMatrix4,

	set: function ( n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44 ) {

		var te = this.elements;

		te[ 0 ] = n11; te[ 4 ] = n12; te[ 8 ] = n13; te[ 12 ] = n14;
		te[ 1 ] = n21; te[ 5 ] = n22; te[ 9 ] = n23; te[ 13 ] = n24;
		te[ 2 ] = n31; te[ 6 ] = n32; te[ 10 ] = n33; te[ 14 ] = n34;
		te[ 3 ] = n41; te[ 7 ] = n42; te[ 11 ] = n43; te[ 15 ] = n44;

		return this;

	},

	identity: function () {

		this.set(

			1, 0, 0, 0,
			0, 1, 0, 0,
			0, 0, 1, 0,
			0, 0, 0, 1

		);

		return this;

	},

	copy: function ( m ) {

		this.elements.set( m.elements );

		return this;

	},

	makeRotationFromQuaternion: function ( q ) {

		var te = this.elements;

		var x = q.x, y = q.y, z = q.z, w = q.w;
		var x2 = x + x, y2 = y + y, z2 = z + z;
		var xx = x * x2, xy = x * y2, xz = x * z2;
		var yy = y * y2, yz = y * z2, zz = z * z2;
		var wx = w * x2, wy = w * y2, wz = w * z2;

		te[ 0 ] = 1 - ( yy + zz );
		te[ 4 ] = xy - wz;
		te[ 8 ] = xz + wy;

		te[ 1 ] = xy + wz;
		te[ 5 ] = 1 - ( xx + zz );
		te[ 9 ] = yz - wx;

		te[ 2 ] = xz - wy;
		te[ 6 ] = yz + wx;
		te[ 10 ] = 1 - ( xx + yy );

		// last column
		te[ 3 ] = 0;
		te[ 7 ] = 0;
		te[ 11 ] = 0;

		// bottom row
		te[ 12 ] = 0;
		te[ 13 ] = 0;
		te[ 14 ] = 0;
		te[ 15 ] = 1;

		return this;

	},

	multiply: function ( n ) {

		return this.multiplyMatrices( this, n );

	},

	multiplyMatrices: function ( a, b ) {

		var ae = a.elements;
		var be = b.elements;
		var te = this.elements;

		var a11 = ae[ 0 ], a12 = ae[ 4 ], a13 = ae[ 8 ], a14 = ae[ 12 ];
		var a21 = ae[ 1 ], a22 = ae[ 5 ], a23 = ae[ 9 ], a24 = ae[ 13 ];
		var a31 = ae[ 2 ], a32 = ae[ 6 ], a33 = ae[ 10 ], a34 = ae[ 14 ];
		var a41 = ae[ 3 ], a42 = ae[ 7 ], a43 = ae[ 11 ], a44 = ae[ 15 ];

		var b11 = be[ 0 ], b12 = be[ 4 ], b13 = be[ 8 ], b14 = be[ 12 ];
		var b21 = be[ 1 ], b22 = be[ 5 ], b23 = be[ 9 ], b24 = be[ 13 ];
		var b31 = be[ 2 ], b32 = be[ 6 ], b33 = be[ 10 ], b34 = be[ 14 ];
		var b41 = be[ 3 ], b42 = be[ 7 ], b43 = be[ 11 ], b44 = be[ 15 ];

		te[ 0 ] = a11 * b11 + a12 * b21 + a13 * b31 + a14 * b41;
		te[ 4 ] = a11 * b12 + a12 * b22 + a13 * b32 + a14 * b42;
		te[ 8 ] = a11 * b13 + a12 * b23 + a13 * b33 + a14 * b43;
		te[ 12 ] = a11 * b14 + a12 * b24 + a13 * b34 + a14 * b44;

		te[ 1 ] = a21 * b11 + a22 * b21 + a23 * b31 + a24 * b41;
		te[ 5 ] = a21 * b12 + a22 * b22 + a23 * b32 + a24 * b42;
		te[ 9 ] = a21 * b13 + a22 * b23 + a23 * b33 + a24 * b43;
		te[ 13 ] = a21 * b14 + a22 * b24 + a23 * b34 + a24 * b44;

		te[ 2 ] = a31 * b11 + a32 * b21 + a33 * b31 + a34 * b41;
		te[ 6 ] = a31 * b12 + a32 * b22 + a33 * b32 + a34 * b42;
		te[ 10 ] = a31 * b13 + a32 * b23 + a33 * b33 + a34 * b43;
		te[ 14 ] = a31 * b14 + a32 * b24 + a33 * b34 + a34 * b44;

		te[ 3 ] = a41 * b11 + a42 * b21 + a43 * b31 + a44 * b41;
		te[ 7 ] = a41 * b12 + a42 * b22 + a43 * b32 + a44 * b42;
		te[ 11 ] = a41 * b13 + a42 * b23 + a43 * b33 + a44 * b43;
		te[ 15 ] = a41 * b14 + a42 * b24 + a43 * b34 + a44 * b44;

		return this;

	},

	multiplyToArray: function ( a, b, r ) {

		var te = this.elements;

		this.multiplyMatrices( a, b );

		r[ 0 ] = te[ 0 ]; r[ 1 ] = te[ 1 ]; r[ 2 ] = te[ 2 ]; r[ 3 ] = te[ 3 ];
		r[ 4 ] = te[ 4 ]; r[ 5 ] = te[ 5 ]; r[ 6 ] = te[ 6 ]; r[ 7 ] = te[ 7 ];
		r[ 8 ]  = te[ 8 ]; r[ 9 ]  = te[ 9 ]; r[ 10 ] = te[ 10 ]; r[ 11 ] = te[ 11 ];
		r[ 12 ] = te[ 12 ]; r[ 13 ] = te[ 13 ]; r[ 14 ] = te[ 14 ]; r[ 15 ] = te[ 15 ];

		return this;

	},

	multiplyScalar: function ( s ) {

		var te = this.elements;

		te[ 0 ] *= s; te[ 4 ] *= s; te[ 8 ] *= s; te[ 12 ] *= s;
		te[ 1 ] *= s; te[ 5 ] *= s; te[ 9 ] *= s; te[ 13 ] *= s;
		te[ 2 ] *= s; te[ 6 ] *= s; te[ 10 ] *= s; te[ 14 ] *= s;
		te[ 3 ] *= s; te[ 7 ] *= s; te[ 11 ] *= s; te[ 15 ] *= s;

		return this;

	},

	determinant: function () {

		var te = this.elements;

		var n11 = te[ 0 ], n12 = te[ 4 ], n13 = te[ 8 ], n14 = te[ 12 ];
		var n21 = te[ 1 ], n22 = te[ 5 ], n23 = te[ 9 ], n24 = te[ 13 ];
		var n31 = te[ 2 ], n32 = te[ 6 ], n33 = te[ 10 ], n34 = te[ 14 ];
		var n41 = te[ 3 ], n42 = te[ 7 ], n43 = te[ 11 ], n44 = te[ 15 ];

		//TODO: make this more efficient
		//( based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm )

		return (
			n41 * (
				+ n14 * n23 * n32
				 - n13 * n24 * n32
				 - n14 * n22 * n33
				 + n12 * n24 * n33
				 + n13 * n22 * n34
				 - n12 * n23 * n34
			) +
			n42 * (
				+ n11 * n23 * n34
				 - n11 * n24 * n33
				 + n14 * n21 * n33
				 - n13 * n21 * n34
				 + n13 * n24 * n31
				 - n14 * n23 * n31
			) +
			n43 * (
				+ n11 * n24 * n32
				 - n11 * n22 * n34
				 - n14 * n21 * n32
				 + n12 * n21 * n34
				 + n14 * n22 * n31
				 - n12 * n24 * n31
			) +
			n44 * (
				- n13 * n22 * n31
				 - n11 * n23 * n32
				 + n11 * n22 * n33
				 + n13 * n21 * n32
				 - n12 * n21 * n33
				 + n12 * n23 * n31
			)

		);

	},

	transpose: function () {

		var te = this.elements;
		var tmp;

		tmp = te[ 1 ]; te[ 1 ] = te[ 4 ]; te[ 4 ] = tmp;
		tmp = te[ 2 ]; te[ 2 ] = te[ 8 ]; te[ 8 ] = tmp;
		tmp = te[ 6 ]; te[ 6 ] = te[ 9 ]; te[ 9 ] = tmp;

		tmp = te[ 3 ]; te[ 3 ] = te[ 12 ]; te[ 12 ] = tmp;
		tmp = te[ 7 ]; te[ 7 ] = te[ 13 ]; te[ 13 ] = tmp;
		tmp = te[ 11 ]; te[ 11 ] = te[ 14 ]; te[ 14 ] = tmp;

		return this;

	},

	flattenToArrayOffset: function ( array, offset ) {

		var te = this.elements;

		array[ offset     ] = te[ 0 ];
		array[ offset + 1 ] = te[ 1 ];
		array[ offset + 2 ] = te[ 2 ];
		array[ offset + 3 ] = te[ 3 ];

		array[ offset + 4 ] = te[ 4 ];
		array[ offset + 5 ] = te[ 5 ];
		array[ offset + 6 ] = te[ 6 ];
		array[ offset + 7 ] = te[ 7 ];

		array[ offset + 8 ]  = te[ 8 ];
		array[ offset + 9 ]  = te[ 9 ];
		array[ offset + 10 ] = te[ 10 ];
		array[ offset + 11 ] = te[ 11 ];

		array[ offset + 12 ] = te[ 12 ];
		array[ offset + 13 ] = te[ 13 ];
		array[ offset + 14 ] = te[ 14 ];
		array[ offset + 15 ] = te[ 15 ];

		return array;

	},

	setPosition: function ( v ) {

		var te = this.elements;

		te[ 12 ] = v.x;
		te[ 13 ] = v.y;
		te[ 14 ] = v.z;

		return this;

	},

	getInverse: function ( m, throwOnInvertible ) {

		// based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm
		var te = this.elements;
		var me = m.elements;

		var n11 = me[ 0 ], n12 = me[ 4 ], n13 = me[ 8 ], n14 = me[ 12 ];
		var n21 = me[ 1 ], n22 = me[ 5 ], n23 = me[ 9 ], n24 = me[ 13 ];
		var n31 = me[ 2 ], n32 = me[ 6 ], n33 = me[ 10 ], n34 = me[ 14 ];
		var n41 = me[ 3 ], n42 = me[ 7 ], n43 = me[ 11 ], n44 = me[ 15 ];

		te[ 0 ] = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44;
		te[ 4 ] = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44;
		te[ 8 ] = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44;
		te[ 12 ] = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;
		te[ 1 ] = n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44;
		te[ 5 ] = n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44;
		te[ 9 ] = n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44;
		te[ 13 ] = n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34;
		te[ 2 ] = n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44;
		te[ 6 ] = n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44;
		te[ 10 ] = n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44;
		te[ 14 ] = n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34;
		te[ 3 ] = n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43;
		te[ 7 ] = n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43;
		te[ 11 ] = n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43;
		te[ 15 ] = n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33;

		var det = n11 * te[ 0 ] + n21 * te[ 4 ] + n31 * te[ 8 ] + n41 * te[ 12 ];

		if ( det == 0 ) {

			var msg = "Matrix4.getInverse(): can't invert matrix, determinant is 0";

			if ( throwOnInvertible || false ) {

				throw new Error( msg );

			} else {

				console.warn( msg );

			}

			this.identity();

			return this;
		}

		this.multiplyScalar( 1 / det );

		return this;

	},

	scale: function ( v ) {

		var te = this.elements;
		var x = v.x, y = v.y, z = v.z;

		te[ 0 ] *= x; te[ 4 ] *= y; te[ 8 ] *= z;
		te[ 1 ] *= x; te[ 5 ] *= y; te[ 9 ] *= z;
		te[ 2 ] *= x; te[ 6 ] *= y; te[ 10 ] *= z;
		te[ 3 ] *= x; te[ 7 ] *= y; te[ 11 ] *= z;

		return this;

	},

	makeTranslation: function ( x, y, z ) {

		this.set(

			1, 0, 0, x,
			0, 1, 0, y,
			0, 0, 1, z,
			0, 0, 0, 1

		);

		return this;

	},

	makeRotationX: function ( theta ) {

		var c = Math.cos( theta ), s = Math.sin( theta );

		this.set(

			1, 0,  0, 0,
			0, c, - s, 0,
			0, s,  c, 0,
			0, 0,  0, 1

		);

		return this;

	},

	makeRotationY: function ( theta ) {

		var c = Math.cos( theta ), s = Math.sin( theta );

		this.set(

			 c, 0, s, 0,
			 0, 1, 0, 0,
			- s, 0, c, 0,
			 0, 0, 0, 1

		);

		return this;

	},

	makeRotationZ: function ( theta ) {

		var c = Math.cos( theta ), s = Math.sin( theta );

		this.set(

			c, - s, 0, 0,
			s,  c, 0, 0,
			0,  0, 1, 0,
			0,  0, 0, 1

		);

		return this;

	},

	makeRotationAxis: function ( axis, angle ) {

		// Based on http://www.gamedev.net/reference/articles/article1199.asp

		var c = Math.cos( angle );
		var s = Math.sin( angle );
		var t = 1 - c;
		var x = axis.x, y = axis.y, z = axis.z;
		var tx = t * x, ty = t * y;

		this.set(

			tx * x + c, tx * y - s * z, tx * z + s * y, 0,
			tx * y + s * z, ty * y + c, ty * z - s * x, 0,
			tx * z - s * y, ty * z + s * x, t * z * z + c, 0,
			0, 0, 0, 1

		);

		 return this;

	},

	makeScale: function ( x, y, z ) {

		this.set(

			x, 0, 0, 0,
			0, y, 0, 0,
			0, 0, z, 0,
			0, 0, 0, 1

		);

		return this;

	},

	compose: function ( position, quaternion, scale ) {

		this.makeRotationFromQuaternion( quaternion );
		this.scale( scale );
		this.setPosition( position );

		return this;

	},

    //Added for LMV
    transformPoint: function (pt) {

            // input: THREE.Matrix4 affine matrix

            var x = pt.x, y = pt.y, z = pt.z;

            var e = this.elements;

            pt.x = e[ 0 ] * x + e[ 4 ] * y + e[ 8 ]  * z + e[ 12 ];
            pt.y = e[ 1 ] * x + e[ 5 ] * y + e[ 9 ]  * z + e[ 13 ];
            pt.z = e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ];

            return pt;
    },

    //Added for LMV
    transformDirection: function(v) {

            // input: THREE.Matrix4 affine matrix
            // vector interpreted as a direction

            var x = v.x, y = v.y, z = v.z;

            var e = this.elements;

            v.x = e[ 0 ] * x + e[ 4 ] * y + e[ 8 ]  * z;
            v.y = e[ 1 ] * x + e[ 5 ] * y + e[ 9 ]  * z;
            v.z = e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z;

            var len = Math.sqrt(v.x*v.x + v.y*v.y + v.z*v.z);
            if (len > 0) {
                var ilen = 1.0 / len;
                v.x *= ilen;
                v.y *= ilen;
                v.z *= ilen;
            }

            return v;
    },


	fromArray: function ( array ) {

		this.elements.set( array );

		return this;

	},

	toArray: function () {

		var te = this.elements;

		return [
			te[ 0 ], te[ 1 ], te[ 2 ], te[ 3 ],
			te[ 4 ], te[ 5 ], te[ 6 ], te[ 7 ],
			te[ 8 ], te[ 9 ], te[ 10 ], te[ 11 ],
			te[ 12 ], te[ 13 ], te[ 14 ], te[ 15 ]
		];

	},

	clone: function () {

		return new LmvMatrix4().fromArray( this.elements );

	}

};
;
/**
 * @author mrdoob / http://mrdoob.com/
 * @author *kile / http://kile.stravaganza.org/
 * @author philogb / http://blog.thejit.org/
 * @author mikael emtinger / http://gomo.se/
 * @author egraether / http://egraether.com/
 * @author WestLangley / http://github.com/WestLangley
 */
/* Pruned version of THREE.Vector3, for use in the LMV web worker */


LmvVector3 = function ( x, y, z ) {

	this.x = x || 0;
	this.y = y || 0;
	this.z = z || 0;

};

LmvVector3.prototype = {

	constructor: LmvVector3,

	set: function ( x, y, z ) {

		this.x = x;
		this.y = y;
		this.z = z;

		return this;

	},

	setX: function ( x ) {

		this.x = x;

		return this;

	},

	setY: function ( y ) {

		this.y = y;

		return this;

	},

	setZ: function ( z ) {

		this.z = z;

		return this;

	},

	setComponent: function ( index, value ) {

		switch ( index ) {

			case 0: this.x = value; break;
			case 1: this.y = value; break;
			case 2: this.z = value; break;
			default: throw new Error( 'index is out of range: ' + index );

		}

	},

	getComponent: function ( index ) {

		switch ( index ) {

			case 0: return this.x;
			case 1: return this.y;
			case 2: return this.z;
			default: throw new Error( 'index is out of range: ' + index );

		}

	},

	clone: function () {

		return new this.constructor( this.x, this.y, this.z );

	},

	copy: function ( v ) {

		this.x = v.x;
		this.y = v.y;
		this.z = v.z;

		return this;

	},

	add: function ( v, w ) {

		if ( w !== undefined ) {

			console.warn( 'THREE.Vector3: .add() now only accepts one argument. Use .addVectors( a, b ) instead.' );
			return this.addVectors( v, w );

		}

		this.x += v.x;
		this.y += v.y;
		this.z += v.z;

		return this;

	},

	addScalar: function ( s ) {

		this.x += s;
		this.y += s;
		this.z += s;

		return this;

	},

	addVectors: function ( a, b ) {

		this.x = a.x + b.x;
		this.y = a.y + b.y;
		this.z = a.z + b.z;

		return this;

	},

	addScaledVector: function ( v, s ) {

		this.x += v.x * s;
		this.y += v.y * s;
		this.z += v.z * s;

		return this;

	},

	sub: function ( v, w ) {

		if ( w !== undefined ) {

			console.warn( 'THREE.Vector3: .sub() now only accepts one argument. Use .subVectors( a, b ) instead.' );
			return this.subVectors( v, w );

		}

		this.x -= v.x;
		this.y -= v.y;
		this.z -= v.z;

		return this;

	},

	subScalar: function ( s ) {

		this.x -= s;
		this.y -= s;
		this.z -= s;

		return this;

	},

	subVectors: function ( a, b ) {

		this.x = a.x - b.x;
		this.y = a.y - b.y;
		this.z = a.z - b.z;

		return this;

	},

	multiply: function ( v, w ) {

		if ( w !== undefined ) {

			console.warn( 'THREE.Vector3: .multiply() now only accepts one argument. Use .multiplyVectors( a, b ) instead.' );
			return this.multiplyVectors( v, w );

		}

		this.x *= v.x;
		this.y *= v.y;
		this.z *= v.z;

		return this;

	},

	multiplyScalar: function ( scalar ) {

		this.x *= scalar;
		this.y *= scalar;
		this.z *= scalar;

		return this;

	},

	multiplyVectors: function ( a, b ) {

		this.x = a.x * b.x;
		this.y = a.y * b.y;
		this.z = a.z * b.z;

		return this;

	},

	applyMatrix3: function ( m ) {

		var x = this.x;
		var y = this.y;
		var z = this.z;

		var e = m.elements;

		this.x = e[ 0 ] * x + e[ 3 ] * y + e[ 6 ] * z;
		this.y = e[ 1 ] * x + e[ 4 ] * y + e[ 7 ] * z;
		this.z = e[ 2 ] * x + e[ 5 ] * y + e[ 8 ] * z;

		return this;

	},

	applyMatrix4: function ( m ) {

		// input: THREE.Matrix4 affine matrix

		var x = this.x, y = this.y, z = this.z;

		var e = m.elements;

		this.x = e[ 0 ] * x + e[ 4 ] * y + e[ 8 ]  * z + e[ 12 ];
		this.y = e[ 1 ] * x + e[ 5 ] * y + e[ 9 ]  * z + e[ 13 ];
		this.z = e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ];

		return this;

	},

	applyProjection: function ( m ) {

		// input: THREE.Matrix4 projection matrix

		var x = this.x, y = this.y, z = this.z;

		var e = m.elements;
		var d = 1 / ( e[ 3 ] * x + e[ 7 ] * y + e[ 11 ] * z + e[ 15 ] ); // perspective divide

		this.x = ( e[ 0 ] * x + e[ 4 ] * y + e[ 8 ]  * z + e[ 12 ] ) * d;
		this.y = ( e[ 1 ] * x + e[ 5 ] * y + e[ 9 ]  * z + e[ 13 ] ) * d;
		this.z = ( e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ] ) * d;

		return this;

	},

	applyQuaternion: function ( q ) {

		var x = this.x;
		var y = this.y;
		var z = this.z;

		var qx = q.x;
		var qy = q.y;
		var qz = q.z;
		var qw = q.w;

		// calculate quat * vector

		var ix =  qw * x + qy * z - qz * y;
		var iy =  qw * y + qz * x - qx * z;
		var iz =  qw * z + qx * y - qy * x;
		var iw = - qx * x - qy * y - qz * z;

		// calculate result * inverse quat

		this.x = ix * qw + iw * - qx + iy * - qz - iz * - qy;
		this.y = iy * qw + iw * - qy + iz * - qx - ix * - qz;
		this.z = iz * qw + iw * - qz + ix * - qy - iy * - qx;

		return this;

	},

	transformDirection: function ( m ) {

		// input: THREE.Matrix4 affine matrix
		// vector interpreted as a direction

		var x = this.x, y = this.y, z = this.z;

		var e = m.elements;

		this.x = e[ 0 ] * x + e[ 4 ] * y + e[ 8 ]  * z;
		this.y = e[ 1 ] * x + e[ 5 ] * y + e[ 9 ]  * z;
		this.z = e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z;

		this.normalize();

		return this;

	},

	divide: function ( v ) {

		this.x /= v.x;
		this.y /= v.y;
		this.z /= v.z;

		return this;

	},

	divideScalar: function ( scalar ) {

		if ( scalar !== 0 ) {

			var invScalar = 1 / scalar;

			this.x *= invScalar;
			this.y *= invScalar;
			this.z *= invScalar;

		} else {

			this.x = 0;
			this.y = 0;
			this.z = 0;

		}

		return this;

	},

	min: function ( v ) {

		if ( this.x > v.x ) {

			this.x = v.x;

		}

		if ( this.y > v.y ) {

			this.y = v.y;

		}

		if ( this.z > v.z ) {

			this.z = v.z;

		}

		return this;

	},

	max: function ( v ) {

		if ( this.x < v.x ) {

			this.x = v.x;

		}

		if ( this.y < v.y ) {

			this.y = v.y;

		}

		if ( this.z < v.z ) {

			this.z = v.z;

		}

		return this;

	},

	clamp: function ( min, max ) {

		// This function assumes min < max, if this assumption isn't true it will not operate correctly

		if ( this.x < min.x ) {

			this.x = min.x;

		} else if ( this.x > max.x ) {

			this.x = max.x;

		}

		if ( this.y < min.y ) {

			this.y = min.y;

		} else if ( this.y > max.y ) {

			this.y = max.y;

		}

		if ( this.z < min.z ) {

			this.z = min.z;

		} else if ( this.z > max.z ) {

			this.z = max.z;

		}

		return this;

	},

	clampScalar: function () {

		var min, max;

		return function clampScalar( minVal, maxVal ) {

			if ( min === undefined ) {

				min = new LmvVector3();
				max = new LmvVector3();

			}

			min.set( minVal, minVal, minVal );
			max.set( maxVal, maxVal, maxVal );

			return this.clamp( min, max );

		};

	}(),

	floor: function () {

		this.x = Math.floor( this.x );
		this.y = Math.floor( this.y );
		this.z = Math.floor( this.z );

		return this;

	},

	ceil: function () {

		this.x = Math.ceil( this.x );
		this.y = Math.ceil( this.y );
		this.z = Math.ceil( this.z );

		return this;

	},

	round: function () {

		this.x = Math.round( this.x );
		this.y = Math.round( this.y );
		this.z = Math.round( this.z );

		return this;

	},

	roundToZero: function () {

		this.x = ( this.x < 0 ) ? Math.ceil( this.x ) : Math.floor( this.x );
		this.y = ( this.y < 0 ) ? Math.ceil( this.y ) : Math.floor( this.y );
		this.z = ( this.z < 0 ) ? Math.ceil( this.z ) : Math.floor( this.z );

		return this;

	},

	negate: function () {

		this.x = - this.x;
		this.y = - this.y;
		this.z = - this.z;

		return this;

	},

	dot: function ( v ) {

		return this.x * v.x + this.y * v.y + this.z * v.z;

	},

	lengthSq: function () {

		return this.x * this.x + this.y * this.y + this.z * this.z;

	},

	length: function () {

		return Math.sqrt( this.x * this.x + this.y * this.y + this.z * this.z );

	},

	lengthManhattan: function () {

		return Math.abs( this.x ) + Math.abs( this.y ) + Math.abs( this.z );

	},

	normalize: function () {

		return this.divideScalar( this.length() );

	},

	setLength: function ( l ) {

		var oldLength = this.length();

		if ( oldLength !== 0 && l !== oldLength  ) {

			this.multiplyScalar( l / oldLength );

		}

		return this;

	},

	lerp: function ( v, alpha ) {

		this.x += ( v.x - this.x ) * alpha;
		this.y += ( v.y - this.y ) * alpha;
		this.z += ( v.z - this.z ) * alpha;

		return this;

	},

	lerpVectors: function ( v1, v2, alpha ) {

		this.subVectors( v2, v1 ).multiplyScalar( alpha ).add( v1 );

		return this;

	},

	cross: function ( v, w ) {

		if ( w !== undefined ) {

			console.warn( 'THREE.Vector3: .cross() now only accepts one argument. Use .crossVectors( a, b ) instead.' );
			return this.crossVectors( v, w );

		}

		var x = this.x, y = this.y, z = this.z;

		this.x = y * v.z - z * v.y;
		this.y = z * v.x - x * v.z;
		this.z = x * v.y - y * v.x;

		return this;

	},

	crossVectors: function ( a, b ) {

		var ax = a.x, ay = a.y, az = a.z;
		var bx = b.x, by = b.y, bz = b.z;

		this.x = ay * bz - az * by;
		this.y = az * bx - ax * bz;
		this.z = ax * by - ay * bx;

		return this;

	},

	projectOnVector: function () {

		var v1, dot;

		return function projectOnVector( vector ) {

			if ( v1 === undefined ) v1 = new LmvVector3();

			v1.copy( vector ).normalize();

			dot = this.dot( v1 );

			return this.copy( v1 ).multiplyScalar( dot );

		};

	}(),

	projectOnPlane: function () {

		var v1;

		return function projectOnPlane( planeNormal ) {

			if ( v1 === undefined ) v1 = new LmvVector3();

			v1.copy( this ).projectOnVector( planeNormal );

			return this.sub( v1 );

		}

	}(),

	reflect: function () {

		// reflect incident vector off plane orthogonal to normal
		// normal is assumed to have unit length

		var v1;

		return function reflect( normal ) {

			if ( v1 === undefined ) v1 = new LmvVector3();

			return this.sub( v1.copy( normal ).multiplyScalar( 2 * this.dot( normal ) ) );

		}

	}(),

	distanceTo: function ( v ) {

		return Math.sqrt( this.distanceToSquared( v ) );

	},

	distanceToSquared: function ( v ) {

		var dx = this.x - v.x;
		var dy = this.y - v.y;
		var dz = this.z - v.z;

		return dx * dx + dy * dy + dz * dz;

	},

	setEulerFromRotationMatrix: function ( m, order ) {

		console.error( 'THREE.Vector3: .setEulerFromRotationMatrix() has been removed. Use Euler.setFromRotationMatrix() instead.' );

	},

	setEulerFromQuaternion: function ( q, order ) {

		console.error( 'THREE.Vector3: .setEulerFromQuaternion() has been removed. Use Euler.setFromQuaternion() instead.' );

	},

	getPositionFromMatrix: function ( m ) {

		console.warn( 'THREE.Vector3: .getPositionFromMatrix() has been renamed to .setFromMatrixPosition().' );

		return this.setFromMatrixPosition( m );

	},

	getScaleFromMatrix: function ( m ) {

		console.warn( 'THREE.Vector3: .getScaleFromMatrix() has been renamed to .setFromMatrixScale().' );

		return this.setFromMatrixScale( m );

	},

	getColumnFromMatrix: function ( index, matrix ) {

		console.warn( 'THREE.Vector3: .getColumnFromMatrix() has been renamed to .setFromMatrixColumn().' );

		return this.setFromMatrixColumn( index, matrix );

	},

	setFromMatrixPosition: function ( m ) {

		this.x = m.elements[ 12 ];
		this.y = m.elements[ 13 ];
		this.z = m.elements[ 14 ];

		return this;

	},

	setFromMatrixScale: function ( m ) {

		var sx = this.set( m.elements[ 0 ], m.elements[ 1 ], m.elements[ 2 ] ).length();
		var sy = this.set( m.elements[ 4 ], m.elements[ 5 ], m.elements[ 6 ] ).length();
		var sz = this.set( m.elements[ 8 ], m.elements[ 9 ], m.elements[ 10 ] ).length();

		this.x = sx;
		this.y = sy;
		this.z = sz;

		return this;

	},

	setFromMatrixColumn: function ( index, matrix ) {

		var offset = index * 4;

		var me = matrix.elements;

		this.x = me[ offset ];
		this.y = me[ offset + 1 ];
		this.z = me[ offset + 2 ];

		return this;

	},

	equals: function ( v ) {

		return ( ( v.x === this.x ) && ( v.y === this.y ) && ( v.z === this.z ) );

	},

	fromArray: function ( array, offset ) {

		if ( offset === undefined ) offset = 0;

		this.x = array[ offset ];
		this.y = array[ offset + 1 ];
		this.z = array[ offset + 2 ];

		return this;

	},

	toArray: function ( array, offset ) {

		if ( array === undefined ) array = [];
		if ( offset === undefined ) offset = 0;

		array[ offset ] = this.x;
		array[ offset + 1 ] = this.y;
		array[ offset + 2 ] = this.z;

		return array;

	},

	fromAttribute: function ( attribute, index, offset ) {

		if ( offset === undefined ) offset = 0;

		index = index * attribute.itemSize + offset;

		this.x = attribute.array[ index ];
		this.y = attribute.array[ index + 1 ];
		this.z = attribute.array[ index + 2 ];

		return this;

	}

};
;
/**
 * @author bhouston / http://exocortex.com
 * @author WestLangley / http://github.com/WestLangley
 */
/* Pruned version of THREE.Box3, for use in the LMV web worker */


var LmvBox3 = function ( min, max ) {

	this.min = ( min !== undefined ) ? min : new LmvVector3( Infinity, Infinity, Infinity );
	this.max = ( max !== undefined ) ? max : new LmvVector3( - Infinity, - Infinity, - Infinity );

};

LmvBox3.prototype = {

	constructor: LmvBox3,

	set: function ( min, max ) {

		this.min.copy( min );
		this.max.copy( max );

		return this;

	},

	setFromPoints: function ( points ) {

		this.makeEmpty();

		for ( var i = 0, il = points.length; i < il; i ++ ) {

			this.expandByPoint( points[ i ] );

		}

		return this;

	},

	setFromArray: function ( array, offset ) {

		this.min.x = array[offset];
		this.min.y = array[offset+1];
		this.min.z = array[offset+2];

		this.max.x = array[offset+3];
		this.max.y = array[offset+4];
		this.max.z = array[offset+5];

		return this;

	},

	copyToArray: function (array, offset) {

		array[offset]   = this.min.x;
		array[offset+1] = this.min.y;
		array[offset+2] = this.min.z;

		array[offset+3] = this.max.x;
		array[offset+4] = this.max.y;
		array[offset+5] = this.max.z;

	},

	setFromCenterAndSize: function () {

		var v1 = new LmvVector3();

		return function ( center, size ) {

			var halfSize = v1.copy( size ).multiplyScalar( 0.5 );

			this.min.copy( center ).sub( halfSize );
			this.max.copy( center ).add( halfSize );

			return this;

		};

	}(),

	clone: function () {

		return new this.constructor().copy( this );

	},

	copy: function ( box ) {

		this.min.copy( box.min );
		this.max.copy( box.max );

		return this;

	},

	makeEmpty: function () {

		this.min.x = this.min.y = this.min.z = Infinity;
		this.max.x = this.max.y = this.max.z = - Infinity;

		return this;

	},

	empty: function () {

		// this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes

		return ( this.max.x < this.min.x ) || ( this.max.y < this.min.y ) || ( this.max.z < this.min.z );

	},

	center: function ( optionalTarget ) {

		var result = optionalTarget || new LmvVector3();
		return result.addVectors( this.min, this.max ).multiplyScalar( 0.5 );

	},

	size: function ( optionalTarget ) {

		var result = optionalTarget || new LmvVector3();
		return result.subVectors( this.max, this.min );

	},

	expandByPoint: function ( point ) {

		this.min.min( point );
		this.max.max( point );

		return this;

	},

	expandByVector: function ( vector ) {

		this.min.sub( vector );
		this.max.add( vector );

		return this;

	},

	expandByScalar: function ( scalar ) {

		this.min.addScalar( - scalar );
		this.max.addScalar( scalar );

		return this;

	},

	containsPoint: function ( point ) {

		if ( point.x < this.min.x || point.x > this.max.x ||
		     point.y < this.min.y || point.y > this.max.y ||
		     point.z < this.min.z || point.z > this.max.z ) {

			return false;

		}

		return true;

	},

	containsBox: function ( box ) {

		if ( ( this.min.x <= box.min.x ) && ( box.max.x <= this.max.x ) &&
			 ( this.min.y <= box.min.y ) && ( box.max.y <= this.max.y ) &&
			 ( this.min.z <= box.min.z ) && ( box.max.z <= this.max.z ) ) {

			return true;

		}

		return false;

	},

	getParameter: function ( point, optionalTarget ) {

		// This can potentially have a divide by zero if the box
		// has a size dimension of 0.

		var result = optionalTarget || new LmvVector3();

		return result.set(
			( point.x - this.min.x ) / ( this.max.x - this.min.x ),
			( point.y - this.min.y ) / ( this.max.y - this.min.y ),
			( point.z - this.min.z ) / ( this.max.z - this.min.z )
		);

	},

	isIntersectionBox: function ( box ) {

		// using 6 splitting planes to rule out intersections.

		if ( box.max.x < this.min.x || box.min.x > this.max.x ||
		     box.max.y < this.min.y || box.min.y > this.max.y ||
		     box.max.z < this.min.z || box.min.z > this.max.z ) {

			return false;

		}

		return true;

	},

	clampPoint: function ( point, optionalTarget ) {

		var result = optionalTarget || new LmvVector3();
		return result.copy( point ).clamp( this.min, this.max );

	},

	distanceToPoint: function () {

		var v1 = new LmvVector3();

		return function ( point ) {

			var clampedPoint = v1.copy( point ).clamp( this.min, this.max );
			return clampedPoint.sub( point ).length();

		};

	}(),

	intersect: function ( box ) {

		this.min.max( box.min );
		this.max.min( box.max );

		return this;

	},

	union: function ( box ) {

		this.min.min( box.min );
		this.max.max( box.max );

		return this;

	},

	applyMatrix4: function () {

		var points = [
			new LmvVector3(),
			new LmvVector3(),
			new LmvVector3(),
			new LmvVector3(),
			new LmvVector3(),
			new LmvVector3(),
			new LmvVector3(),
			new LmvVector3()
		];

		return function ( matrix ) {

			// NOTE: I am using a binary pattern to specify all 2^3 combinations below
			points[ 0 ].set( this.min.x, this.min.y, this.min.z ).applyMatrix4( matrix ); // 000
			points[ 1 ].set( this.min.x, this.min.y, this.max.z ).applyMatrix4( matrix ); // 001
			points[ 2 ].set( this.min.x, this.max.y, this.min.z ).applyMatrix4( matrix ); // 010
			points[ 3 ].set( this.min.x, this.max.y, this.max.z ).applyMatrix4( matrix ); // 011
			points[ 4 ].set( this.max.x, this.min.y, this.min.z ).applyMatrix4( matrix ); // 100
			points[ 5 ].set( this.max.x, this.min.y, this.max.z ).applyMatrix4( matrix ); // 101
			points[ 6 ].set( this.max.x, this.max.y, this.min.z ).applyMatrix4( matrix ); // 110
			points[ 7 ].set( this.max.x, this.max.y, this.max.z ).applyMatrix4( matrix );  // 111

			this.makeEmpty();
			this.setFromPoints( points );

			return this;

		};

	}(),

	translate: function ( offset ) {

		this.min.add( offset );
		this.max.add( offset );

		return this;

	},

	equals: function ( box ) {

		return box.min.equals( this.min ) && box.max.equals( this.max );

	}

};
;
/*
 * @author mrdoob / http://mrdoob.com/
 */
 
function init_three_dds_loader() { 

THREE.DDSLoader = function () {
	this._parser = THREE.DDSLoader.parse;
};

THREE.DDSLoader.prototype = Object.create( THREE.CompressedTextureLoader.prototype );
THREE.DDSLoader.prototype.constructor = THREE.DDSLoader;

THREE.DDSLoader.parse = function ( buffer, loadMipmaps ) {

	var dds = { mipmaps: [], width: 0, height: 0, format: null, mipmapCount: 1 };

	// Adapted from @toji's DDS utils
	//	https://github.com/toji/webgl-texture-utils/blob/master/texture-util/dds.js

	// All values and structures referenced from:
	// http://msdn.microsoft.com/en-us/library/bb943991.aspx/

	var DDS_MAGIC = 0x20534444;

	var DDSD_CAPS = 0x1,
		DDSD_HEIGHT = 0x2,
		DDSD_WIDTH = 0x4,
		DDSD_PITCH = 0x8,
		DDSD_PIXELFORMAT = 0x1000,
		DDSD_MIPMAPCOUNT = 0x20000,
		DDSD_LINEARSIZE = 0x80000,
		DDSD_DEPTH = 0x800000;

	var DDSCAPS_COMPLEX = 0x8,
		DDSCAPS_MIPMAP = 0x400000,
		DDSCAPS_TEXTURE = 0x1000;

	var DDSCAPS2_CUBEMAP = 0x200,
		DDSCAPS2_CUBEMAP_POSITIVEX = 0x400,
		DDSCAPS2_CUBEMAP_NEGATIVEX = 0x800,
		DDSCAPS2_CUBEMAP_POSITIVEY = 0x1000,
		DDSCAPS2_CUBEMAP_NEGATIVEY = 0x2000,
		DDSCAPS2_CUBEMAP_POSITIVEZ = 0x4000,
		DDSCAPS2_CUBEMAP_NEGATIVEZ = 0x8000,
		DDSCAPS2_VOLUME = 0x200000;

	var DDPF_ALPHAPIXELS = 0x1,
		DDPF_ALPHA = 0x2,
		DDPF_FOURCC = 0x4,
		DDPF_RGB = 0x40,
		DDPF_YUV = 0x200,
		DDPF_LUMINANCE = 0x20000;

	function fourCCToInt32( value ) {

		return value.charCodeAt(0) +
			(value.charCodeAt(1) << 8) +
			(value.charCodeAt(2) << 16) +
			(value.charCodeAt(3) << 24);

	}

	function int32ToFourCC( value ) {

		return String.fromCharCode(
			value & 0xff,
			(value >> 8) & 0xff,
			(value >> 16) & 0xff,
			(value >> 24) & 0xff
		);
	}

	function loadARGBMip( buffer, dataOffset, width, height ) {
		var dataLength = width * height * 4;
		var srcBuffer = new Uint8Array( buffer, dataOffset, dataLength );
		var byteArray = new Uint8Array( dataLength );
		var dst = 0;
		var src = 0;
		for ( var y = 0; y < height; y ++ ) {
			for ( var x = 0; x < width; x ++ ) {
				var b = srcBuffer[src]; src ++;
				var g = srcBuffer[src]; src ++;
				var r = srcBuffer[src]; src ++;
				var a = srcBuffer[src]; src ++;
				byteArray[dst] = r; dst ++;	//r
				byteArray[dst] = g; dst ++;	//g
				byteArray[dst] = b; dst ++;	//b
				byteArray[dst] = a; dst ++;	//a
			}
		}
		return byteArray;
	}

	var FOURCC_DXT1 = fourCCToInt32("DXT1");
	var FOURCC_DXT3 = fourCCToInt32("DXT3");
	var FOURCC_DXT5 = fourCCToInt32("DXT5");

	var headerLengthInt = 31; // The header length in 32 bit ints

	// Offsets into the header array

	var off_magic = 0;

	var off_size = 1;
	var off_flags = 2;
	var off_height = 3;
	var off_width = 4;

	var off_mipmapCount = 7;

	var off_pfFlags = 20;
	var off_pfFourCC = 21;
	var off_RGBBitCount = 22;
	var off_RBitMask = 23;
	var off_GBitMask = 24;
	var off_BBitMask = 25;
	var off_ABitMask = 26;

	var off_caps = 27;
	var off_caps2 = 28;
	var off_caps3 = 29;
	var off_caps4 = 30;

	// Parse header

	var header = new Int32Array( buffer, 0, headerLengthInt );

	if ( header[ off_magic ] !== DDS_MAGIC ) {

		console.error( 'THREE.DDSLoader.parse: Invalid magic number in DDS header.' );
		return dds;

	}

	if ( ! header[ off_pfFlags ] & DDPF_FOURCC ) {

		console.error( 'THREE.DDSLoader.parse: Unsupported format, must contain a FourCC code.' );
		return dds;

	}

	var blockBytes;

	var fourCC = header[ off_pfFourCC ];

	var isRGBAUncompressed = false;

	switch ( fourCC ) {

		case FOURCC_DXT1:

			blockBytes = 8;
			dds.format = THREE.RGB_S3TC_DXT1_Format;
			break;

		case FOURCC_DXT3:

			blockBytes = 16;
			dds.format = THREE.RGBA_S3TC_DXT3_Format;
			break;

		case FOURCC_DXT5:

			blockBytes = 16;
			dds.format = THREE.RGBA_S3TC_DXT5_Format;
			break;

		default:

			if ( header[off_RGBBitCount] == 32 
				&& header[off_RBitMask]&0xff0000
				&& header[off_GBitMask]&0xff00 
				&& header[off_BBitMask]&0xff
				&& header[off_ABitMask]&0xff000000  ) {
				isRGBAUncompressed = true;
				blockBytes = 64;
				dds.format = THREE.RGBAFormat;
			} else {
				console.error( 'THREE.DDSLoader.parse: Unsupported FourCC code ', int32ToFourCC( fourCC ) );
				return dds;
			}
	}

	dds.mipmapCount = 1;

	if ( header[ off_mipmapCount ] > 0 && loadMipmaps !== false ) {

		dds.mipmapCount = Math.max( 1, header[ off_mipmapCount ] );

	}

	//TODO: Verify that all faces of the cubemap are present with DDSCAPS2_CUBEMAP_POSITIVEX, etc.

	dds.isCubemap = header[ off_caps2 ] & DDSCAPS2_CUBEMAP ? true : false;

	dds.width = header[ off_width ];
	dds.height = header[ off_height ];

	var dataOffset = header[ off_size ] + 4;

	// Extract mipmaps buffers

	var width = dds.width;
	var height = dds.height;

	var faces = dds.isCubemap ? 6 : 1;

	for ( var face = 0; face < faces; face ++ ) {

		for ( var i = 0; i < dds.mipmapCount; i ++ ) {

			if ( isRGBAUncompressed ) {
				var byteArray = loadARGBMip( buffer, dataOffset, width, height );
				var dataLength = byteArray.length;
			} else {
				var dataLength = Math.max( 4, width ) / 4 * Math.max( 4, height ) / 4 * blockBytes;
				var byteArray = new Uint8Array( buffer, dataOffset, dataLength );
			}
			
			var mipmap = { "data": byteArray, "width": width, "height": height };
			dds.mipmaps.push( mipmap );

			dataOffset += dataLength;

			width = Math.max( width * 0.5, 1 );
			height = Math.max( height * 0.5, 1 );

		}

		width = dds.width;
		height = dds.height;

	}

	return dds;

};

};
/*
 *	 PVRLoader
 *   Author: pierre lepers
 *   Date: 17/09/2014 11:09
 *
 *	 PVR v2 (legacy) parser
 *   TODO : Add Support for PVR v3 format
 *   TODO : implement loadMipmaps option
 */
function init_three_pvr_loader() {

THREE.PVRLoader = function ( manager ) {

	this.manager = ( manager !== undefined ) ? manager : THREE.DefaultLoadingManager;

	this._parser = THREE.PVRLoader.parse;

};

THREE.PVRLoader.prototype = Object.create( THREE.CompressedTextureLoader.prototype );
THREE.PVRLoader.prototype.constructor = THREE.PVRLoader;


THREE.PVRLoader.parse = function ( buffer, loadMipmaps ) {

	var headerLengthInt = 13;
	var header = new Uint32Array( buffer, 0, headerLengthInt );

	var pvrDatas = {
		buffer: buffer,
		header : header,
		loadMipmaps : loadMipmaps
	};

	// PVR v3
	if ( header[ 0 ] === 0x03525650 ) {

		return THREE.PVRLoader._parseV3( pvrDatas );

	}
	// PVR v2
	else if ( header[ 11 ] === 0x21525650 ) {

		return THREE.PVRLoader._parseV2( pvrDatas );

	} else {

		throw new Error( "[THREE.PVRLoader] Unknown PVR format" );

	}

};

THREE.PVRLoader._parseV3 = function ( pvrDatas ) {

	var header = pvrDatas.header;
	var bpp, format;


	var metaLen 	  = header[ 12 ],
		pixelFormat   =  header[ 2 ],
		height        =  header[ 6 ],
		width         =  header[ 7 ],
		numSurfs      =  header[ 9 ],
		numFaces      =  header[ 10 ],
		numMipmaps    =  header[ 11 ];

	switch ( pixelFormat ) {
		case 0 : // PVRTC 2bpp RGB
			bpp = 2;
			format = THREE.RGB_PVRTC_2BPPV1_Format;
			break;
		case 1 : // PVRTC 2bpp RGBA
			bpp = 2;
			format = THREE.RGBA_PVRTC_2BPPV1_Format;
			break;
		case 2 : // PVRTC 4bpp RGB
			bpp = 4;
			format = THREE.RGB_PVRTC_4BPPV1_Format;
			break;
		case 3 : // PVRTC 4bpp RGBA
			bpp = 4;
			format = THREE.RGBA_PVRTC_4BPPV1_Format;
			break;
		default :
			throw new Error( "pvrtc - unsupported PVR format " + pixelFormat );
	}

	pvrDatas.dataPtr 	 = 52 + metaLen;
	pvrDatas.bpp 		 = bpp;
	pvrDatas.format 	 = format;
	pvrDatas.width 		 = width;
	pvrDatas.height 	 = height;
	pvrDatas.numSurfaces = numFaces;
	pvrDatas.numMipmaps  = numMipmaps;

	pvrDatas.isCubemap 	= ( numFaces === 6 );

	return THREE.PVRLoader._extract( pvrDatas );

};

THREE.PVRLoader._parseV2 = function ( pvrDatas ) {

	var header = pvrDatas.header;

	var headerLength  =  header[ 0 ],
		height        =  header[ 1 ],
		width         =  header[ 2 ],
		numMipmaps    =  header[ 3 ],
		flags         =  header[ 4 ],
		dataLength    =  header[ 5 ],
		bpp           =  header[ 6 ],
		bitmaskRed    =  header[ 7 ],
		bitmaskGreen  =  header[ 8 ],
		bitmaskBlue   =  header[ 9 ],
		bitmaskAlpha  =  header[ 10 ],
		pvrTag        =  header[ 11 ],
		numSurfs      =  header[ 12 ];


	var TYPE_MASK = 0xff;
	var PVRTC_2 = 24,
		PVRTC_4 = 25;

	var formatFlags = flags & TYPE_MASK;



	var bpp, format;
	var _hasAlpha = bitmaskAlpha > 0;

	if ( formatFlags === PVRTC_4 ) {

		format = _hasAlpha ? THREE.RGBA_PVRTC_4BPPV1_Format : THREE.RGB_PVRTC_4BPPV1_Format;
		bpp = 4;

	} else if ( formatFlags === PVRTC_2 ) {

		format = _hasAlpha ? THREE.RGBA_PVRTC_2BPPV1_Format : THREE.RGB_PVRTC_2BPPV1_Format;
		bpp = 2;

	} else
		throw new Error( "pvrtc - unknown format " + formatFlags );



	pvrDatas.dataPtr 	 = headerLength;
	pvrDatas.bpp 		 = bpp;
	pvrDatas.format 	 = format;
	pvrDatas.width 		 = width;
	pvrDatas.height 	 = height;
	pvrDatas.numSurfaces = numSurfs;
	pvrDatas.numMipmaps  = numMipmaps + 1;

	// guess cubemap type seems tricky in v2
	// it juste a pvr containing 6 surface (no explicit cubemap type)
	pvrDatas.isCubemap 	= ( numSurfs === 6 );

	return THREE.PVRLoader._extract( pvrDatas );

};


THREE.PVRLoader._extract = function ( pvrDatas ) {

	var pvr = {
		mipmaps: [],
		width: pvrDatas.width,
		height: pvrDatas.height,
		format: pvrDatas.format,
		mipmapCount: pvrDatas.numMipmaps,
		isCubemap : pvrDatas.isCubemap
	};

	var buffer = pvrDatas.buffer;



	// console.log( "--------------------------" );

	// console.log( "headerLength ", headerLength);
	// console.log( "height       ", height      );
	// console.log( "width        ", width       );
	// console.log( "numMipmaps   ", numMipmaps  );
	// console.log( "flags        ", flags       );
	// console.log( "dataLength   ", dataLength  );
	// console.log( "bpp          ", bpp         );
	// console.log( "bitmaskRed   ", bitmaskRed  );
	// console.log( "bitmaskGreen ", bitmaskGreen);
	// console.log( "bitmaskBlue  ", bitmaskBlue );
	// console.log( "bitmaskAlpha ", bitmaskAlpha);
	// console.log( "pvrTag       ", pvrTag      );
	// console.log( "numSurfs     ", numSurfs    );




	var dataOffset = pvrDatas.dataPtr,
		bpp = pvrDatas.bpp,
		numSurfs = pvrDatas.numSurfaces,
		dataSize = 0,
		blockSize = 0,
		blockWidth = 0,
		blockHeight = 0,
		widthBlocks = 0,
		heightBlocks = 0;



	if ( bpp === 2 ) {

		blockWidth = 8;
		blockHeight = 4;

	} else {

		blockWidth = 4;
		blockHeight = 4;

	}

	blockSize = ( blockWidth * blockHeight ) * bpp / 8;

	pvr.mipmaps.length = pvrDatas.numMipmaps * numSurfs;

	var mipLevel = 0;

	while ( mipLevel < pvrDatas.numMipmaps ) {

		var sWidth = pvrDatas.width >> mipLevel,
		sHeight = pvrDatas.height >> mipLevel;

		widthBlocks = sWidth / blockWidth;
		heightBlocks = sHeight / blockHeight;

		// Clamp to minimum number of blocks
		if ( widthBlocks < 2 )
			widthBlocks = 2;
		if ( heightBlocks < 2 )
			heightBlocks = 2;

		dataSize = widthBlocks * heightBlocks * blockSize;


		for ( var surfIndex = 0; surfIndex < numSurfs; surfIndex ++ ) {

			var byteArray = new Uint8Array( buffer, dataOffset, dataSize );

			var mipmap = {
				data: byteArray,
				width: sWidth,
				height: sHeight
			};

			pvr.mipmaps[ surfIndex * pvrDatas.numMipmaps + mipLevel ] = mipmap;

			dataOffset += dataSize;


		}

		mipLevel ++;

	}


	return pvr;

};

}
;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;

// http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt
/* utf.js - UTF-8 <=> UTF-16 convertion
 *
 * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>
 * Version: 1.0
 * LastModified: Dec 25 1999
 * This library is free.  You can redistribute it and/or modify it.
 */
function utf8BlobToStr(array, start, length) {
    var out, i, len, c;
    var char2, char3;

    out = "";
    len = length;
    i = 0;
    while(i < len) {
        c = array[start + i++];
        switch(c >> 4)
        {
          case 0: case 1: case 2: case 3: case 4: case 5: case 6: case 7:
            // 0xxxxxxx
            out += String.fromCharCode(c);
            break;
          case 12: case 13:
            // 110x xxxx   10xx xxxx
            char2 = array[start + i++];
            out += String.fromCharCode(((c & 0x1F) << 6) | (char2 & 0x3F));
            break;
          case 14:
            // 1110 xxxx  10xx xxxx  10xx xxxx
            char2 = array[start + i++];
            char3 = array[start + i++];
            out += String.fromCharCode(((c & 0x0F) << 12) |
                           ((char2 & 0x3F) << 6) |
                           ((char3 & 0x3F) << 0));
            break;
        }
    }

    return out;
}


function utf16to8(str, array, start) {
    var i, len, c;

    var j = start || 0;
    len = str.length;

    if (array) {
        for(i = 0; i < len; i++) {
            c = str.charCodeAt(i);
            if ((c >= 0x0001) && (c <= 0x007F)) {
                array[j++] = str.charAt(i);
            } else if (c > 0x07FF) {
                array[j++] = String.fromCharCode(0xE0 | ((c >> 12) & 0x0F));
                array[j++] = String.fromCharCode(0x80 | ((c >>  6) & 0x3F));
                array[j++] = String.fromCharCode(0x80 | ((c >>  0) & 0x3F));
            } else {
                array[j++] = String.fromCharCode(0xC0 | ((c >>  6) & 0x1F));
                array[j++] = String.fromCharCode(0x80 | ((c >>  0) & 0x3F));
            }
        }
    } else {
        //If no output buffer is passed in, estimate the required
        //buffer size and return that.
        for(i = 0; i < len; i++) {
            c = str.charCodeAt(i);
            if ((c >= 0x0001) && (c <= 0x007F)) {
                j++;
            } else if (c > 0x07FF) {
                j+=3;
            } else {
                j+=2;
            }
        }
    }

    return j - (start || 0);
}

var USE_MANUAL_UTF8 = true;

lmv.utf8ArrayToString = function(array, start, length) {

    if (start === undefined)
        start = 0;
    if (length === undefined)
        length = array.length;

    if (USE_MANUAL_UTF8) {
        return utf8BlobToStr(array, start, length);
    } else {
        var encodedString = "";
        for (var i=start, iEnd=start+length; i<iEnd; i++)
            encodedString += String.fromCharCode(array[i]);

        return decodeURIComponent(escape(encodedString));
    }
};

lmv.blobToJson = function(blob) {

    var decodedString = lmv.utf8ArrayToString(blob, 0, blob.length);

    return JSON.parse(decodedString);
};

//parses a piece of json from a given blob (representing an array of json values)
//up to the next comma+newline combo (i.e. array delimiter).
lmv.subBlobToJson = function(blob, startIndex) {
    if (startIndex === undefined) {
        return '';
    }

    var i = startIndex;

    while (i<blob.length-1) {
        var c = blob[i];
        if (c == 44 && (blob[i+1] == 10 || blob[i+1] == 13)) //comma followed by newline?
            break;
        if (c == 10 || c == 13) //detect newline or line feed
            break;
        i++;
    }

    var decodedString = lmv.utf8ArrayToString(blob, startIndex, i-startIndex);
    try {
        return JSON.parse(decodedString);
    } catch (e) {
        console.error("Error parsing property blob to JSON : " + decodedString);
        return decodedString;
    }
};

lmv.subBlobToJsonInt = function(blob, startIndex) {
    var val = 0;
    var i = startIndex;

    //Check for integers that were serialized as strings.
    //This should not happen, ever, but hey, it does.
    if (blob[i] == 34)
        i++;

    while (i<blob.length-1) {
        var c = blob[i];
        if (c == 44 && (blob[i+1] == 10 || blob[i+1] == 13))
            break;
        if (c == 10 || c == 13 || c == 34)
            break;
        if (c >= 48 && c <= 57)
            val = val * 10 + (c - 48);

        i++;
    }

    return val;
};

//Simple integer array parse -- expects the array in property database
//format, where the array is packed with possibly newline separator,
//but no other white space. Does not do extensive error checking
lmv.parseIntArray = function(blob, wantSentinel) {

    //find out how many items we have
    var count = 0;
    for (var i= 0, iEnd=blob.length; i<iEnd; i++)
        if (blob[i] == 44) //44 = ','
            count++;

    count++; //last item has no comma after it

    var items = new Uint32Array(count + (wantSentinel ? 1 : 0));

    i=0;
    var end = blob.length;

    while (blob[i] != 91 && i<end) //91 = '['
        i++;

    if (i == blob.length)
        return null;

    i++;

    var seenDigit = false;
    count = 0;
    var curInt = 0;
    while (i<end) {
        var c = blob[i];
        if (c >= 48 && c <= 57) { //digit
            curInt = 10 * curInt + (c - 48);
            seenDigit = true;
        }
        else if (c == 44 || c == 93) { //',' or ']'
            if (seenDigit) {
                items[count++] = curInt;
                seenDigit = false;
                curInt = 0;
            }
        } else {
            seenDigit = false; //most likely a newline (the only other thing we have in our arrays
            curInt = 0;
        }
        i++;
    }

    return items;
};

//Scans an array of json values (strings, integers, doubles) and finds the
//offset of each value in the array, so that we can later pick off that
//specific value, without parsing the whole (potentially huge) json array up front.
//This expects the input blob to be in the form serialized by the property database
//C++ component -- one value per line. A more sophisticated parser would be needed
//in case the format changes and this assumption is not true anymore.
lmv.findValueOffsets = function(blob) {

    //first, count how many items we have
    var count = 0;
    var end = blob.length-1;

    for (var i= 0; i<end; i++) {
        if ( blob[i] == 44 && (blob[i+1] == 10 || blob[i+1] == 13)) // ',' + newline is the item delimiter
            count++;
    }

    if (!count)
        return null;

    count++; //one for the last item

    var items = new Uint32Array(count);

    i=0;
    count = 0;

    //find opening [
    while (blob[i] != 91 && i<end) //91 = '['
        i++;

    i++;

    items[count++] = i;
    var seenEol = false;
    while (i<end) {
        if (blob[i] == 10 || blob[i] == 13)
            seenEol = true;
        else if (seenEol) {
            seenEol = false;
            items[count++] = i;
        }

        i++;
    }

    return items;
};



})();;

(function() {

"use strict";

var lmv = Autodesk.LMVTK;

//We will use these shared memory arrays to
//convert from bytes to the desired data type.
var convBuf = new ArrayBuffer(8);
var convUint8 = new Uint8Array(convBuf);
var convUint16 = new Uint16Array(convBuf);
var convInt32 = new Int32Array(convBuf);
var convUint32 = new Uint32Array(convBuf);
var convFloat32 = new Float32Array(convBuf);
var convFloat64 = new Float64Array(convBuf);


/** @constructor */
function InputStream(buf) {
    this.buffer = buf;
    this.offset = 0;
    this.byteLength = buf.length;
}


InputStream.prototype.seek = function(off) {
    this.offset = off;
};

InputStream.prototype.getBytes = function(len) {
    var ret = new Uint8Array(this.buffer.buffer, this.offset, len);
    this.offset += len;
    return ret;
};

InputStream.prototype.getVarints = function () {
    var b;
    var value = 0;
    var shiftBy = 0;
    do {
        b = this.buffer[this.offset++];
        value |= (b & 0x7f) << shiftBy;
        shiftBy += 7;
    } while (b & 0x80);
    return value;
};

InputStream.prototype.getUint8 = function() {
    return this.buffer[this.offset++];
};

InputStream.prototype.getUint16 = function() {
    convUint8[0] = this.buffer[this.offset++];
    convUint8[1] = this.buffer[this.offset++];
    return convUint16[0];
};

InputStream.prototype.getInt16 = function() {
    var tmp = this.getUint16();
    //make negative integer if the ushort is negative
    if (tmp > 0x7fff)
        tmp = tmp | 0xffff0000;
    return tmp;
};

InputStream.prototype.getInt32 = function() {
    var src = this.buffer;
    var dst = convUint8;
    var off = this.offset;
    dst[0] = src[off];
    dst[1] = src[off+1];
    dst[2] = src[off+2];
    dst[3] = src[off+3];
    this.offset += 4;
    return convInt32[0];
};

InputStream.prototype.getUint32 = function() {
    var src = this.buffer;
    var dst = convUint8;
    var off = this.offset;
    dst[0] = src[off];
    dst[1] = src[off+1];
    dst[2] = src[off+2];
    dst[3] = src[off+3];
    this.offset += 4;
    return convUint32[0];
};

InputStream.prototype.getFloat32 = function() {
    var src = this.buffer;
    var dst = convUint8;
    var off = this.offset;
    dst[0] = src[off];
    dst[1] = src[off+1];
    dst[2] = src[off+2];
    dst[3] = src[off+3];
    this.offset += 4;
    return convFloat32[0];
};

//Specialized copy which copies 4 byte integers into 2-byte target.
//Used for downcasting OCTM int32 index buffers to int16 index buffers,
//in cases we know we don't need more (LMVTK guarantees 2 byte indices).
InputStream.prototype.getIndicesArray = function(buffer, offset, numItems) {

    var src = this.buffer;
    var dst = new Uint8Array(buffer, offset, numItems*2);
    var off = this.offset;

    for (var i= 0, iEnd=numItems*2; i<iEnd; i+=2) {
        dst[i] = src[off];
        dst[i+1] = src[off+1];
        off += 4;
    }

    this.offset = off;
};

InputStream.prototype.getVector3Array = function(arr, numItems, startOffset, stride) {
    var src = this.buffer;
    var off = this.offset;

    //We cannot use Float32Array copying here because the
    //source stream is out of alignment
    var dst = new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);

    if (stride === 3 && startOffset === 0) {
        var len = numItems*12;
        dst.set(src.subarray(off, off+len));
        this.offset += len;
    } else {

        stride *= 4;
        var aoff = startOffset * 4;
        for (var i=0; i<numItems; i++) {
            for (var j=0; j<12; j++) {
                dst[aoff+j] = src[off++];
            }
            aoff += stride;
        }

        this.offset = off;
    }
};

InputStream.prototype.getVector2Array = function(arr, numItems, startOffset, stride) {
    var src = this.buffer;
    var dst = new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);
    var off = this.offset;

    stride *= 4;
    var aoff = startOffset * 4;
    for (var i=0; i<numItems; i++) {
        for (var j=0; j<8; j++) {
            dst[aoff+j] = src[off++];
        }
        aoff += stride;
    }

    this.offset = off;
};

InputStream.prototype.getVector4 = function(arr, offset) {
    var src = this.buffer;
    var dst = convUint8;
    var off = this.offset;
    var conv = convFloat32;

    for (var j=0; j<4; j++) {
        dst[0] = src[off];
        dst[1] = src[off+1];
        dst[2] = src[off+2];
        dst[3] = src[off+3];
        arr[offset+j] = conv[0];
        off += 4;
    }

    this.offset = off;
};

InputStream.prototype.getFloat64 = function() {
    var src = this.buffer;
    var dst = convUint8;
    var off = this.offset;
    for (var i=0; i<8; i++)
        dst[i] = src[off+i];
    this.offset += 8;
    return convFloat64[0];
};



InputStream.prototype.getString = function(len) {
    var res = lmv.utf8ArrayToString(this.buffer, this.offset, len);
    this.offset += len;
    return res;
};

InputStream.prototype.reset = function (buf) {
    this.buffer = buf;
    this.offset = 0;
    this.byteLength = buf.length;
};

lmv.InputStream = InputStream;

})();
;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;


lmv.VBUtils = {


    deduceUVRepetition: function(mesh) {

        for (var p in mesh.vblayout) {

            if (p.indexOf("uv") != 0 || p.indexOf("uvw") == 0)
                continue;

            var baseOffset = mesh.vblayout[p].offset;
            var floatStride = mesh.vbstride;
            var vbf = mesh.vb;
            var vcount = mesh.vb.length/floatStride;

            for (var i = 0, offset = baseOffset; i<vcount; i++, offset += floatStride)
            {
                var u = vbf[offset];
                var v = vbf[offset+1];
                if (u > 2 || u < 0 || v > 2 || v < 0) {
                    mesh.vblayout[p].isPattern = true;
                    break;
                }
            }
        }
    },


    //Calculate the 3D bounding box and bounding sphere
    //of a mesh containing an interleaved vertex buffer
    computeBounds3D : function(mesh) {

        var minx = Infinity, miny = Infinity, minz = Infinity;
        var maxx = -Infinity, maxy = -Infinity, maxz = -Infinity;
        var i, offset, x, y, z;

        var floatStride = mesh.vbstride;
        var baseOffset = mesh.vblayout.position.offset;
        var vbf = mesh.vb;
        var vcount = mesh.vb.length/floatStride;

        for (i = 0, offset = baseOffset; i<vcount; i++, offset += floatStride)
        {
            x = vbf[offset];
            y = vbf[offset+1];
            z = vbf[offset+2];

            if (minx > x) minx = x;
            if (miny > y) miny = y;
            if (minz > z) minz = z;

            if (maxx < x) maxx = x;
            if (maxy < y) maxy = y;
            if (maxz < z) maxz = z;
        }

        var bb = mesh.boundingBox = {
                min:{x:minx, y:miny, z:minz},
                max:{x:maxx, y:maxy, z:maxz}
        };

        var cx = 0.5*(minx + maxx), cy = 0.5*(miny + maxy), cz = 0.5*(minz + maxz);

        var bs = mesh.boundingSphere = {};
        bs.center = {x:cx, y:cy, z:cz};

        var maxRadiusSq = 0;
        for (i = 0, offset = baseOffset; i < vcount; i++, offset += floatStride) {

            x = vbf[offset];
            y = vbf[offset+1];
            z = vbf[offset+2];

            var dx = x - cx;
            var dy = y - cy;
            var dz = z - cz;
            var distsq = dx*dx + dy*dy + dz*dz;
            if (distsq > maxRadiusSq)
                maxRadiusSq = distsq;
        }

        bs.radius = Math.sqrt(maxRadiusSq);

    },

    bboxUnion : function(bdst, bsrc) {
        if (bsrc.min.x < bdst.min.x)
            bdst.min.x = bsrc.min.x;
        if (bsrc.min.y < bdst.min.y)
            bdst.min.y = bsrc.min.y;
        if (bsrc.min.z < bdst.min.z)
            bdst.min.z = bsrc.min.z;

        if (bsrc.max.x > bdst.max.x)
            bdst.max.x = bsrc.max.x;
        if (bsrc.max.y > bdst.max.y)
            bdst.max.y = bsrc.max.y;
        if (bsrc.max.z > bdst.max.z)
            bdst.max.z = bsrc.max.z;
    }

};

})();
;

(function() {

"use strict";

var av = Autodesk.Viewing,
    avp = av.Private;

var TAU = Math.PI * 2;

var VBB_GT_TRIANGLE_INDEXED = 0,
    VBB_GT_LINE_SEGMENT     = 1,
    VBB_GT_ARC_CIRCULAR     = 2,
    VBB_GT_ARC_ELLIPTICAL   = 3,
    VBB_GT_TEX_QUAD         = 4,
    VBB_GT_ONE_TRIANGLE     = 5;

var VBB_INSTANCED_FLAG  = 0, // this is intentionally 0 for the instancing case!
    VBB_SEG_START_RIGHT = 0, // this starts intentionally at 0!
    VBB_SEG_START_LEFT  = 1,
    VBB_SEG_END_RIGHT   = 2,
    VBB_SEG_END_LEFT    = 3;

var VBB_COLOR_OFFSET    = 6,
    VBB_DBID_OFFSET     = 7,
    VBB_FLAGS_OFFSET    = 8,
    VBB_LAYER_VP_OFFSET = 9;

var QUAD_TRIANGLE_INDICES = [ 0,1,3, 0,3,2 ];

function VertexBufferBuilder(useInstancing, allocSize, fullCount)
{
    var MAX_VCOUNT = allocSize || 65536;
    this.FULL_COUNT = (fullCount || 32767) | 0;

    this.useInstancing = useInstancing;

    //TODO: Temporarily expand the stride to the full one, in order to work around new
    //more strict WebGL validation which complains when a shader addresses attributes outside
    //the vertex buffer, even when it does not actually access them. We would need separate shader
    //configurations for each of the two possible vertex strides for the selection shader, which is
    //currently shared between all 2d geometries.
    //this.stride = 10;
    this.stride = 12;

    this.vb  = new ArrayBuffer(this.stride * 4 * (this.useInstancing ? MAX_VCOUNT / 4 : MAX_VCOUNT));
    this.vbf = new Float32Array(this.vb);
    this.vbi = new Int32Array(this.vb);
    this.ib = this.useInstancing ? null : new Uint16Array(MAX_VCOUNT);
    this.reset(0);
}

VertexBufferBuilder.prototype.reset = function(vcount) {
    // This is used to restore the vcount when restoring stream state as well as at init time.
    this.vcount = vcount;

    this.icount = 0;

    this.minx = this.miny =  Infinity;
    this.maxx = this.maxy = -Infinity;

    //Keeps track of objectIds referenced by geometry in the VB
    this.dbIds = {};

    this.numEllipticals   = 0;
    this.numCirculars     = 0;
    this.numTriangleGeoms = 0;
}

VertexBufferBuilder.prototype.expandStride = function()
{
    // since we already set the stride to the current max value of 12 in the
    // constructor above, we don't need to do anything here right now...
    return;

/*
    //Currently hardcoded to expand by 4 floats.
    var expandBy = 2;

    var stride = this.stride;

    if (stride >= 12)
        return;

    var nstride = this.stride + expandBy;

    var nvb = new ArrayBuffer(nstride * (this.vb.byteLength / stride));

    var src = new Uint8Array(this.vb);
    var dst = new Uint8Array(nvb);

    for (var i = 0, iEnd = this.vcount; i<iEnd; i++) {
        var os = i * stride * 4;
        var od = i * nstride * 4;

        for (var j=0; j<stride * 4; j++)
            dst[od+j] = src[os+j];
    }

    this.vb = nvb;
    this.vbf = new Float32Array(nvb);
    this.vbi = new Int32Array(nvb);
    this.stride = nstride;
*/
};

VertexBufferBuilder.prototype.addToBounds = function(x, y)
{
    if (x < this.minx) this.minx = x;
    if (x > this.maxx) this.maxx = x;
    if (y < this.miny) this.miny = y;
    if (y > this.maxy) this.maxy = y;
};

VertexBufferBuilder.prototype.setCommonVertexAttribs = function(offset, vertexId, geomType, color, dbId, layerId, vpId, linePattern)
{
    // align changes here with the "decodeCommonAttribs()" function in LineShader.js and VertexBufferReader.js!!!
    vertexId    = (vertexId    &   0xff); //  8 bit
    geomType    = (geomType    &   0xff); //  8 bit
    linePattern = (linePattern &   0xff); //  8 bit
    layerId     = (layerId     & 0xffff); // 16 bit
    vpId        = (vpId        & 0xffff); // 16 bit

    this.vbi[offset + VBB_FLAGS_OFFSET]    = vertexId | (geomType << 8) | (linePattern << 16); // vertexId: int8; geomType: int8; linePattern: int8; unused: int8
    this.vbi[offset + VBB_COLOR_OFFSET]    = color;
    this.vbi[offset + VBB_DBID_OFFSET]     = dbId;
    this.vbi[offset + VBB_LAYER_VP_OFFSET] = layerId | (vpId << 16); // layerId: int16; vpId: int16

    this.dbIds[dbId] = 1; // mark this feature as used
}

//Creates a non-indexed triangle geometry vertex (triangle vertex coords stored in single vertex structure)
VertexBufferBuilder.prototype.addVertexTriangleGeom = function(x1, y1, x2, y2, x3, y3, color, dbId, layerId, vpId)
{
    var vi  = this.vcount;
    var vbf = this.vbf;

    var repeat = this.useInstancing ? 1 : 4;
    for (var i=0; i<repeat; i++) {
        var offset = (vi+i) * this.stride;

        // align changes here with the "decodeTriangleData()" function in LineShader.js!!!
        vbf[offset]   = x1;
        vbf[offset+1] = y1;
        vbf[offset+2] = x2;

        vbf[offset+3] = y2;
        vbf[offset+4] = x3;
        vbf[offset+5] = y3;

        this.setCommonVertexAttribs(offset, VBB_SEG_START_RIGHT + i, VBB_GT_ONE_TRIANGLE, color, dbId, layerId, vpId, /*linePattern*/0);
        this.vcount++;
    }

    return vi;
};


VertexBufferBuilder.prototype.addVertexLine = function(x, y, angle, distanceAlong, totalDistance, lineWidth, color, dbId, layerId, vpId, lineType)
{
    var vi  = this.vcount;
    var vbf = this.vbf;

    var repeat = this.useInstancing ? 1 : 4;
    for (var i=0; i<repeat; i++) {
        var offset = (vi + i) * this.stride;

        // align changes here with the "decodeSegmentData()" function in LineShader.js!!!
        vbf[offset]   = x;
        vbf[offset+1] = y;
        vbf[offset+2] = angle;

        vbf[offset+3] = distanceAlong;
        vbf[offset+4] = lineWidth * 0.5; // we are storing only the half width (i.e., the radius)
        vbf[offset+5] = totalDistance;

        this.setCommonVertexAttribs(offset, VBB_SEG_START_RIGHT + i, VBB_GT_LINE_SEGMENT, color, dbId, layerId, vpId, lineType);
        this.vcount++;
    }

    return vi;
};

VertexBufferBuilder.prototype.addVertexTexQuad = function(centerX, centerY, width, height, rotation, color, dbId, layerId, vpId)
{
    var vi  = this.vcount;
    var vbf = this.vbf;

    var repeat = this.useInstancing ? 1 : 4;
    for (var i=0; i<repeat; i++) {
        var offset = (vi + i) * this.stride;

        // align changes here with the "decodeTexQuadData()" function in LineShader.js!!!
        vbf[offset]   = centerX;
        vbf[offset+1] = centerY;
        vbf[offset+2] = rotation;

        vbf[offset+3] = width;
        vbf[offset+4] = height;

        this.setCommonVertexAttribs(offset, VBB_SEG_START_RIGHT + i, VBB_GT_TEX_QUAD, color, dbId, layerId, vpId, /*linePattern*/0);
        this.vcount++;
    }

    return vi;
};


VertexBufferBuilder.prototype.addVertexArc = function(x, y, startAngle, endAngle, major, minor, tilt, lineWidth, color, dbId, layerId, vpId)
{
    var vi  = this.vcount;
    var vbf = this.vbf;

    var geomType = (major == minor) ? VBB_GT_ARC_CIRCULAR : VBB_GT_ARC_ELLIPTICAL;

    var repeat = this.useInstancing ? 1 : 4;
    for (var i=0; i<repeat; i++) {
        var offset = (vi+i) * this.stride;

        // align changes here with the "decodeArcData()" function in LineShader.js!!!
        vbf[offset]   = x;
        vbf[offset+1] = y;
        vbf[offset+2] = startAngle;

        vbf[offset+3] = endAngle;
        vbf[offset+4] = lineWidth * 0.5; // we are storing only the half width (i.e., the radius)
        vbf[offset+5] = major; // = radius for circular arcs

        if (geomType === VBB_GT_ARC_ELLIPTICAL) {
            vbf[offset+10] = minor;
            vbf[offset+11] = tilt;
        }

        this.setCommonVertexAttribs(offset, VBB_SEG_START_RIGHT + i, geomType, color, dbId, layerId, vpId, /*linePattern*/0);
        this.vcount++;
    }

    return vi;
};




//====================================================================================================
//====================================================================================================
// Indexed triangle code path can only be used when hardware instancing is not in use.
// Otherwise, the addTriangleGeom operation should be used to add simple triangles to the buffer.
//====================================================================================================
//====================================================================================================

VertexBufferBuilder.prototype.addVertex = function(x, y, color, dbId, layerId, vpId)
{
    if (this.useInstancing)
        return;//not supported if instancing is used.

    var vi     = this.vcount;
    var offset = this.stride * vi;
    var vbf    = this.vbf;

    // align changes here with the "decodeTriangleData()" function in LineShader.js!!!
    vbf[offset]   = x;
    vbf[offset+1] = y;

    this.setCommonVertexAttribs(offset, /*vertexId*/0, VBB_GT_TRIANGLE_INDEXED, color, dbId, layerId, vpId, /*linePattern*/0);
    this.vcount++;

    return vi;
};


VertexBufferBuilder.prototype.addVertexPolytriangle = function(x, y, color, dbId, layerId, vpId)
{
    if (this.useInstancing)
        return;//not supported if instancing is used.

    this.addVertex(x, y, color, dbId, layerId, vpId);

    this.addToBounds(x, y);
};

VertexBufferBuilder.prototype.addIndices = function(indices, vindex) {

    if (this.useInstancing)
        return; //not supported if instancing is used.

    var ib = this.ib;
    var ii = this.icount;

    if (ii + indices.length >= ib.length) {
        var ibnew = new Uint16Array(Math.max(indices.length, ib.length) * 2);
        for (var i=0; i<ii; ++i) {
            ibnew[i] = ib[i];
        }
        this.ib = ib = ibnew;
    }

    for(var i=0; i<indices.length; ++i) {
        ib[ii+i] = vindex + indices[i];
    }

    this.icount += indices.length;
};

//====================================================================================================
//====================================================================================================
// End indexed triangle code path.
//====================================================================================================
//====================================================================================================


VertexBufferBuilder.prototype.finalizeQuad = function(vindex)
{
    if (!this.useInstancing) {
        this.addIndices(QUAD_TRIANGLE_INDICES, vindex);
    }
};


VertexBufferBuilder.prototype.addSegment = function(x1, y1, x2, y2, totalDistance, lineWidth, color, dbId, layerId, vpId, lineType)
{
    var dx = x2 - x1;
    var dy = y2 - y1;
    var angle  = (dx || dy) ? Math.atan2(dy, dx)       : 0.0;
    var segLen = (dx || dy) ? Math.sqrt(dx*dx + dy*dy) : 0.0;

    //Add four vertices for the bbox of this line segment
    //This call sets the stuff that's common for all four
    var v = this.addVertexLine(x1, y1, angle, segLen, totalDistance, lineWidth, color, dbId, layerId, vpId, lineType);

    this.finalizeQuad(v);
    this.addToBounds(x1, y1);
    this.addToBounds(x2, y2);
};


//Creates a non-indexed triangle geometry (triangle vertex coords stored in single vertex structure)
VertexBufferBuilder.prototype.addTriangleGeom = function(x1, y1, x2, y2, x3, y3, color, dbId, layerId, vpId)
{
    this.numTriangleGeoms++;

    var v = this.addVertexTriangleGeom(x1, y1, x2, y2, x3, y3, color, dbId, layerId, vpId);

    this.finalizeQuad(v);
    this.addToBounds(x1, y1);
    this.addToBounds(x2, y2);
    this.addToBounds(x3, y3);
};

VertexBufferBuilder.prototype.addArc = function(cx, cy, start, end, major, minor, tilt, lineWidth, color, dbId, layerId, vpId)
{
    if(major == minor)  {
        this.numCirculars++;
    } else {
        this.numEllipticals++;
    }

    // This is a workaround, when the circular arc has rotation, the extractor cannot handle it.
    // After the fix is deployed in extractor, this can be removed.
    var result = fixUglyArc(start, end);
    start = result.start;
    end   = result.end;

    //If both start and end angles are exactly 0, it's a complete ellipse/circle
    //This is working around a bug in the F2D writer, where an fmod operation will potentially.
    //convert 2pi to 0.
    if (start == 0 && end == 0)
        end = TAU;

    //Add two zero length segments as round caps at the end points
    {
        //If it's a full ellipse, then we don't need caps
        var range = Math.abs(start - end);
        if (range > 0.0001 && Math.abs(range - TAU) > 0.0001)
        {
            var sx = cx + major * Math.cos(start);
            var sy = cy + minor * Math.sin(start);
            this.addSegment(sx, sy, sx, sy, 0, lineWidth, color, dbId, layerId, vpId);

            var ex = cx + major * Math.cos(end);
            var ey = cy + minor * Math.sin(end);
            this.addSegment(ex, ey, ex, ey, 0, lineWidth, color, dbId, layerId, vpId);

            //TODO: also must add all the vertices at all multiples of PI/2 in the start-end range to get exact bounds
        }
        else
        {
            this.addToBounds(cx - major, cy - minor);
            this.addToBounds(cx + major, cy + minor);
        }
    }

    var v = this.addVertexArc(cx, cy, start, end, major, minor, tilt, lineWidth, color, dbId, layerId, vpId);

    this.finalizeQuad(v);

    //Testing caps
    if(false) {
        //If it's a full ellipse, then we don't need caps
        var range = Math.abs(start - end);
        if (Math.abs(range - TAU) > 0.0001)
        {
            var sx = cx + major * Math.cos(start);
            var sy = cy + minor * Math.sin(start);
            this.addSegment(sx, sy, sx, sy, 0, lineWidth, 0xff00ffff, dbId, layerId, vpId);

            var ex = cx + major * Math.cos(end);
            var ey = cy + minor * Math.sin(end);
            this.addSegment(ex, ey, ex, ey, 0, lineWidth, 0xff00ffff, dbId, layerId, vpId);
        }
    }
}


VertexBufferBuilder.prototype.addTexturedQuad = function(centerX, centerY, width, height, rotation, color, dbId, layerId, vpId)
{
    //Height is specified using the line weight field.
    //This will result in height being clamped to at least one pixel
    //but that's ok (zero height for an image would be rare).
    var v = this.addVertexTexQuad(centerX, centerY, width, height, rotation, color, dbId, layerId, vpId);

    this.finalizeQuad(v);

    var cos = 0.5 * Math.cos(rotation);
    var sin = 0.5 * Math.sin(rotation);
    var w = Math.abs(width * cos) + Math.abs(height * sin);
    var h = Math.abs(width * sin) + Math.abs(height * cos);
    this.addToBounds(centerX - w, centerY - h);
    this.addToBounds(centerX + w, centerY + h);
};

VertexBufferBuilder.prototype.isFull = function(addCount)
{
    addCount = addCount || 3;
    var mult = this.useInstancing ? 4 : 1;

    return (this.vcount * mult + addCount > this.FULL_COUNT);
};

VertexBufferBuilder.prototype.toMesh = function()
{
    var mesh = {};

    mesh.vb = new Float32Array(this.vb.slice(0, this.vcount * this.stride * 4));
    mesh.vbstride = this.stride;

    var d = this.useInstancing ? 1 : 0;

    mesh.vblayout = {
        "fields1" :    { offset: 0,                   itemSize: 3, bytesPerItem: 4, divisor: d, normalize: false },
        "fields2" :    { offset: 3,                   itemSize: 3, bytesPerItem: 4, divisor: d, normalize: false },
        "color4b":     { offset: VBB_COLOR_OFFSET,    itemSize: 4, bytesPerItem: 1, divisor: d, normalize: true  },
        "dbId4b":      { offset: VBB_DBID_OFFSET,     itemSize: 4, bytesPerItem: 1, divisor: d, normalize: false },
        "flags4b":     { offset: VBB_FLAGS_OFFSET,    itemSize: 4, bytesPerItem: 1, divisor: d, normalize: false },
        "layerVp4b":   { offset: VBB_LAYER_VP_OFFSET, itemSize: 4, bytesPerItem: 1, divisor: d, normalize: false }
    };

    //Are we using an expanded vertex layout -- then add the extra attribute to the layout
    if (this.stride > 10) {
        mesh.vblayout["extraParams"] = { offset: 10, itemSize: 2, bytesPerItem: 4, divisor: d, normalize: false };
    }

    if (this.useInstancing) {
        mesh.numInstances = this.vcount;

        //Set up trivial vertexId and index attributes

        var instFlags = new Int32Array([ VBB_SEG_START_RIGHT, VBB_SEG_START_LEFT, VBB_SEG_END_RIGHT, VBB_SEG_END_LEFT ]);
        mesh.vblayout.instFlags4b = { offset: 0, itemSize: 4, bytesPerItem: 1, divisor: 0, normalize: false };
        mesh.vblayout.instFlags4b.array = instFlags.buffer;

        var idx = mesh.indices = new Uint16Array(QUAD_TRIANGLE_INDICES);
    } else {
        mesh.indices = new Uint16Array(this.ib.buffer.slice(0, 2 * this.icount));
    }

    mesh.dbIds = this.dbIds;

    var w  = this.maxx - this.minx;
    var h  = this.maxy - this.miny;
    var sz = Math.max(w, h);

    mesh.boundingBox = {
        min: { x: this.minx, y: this.miny, z: -sz * 1e-3 },
        max: { x: this.maxx, y: this.maxy, z:  sz * 1e-3 }
    };

    //Also compute a rough bounding sphere
    var bs = mesh.boundingSphere = {
        center: {
            x: 0.5 * (this.minx + this.maxx),
            y: 0.5 * (this.miny + this.maxy),
            z: 0.0
        },
        radius: 0.5 * Math.sqrt(w*w + h*h)
    };

    return mesh;
};

// The following logic attempts to "fix" imprecisions in arc definitions introduced
// by Heidi's fixed point math, in case that the extractor doesn't handle it correctly.

var fixUglyArc = function (start, end)
{
    //Snap critical angles exactly
    function snapCritical() {
        function fuzzyEquals(a, b) { return (Math.abs(a - b) < 1e-3); }

        if (fuzzyEquals(start, 0))   start = 0.0;
        if (fuzzyEquals(end,   0))   end   = 0.0;
        if (fuzzyEquals(start, TAU)) start = TAU;
        if (fuzzyEquals(end,   TAU)) end   = TAU;
    }

    snapCritical();

    //OK, in some cases the angles are both over-rotated...
    if (start > end) {
        while (start > TAU) {
            start -= TAU;
            end   -= TAU;
        }
    } else {
        while (end > TAU) {
            start -= TAU;
            end   -= TAU;
        }
    }

    //Snap critical angles exactly -- again
    snapCritical();

    //If the arc crosses the x axis, we have to make it clockwise...
    //This is a side effect of bringing over-rotated arcs in range above.
    //For example start = 5.0, end = 7.0 will result in start < 0 and end > 0,
    //so we have to make start > end in order to indicate we are crossing angle = 0.
    if (start < 0 && end > 0) {
        start += TAU;
    }

    return {start: start, end: end};
};

avp.VertexBufferBuilder = VertexBufferBuilder;

})();
;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;

var warnedGzip = false;

/** @constructor */
function PackFileReader(data)
{
    var stream = this.stream = new lmv.InputStream(data);

    var len = stream.getInt32();
    this.type = stream.getString(len);
    this.version = stream.getInt32();

    this.types = null;
    this.entryOffsets = [];

    //read the table of contents
    {
        var offset = stream.offset;

        // Jump to file footer.
        stream.seek(stream.byteLength - 8);

        // Jump to toc.
        var tocOffset = stream.getUint32();
        this.typesOffset = stream.getUint32();

        // Populate type sets.
        stream.seek(this.typesOffset);
        var typesCount = this.readU32V();
        this.types = [];
        for (var i = 0; i < typesCount; ++i)
            this.types.push({
                "entryClass": this.readString(),
                "entryType": this.readString(),
                "version": this.readU32V()
            });

        // Populate data offset list.
        stream.seek(tocOffset);
        var entryCount = this.readU32V();
        var dso = this.entryOffsets;
        for (var i = 0; i < entryCount; ++i)
            dso.push(stream.getUint32());

        // Restore sanity of the world.
        stream.seek(offset);
    }
};

PackFileReader.prototype.readVarint = function() {
    var b;
    var value = 0;
    var shiftBy = 0;
    do {
        b = this.stream.getUint8();
        value |= (b & 0x7f) << shiftBy;
        shiftBy += 7;
    } while (b & 0x80);
    return value;
};
PackFileReader.prototype.readU32V = PackFileReader.prototype.readVarint;

PackFileReader.prototype.readU16 = function () {
    return this.stream.getUint16();
};

PackFileReader.prototype.readU8 = function () {
    return this.stream.getUint8();
};

PackFileReader.prototype.readString = function() {
    return this.stream.getString(this.readU32V());
};

PackFileReader.prototype.readVector3f = function () {
    var s = this.stream;
    return { x:s.getFloat32(), y:s.getFloat32(), z:s.getFloat32()};
};

PackFileReader.prototype.readF32 = function () {
    return this.stream.getFloat32();
};

PackFileReader.prototype.readVector3d = (function() {

    var t = { x:0, y:0, z:0 };

    return function () {
        var s = this.stream;
        t.x = s.getFloat64();
        t.y = s.getFloat64();
        t.z = s.getFloat64();

        return t;
    };
})();

PackFileReader.prototype.readQuaternionf = (function() {

    var q = { x:0, y:0, z:0, w:0 };

    return function() {
        var s = this.stream;
        q.x = s.getFloat32();
        q.y = s.getFloat32();
        q.z = s.getFloat32();
        q.w = s.getFloat32();

        return q;
    };

})();

PackFileReader.prototype.readMatrix3f = (function() {

    var _m = new LmvMatrix4();

    return function(dst) {
        if (!dst) dst = _m;
            
        var s = this.stream;
        dst.identity();
        for (var i = 0; i < 3; ++i)
            for (var j = 0; j < 3; ++j)
                dst.elements[4*i+j] = s.getFloat32();

        return dst;
    };

})();



PackFileReader.prototype.readTransform = (function() {

    var s = { x:1, y:1, z:1 };
    var m = new LmvMatrix4(true);

    return function(entityIndex, buffer, offset, placementTransform, globalOffset, originalTranslation)
    {
        var stream = this.stream;
        var t, q;

        var transformType = stream.getUint8();

        switch (transformType)
        {
            case 4/*TransformType.Identity*/: {
                m.identity();
            } break;
            case 0/*TransformType.Translation*/: {
                t = this.readVector3d();
                m.makeTranslation(t.x, t.y, t.z);
            } break;
            case 1/*TransformType.RotationTranslation*/: {
                q = this.readQuaternionf();
                t = this.readVector3d();
                s.x = 1;s.y = 1;s.z = 1;
                m.compose(t, q, s);
            } break;
            case 2/*TransformType.UniformScaleRotationTranslation*/: {
                var scale = stream.getFloat32();
                q = this.readQuaternionf();
                t = this.readVector3d();
                s.x = scale; s.y = scale; s.z = scale;
                m.compose(t, q, s);
            } break;
            case 3/*TransformType.AffineMatrix*/: {
                this.readMatrix3f(m);
                t = this.readVector3d();
                m.setPosition(t);
            } break;
            default:
                break; //ERROR
        }

        //Report the original translation term to the caller, if they need it.
        //This is only required when reading fragment bounding boxes, where the translation
        //term of this matrix is subtracted from the bbox terms.
        if (originalTranslation) {
            originalTranslation[0] = m.elements[12];
            originalTranslation[1] = m.elements[13];
            originalTranslation[2] = m.elements[14];
        }

        //Apply any placement transform
        if (placementTransform) {
            m.multiplyMatrices(placementTransform, m);
        }

        //Apply global double precision offset on top
        if (globalOffset) {
            m.elements[12] -= globalOffset.x;
            m.elements[13] -= globalOffset.y;
            m.elements[14] -= globalOffset.z;
        }

        //Store result back into single precision matrix or array
        if (entityIndex !== undefined) {
            var src = m.elements;
            // Sometimes we don't want to keep this data (e.g. when we are probing the fragment list
            // to find the data base id to fragment index mappings used for fragment filtering) so we
            // pass a null buffer and if that is the case, bail out here.
            if (!buffer) return;
            buffer[offset+0] = src[0]; buffer[offset+1] = src[1]; buffer[offset+2] = src[2];
            buffer[offset+3] = src[4]; buffer[offset+4] = src[5]; buffer[offset+5] = src[6];
            buffer[offset+6] = src[8]; buffer[offset+7] = src[9]; buffer[offset+8] = src[10];
            buffer[offset+9] = src[12]; buffer[offset+10] = src[13]; buffer[offset+11] = src[14];
        }
        else {
            return new LmvMatrix4().copy(m);
        }
    };

})();

PackFileReader.prototype.getEntryCounts = function() {
    return this.entryOffsets.length;
};

PackFileReader.prototype.seekToEntry = function(entryIndex) {
    var count = this.getEntryCounts();
    if (entryIndex >= count)
        return null;

    // Read the type index and populate the entry data
    this.stream.seek(this.entryOffsets[entryIndex]);
    var typeIndex = this.stream.getUint32();
    if (typeIndex >= this.types.length)
        return null;

    return this.types[typeIndex];
};


PackFileReader.prototype.readPathID = function() {
    var s = this.stream;

    //Construct a /-delimited string as the path to a node
    //TODO: in case we need a split representation (e.g. to follow paths), then
    //an array of numbers might be better to return from here.
    if (this.version < 2) {
        var pathLength = s.getUint16();
        if (!pathLength)
            return null;

        //The first number in a path ID is always zero (root)
        //so we skip adding it to the path string here.
        //Remove this section if that is not the case in the future.
        s.getUint16();
        if (pathLength == 1)
            return "";

        var path = s.getUint16();
        for (var i = 2; i < pathLength; ++i) {
            path += "/" + s.getUint16();
        }
    }
    else {
        var pathLength = this.readU32V();
        if (!pathLength)
            return null;

        //The first number in a path ID is always zero (root)
        //so we skip adding it to the path string here.
        //Remove this section if that is not the case in the future.
        this.readU32V();
        if (pathLength == 1)
            return "";

        var path = this.readU32V();
        for (var i = 2; i < pathLength; ++i) {
            path += "/" + this.readU32V();
        }
    }
    return path;
};

lmv.PackFileReader = PackFileReader;

})();;

(function() {

"use strict";

var lmv = Autodesk.LMVTK;


//=====================================================================
//=====================================================================
//=====================================================================
//=====================================================================
//=====================================================================
//=====================================================================
//=====================================================================

var ntmp = new Float32Array(3);

var INV_PI = 1.0 / Math.PI;

//Faster approximation to atan2
//http://math.stackexchange.com/questions/1098487/atan2-faster-approximation
//The algorithm does not deal with special cases such as x=0,y=0x=0,y=0,
//nor does it consider special IEEE-754 floating-point operands such as infinities and NaN.
function atan2(y, x) {
    var ax = Math.abs(x);
    var ay = Math.abs(y);
    //var a = (ax > ay) ? ay / ax : ax / ay;
    var a = Math.min(ax, ay) / Math.max(ax, ay);
    var s = a * a;
    var r = ((-0.0464964749 * s + 0.15931422) * s - 0.327622764) * s * a + a;
    if (ay > ax)
        r = 1.57079637 - r;
    if (x < 0)
        r = 3.14159274 - r;
    if (y < 0)
        r = -r;
    return r;
}

function readOpenCTM_RAW(stream, mesh, dstBuffer, startOffset, estimateSizeOnly) {

    var readOpenCTMString = function() {
        return stream.getString(stream.getInt32());
    };

    //Now do the data reads
    var name = stream.getString(4);
    if (name != "INDX") return null;

    var vcount = mesh.vertexCount;
    var tcount = mesh.triangleCount;
    var stride = mesh.vbstride;

    //We will create a single ArrayBuffer to back both the vertex and index buffers
    //The indices will be places after the vertex information, because we need alignment
    //of 4 bytes
    var vbSizeFloat = vcount * stride;
    var totalSizeInFloats = vbSizeFloat + ((tcount*3*2 + 3) / 4)|0;

    mesh.sharedBufferBytes = totalSizeInFloats * 4;

    if (estimateSizeOnly) {
        return;
    }

    var vbf;
    if (!dstBuffer) {
        dstBuffer = new ArrayBuffer(totalSizeInFloats * 4);
        startOffset = 0;
    }

    vbf = mesh.vb = new Float32Array(dstBuffer, startOffset, vbSizeFloat);
    mesh.indices = new Uint16Array(dstBuffer, startOffset + vbSizeFloat*4, tcount*3);
    stream.getIndicesArray(vbf.buffer, startOffset + vbSizeFloat*4, tcount*3);

    name = stream.getString(4);
    if (name != "VERT") return null;

    var vbi;
    //See if we want to pack the normals into two shorts
    if (mesh.vblayout.normal && mesh.vblayout.normal.itemSize === 2)
        vbi = new Uint16Array(vbf.buffer, vbf.byteOffset, vbf.byteLength / 2);

    //Read positions
    stream.getVector3Array(vbf, vcount, mesh.vblayout['position'].offset, stride);

    //Read normals
    if (mesh.flags & 1) {
        name = stream.getString(4);
        if (name != "NORM") return null;

        if (vbi) {
            if (ntmp.length < vcount*3)
                ntmp = new Float32Array(vcount*3);
            stream.getVector3Array(ntmp, vcount, 0, 3);

            for (var i=0, offset=mesh.vblayout['normal'].offset;
                 i<vcount;
                 i++, offset += stride)
            {
                var pnx = (atan2(ntmp[i*3+1], ntmp[i*3]) * INV_PI + 1.0) * 0.5;
                var pny = (ntmp[i*3+2] + 1.0) * 0.5;

                vbi[offset*2] = (pnx * 65535)|0;
                vbi[offset*2+1] = (pny * 65535)|0;
            }
        } else {
            stream.getVector3Array(vbf, vcount, mesh.vblayout['normal'].offset, stride);
        }

    }

    //Read uv layers
    for (var t=0; t<mesh.texMapCount; t++) {
        name = stream.getString(4);
        if (name != "TEXC") return null;

        var uv = {
            name : readOpenCTMString(),
            file : readOpenCTMString()
        };
        mesh.uvs.push(uv);

        var uvname = "uv";
        if (t)
            uvname += (t+1).toString();

        stream.getVector2Array(vbf, vcount, mesh.vblayout[uvname].offset, stride);
    }

    var attributeOffset = stride - (mesh.attribMapCount||0) * 3;

    //Read vertex colors and uvw (and skip any other attributes that we don't know)
    for (var t=0; t<mesh.attribMapCount; t++) {
        name = stream.getString(4);
        if (name != "ATTR") return null;

        var attr = {
            name : readOpenCTMString()
        };

        // console.log("attribute", attr.name);

        var attrname;
        if (attr.name.indexOf("Color") != -1)//Special case of vertex colors
            attrname = 'color';
        else if (attr.name.indexOf("UVW") != -1)//Only used by prism 3d wood.
            attrname = 'uvw';
        else {
            //Other attributes, though we don't know what to do with those
            mesh.attrs.push(attr);
            stream.getBytes(vcount*16); //skip past
            continue;
        }

        mesh.vblayout[attrname] = { offset : attributeOffset, itemSize : 3};

        var v4 = [0,0,0,0];
        for (var i=0, offset=attributeOffset;
                i<vcount;
                i++, offset += stride) {
            stream.getVector4(v4,0);
            vbf[offset] = v4[0];
            vbf[offset+1] = v4[1];
            vbf[offset+2] = v4[2];
            //Ignoring the alpha term. For color attribute, we can actually pack it in a 4-byte attribute,
            //but we do not know in advance (when we allocate the target buffer) if the OCTM attribute is UVW or color
        }
        attributeOffset += 3;
    }

}


//=====================================================================
//=====================================================================
//=====================================================================
//=====================================================================
//=====================================================================
//=====================================================================
//=====================================================================


var readOpenCTM = function(stream, dstBuffer, startOffset, estimateSizeOnly, packNormals) {

    var readOpenCTMString = function() {
        return stream.getString(stream.getInt32());
    };

    var fourcc = stream.getString(4);
    if (fourcc != "OCTM") return null;

    var version = stream.getInt32();
    if (version != 5) return null;

    var method = stream.getString(3);
    stream.getUint8(); //read the last 0 char of the RAW or MG2 fourCC.

    var mesh = {
        stream: null,
        vertices:   null,
        indices:    null,
        normals:    null,
        colors:     null,
        uvs:        [],
        attrs:      []
    };

    mesh.vertexCount = stream.getInt32();
    mesh.triangleCount = stream.getInt32();
    mesh.texMapCount = stream.getInt32();
    mesh.attribMapCount = stream.getInt32();
    mesh.flags = stream.getInt32();
    mesh.comment = readOpenCTMString();

    var usePackedNormals = packNormals;


    //Calculate stride of the interleaved buffer we need
    mesh.vbstride = 3; //position is always there
    if (mesh.flags & 1)
        mesh.vbstride += usePackedNormals ? 1 : 3; //normal
    mesh.vbstride += 2 * (mesh.texMapCount || 0); //texture coords
    mesh.vbstride += 3 * (mesh.attribMapCount || 0); //we now support color and uvw. Both of them use three floats.

    mesh.vblayout = {};
    var offset = 0;

    mesh.vblayout['position'] = { offset: offset, itemSize: 3 };

    offset += 3;
    if (mesh.flags & 1) {
        mesh.vblayout['normal'] = { offset : offset, 
                                    itemSize : usePackedNormals ? 2 : 3, 
                                    bytesPerItem: usePackedNormals ? 2 : 4,
                                    normalize: usePackedNormals };

        offset += usePackedNormals ? 1 : 3; //offset is counted in units of 4 bytes
    }
    if (mesh.texMapCount) {
        for (var i=0; i<mesh.texMapCount; i++) {
            var uvname = "uv";
            if (i)
                uvname += (i+1).toString();

            mesh.vblayout[uvname] = { offset : offset, itemSize: 2 };
            offset += 2;
        }
    }

    //Now read and populate the mesh data
    if (method == "RAW") {
        readOpenCTM_RAW(stream, mesh, dstBuffer, startOffset, estimateSizeOnly);
        if (!estimateSizeOnly) {
            lmv.VBUtils.deduceUVRepetition(mesh);
            lmv.VBUtils.computeBounds3D(mesh);
        }
        return mesh;
    }
    else if (method == "MG2") {
        //This code path is never used, since MG2 compression is disabled at the LMVTK C++ level
        readOpenCTM_MG2(stream, mesh, dstBuffer, startOffset, estimateSizeOnly);
        if (!estimateSizeOnly) {
            lmv.VBUtils.deduceUVRepetition(mesh);
            lmv.VBUtils.computeBounds3D(mesh);
        }
        return mesh;
    }
    else
        return null;
};


var readLinesOrPoints = function(pfr, tse, estimateSizeOnly, lines) {

    //TODO: Line geometry does not go into shared buffers yet
    if (estimateSizeOnly)
        return null;

    // Initialize mesh
    var mesh = {
        vertices:   null,
        indices:    null,
        colors:     null,
        normals:    null,
        uvs:        [],
        attrs:      []
    };

    var indexCount;
    if (lines) {
        // Read vertex count, index count, polyline bound count
        var polyLineBoundCount;
        if ( tse.version > 1 ) {
            mesh.vertexCount   = pfr.readU16();
            indexCount         = pfr.readU16();
            polyLineBoundCount = pfr.readU16();
        }
        else {
            mesh.vertexCount   = pfr.readU32V();
            indexCount         = pfr.readU32V();
            polyLineBoundCount = pfr.readU32V();
        }
        mesh.isLines = true;
    } else {
        // Read vertex count, index count, point size
        mesh.vertexCount   = pfr.readU16();
        indexCount         = pfr.readU16();
        mesh.pointSize     = pfr.readF32();
        mesh.isPoints = true;
    }

    // Determine if color is defined
    var  hasColor = (pfr.stream.getUint8() != 0);


    //Calculate stride of the interleaved buffer we need
    mesh.vbstride = 3; //position is always there
    if (hasColor)
        mesh.vbstride += 3; //we only interleave the color attribute, and we reduce that to RGB from ARGB.

    mesh.vblayout = {};
    var offset = 0;

    mesh.vblayout['position'] = { offset: offset, itemSize: 3 };

    offset += 3;
    if (hasColor) {
        mesh.vblayout['color'] = { offset : offset, itemSize : 3};
    }

    mesh.vb = new Float32Array(mesh.vertexCount * mesh.vbstride);


    // Read vertices
    var vbf = mesh.vb;
    var stride = mesh.vbstride;
    var stream = pfr.stream;

    stream.getVector3Array(vbf, mesh.vertexCount, mesh.vblayout['position'].offset, stride);

    // Determine color if specified
    if (hasColor) {
        for (var c=0, offset=mesh.vblayout['color'].offset, cEnd=mesh.vertexCount;
             c<cEnd;
             c++, offset += stride)
        {
            vbf[offset] = stream.getFloat32();
            vbf[offset+1] = stream.getFloat32();
            vbf[offset+2] = stream.getFloat32();
            stream.getFloat32(); //skip alpha -- TODO: convert color to ARGB 32 bit integer in the vertex layout and shader
        }
    }

    // Copies bytes from buffer
    var forceCopy = function(b) {
        return b.buffer.slice(b.byteOffset, b.byteOffset + b.length);
    };

    // Read indices and polyline bound buffer
    if (lines) {
        var indices;
        var polyLineBoundBuffer;
        if ( tse.version > 1 ) {
            // 16 bit format
            indices = new Uint16Array(forceCopy(stream.getBytes(indexCount*2)));
            polyLineBoundBuffer = new Uint16Array(forceCopy(stream.getBytes(polyLineBoundCount*2)));
        }
        else {
            // 32 bit format
            indices = new Int32Array(forceCopy(stream.getBytes(indexCount*4)));
            polyLineBoundBuffer = new Int32Array(forceCopy(stream.getBytes(polyLineBoundCount*4)));
        }

        // three.js uses GL-style index pairs in its index buffer. We need one pair
        // per segment in each polyline
        var indexPairs = polyLineBoundBuffer[polyLineBoundCount-1] - polyLineBoundCount + 1;

        mesh.indices = new Uint16Array(2*indexPairs);

        // Extract the individual line segment index pairs
        var meshIndex = 0;
        for (var i=0; i+1 < polyLineBoundCount; i++){
            for(var j = polyLineBoundBuffer[i]; j+1 < polyLineBoundBuffer[i+1]; j++){
                mesh.indices[meshIndex++] = indices[j];
                mesh.indices[meshIndex++] = indices[j+1];
            }
        }
    } else {
        mesh.indices = new Uint16Array(forceCopy(stream.getBytes(indexCount*2)));
    }

    lmv.VBUtils.computeBounds3D(mesh);

    return mesh;
};

var readLines = function(pfr, tse, estimateSizeOnly) {
    return readLinesOrPoints(pfr, tse, estimateSizeOnly, true);
};

var readPoints = function(pfr, tse, estimateSizeOnly) {
    return readLinesOrPoints(pfr, tse, estimateSizeOnly, false);
};

function readGeometry(pfr, entry, options) {
    var tse = pfr.seekToEntry(entry);
    if (!tse)
        return null;

    if (tse.entryType == "Autodesk.CloudPlatform.OpenCTM") {
        return readOpenCTM(pfr.stream, options.dstBuffer, options.startOffset, options.estimateSizeOnly, options.packNormals);
    }
    else if (tse.entryType == "Autodesk.CloudPlatform.Lines") {
        return readLines(pfr, tse, options.estimateSizeOnly);
    }
    else if (tse.entryType == "Autodesk.CloudPlatform.Points") {
        return readPoints(pfr, tse, options.estimateSizeOnly);
    }

    return null;
}

lmv.readGeometry = readGeometry;

})();
;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;


function readLightDefinition(pfr, entry) {
    var tse = pfr.seekToEntry(entry);
    if (!tse)
        return null;
    if (tse.version > 1 /*Constants::LightDefinitionVersion*/)
        return null;

    var s = pfr.stream;

    var light = {
        position:   pfr.readVector3f(),
        dir:        pfr.readVector3f(),
        r:          s.getFloat32(),
        g:          s.getFloat32(),
        b:          s.getFloat32(),
        intensity:  s.getFloat32(),
        spotAngle:  s.getFloat32(),
        size:       s.getFloat32(),
        type:       s.getUint8()
    };

    return light;
}

lmv.readLightDefinition = readLightDefinition;

})();;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;


function readCameraDefinition(pfr, inst) {
    var entry = inst.definition;
    var tse = pfr.seekToEntry(entry);
    if (!tse)
        return null;
    if (tse.version > 2 /*Constants::CameraDefinitionVersion*/)
        return null;

    var s = pfr.stream;
    var cam = {
        isPerspective : !s.getUint8(), /* 0 = perspective, 1 = ortho */
        position : pfr.readVector3f(),
        target: pfr.readVector3f(),
        up: pfr.readVector3f(),
        aspect: s.getFloat32(),
        fov: s.getFloat32()*(180/Math.PI)
    };
    if (tse.version < 2) {
        // Skip the clip planes for old files.
        s.getFloat32();
        s.getFloat32();
    }

    cam.orthoScale = s.getFloat32();

    return cam;
}

lmv.readCameraDefinition = readCameraDefinition;

})();;

(function() {

"use strict";

var lmv = Autodesk.LMVTK;
var av = Autodesk.Viewing,
    avp = av.Private;

//FragList represents an array of fragments, stored in Structure of Arrays form
//which allows us to free some parts easily and transfer the fragment information in large chunks.
var NUM_FRAGMENT_LIMITS = (av.isMobileDevice()) ? null : null;

/** @constructor */
function FragList() {
    this.length = 0;
    this.numLoaded = 0;

    this.boxes = null;
    this.transforms = null;
    this.materials = null;

    this.packIds = null;
    this.entityIndexes = null;

    this.fragId2dbId = null;

    this.topoIndexes = null;
}

function readGeometryMetadataIntoFragments(pfr, fragments) {
    var length = fragments.geomDataIndexes.length;
    var stream = pfr.stream;
    var primsCount = 0;

    // Read from cache if the same entry has been reading from stream.
    var entryCache = {};
    var mesh2frag = fragments.mesh2frag = {};
    fragments.polygonCounts = fragments.geomDataIndexes;
    for (var g = 0; g < length; g++) {
        var entry = fragments.geomDataIndexes[g];

        if (entryCache[entry]) {
            var i = entryCache[entry];
            fragments.polygonCounts[g] = fragments.polygonCounts[i];
            fragments.packIds[g] = fragments.packIds[i];
            fragments.entityIndexes[g] = fragments.entityIndexes[i];
            primsCount += fragments.polygonCounts[g];
        }
        else {
            var tse = pfr.seekToEntry(entry);
            if (!tse)
                return;

            // Frag type, seems no use any more.
            stream.getUint8();
            //skip past object space bbox -- we don't use that
            stream.seek(stream.offset + 24);

            fragments.polygonCounts[g] = stream.getUint16();
            fragments.packIds[g] = parseInt(pfr.readString());
            fragments.entityIndexes[g] = pfr.readU32V();
            primsCount += fragments.polygonCounts[g];

            entryCache[entry] = g;
        }
        
        // Construct mesh2frag here directly
        var meshid = fragments.packIds[g] + ":" + fragments.entityIndexes[g];
        var meshRefs = mesh2frag[meshid];
        if (meshRefs === undefined) {
            //If it's the first fragments for this mesh,
            //store the index directly -- most common case.
            mesh2frag[meshid] = g;
        }
        else if (!Array.isArray(meshRefs)) {
            //otherwise put the fragments that
            //reference the mesh into an array
            mesh2frag[meshid] = [meshRefs, g];
        }
        else {
            //already is an array
            meshRefs.push(g);
        }

    }
    fragments.geomDataIndexes = null;
    entryCache = null;

    return primsCount;
}

function readGeometryMetadata(pfr, geoms)
{
    var numGeoms = pfr.getEntryCounts();
    var stream = pfr.stream;

    geoms.length = numGeoms;
    var fragTypes = geoms.fragTypes = new Uint8Array(numGeoms);
    var primCounts = geoms.primCounts = new Uint16Array(numGeoms);
    var packIds = geoms.packIds = new Int32Array(numGeoms);
    var entityIndexes = geoms.entityIndexes = new Int32Array(numGeoms);
    // Holds the indexes to the topology data.
    var topoIndexes;

    for (var g = 0, gEnd = numGeoms; g<gEnd; g++) {
        var tse = pfr.seekToEntry(g);
        if (!tse)
            return;

        fragTypes[g] = stream.getUint8();
        //skip past object space bbox -- we don't use that
        stream.seek(stream.offset + 24);
        primCounts[g] = stream.getUint16();
        packIds[g] = parseInt(pfr.readString());
        entityIndexes[g] = pfr.readU32V();

        if (tse.version > 2) {
            var topoIndex = stream.getInt32();
            if (topoIndex != -1 && topoIndexes === undefined) {
                 topoIndexes = geoms.topoIndexes = new Int32Array(numGeoms);
                 // Fill in the first entries to indicate
                 for(var i = 0; i < g; i++)
                     topoIndexes[i] = -1;
            }

            if (topoIndexes != undefined)
                 topoIndexes[g] = topoIndex;
        }

    }
}

// Convert a list of object id (dbid) to a list of integers where each integer is an index of the fragment
// in fragment list that associated with the object id.
function objectIds2FragmentIndices(pfr, ids) {
    var ret = [];

    if (!ids) {
        return ret;
    }

    var counts = pfr.getEntryCounts();
    var stream = pfr.stream;
    for (var entry = 0; entry < counts; entry++) {
        var tse = pfr.seekToEntry(entry);
        if (!tse)
            return;
        if (tse.version > 5)
            return;

        // Keep reading fragment fields as usual, but does not store anything as we only
        // interested in the data base id / object id field at the very end.
        if ( tse.version > 4 ) {
            // Flag byte.
            pfr.readU8();
        }
        // Material index
        pfr.readU32V();
        if (tse.version > 2) {
            // Geometry metadata reference
            pfr.readU32V();
        } else {
            // Pack file reference
            pfr.readString();
            pfr.readU32V();
        }

        // Transform
        pfr.readTransform(entry, null, 12 * entry);

        // Bounding box
        for (var i = 0; i < 6; i++) {
            stream.getFloat32();
        }

        if (tse.version > 1) {
            var dbid = pfr.readU32V();
            if (ids.indexOf(dbid) >= 0) {
                ret.push(entry);
            }
        }
    }

    return ret;
}


function readFragments(pfr, frags, globalOffset, placementTransform, ids) {
    var filteredIndices = objectIds2FragmentIndices(pfr, ids);

    //Initialize all the fragments structures
    //once we know how many fragments we have.
    var numFrags = filteredIndices.length ? filteredIndices.length : pfr.getEntryCounts();
    var stream = pfr.stream;

    if (NUM_FRAGMENT_LIMITS && numFrags > NUM_FRAGMENT_LIMITS) {
        numFrags = NUM_FRAGMENT_LIMITS;
    }

    // Recored the total length of the fragments
    frags.totalLength = pfr.getEntryCounts();
    frags.length = numFrags;
    frags.numLoaded = 0;

    //Allocate flat array per fragment property
    var fragBoxes       = frags.boxes =                 new Float32Array(6*numFrags);
    var transforms      = frags.transforms =            new Float32Array(12*numFrags);
    var materials       = frags.materials =             new Int32Array(numFrags);
    var packIds         = frags.packIds =               new Int32Array(numFrags);
    var entityIndexes   = frags.entityIndexes =         new Int32Array(numFrags);
    var geomDataIndexes = frags.geomDataIndexes =       new Int32Array(numFrags);
    var fragId2dbId     = frags.fragId2dbId =           new Int32Array(numFrags); //NOTE: this potentially truncates IDs bigger than 4 billion -- can be converted to array if needed.

    var tmpBox;
    var tmpMat;
    var boxTranslation = [0,0,0];
    if (placementTransform) {
        tmpBox = new LmvBox3();
        tmpMat = new LmvMatrix4(true).fromArray(placementTransform.elements);
    }

    //Helper functions used by the main fragment read loop.

    function applyPlacement(index) {
        if (placementTransform) {
            var offset = index * 6;
            tmpBox.setFromArray(fragBoxes, offset);
            tmpBox.applyMatrix4(tmpMat);
            tmpBox.copyToArray(fragBoxes, offset);
        }
    }

    function readBoundingBox(entry) {
        var offset = entry * 6;
        for (var i=0; i<6; i++)
            fragBoxes[offset++] = stream.getFloat32();
    }

    function readBoundingBoxOffset(entry, boxTranslation) {
        var offset = entry * 6;
        for (var i=0; i<6; i++)
            fragBoxes[offset++] = stream.getFloat32() + boxTranslation[i % 3];
    }

    //Spin through all the fragments now
    for (var entry=0, eEnd=frags.length; entry<eEnd; entry++) {
        var tse = filteredIndices.length ? pfr.seekToEntry(filteredIndices[entry]) : pfr.seekToEntry(entry);

        if (!tse)
            return;
        if (tse.version > 5)
            return;

        var isVisible = true;
        if ( tse.version > 4 ) {
            // Fragments v5+ include a flag byte, the LSB of which denotes
            // visibility
            var flags = pfr.readU8();
            isVisible = (flags & 0x01) != 0;
        }

        materials[entry] = pfr.readU32V();

        if (tse.version > 2) {
            //In case it's new style fragment that
            //points to a geometry metadata entry
            geomDataIndexes[entry] = pfr.readU32V();
        }
        else {
            //Old style fragment, pack reference is directly
            //encoded in the fragment entry
            packIds[entry] = parseInt(pfr.readString());
            entityIndexes[entry] = pfr.readU32V();
        }

        pfr.readTransform(entry, transforms, 12*entry, placementTransform, globalOffset, boxTranslation);

        if (tse.version > 3) {
            // With this version the transform's (double precision) translation is subtracted from the BB,
            // so we have to add it back
            readBoundingBoxOffset(entry, boxTranslation);
        }
        else {
            readBoundingBox(entry);
        }

        //Apply the placement transform to the world space bbox
        applyPlacement(entry);

        //Apply any global offset to the world space bbox
        if (globalOffset) {
            var offset = entry * 6;
            fragBoxes[offset++] -= globalOffset.x;
            fragBoxes[offset++] -= globalOffset.y;
            fragBoxes[offset++] -= globalOffset.z;
            fragBoxes[offset++] -= globalOffset.x;
            fragBoxes[offset++] -= globalOffset.y;
            fragBoxes[offset++] -= globalOffset.z;
        }

        if (tse.version > 1) {
            fragId2dbId[entry] = pfr.readU32V();
        }
        // Skip reading path ID which is not in use now.
        // pfr.readPathID();
    }

    frags.finishLoading = true;
}

// Filter fragments based on specified object id list, by picking
// up fragment whose id is in the specified id list, and dropping others.
// This is used to produce a list of fragments that matches a search hit.
function filterFragments(frags, ids) {
    frags.length = ids.length;
    frags.numLoaded = 0;
    var numFrags = frags.length;
    var bb = [Infinity, Infinity, Infinity, -Infinity, -Infinity, -Infinity];

    var fragBoxes       = new Float32Array(6 * numFrags);
    var transforms      = new Float32Array(12 * numFrags);
    var materials       = new Int32Array(numFrags);
    var packIds         = new Int32Array(numFrags);
    var entityIndexes   = new Int32Array(numFrags);
    var mesh2frag = {};

    for (var i = 0; i < ids.length; ++i) {
        var index = ids[i];

        var idxOld = index * 6;
        var idxNew = i * 6;
        for (var j = 0; j < 6; ++j)
            fragBoxes[idxNew++] = frags.boxes[idxOld++];

        idxOld = index * 12;
        idxNew = i * 12;
        for (var j = 0; j < 12; ++j)
            transforms[idxNew++] = frags.transforms[idxOld++];

        materials[i] = frags.materials[index];
        packIds[i] = frags.packIds[index];
        entityIndexes[i] = frags.entityIndexes[index];

        // TODO: consolidate this with addToMeshMap.
        var meshID = frags.packIds[index] + ":" + frags.entityIndexes[index];
        var meshRefs = mesh2frag[meshID];
        if (meshRefs == undefined) {
            mesh2frag[meshID] = i;
        }
        else if (!Array.isArray(meshRefs)) {
            mesh2frag[meshID] = [meshRefs, i];
        }
        else {
            meshRefs.push(i);
        }

        var bbIndex = i * 6;
        for (var j = 0; j < 3; ++j)
            if (fragBoxes[bbIndex + j] < bb[j])
                bb[j] = fragBoxes[bbIndex + j];
        for (var j = 3; j < 6; ++j)
            if (fragBoxes[bbIndex + j] > bb[j])
                bb[j] = fragBoxes[bbIndex + j];
    }

    frags.boxes = fragBoxes;
    frags.transforms = transforms;
    frags.materials = materials;
    frags.packIds = packIds;
    frags.entityIndexes = entityIndexes;
    frags.mesh2frag = mesh2frag;

    return bb;
}

lmv.FragList = FragList;
lmv.readGeometryMetadataIntoFragments = readGeometryMetadataIntoFragments;
lmv.readGeometryMetadata = readGeometryMetadata;
lmv.filterFragments = filterFragments;
lmv.readFragments = readFragments;

})();
;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;


function readInstance(pfr, entry, placementTransform, globalOffset) {
    var tse = pfr.seekToEntry(entry);
    if (!tse)
        return null;
    if (tse.version > 2 /*Constants::InstanceVersion*/)
        return null;

    var isVisible = true;
    if ( tse.version > 1 ) {
        // Instances v2+ include a flag byte, the LSB of which denotes visibility
        var flags = pfr.readU8();
        isVisible = (flags & 0x01) != 0;
    }

    return {
        definition: pfr.stream.getUint32(),
        transform: pfr.readTransform(undefined, undefined, undefined, placementTransform, globalOffset),
        instanceNodePath: pfr.readPathID()
    }
}



var NodeType = {
    NT_Inner : 0,
    NT_Geometry : 1,
    NT_Camera : 2,
    NT_Light : 3
};

function readInstanceTree(pfr, version) {

    var transforms = [];
    var dbIds = [];
    var fragIds = [];
    var childCounts = [];
    var nodeIndex = 0;
    var s = pfr.stream;

    while (s.offset < s.byteLength - 8 - 1) {

        pfr.readTransform(nodeIndex, transforms, nodeIndex * 12, undefined, undefined, undefined);

        // Version 1-4 had optional "shared nodes" that were never used in practice. If found, consume and ignore.
        if (version < 5) {
            var hasSharedNode = s.getUint8();
            if (hasSharedNode) {
                s.getUint32();
            }
        }

        var nodeType = s.getUint8();

        // Version 5 introduced a flags byte and the visibility flag.
        if (version >= 5) {
            var flags = s.getUint8();
            var visible = !!(flags & 1);
        }

        // Version 3 introduced the database ID
        if (version >= 3) {
            dbIds[nodeIndex] = s.getVarints();
        }

        if (nodeIndex) {
            // Not a root, behavior depends on type
            // Leaf, instantiate and add fragment references before returning
            switch (nodeType) {

                case NodeType.NT_Inner:
                    break;
                case NodeType.NT_Geometry: {
                        if (version < 2) {
                            var fragCount = s.getUint16();
                            if (fragCount === 1) {
                                fragIds[nodeIndex] = s.getUint32();
                            } else if (fragCount > 0) {
                                var flist = [];
                                for (var i=0; i<fragCount; i++)
                                    flist.push(s.getUint32());
                                fragIds[nodeIndex] = flist;
                            }
                        } else {
                            var fragCount = s.getVarints();
                            if (fragCount === 1) {
                                fragIds[nodeIndex] = s.getVarints();
                            } else if (fragCount > 0) {
                                var flist = [];
                                for (var i=0; i<fragCount; i++)
                                    flist.push(s.getVarints());
                                fragIds[nodeIndex] = flist;
                            }
                        }
                    }
                    break;
                case NodeType.NT_Camera:
                case NodeType.NT_Light: {
                        var hasInstanceEntryId = s.getUint8();
                        if (hasInstanceEntryId) {
                            s.getUint32();
                        }
                    }
                    break;
                default:
                    debug("Unrecognized instance tree node type.");
                    break;
            }
        }

        var childCount = 0;
        if (nodeType === NodeType.NT_Inner) {
            if (version < 2) {
                childCount = s.getUint16();
            } else {
                childCount = s.getVarints();
            }
        }
        childCounts[nodeIndex] = childCount;

        nodeIndex++;
    }

    var dbIdBuffer = new Uint32Array(dbIds.length);
    dbIdBuffer.set(dbIds);

    var xformBuffer = new Float32Array(transforms.length);
    xformBuffer.set(transforms);

    var childCountsBuffer = new Uint32Array(childCounts.length);
    childCountsBuffer.set(childCounts);

    return { dbIds: dbIdBuffer, fragIds:fragIds, transforms: xformBuffer, childCounts: childCountsBuffer };
}


lmv.readInstance = readInstance;
lmv.readInstanceTree = readInstanceTree;

})();;
(function() {
    'use strict';

var av = Autodesk.Viewing,
    lmv = Autodesk.LMVTK,
    avp = av.Private;

var MAX_PF_FILES = av.isMobileDevice() ? 50 : 2000;
var MAX_TOPOLOGY = av.isMobileDevice() ? 20 :  100; // MegaBytes; Non-gzipped



function getUnitScale(unit) {
    //Why are translators not using standard strings for those?!?!?!?
    switch (unit) {
        case 'meter'      :
        case 'meters'     :
        case 'm'          : return 1.0;
        case 'feet and inches':
        case 'foot'       :
        case 'feet'       :
        case 'ft'         : return 0.3048;
        case 'inch'       :
        case 'inches'     :
        case 'in'         : return 0.0254;
        case 'centimeter' :
        case 'centimeters':
        case 'cm'         : return 0.01;
        case 'millimeter' :
        case 'millimeters':
        case 'mm'         : return 0.001;
        default: return 1.0;
    }
}
        


/** @constructor */
function Package(zipPack) {

    this.unzip = new Zlib.Unzip(zipPack);

    this.manifest = null;

    this.materials = null; //The materials json as it came from the SVF

    this.metadata = null; //metadata json

    this.fragments = null; //will be a FragList

    this.geompacks = [];

    //TODO:
    //Those will not be parsed immediately
    //but we will remember the raw arrays
    //and fire off async workers to parse
    //them later, once we are loading geometry packs
    this.instances = [];

    this.cameras = [];
    this.lights = [];

    this.propertydb = {
        attrs : [],
        avs: [],
        ids: [],
        values: [],
        offsets: []
    };

    this.bbox = null; //Overall scene bounds

    this.animations = null; // animations json

    this.pendingRequests = 0;

    this.globalOffset = { x: 0, y: 0, z: 0 };

    this.topology = null; // Topology json

}



Package.prototype.loadAsyncResource = function(loadContext, resourcePath, contents, callback) {

    //Data is immediately available from the SVF zip
    if (contents) {
        callback(contents);
        return;
    }

    //Launch an XHR to load the data from external file
    var svf = this;

    this.pendingRequests ++;

    function xhrCB(responseData) {
        svf.pendingRequests--;

        callback(responseData);

        if (svf.pendingRequests == 0)
            svf.postLoad(loadContext);
    }

    avp.ViewingService.getItem(loadContext, loadContext.basePath + resourcePath,
                            xhrCB,
                            loadContext.onFailureCallback,
                            { asynchronous:true }
                           );

};

Package.prototype.loadManifest = function(loadContext) {
    // TODO: zlib.js throws exceptions on failure;
    // it doesn't return null as this code seems to assume.
    // yes, LoadContext is passed in, but is not used.
    var manifestJson = this.unzip.decompress("manifest.json");
    if (!manifestJson)
        return false;

    var jdr = new lmv.InputStream(manifestJson);
    this.manifest = JSON.parse(jdr.getString(manifestJson.byteLength));
};

Package.prototype.parseFragmentList = function(asset, loadContext, path, contents) {

    var self = this;
    this.loadAsyncResource(loadContext, path, contents, function(data) {
        var pfr = new lmv.PackFileReader(data);

        //Use a single large blocks to store all fragment elements
        //TODO: perhaps have a FragList per pack file to keep block size down?
        var frags = self.fragments = new lmv.FragList();
        lmv.readFragments(pfr, frags, self.globalOffset, loadContext.placementTransform);
        pfr = null;

    });
};

Package.prototype.parseGeometryMetadata = function(asset, loadContext, path, contents) {
    var self = this;
    this.loadAsyncResource(loadContext, path, contents, function(data) {
        var pfr = new lmv.PackFileReader(data);

        self.geomMetadata = {};
        lmv.readGeometryMetadata(pfr, self.geomMetadata);
    });    
};


Package.prototype.parseInstanceTree = function(loadContext, path, contents, version) {

    var that = this;

    this.loadAsyncResource(loadContext, path, contents, function(data) {
        var pfr = new lmv.PackFileReader(data);
        that.instanceTransforms = lmv.readInstanceTree(pfr, version);
    });

};


Package.prototype.loadRemainingSvf = function(loadContext) {
    var svf = this;

    var unzip = this.unzip;

    //var filenames = unzip.getFilenames();
    this.manifest = loadContext.manifest;
    var manifest = this.manifest;

    var assets = manifest["assets"];

    var metadataJson = unzip.decompress("metadata.json");
    var jdr = new lmv.InputStream(metadataJson);

    // Test to see if this is json (not a binary header)
    // Done by verifying that there is no 0 (Hence ASCII)
    if(metadataJson.byteLength > 3 && metadataJson[3] !== 0) {
        this.metadata = JSON.parse(jdr.getString(metadataJson.byteLength)).metadata;

        //Retrieve world bounding box
        if ( this.metadata ) {
            var bbox = this.metadata["world bounding box"];
            var min = { x: bbox.minXYZ[0], y: bbox.minXYZ[1], z: bbox.minXYZ[2] };
            var max = { x: bbox.maxXYZ[0], y: bbox.maxXYZ[1], z: bbox.maxXYZ[2] };
            this.bbox ={min:min, max:max };

            //Global offset is used to avoid floating point precision issues for models
            //located enormous distances from the origin. The default is to move the model to the origin
            //but it can be overridden in case of model aggregation scenarios, where multiple
            //models are loaded into the scene and a common offset is needed for all.
            this.globalOffset = loadContext.globalOffset ||  { x: 0.5 * (min.x + max.x), y: 0.5 * (min.y + max.y), z: 0.5 * (min.z + max.z) };

            // We now will apply overall model transforms, following the following logic:
            //    1) placementTransform = options.placementTransform);
            //    2) placementTransform = placementTransform.multiply(scalingTransform);
            //    3) placementTransform = placementTransform.multiply(refPointTransform);
            // This is for aggregation scenarios, where multiple models are loaded into the scene 
            // In such scenarios the client will most probably manually override the model units
         

            //First, take the input placement transform as is (could be null).
            this.placementTransform = loadContext.placementTransform;

            // If requested in the load options, apply scaling from optional 'from' to 'to' units.
            // If unpecified, then units will be read from the models metadata.
            // * usage overloads 
            //      options.appyScaling: { from: 'ft', to: 'm' }
            //      options.appyScaling: 'm'   ( equivalent to { to: 'm' })
            // * this is aimed at multiple 3D model situations where models potentialy have different units, but
            //   one  doesn't up-front know what these units are.It also allows overriding of such units.
            // * Model methods: getUnitString , getUnitScale &  getDisplayUnit will be automatically return corrected values
            //   as long as there are no additional options.placementTransform scalings applied.  
            if (loadContext.applyScaling) {
                
                // default 'from' & 'to'  units are from metadata, or 'm' not present
                var scalingFromUnit = 'm';
                if (this.metadata["distance unit"]) {
                    scalingFromUnit = this.metadata["distance unit"]["value"];
                } 
                this.scalingUnit = scalingFromUnit;

                if('object' === typeof(loadContext.applyScaling)){
                    if(loadContext.applyScaling.from) {
                        scalingFromUnit = loadContext.applyScaling.from; 
                    }
                    if(loadContext.applyScaling.to) {
                       this.scalingUnit = loadContext.applyScaling.to; 
                    }
                } else {
                    this.scalingUnit = loadContext.applyScaling;
                }


                // Work out overall desired scaling factor.
                var scalingFactor = getUnitScale(scalingFromUnit) / getUnitScale(this.scalingUnit);

                if(1 != scalingFactor) {

                    var placementS = new LmvMatrix4(true);

                     var scalingTransform = new LmvMatrix4(true);
                     scalingTransform.elements[0] = scalingFactor;
                     scalingTransform.elements[5]  = scalingFactor;
                     scalingTransform.elements[10] = scalingFactor;

                    if (loadContext.placementTransform) {
                        // There may well already be a placementTransform from previous options/operations.
                        placementS.copy(loadContext.placementTransform);

                    }

                    this.placementTransform = loadContext.placementTransform = placementS.multiply(scalingTransform);
                }
            }


            //Is there an extra offset specified in the georeference?
            //This is important when aggregating Revit models from the same Revit
            //project into the same scene, because Revit SVFs use RVT internal coordinates, which
            //need extra offset to get into the world space.
            var georeference = this.metadata["georeference"];
            if (georeference) {
                var refPointLMV = georeference["refPointLMV"];
                if (refPointLMV) {

                    //Here we convert the reference point and rotation angles
                    //to a simple 4x4 transform for easier use and application later.
    
                    var angle = 0;
                    var cv = this.metadata["custom values"];
                    if (cv && cv.hasOwnProperty("angleToTrueNorth")) {
                        angle = (Math.PI / 180.0) * cv["angleToTrueNorth"];
                    }
    
                    var refPoint = new LmvMatrix4(true);
                    var m = refPoint.elements;
    
                    m[0] = m[5] = Math.cos(angle);
                    m[1] = -Math.sin(angle);
                    m[4] = Math.sin(angle);
    
                    m[12] = refPointLMV[0];
                    m[13] = refPointLMV[1];
                    m[14] = refPointLMV[2];
    
                    this.refPointTransform = refPoint;
                }
            }

            //If request in the load options, apply the reference point transform when loading the model
            if (loadContext.applyRefPoint && this.refPointTransform) {

                var placement = new LmvMatrix4(true);

                //Normally we expect the input placement transform to come in as identity in case
                //we have it specified in the georef here, but, whatever, let's be thorough for once.
                if (loadContext.placementTransform)
                    placement.copy(loadContext.placementTransform);

                placement.multiply(this.refPointTransform);

                this.placementTransform = loadContext.placementTransform = placement;
            }

            min.x -= this.globalOffset.x;
            min.y -= this.globalOffset.y;
            min.z -= this.globalOffset.z;
            max.x -= this.globalOffset.x;
            max.y -= this.globalOffset.y;
            max.z -= this.globalOffset.z;

            if (this.metadata.hasOwnProperty("double sided geometry")
                && this.metadata["double sided geometry"]["value"]) //TODO: do we want to check the global flag or drop that and rely on material only?
            {
                this.doubleSided = true;
            }
        }
    }

    //Version strings seem to be variable at the moment.
    //var manifestVersion = manifest["manifestversion"];
    //if (   manifest["name"] != "LMV Manifest"
    //    || manifest["manifestversion"] != 1)
    //    return false;

    this.packFileTotalSize = 0;
    this.primitiveCount = 0;

    var typesetsList = manifest["typesets"];
    var typesets = {};
    for (var i=0; i<typesetsList.length; i++) {
        var ts = typesetsList[i];
        typesets[ts['id']] = ts['types'];
    }

    //Loop through the assets, and schedule non-embedded
    //ones for later loading.
    //TODO: currently only geometry pack files are stored for later
    //load and other assets will be loaded by this worker thread before
    //we return to the SvfLoader in the main thread.
    function applyOffset(a, offset) {
        a[0] -= offset.x;
        a[1] -= offset.y;
        a[2] -= offset.z;
    }
    
    for (var i=0; i<assets.length; i++)
    {
        var asset = assets[i];
        if (av.isMobileDevice() && ((asset.id === "Set.bin") || (asset.id === "Topology.json.gz"))) continue;
        var type = asset["type"];
        if (type.indexOf("Autodesk.CloudPlatform.") == 0)
            type = type.substr(23);
        var uri = asset["URI"];
        var typeset = asset["typeset"] ? typesets[asset["typeset"]] : null;
        var usize = asset["usize"] || 0;
        var megaBytes = (Math.round(usize/1048576*100000)/100000) | 0;

        //If the asset is a geometry pack or property pack
        //just remember it for later demand loading
        if (uri.indexOf("embed:/") != 0) {
            if (type == "PackFile") {
                var typeclass = typeset ? typeset[0]["class"] : null;

                if (typeclass == "Autodesk.CloudPlatform.Geometry") {

                    this.packFileTotalSize += asset["usize"] || 0;

                    this.geompacks.push({ id: asset["id"], uri: uri });
                }
            }
            else if (type == "PropertyAttributes") {
                this.propertydb.attrs.push(uri);
            }
            else if (type == "PropertyAVs") {
                this.propertydb.avs.push(uri);
            }
            else if (type == "PropertyIDs") {
                this.propertydb.ids.push(uri);
            }
            else if (type == "PropertyOffsets") {
                this.propertydb.offsets.push(uri);
            }
            else if (type == "PropertyValues") {
                this.propertydb.values.push(uri);
            }
        }

        //parse assets which we will need immediately when
        // setting up the scene (whether embedded or not)
        var path = asset["URI"];
        var contents = null; //if the data was in the zip, this will contain it
        if (path.indexOf("embed:/") == 0) {
            path = path.substr(7);
            contents = unzip.decompress(path);
        }

        if (type == "ProteinMaterials") {
            //For simple materials, we want the file named "Materials.json" and not "ProteinMaterials.json"
            if (path.indexOf("Protein") == -1) {
                this.loadAsyncResource(loadContext, path, contents, function(data) {
                    var jdr = new lmv.InputStream(data);
                    var byteLength = data.byteLength;
                    if (0 < byteLength) {
                        svf.materials = JSON.parse(jdr.getString(byteLength));
                    } else {
                        svf.materials = null;
                    }
                });
            } else {
                //Also parse the Protein materials -- at the moment this helps
                //With some Prism materials that have properties we can handle, but
                //are not in the Simple variant.
                this.loadAsyncResource(loadContext, path, contents, function(data) {
                    var jdr = new lmv.InputStream(data);
                    var byteLength = data.byteLength;
                    if (0 < byteLength) {
                        svf.proteinMaterials = JSON.parse(jdr.getString(byteLength));
                    } else {
                        svf.proteinMaterials = null;
                    }
                });
            }
        }
        else if (type == "FragmentList") {

            this.parseFragmentList(asset, loadContext, path, contents);

        }
        else if (type == "GeometryMetadataList") {
            
            this.parseGeometryMetadata(asset, loadContext, path, contents);

        }
        else if (type == "PackFile") {

            if (path.indexOf("CameraDefinitions.bin") != -1) {
                this.loadAsyncResource(loadContext, path, contents, function(data) {
                    svf.camDefPack = new lmv.PackFileReader(data);
                });
            }

            else if (path.indexOf("CameraList.bin") != -1) {
                this.loadAsyncResource(loadContext, path, contents, function(data) {
                    svf.camInstPack = new lmv.PackFileReader(data);
                });
            }

            else if (path.indexOf("LightDefinitions.bin") != -1) {
                this.loadAsyncResource(loadContext, path, contents, function(data) {
                    svf.lightDefPack = new lmv.PackFileReader(data);
                });
            }

            else if (path.indexOf("LightList.bin") != -1) {
                this.loadAsyncResource(loadContext, path, contents, function(data) {
                    svf.lightInstPack = new lmv.PackFileReader(data);
                });
            }
        }
        else if (type == "Animations") {
            this.loadAsyncResource(loadContext, path, contents, function(data) {
                var jdr = new lmv.InputStream(data);
                var byteLength = data.byteLength;
                if (0 < byteLength) {
                    svf.animations = JSON.parse(jdr.getString(byteLength));

                    // apply global offset to animations
                    var animations = svf.animations["animations"];
                    if (animations) {
                        var globalOffset = svf.globalOffset;
                        var t = new LmvMatrix4().makeTranslation(globalOffset.x, globalOffset.y, globalOffset.z);
                        var tinv = new LmvMatrix4().makeTranslation(-globalOffset.x, -globalOffset.y, -globalOffset.z);
                        var r = new LmvMatrix4();
                        var m = new LmvMatrix4();
                        for (var a = 0; a < animations.length; a++) {
                            var anim = animations[a];
                            if (anim.hierarchy) {
                                for (var h = 0; h < anim.hierarchy.length; h++) {
                                    var keys = anim.hierarchy[h].keys;
                                    if (keys) {
                                        for (var k = 0; k < keys.length; k++) {
                                            var pos = keys[k].pos;
                                            if (pos) {
                                                var offset = globalOffset;
                                                var rot = keys[k].rot;
                                                if (rot) {
                                                    r.makeRotationFromQuaternion({x:rot[0], y:rot[1], z:rot[2], w:rot[3]});
                                                    m.multiplyMatrices(t, r).multiply(tinv);
                                                    offset = {x: m.elements[12], y: m.elements[13], z: m.elements[14]};
                                                }
                                                applyOffset(pos, offset);
                                            }
                                            var target = keys[k].target;
                                            if (target) {
                                                applyOffset(target, globalOffset);
                                            }
                                            var points = keys[k].points;
                                            if (points) {
                                                for (var p = 0; p < points.length; p++) {
                                                    applyOffset(points[p], globalOffset);
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                } else {
                    svf.animations = null;
                }
            });
        }
        else if (type == "Topology") {

            // Avoid downloading a topology file that is "too big".
            if (megaBytes < MAX_TOPOLOGY) {
                this.loadAsyncResource(loadContext, path, contents, function(data) {
                    var jdr = new lmv.InputStream(data);
                    var byteLength = data.byteLength;
                    if (0 < byteLength) {
                        svf.topology = JSON.parse(jdr.getString(byteLength));
                    } else {
                        svf.topology = null;
                    }
                });
            } else {
                // Instead, log it to ADP
                svf.topologyTooBig = true;
            }
            
        }
        else if (loadContext.loadInstanceTree &&
                    (type == "InstanceTree" || type == "InstanceTreeTree")) { //Yes, the typo does occur in some older files

            //Instance tree node serialization version is stored in the type set
            var version = typeset ? typeset[0]["version"] : 1;

            this.parseInstanceTree(loadContext, path, contents, version);
        }
    }


    if (this.pendingRequests == 0)
        this.postLoad(loadContext);

    delete this.unzip;
};

Package.prototype.addTransparencyFlagsToMaterials = function(mats) {
    for(var id in mats) {
        var mat = mats[id];
        var userAssets = mat["userassets"];
        var innerMats = mat["materials"];
        var innerMat = innerMats[userAssets[0]];
        mat.transparent = innerMat["transparent"];
    }
};

Package.prototype.postLoadOfCam = function(loadContext) {

    //Combine camera instances and camera definitions -- we need
    //both to be loaded to get the camera list
    if (this.camDefPack && this.camInstPack) {
        for (var k = 0, kEnd = this.camInstPack.getEntryCounts(); k < kEnd; k++) {
            var inst = lmv.readInstance(this.camInstPack, k, this.placementTransform, this.globalOffset);
            var cam = lmv.readCameraDefinition(this.camDefPack, inst);

            //Apply any instance transform to get the camera to world space.
            if (inst.transform) {
                // Apply any transformations associated with the camera
                // to put it into world space
                inst.transform.transformPoint(cam.position);
                inst.transform.transformPoint(cam.target);
                inst.transform.transformDirection(cam.up);
            }

            this.cameras.push(cam);
        }

        delete this.camDefPack;
        delete this.camInstPack;
    }

};

Package.prototype.postLoadOfLight = function(loadContext) {

    //Lights need the same thing as the cameras
    if (this.lightDefPack && this.lightInstPack) {
        for (var k = 0, kEnd = this.lightInstPack.getEntryCounts(); k < kEnd; k++) {
            var inst = lmv.readInstance(this.lightInstPack, k, this.placementTransform, this.globalOffset);
            this.lights.push(lmv.readLightDefinition(this.lightDefPack, inst.definition));
        }

        delete this.lightInstPack;
        delete this.lightDefPack;
    }

};

Package.prototype.postLoadOfFragments = function(loadContext) {

    //Post processing step -- splice geometry metadata information
    //into the fragments list, in case it was given separately
    //TODO: consider keeping the geom metadata as is instead of splicing
    //into the fragments, as it would be more efficient --
    //but that would require special handling on the viewer side,
    //changing the fragment filter code, etc.
    var frags = this.fragments;

    if (this.geomMetadata) {

        //reusing the geomDataIndexes array to store
        //polygon counts, now that we don't need the geomIndexes
        //after this loop.
        frags.polygonCounts = frags.geomDataIndexes;

        var gm = this.geomMetadata;

        // Holds the indexes to the topology data.
        if (gm.topoIndexes != undefined) {
            frags.topoIndexes = new Int32Array(frags.length);
        }

        for (var i= 0, iEnd=frags.length; i<iEnd; i++) {
            var geomIndex = frags.geomDataIndexes[i];
            frags.entityIndexes[i] = gm.entityIndexes[geomIndex];
            frags.packIds[i] = gm.packIds[geomIndex];

            frags.polygonCounts[i] = gm.primCounts[geomIndex];
            this.primitiveCount += gm.primCounts[geomIndex];

            // Fills in the indexes to the topology data.
            if (gm.topoIndexes != undefined) {
                frags.topoIndexes[i] = gm.topoIndexes[geomIndex];
            }
        }

        frags.geomDataIndexes = null;

        this.geomMetadata = null;
    }

    //Build a map from mesh to its referencing fragment(s)
    //So that we can quickly find them once meshes begin loading
    //incrementally. This requires the packIds and entityIndexes
    //to be known per fragment, so it happens after geometry metadata
    //is resolved above
    {
        var mesh2frag = frags.mesh2frag = {};
        var packIds = frags.packIds;
        var entityIndexes = frags.entityIndexes;

        for (var i= 0, iEnd=frags.length; i<iEnd; i++) {
            var meshid = packIds[i] + ":" + entityIndexes[i];

            var meshRefs = mesh2frag[meshid];
            if (meshRefs === undefined) {
                //If it's the first fragments for this mesh,
                //store the index directly -- most common case.
                mesh2frag[meshid] = i;
            }
            else if (!Array.isArray(meshRefs)) {
                //otherwise put the fragments that
                //reference the mesh into an array
                mesh2frag[meshid] = [meshRefs, i];
            }
            else {
                //already is an array
                meshRefs.push(i);
            }
        }
    }

    // Constrain the max number of PF files here, if not use packageless class
    // Previously geom pack file uri are directly discarded when read from 
    // manifest, but with the on demand loading and paging enabled, it is expected
    // to handle all the pack files.
    // So, assume the packageless is used together with on demand loading enabled. 
    // ??? probably better to have another option to control whether need this or not.
    if (this.geompacks.length > MAX_PF_FILES) {
        this.geompacks.splice(MAX_PF_FILES, this.geompacks.length - MAX_PF_FILES);
    }
};

Package.prototype.postLoadOfBBox = function(loadContext) {

    //if we don't know the overall scene bounds, compute them from the
    //fragment boxes
    if (!this.bbox || loadContext.placementTransform) {

        if (this.bbox && loadContext.placementTransform)
            this.modelBox = this.bbox;

        var totalbox = [Infinity, Infinity, Infinity, -Infinity, -Infinity, -Infinity];
        var frags = this.fragments;
        var fragBoxes = frags.boxes;

        for (var f= 0, fEnd=frags.length; f<fEnd; f++) {
            var bboff = f*6;
            var i;
            for (i=0; i<3; i++)
                if (fragBoxes[bboff+i] < totalbox[i])
                    totalbox[i] = fragBoxes[bboff+i];

            for (i=3; i<6; i++)
                if (fragBoxes[bboff+i] > totalbox[i])
                    totalbox[i] = fragBoxes[bboff+i];
        }

        this.bbox = {
                        min: { x:totalbox[0], y:totalbox[1], z:totalbox[2]},
                        max: { x:totalbox[3], y:totalbox[4], z:totalbox[5]}
                     };
    }


};

Package.prototype.postLoadOfObjectIds = function(loadContext) {

    // If object ids are specified, clean up pack file list by only keeping the packs that's
    // we intended to load.
    var ids = loadContext.objectIds;
    if (ids != null) {
        var packIds = [];
        var fragIndexes = [];
        // Pick out pack ids that referenced by fragments with specified db ids.
        for (var i = 0; i < ids.length; ++i) {
            for (var j = 0; j < this.fragments.length; ++j) {
                if (this.fragments.fragId2dbId[j] == ids[i]) {
                    packIds.push(this.fragments.packIds[j]);
                    fragIndexes.push(j);
                }
            }
        }

        // Two fragments could reference same pack file, so packIds may contain duplicates.
        // Remove any duplicates here.
        var end = 1, n = packIds.length; // end is the length of reduced array.
        for (var i = 1; i < n;) {
            while (i < n && packIds[i] == packIds[i - 1])
                ++i;
            if (n == i)
                break;
            packIds[end++] = packIds[i++];
        }
        packIds.splice(end - 1, n - end);

        // Reduce pack files based on selected pack ids.
        var packs = [];
        for (var i = 0; i < this.geompacks.length; ++i) {
            for (var j = 0; j < packIds.length; ++j) {
                // LMVTK pre-2.0 release uses integers for pack file id.
                // LMVTK 2.0 release uses integer + .pf as id.
                // We just drop the suffix here as we did in SVFLoader.
                // More info: https://git.autodesk.com/A360/LMVTK/commit/68b8c07a643a7ac39ecd5651d031d170e3a325be
                if (parseInt(this.geompacks[i].id) == packIds[j])
                    packs.push(this.geompacks[i]);
            }
        }
        this.geompacks = packs;

        var bb = lmv.filterFragments(this.fragments, fragIndexes);
        this.bbox = {
                        min: { x:bb[0], y:bb[1], z:bb[2] },
                        max: { x:bb[3], y:bb[4], z:bb[5]}
                    };
    }

};

Package.prototype.postLoadComplete = function(loadContext) {

    loadContext.loadDoneCB("svf");

    if (this.fragments.polygonCounts) {
        //Build the R-Tree
        var t0 = performance.now();
        var mats = this.materials ? this.materials["materials"] : null;
        if (mats)
            this.addTransparencyFlagsToMaterials(mats);
        this.bvh = new avp.BVHBuilder(this.fragments, mats);
        this.bvh.build(loadContext.bvhOptions);
        var t1 = performance.now();
        loadContext.worker.debug("BVH build time (worker thread):" + (t1 - t0));

        // In normal mode, just post back BVH as svf is already posted back earlier.
        loadContext.loadDoneCB("bvh");
    }

    loadContext.loadDoneCB("done");
};

Package.prototype.postLoad = function(loadContext) {

    this.postLoadOfCam(loadContext);

    this.postLoadOfLight(loadContext);

    this.postLoadOfFragments(loadContext);

    this.postLoadOfBBox(loadContext);

    this.postLoadOfObjectIds(loadContext);

    this.postLoadComplete(loadContext);
};

lmv.Package = Package;

})();
;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;

var warnedGzip = false;

/** @constructor */
function PackFileReader(data)
{
    var stream = this.stream = new lmv.InputStream(data);

    var len = stream.getInt32();
    this.type = stream.getString(len);
    this.version = stream.getInt32();

    this.types = null;
    this.entryOffsets = [];

    //read the table of contents
    {
        var offset = stream.offset;

        // Jump to file footer.
        stream.seek(stream.byteLength - 8);

        // Jump to toc.
        var tocOffset = stream.getUint32();
        this.typesOffset = stream.getUint32();

        // Populate type sets.
        stream.seek(this.typesOffset);
        var typesCount = this.readU32V();
        this.types = [];
        for (var i = 0; i < typesCount; ++i)
            this.types.push({
                "entryClass": this.readString(),
                "entryType": this.readString(),
                "version": this.readU32V()
            });

        // Populate data offset list.
        stream.seek(tocOffset);
        var entryCount = this.readU32V();
        var dso = this.entryOffsets;
        for (var i = 0; i < entryCount; ++i)
            dso.push(stream.getUint32());

        // Restore sanity of the world.
        stream.seek(offset);
    }
};

PackFileReader.prototype.readVarint = function() {
    var b;
    var value = 0;
    var shiftBy = 0;
    do {
        b = this.stream.getUint8();
        value |= (b & 0x7f) << shiftBy;
        shiftBy += 7;
    } while (b & 0x80);
    return value;
};
PackFileReader.prototype.readU32V = PackFileReader.prototype.readVarint;

PackFileReader.prototype.readU16 = function () {
    return this.stream.getUint16();
};

PackFileReader.prototype.readU8 = function () {
    return this.stream.getUint8();
};

PackFileReader.prototype.readString = function() {
    return this.stream.getString(this.readU32V());
};

PackFileReader.prototype.readVector3f = function () {
    var s = this.stream;
    return { x:s.getFloat32(), y:s.getFloat32(), z:s.getFloat32()};
};

PackFileReader.prototype.readF32 = function () {
    return this.stream.getFloat32();
};

PackFileReader.prototype.readVector3d = (function() {

    var t = { x:0, y:0, z:0 };

    return function () {
        var s = this.stream;
        t.x = s.getFloat64();
        t.y = s.getFloat64();
        t.z = s.getFloat64();

        return t;
    };
})();

PackFileReader.prototype.readQuaternionf = (function() {

    var q = { x:0, y:0, z:0, w:0 };

    return function() {
        var s = this.stream;
        q.x = s.getFloat32();
        q.y = s.getFloat32();
        q.z = s.getFloat32();
        q.w = s.getFloat32();

        return q;
    };

})();

PackFileReader.prototype.readMatrix3f = (function() {

    var _m = new LmvMatrix4();

    return function(dst) {
        if (!dst) dst = _m;
            
        var s = this.stream;
        dst.identity();
        for (var i = 0; i < 3; ++i)
            for (var j = 0; j < 3; ++j)
                dst.elements[4*i+j] = s.getFloat32();

        return dst;
    };

})();



PackFileReader.prototype.readTransform = (function() {

    var s = { x:1, y:1, z:1 };
    var m = new LmvMatrix4(true);

    return function(entityIndex, buffer, offset, placementTransform, globalOffset, originalTranslation)
    {
        var stream = this.stream;
        var t, q;

        var transformType = stream.getUint8();

        switch (transformType)
        {
            case 4/*TransformType.Identity*/: {
                m.identity();
            } break;
            case 0/*TransformType.Translation*/: {
                t = this.readVector3d();
                m.makeTranslation(t.x, t.y, t.z);
            } break;
            case 1/*TransformType.RotationTranslation*/: {
                q = this.readQuaternionf();
                t = this.readVector3d();
                s.x = 1;s.y = 1;s.z = 1;
                m.compose(t, q, s);
            } break;
            case 2/*TransformType.UniformScaleRotationTranslation*/: {
                var scale = stream.getFloat32();
                q = this.readQuaternionf();
                t = this.readVector3d();
                s.x = scale; s.y = scale; s.z = scale;
                m.compose(t, q, s);
            } break;
            case 3/*TransformType.AffineMatrix*/: {
                this.readMatrix3f(m);
                t = this.readVector3d();
                m.setPosition(t);
            } break;
            default:
                break; //ERROR
        }

        //Report the original translation term to the caller, if they need it.
        //This is only required when reading fragment bounding boxes, where the translation
        //term of this matrix is subtracted from the bbox terms.
        if (originalTranslation) {
            originalTranslation[0] = m.elements[12];
            originalTranslation[1] = m.elements[13];
            originalTranslation[2] = m.elements[14];
        }

        //Apply any placement transform
        if (placementTransform) {
            m.multiplyMatrices(placementTransform, m);
        }

        //Apply global double precision offset on top
        if (globalOffset) {
            m.elements[12] -= globalOffset.x;
            m.elements[13] -= globalOffset.y;
            m.elements[14] -= globalOffset.z;
        }

        //Store result back into single precision matrix or array
        if (entityIndex !== undefined) {
            var src = m.elements;
            // Sometimes we don't want to keep this data (e.g. when we are probing the fragment list
            // to find the data base id to fragment index mappings used for fragment filtering) so we
            // pass a null buffer and if that is the case, bail out here.
            if (!buffer) return;
            buffer[offset+0] = src[0]; buffer[offset+1] = src[1]; buffer[offset+2] = src[2];
            buffer[offset+3] = src[4]; buffer[offset+4] = src[5]; buffer[offset+5] = src[6];
            buffer[offset+6] = src[8]; buffer[offset+7] = src[9]; buffer[offset+8] = src[10];
            buffer[offset+9] = src[12]; buffer[offset+10] = src[13]; buffer[offset+11] = src[14];
        }
        else {
            return new LmvMatrix4().copy(m);
        }
    };

})();

PackFileReader.prototype.getEntryCounts = function() {
    return this.entryOffsets.length;
};

PackFileReader.prototype.seekToEntry = function(entryIndex) {
    var count = this.getEntryCounts();
    if (entryIndex >= count)
        return null;

    // Read the type index and populate the entry data
    this.stream.seek(this.entryOffsets[entryIndex]);
    var typeIndex = this.stream.getUint32();
    if (typeIndex >= this.types.length)
        return null;

    return this.types[typeIndex];
};


PackFileReader.prototype.readPathID = function() {
    var s = this.stream;

    //Construct a /-delimited string as the path to a node
    //TODO: in case we need a split representation (e.g. to follow paths), then
    //an array of numbers might be better to return from here.
    if (this.version < 2) {
        var pathLength = s.getUint16();
        if (!pathLength)
            return null;

        //The first number in a path ID is always zero (root)
        //so we skip adding it to the path string here.
        //Remove this section if that is not the case in the future.
        s.getUint16();
        if (pathLength == 1)
            return "";

        var path = s.getUint16();
        for (var i = 2; i < pathLength; ++i) {
            path += "/" + s.getUint16();
        }
    }
    else {
        var pathLength = this.readU32V();
        if (!pathLength)
            return null;

        //The first number in a path ID is always zero (root)
        //so we skip adding it to the path string here.
        //Remove this section if that is not the case in the future.
        this.readU32V();
        if (pathLength == 1)
            return "";

        var path = this.readU32V();
        for (var i = 2; i < pathLength; ++i) {
            path += "/" + this.readU32V();
        }
    }
    return path;
};

lmv.PackFileReader = PackFileReader;

})();;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;

/** @constructor */
function PropertyDatabase(dbjsons) {

    "use strict";

    var _this = this;

    //The property db json arrays.
    //Some of them are held unparsed in blob form
    //with helper arrays containing offsets into the blobs for each value to be parsed on demand
    var _attrs; // Array of arrays. Inner array is in the form [attrName(0), category(1), dataType(2), dataTypeContext(3), description(4), displayName(5), flags(6) ] 
                // See struct AttributeDef in https://git.autodesk.com/A360/platform-translation-propertydb/blob/master/propertydb/PropertyDatabase.h 
    var _offsets;
    var _avs;
    var _valuesBlob;
    var _valuesOffsets;
    var _idsBlob;
    var _idsOffsets;

    //Cached ids of commonly used well known attributes (child, parent, name)
    var _childAttrId;
    var _parentAttrId;
    var _nameAttrId;
    var _instanceOfAttrId;
    var _viewableInAttrId;
    var _externalRefAttrId;
    var _nodeFlagsAttrId;

    //dbjsons is expected to be of the form
    //{ attrs: {filename1:x, filename2:y}, ids: {filename1:x... }, values: {... }, offsets: {... }, avs: {... } }
    //where each of the elements of each array is a pair of the original name and the unzipped *raw* byte
    //array buffer corresponding to the respective property database constituent. In the current implementation
    //each array is expected to only have one name-value element.


    //=========================================================================

    //The attribute definitions blob is considered small enough
    //to parse using regular APIs
    for (var p in dbjsons.attrs) {
        _attrs = lmv.blobToJson(dbjsons.attrs[p]);

        for (var i = 0; i<_attrs.length; i++) {
            var category = _attrs[i][1];

            switch (category) {
                case "__parent__":      _parentAttrId = i; break;
                case "__child__":       _childAttrId = i; break;
                case "__name__":        _nameAttrId = i; break;
                case "__instanceof__":  _instanceOfAttrId = i; break;
                case "__viewable_in__": _viewableInAttrId = i; break;
                case "__externalref__": _externalRefAttrId = i; break;
                case "__node_flags__": _nodeFlagsAttrId = i; break;
                default: break;
            }
        }

        break; //currently we can only handle single property file (no chunking)
    }

    //manual parse of the attribute-value index pairs array
    for (var p in dbjsons.avs) {
        _avs = lmv.parseIntArray(dbjsons.avs[p], 0);

        delete dbjsons.avs; //don't need thi blob anymore

        break; //currently we can only handle single property file (no chunking)

    }


    //manual parse of the offsets array
    for (var p in dbjsons.offsets) {
        _offsets = lmv.parseIntArray(dbjsons.offsets[p], 1); //passing in 1 to reserve a spot for the sentinel value

        //just a sentinel value to make lookups for the last item easier
        _offsets[_offsets.length-1] = _avs.length / 2;

        delete dbjsons.offsets; //don't need this

        break; //currently we can only handle single property file (no chunking)

    }

    //Instead of parsing the values and ids arrays, find the
    //offset of each json item in the blob, and then we can
    //pick and parse specific items later on demand, without
    //parsing the potentially large json blob up front.
    for (var p in dbjsons.values) {
        _valuesBlob = dbjsons.values[p];
        _valuesOffsets = lmv.findValueOffsets(_valuesBlob);

        break; //currently we can only handle single property file (no chunking)

    }

    //Do the same for the ids array -- find the offset to each
    //value but skip the full parse. Note that the ids array is
    //optional as we don't currently use it anywhere
    for (var p in dbjsons.ids) {
        _idsBlob = dbjsons.ids[p];
        _idsOffsets = lmv.findValueOffsets(_idsBlob);

        break; //currently we can only handle single property file (no chunking)

    }



    //=========================================================================

    this.getObjectCount = function() {
        return _offsets.length-1;
    };

    this.getValueAt = function(valId) {
        return lmv.subBlobToJson(_valuesBlob, _valuesOffsets[valId]);
    };

    //faster variant used for traversing the object hierarchy where
    //we know the data type of the value to be an integer
    this.getIntValueAt = function(valId) {
        return lmv.subBlobToJsonInt(_valuesBlob, _valuesOffsets[valId]);
    };


    this.getIdAt = function(entId) {
        return lmv.subBlobToJson(_idsBlob, _idsOffsets[entId]);
    };

    this.getObjectProperties = function(dbId, propFilter, ignoreHidden, propIgnored) {
        var result = {
            "dbId":dbId,
            "properties": []
        };

        var needExternalId = false;
        var needName = false;

        if (!propFilter || propFilter.indexOf("externalId") !== -1) {
            result.externalId = this.getIdAt(dbId);
            needExternalId = true;

            // If there are no other properties required, then just return
            // Useful when we only care about fetching externalId-only data.
            if (propFilter && propFilter.length === 1) {
                return result;
            }
        }

        var parentProps = null;

        //Loop over the attribute index - value index pairs for the objects
        //and for each one look up the attribute and the value in their
        //respective arrays.
        this.enumObjectProperties(dbId, function(attrId, valId) {
            if (attrId == _instanceOfAttrId) {
                //Recursively resolve any common properties from the parent of this instance
                var res = _this.getObjectProperties(_this.getValueAt(valId), propFilter, ignoreHidden);
                if (res && res.properties) {
                    parentProps = res;
                }
                return;
            }

            var attr = _attrs[attrId];

            if (propFilter && propFilter.indexOf(attr[0]) === -1 && propFilter.indexOf(attr[5]) === -1 )
                return;

            if (propIgnored && (propIgnored.indexOf(attr[0]) > -1 || propIgnored.indexOf(attr[5]) > -1 ))
                return;

            if (attrId == _nameAttrId) {
                var val = _this.getValueAt(valId);
                needName = true;
                result.name = val;
            }
            else {
                var flags = (attr[6]) ? attr[6] : 0;
                var displayName = (attr[5]) ? attr[5] : attr[0];

                //skip structural attributes, we don't want those to display
                //NOTE: The list of structural attributes that we check explicitly is not marked
                //as hidden in older versions of the property database, so if we ever want to
                //add them to the result list, we have to explicitly set the hidden flag for those.
                var hidden = (flags & 1 /*afHidden*/)
                      || attrId == _parentAttrId
                      || attrId == _childAttrId
                      || attrId == _viewableInAttrId
                      || attrId == _externalRefAttrId;

                if (ignoreHidden && hidden) {
                    return;
                }

                // type values match those in PropertyDatabase.h
                // See: https://git.autodesk.com/A360/platform-translation-propertydb/blob/master/propertydb/PropertyDatabase.h#L67
                result.properties.push({
                    displayName: displayName,
                    displayValue: _this.getValueAt(valId),
                    displayCategory: attr[1],
                    attributeName: attr[0],
                    type: attr[2],
                    units: attr[3],
                    hidden: hidden
                });
            }
        });

        //Combine instance properties with any parent object properties
        if (parentProps) {
            var myProps = {};
            var rp = result.properties;
            for (var i=0; i<rp.length; i++) {
                myProps[rp[i].displayName] = 1;
            }

            if (!result.name)
                result.name = parentProps.name;

            var pp = parentProps.properties;
            for (var i=0; i<pp.length; i++) {
                if (!myProps.hasOwnProperty(pp[i].displayName)) {
                    rp.push(pp[i]);
                }
            }
        }

        if (propFilter && !result.properties.length && !needExternalId && !needName)
            return null;

        return result;
    };

    this.getExternalIdMapping = function() {
        var mapping = {};
        if (_idsOffsets && 'length' in _idsOffsets) { // Check that it's an indexable type
            for (var dbId=1, len=_idsOffsets.length; dbId<len; ++dbId) {
                var externalId = this.getIdAt(dbId);
                mapping[externalId] = dbId;
            }
        }
        return mapping;
    };

    //Heuristically find the root node(s) of a scene
    //A root is a node that has children, has no (or null) parent and has a name.
    //There can be multiple nodes at the top level (e.g. Revit DWF), which is why
    //we should get the scene root with absolute certainty from the SVF instance tree,
    //but we would have to uncompress and parse that in -- something that is
    //not currently done. This is good enough for now (if pretty slow).
    this.findRootNodes = function() {

        var idroots = [];

        this.enumObjects(function(id) {
            var hasChild = false;
            var hasParent = false;
            var hasName = false;

            _this.enumObjectProperties(id, function(attrId, valId) {
                if (attrId == _parentAttrId) {
                    if (_this.getIntValueAt(valId)) //checks for null or zero parent id, in which case it's considered non-parent
                        hasParent = true;
                } else if (attrId == _childAttrId) {
                    hasChild = true;
                }
                else if (attrId == _nameAttrId) {
                    hasName = true;
                }
            });

            if (hasChild && hasName && !hasParent) {
                idroots.push(id);
            }
        });

        return idroots;
    };

    //Gets the immediate children of a node with the given dbId
    this.getNodeNameAndChildren = function(node /* {dbId:X, name:""} */, skipChildren) {

        var id = node.dbId;

        var children;

        this.enumObjectProperties(id, function(attrId, valId) {
            var val;

            if (attrId == _parentAttrId) {
                //node.parent = this.getIntValueAt(valId); //eventually we will needs this instead of setting parent pointer when creating children below.
            } else if (attrId == _childAttrId && !skipChildren) {
                val = _this.getIntValueAt(valId);
                var child = { dbId:val, parent:node.dbId };
                if (!children)
                    children = [child];
                else
                    children.push(child);

            } else if (attrId == _nameAttrId) {
                node.name = _this.getValueAt(valId); //name is necessary for GUI purposes, so add it to the node object explicitly
            } else if (attrId == _nodeFlagsAttrId) {
                node.flags = _this.getIntValueAt(valId); //flags are necessary for GUI/selection purposes, so add them to the node object
            }
        });

        //If this is an instance of another object,
        //try to get the object name from there.
        //This is not done in the main loop above for performance reasons,
        //we only want to do the expensive thing of going up the object hierarchy
        //if the node does not actually have a name attribute.
        if (!node.name) {
            this.enumObjectProperties(id, function(attrId, valId) {
                if (attrId == _instanceOfAttrId) {
                     var tmp = { dbId:_this.getIntValueAt(valId), name:null };
                     _this.getNodeNameAndChildren(tmp, true);
                     if (tmp && tmp.name && !node.name)
                        node.name = tmp.name;
                }
            });
        }

        return children;
    };


//Duplicated from InstanceTree.js
var NODE_TYPE_ASSEMBLY   = 0x0,    // Real world object as assembly of sub-objects
    NODE_TYPE_GEOMETRY   = 0x6;    // Leaf geometry node

    //Builds a tree of nodes according to the parent/child hierarchy
    //stored in the property database, starting at the node with the given dbId
    this.buildObjectTreeFlat = function(dbId, //current node dbId
                                    parent, //parent dbId
                                    dbToFrag, //map of dbId to fragmentIds
                                    depth, /* start at 0 */
                                    maxDepth, /* returns max tree depth */
                                    nodeStorage
                                    ) {

        if (depth > maxDepth[0])
            maxDepth[0] = depth;

        var node = {dbId : dbId};
        var children = this.getNodeNameAndChildren(node);

        var childrenIds = [];
        var isLeaf = false;

        //leaf node
        if (dbToFrag) {
            var frags = dbToFrag[dbId];
            if (frags !== undefined) {
                if (children && children.length)
                    console.error("Node that has both node children and fragment children! Not supported by flat storage");
                if (!Array.isArray(frags))
                    childrenIds = [frags];
                else
                    childrenIds = frags;
                isLeaf = true;
            }
        }

        //Use default node flags in case none are set
        //This is not the best place to do this, but it's
        //the last place where we can differentiate between "not set" and zero.
        var flags = node.flags || 0;
        if (flags === undefined) {
            if (isLeaf)
                flags = NODE_TYPE_GEOMETRY;
            else if (children)
                flags = NODE_TYPE_ASSEMBLY;
            else
                flags = 0; //??? Should not happen (those nodes are pruned below)
        }

        if (children) {
            for (var j=0; j<children.length; j++) {
                var childHasChildren = this.buildObjectTreeFlat(children[j].dbId, dbId, dbToFrag, depth+1, maxDepth, nodeStorage);

                //For display purposes, prune children that are leafs without graphics
                //and add the rest to the node
                if (childHasChildren)
                    childrenIds.push(children[j].dbId);
            }
        }

        if (childrenIds.length)
            nodeStorage.setNode(dbId, parent, node.name, flags, childrenIds, isLeaf);

        return childrenIds.length;
    };


    this.bruteForceSearch = function(searchText, attributeNames, completeInfo) {
        //var regex = new RegExp(e.data.searchText, "i");
        searchText = searchText.toLowerCase();
        //regex preserves double-quote delimited strings as phrases
        var searchTerms = searchText.match(/"[^"]+"|[^\s]+/g) || [];
        var i = searchTerms.length;
        while (i--) {
            searchTerms[i] = searchTerms[i].replace(/"/g, "");
        }

        var searchList = [];
        for (var i=0; i<searchTerms.length; i++) {

            if (completeInfo || searchTerms[i].length > 1)
                searchList.push(searchTerms[i]);
        }

        if (searchList.length === 0)
            return [];

        //For each search word, find matching IDs
        var results = [];
        var resultNames = {};
        var completeResults = [];

        for (var k=0; k<searchList.length; k++) {
            var result = [];

            //Find all values that match the search text
            //Hopefully this is a small number, otherwise
            //we need a sorted array or an object with properties instead of array
            var matching_vals = [];

            for (var i=0, iEnd=_valuesOffsets.length; i<iEnd; i++) {
                var val = this.getValueAt(i);
                if (typeof val == "string") {
                    if (val.toLowerCase().indexOf(searchList[k]) != -1)
                        matching_vals.push(i);
                }
                else {
                    if (val.toString().toLowerCase().indexOf(searchList[k]) != -1)
                        matching_vals.push(i);
                }
            }

            this.enumObjects(function(id) {
                var name = "";
                var item = null;

                _this.enumObjectProperties(id, function(attrId, valId) {

                    var attr = _attrs[attrId];
                    var displayName = (attr[5]) ? attr[5] : attr[0];

                    if(completeInfo && displayName.toLowerCase() === "name") {
                        name = _this.getValueAt(valId);
                    }

                    if (matching_vals.indexOf(valId) != -1) {
                        //Check attribute name in case a restriction is passed in
                        if (attributeNames && attributeNames.length && attributeNames.indexOf(_attrs[attrId][0]) === -1)
                            return;

                        result.push(id);
                        item = {id: id, nodeName: "", value: _this.getValueAt(valId), name: displayName};
                        return true;
                    }
                });

                if (item && completeInfo && k === 0) {
                    //since we return the intersection we just get the completeInfo for the first term
                    item.nodeName = name;
                    if (searchList.length === 1) {
                        completeResults.push(item);
                    } else {
                        resultNames[id] = item;
                    }
                }

            });

            results.push(result);
        }

        if (results.length === 1) {
            if (completeInfo) {
                return completeResults;
            }

            return results[0];
        }

        //If each search term resulted in hits, compute the intersection of the sets
        var map = {};
        var hits = results[0];
        for (var i=0; i<hits.length; i++)
            map[hits[i]] = 1;


        for (var j=1; j<results.length; j++) {
            hits = results[j];
            var mapint = {};

            for (var i=0; i<hits.length; i++) {
                if (map[hits[i]] === 1)
                    mapint[hits[i]] = 1;
            }

            map = mapint;
        }

        var result = [];
        for (var k in map) {
            result.push(parseInt(k));
            if (completeInfo) {
                completeResults.push(resultNames[k]);
            }
        }

        if (completeInfo) {
            return completeResults;
        }

        return result;

    };


    //Low level access APIs
    this.getAttributeDef = function(attrId) {
        var _raw = _attrs[attrId];
        return {
            //attrName(0), category(1), dataType(2), dataTypeContext(3), description(4), displayName(5), flags(6)
            name:_raw[0],
            category: _raw[1],
            dataType: _raw[2],
            dataTypeContext: _raw[3],
            description: _raw[4],
            displayName: _raw[5],
            flags: _raw[6]
        };
    };

    this.enumAttributes = function(cb) {
        for (var i=1; i<_attrs.length; i++) {
            if (cb(i, this.getAttributeDef(i), _attrs[i]))
                break;
        }
    };

    this.enumObjectProperties = function(dbId, cb) {

        //Start offset of this object's properties in the Attribute-Values table
        var propStart = 2 * _offsets[dbId];

        //End offset of this object's properties in the Attribute-Values table
        var propEnd = 2 * _offsets[dbId+1];

        //Loop over the attribute index - value index pairs for the objects
        //and for each one look up the attribute and the value in their
        //respective arrays.
        for (var i=propStart; i<propEnd; i+=2) {
            var attrId = _avs[i];
            var valId = _avs[i+1];

            if (cb(attrId, valId))
                break;
        }
    };


    this.enumObjects = function(cb) {
        for (var id=1, idend=_offsets.length; id<idend; id++) {
            if (cb(id))
                break;
        }
    };

    this.getAttrChild = function() {
        return _childAttrId;
    };

    this.getAttrParent = function() {
        return _parentAttrId;
    };

    this.getAttrName = function() {
        return _nameAttrId;
    };

    this.getAttrInstanceOf = function() {
        return _instanceOfAttrId;
    };

    this.getAttrViewableIn = function() {
        return _viewableInAttrId;
    };

    this.getAttrXref = function() {
        return _externalRefAttrId;
    };

    this.getAttrNodeFlags = function() {
        return _nodeFlagsAttrId;
    };
}

lmv.PropertyDatabase = PropertyDatabase;

})();
;

(function() {

"use strict";

var av = Autodesk.Viewing,
    avp = av.Private;
var lmv = Autodesk.LMVTK;

var MOBILE_MAX_VCOUNT = 16383;

var F2dDataType = {
    //Fixed size types
    dt_object : 0,
    dt_void : 1,
    dt_byte : 2,
    dt_int : 3,
    dt_float : 4,
    dt_double : 5,
    dt_varint : 6,
    dt_point_varint : 7,

    //Variable size types
    //Data bytes are prefixed by an integer
    //representing the number of elements in the array.
    dt_byte_array : 32,
    dt_int_array : 33,
    dt_float_array : 34,
    dt_double_array : 35,
    dt_varint_array : 36,
    //Special variable int encoding for point data
    dt_point_varint_array : 37,

    //Well-known data types that help reduce output size for commonly
    //encountered simple geometries
    dt_arc : 38,
    dt_circle : 39,
    dt_circular_arc : 40,

    dt_string : 63,
    //do not want to go into varint range
    dt_last_data_type : 127
};

var F2dSemanticType = {
    //For objects with fixed serialization (arc, raster) we don't bother having dedicated semantic for each member
    //and assume the parsing application knows the order they appear. There is still an end-object tag of course
    //which shows where the object ends.
    st_object_member : 0,

    //Simple / fixed size attributes
    st_fill : 1,
    st_fill_off : 2,
    st_clip_off : 3,
    st_layer : 4,
    st_link : 5,
    st_line_weight : 6,
    st_miter_angle : 7,
    st_miter_length : 8,
    st_line_pattern_ref : 9,
    st_back_color : 10,
    st_color : 11,
    st_markup : 12,
    st_object_id : 13,
    st_markup_id : 14,
    st_reset_rel_offset : 15,
    st_font_ref : 16,

    //Compound object opcodes

    //Begin a generic object opcode
    st_begin_object : 32,

    //Style attribute related opcodes. Those are compound objects
    st_clip : 33,
    st_line_caps : 34,
    st_line_join : 35,
    st_line_pattern_def : 36,
    st_font_def : 37,
    st_viewport : 38,

    //Drawables are all objects-typed bounded by begin/end object opcodes

    //Root level document begin
    st_sheet : 42,
    //Circle, Ellipse, Arcs
    st_arc : 43,
    //The grandfather of them all
    st_polyline : 44,
    st_raster : 45,
    st_text : 46,
    st_polytriangle : 47,
    st_dot : 48,
    //end object -- could be ending a generic object or drawable, etc.
    st_end_object : 63,

    st_last_semantic_type : 127
};



function F2D(metadata, manifest, basePath, options) {
    this.metadata = metadata;
    this.scaleX = 1;
    this.scaleY = 1;
    this.bbox = { min:{x:0,y:0,z:0}, max:{x:0,y:0,z:0} };
    this.is2d = true;
    this.layersMap = {};
    this.fontDefs = {};
    this.fontCount = 0;
    this.fontId = 0;
    this.manifestAvailable = false;

    this.objectMemberQueue = [];

    this.propertydb = {
        attrs : [],
        avs: [],
        ids: [],
        values: [],
        offsets: [],
        rcv_offsets: [],
        rcvs : [],
        viewables: []
    };

    if (metadata) {

        var dims = metadata.page_dimensions;

        this.paperWidth = dims.page_width;
        this.paperHeight = dims.page_height;

        // TODO: scale parsing.
        this.scaleX = this.paperWidth / dims.plot_width;
        this.scaleY = this.paperHeight / dims.plot_height;

        this.hidePaper = dims.hide_paper;

        this.bbox.max.x = this.paperWidth;
        this.bbox.max.y = this.paperHeight;

        //Initialize mapping between layer index -> layer number to be used for rendering
        var count = 0;
        //Some geometry comes on null layer, and we reserve a spot for that one.
        //For example, Revit plots have no layers at all.
        this.layersMap[0] = count++;

        for (var l in metadata.layers) {

            var index = parseInt(l);

            //We store in a map in order to allow non-consecutive layer numbers,
            //which does happen.
            this.layersMap[index] = count++;
        }

        this.layerCount = count;

        //Create a layers tree to be used by the UI -- this splits AutoCAD style
        //layer groups (specified using | character) into a tree of layers.
        this.createLayerGroups(metadata.layers);
    }

    this.hidePaper = this.hidePaper || (options && options.modelSpace);

    // For debugging only. Could be removed.
    this.opCount = 0;


    this.fontFaces = [];
    this.fontFamilies = [];
    this.viewports = [0]; // make viewport index start at 1, 0 as paper is used in LineShader
    this.currentVpId = 0; // current viewport index
    this.clips = [0]; // make clip index start at 1, matched with viewport index

    this.strings = [];
    this.stringDbIds = [];
    this.stringBoxes = [];
    this.currentStringNumber = -1;
    this.currentStringBox = new LmvBox3();

    this.objectNumber = 0;
    this.currentFakeId = -2; //We tag certain objects that we care about (like strings) that have no ID with fake negative IDs instead of giving them default ID of 0.
    this.imageNumber = 0;
    this.maxObjectNumber = 0;

    this.objectStack = [];
    this.objectNameStack = [];
    this.parseObjState = {
        polyTriangle : {},
        viewport : {},
        clip : {},
        raster : {},
        text: {},
        fontDef: {},
        uknown: {}
    };

    this.layer = 0;

    this.bgColor = (typeof options.bgColor === "number") ? options.bgColor : 0xffffffff;

    //NOTE: Use of contrast color is turned off in mapColor() until UX makes up their mind
    //one way or another.
    this.contrastColor = this.color = this.fillColor = 0xff000000;
    if (this.hidePaper)
        this.contrastColor = 0xffffff00;

    this.useInstancing = options && !!options.useInstancing; 
    this.isMobile = options && !!options.isMobile;
    this.max_vcount = this.isMobile ? MOBILE_MAX_VCOUNT : undefined;
    this.currentVbb = new avp.VertexBufferBuilder(this.useInstancing, undefined, this.max_vcount);
    this.meshes = [];

    this.numCircles = this.numEllipses = this.numPolylines = this.numLineSegs = 0;
    this.numPolytriangles = this.numTriangles = 0;

    // Newly added f2d pasing stuff.
    this.error = false;

    // Last absolute positions of point parsed so far.
    // Used to decode relative positions parsed from points array.
    this.offsetX = 0;
    this.offsetY = 0;

    // Parse manifest, do stuff.
    // 1. Build image id to raster URI map used to assign values to texture path.
    // 2. Acquire names of property database json streams.
    if (manifest) {
        this.manifestAvailable = true;
        this.imageId2URI = {};
        var assets = manifest.assets;
        for (var i = 0, e = assets.length; i < e; ++i) {
            var entry = assets[i];
            var mime = entry.mime;
            if (mime.indexOf('image/') != -1) {
                var id = entry.id;
                id = id.substr(0, id.indexOf('.'));
                this.imageId2URI[id] = basePath + entry.URI;
            }

            if (entry.type == "Autodesk.CloudPlatform.PropertyAttributes")
                this.propertydb.attrs.push(entry.URI);
            if (entry.type == "Autodesk.CloudPlatform.PropertyValues")
                this.propertydb.values.push(entry.URI);
            if (entry.type == "Autodesk.CloudPlatform.PropertyIDs")
                this.propertydb.ids.push(entry.URI);
            if (entry.type == "Autodesk.CloudPlatform.PropertyViewables")
                this.propertydb.viewables.push(entry.URI);
            if (entry.type == "Autodesk.CloudPlatform.PropertyOffsets") {
                if (entry.id.indexOf('rcv') != -1)
                    this.propertydb.rcv_offsets.push(entry.URI);
                else
                    this.propertydb.offsets.push(entry.URI);
            }
            if (entry.type == "Autodesk.CloudPlatform.PropertyAVs")
                this.propertydb.avs.push(entry.URI);
            if (entry.type == "Autodesk.CloudPlatform.PropertyRCVs")
                this.propertydb.rcvs.push(entry.URI);
        }

    }
}

F2D.prototype.load = function(loadContext, fydoPack) {

    if (!(fydoPack instanceof Uint8Array))
        fydoPack = new Uint8Array(fydoPack);
    this.data = fydoPack;
    this.parse();

    if (this.stringBoxes.length) {
        var fbuf = new Float32Array(this.stringBoxes.length);
        fbuf.set(this.stringBoxes);
        this.stringBoxes = fbuf;
    }

    loadContext.loadDoneCB(true);
};

F2D.prototype.loadFrames = function(loadContext) {

    this.loadContext = loadContext;

    var data = loadContext.data;

    if (data) {
        if (!(data instanceof Uint8Array))
            data = new Uint8Array(data);
        this.data = data;
    } else if (loadContext.finalFrame) {
        this.data = null;

        if (this.stringBoxes.length) {
            var fbuf = new Float32Array(this.stringBoxes.length);
            fbuf.set(this.stringBoxes);
            this.stringBoxes = fbuf;
        }
    }

    this.parseFrames(loadContext.finalFrame);

    loadContext.loadDoneCB(true);
};


F2D.prototype.pushMesh = function(mesh) {
    this.meshes.push(mesh);


    mesh.material = {
                        skipEllipticals : !this.currentVbb.numEllipticals,
                        skipCircles: !this.currentVbb.numCirculars,
                        skipTriangleGeoms : !this.currentVbb.numTriangleGeoms,
                        useInstancing : this.currentVbb.useInstancing
                    };

    if (this.currentImage) {
        mesh.material.image = this.currentImage;
        mesh.material.image.name = this.imageNumber++;
        this.currentImage = null;
    }
}

F2D.prototype.flushBuffer = function(addCount, finalFlush)
{
    if (!this.currentVbb.vcount && !finalFlush)
    {
        return;
    }

    var flush = finalFlush;
    flush = flush || this.currentVbb.isFull(addCount);

    if (flush) {
        if (this.currentVbb.vcount) {
            var mesh = this.currentVbb.toMesh();
            lmv.VBUtils.bboxUnion(this.bbox, mesh.boundingBox);

            this.pushMesh(mesh);
            this.currentVbb = new avp.VertexBufferBuilder(this.useInstancing, undefined, this.max_vcount);
        }

        if (this.loadContext)
            this.loadContext.loadDoneCB(true, finalFlush);
    }


};

F2D.prototype.tx = function(x) {
    return this.sx(x);
};

F2D.prototype.ty = function(y) {
    return this.sy(y);
};

F2D.prototype.sx = function(x) {
    //TODO: The hardcoded scale is used to get the integer coords from FYDO
    //into something normal and close to page coordinates
    return x * this.scaleX;
};

F2D.prototype.sy = function(y) {
    //TODO: The hardcoded scale is used to get the integer coords from FYDO
    //into something normal and close to page coordinates
    return y * this.scaleY;
};

F2D.prototype.invertColor = function(c) {
    var a = ((c >> 24) & 0xff);
    var b = ((c >> 16) & 0xff);
    var g = ((c >>  8) & 0xff);
    var r = ((c)       & 0xff);

    b = 255 - b;
    g = 255 - g;
    r = 255 - r;

    return (a << 24) | (b << 16) | (g << 8) | r;
};

F2D.prototype.mapColor = function(c, isFill) {

    if (!this.hidePaper)
        return c;

    if (this.bgColor !== 0)
        return c;

    //Color substitution in cases when we want to interleave the 2D drawing
    //into a 3D scene (when bgColor is explicitly specified as transparent black (0)
    //and hidePaper is set to true.

    var r = c & 0xff;
    var g = (c & 0xff00) >> 8;
    var b = (c & 0xff0000) >> 16;

    var isGrey = (r === g) && (r === b);

    if (r < 0x7f) {
        //c = this.contrastColor;
    } else if (isGrey && isFill) {
        c = c & 0x99ffffff;
    }

    return c;
};

// ====================== F2D Parser ================================= //

// Restore sign bit from LSB of an encoded integer which has the sign bit
// moved from MSB to LSB.
// The decoding process is the reverse by restoring the sign bit from LSB to MSB.
F2D.prototype.restoreSignBitFromLSB = function(integer) {
    return (integer & 1) ? -(integer >>> 1) : (integer >>> 1);
};

// Convert relative positions to absolute positions, and update global offsets.
F2D.prototype.parsePointPositions = function() {
    var x = this.stream.getVarints();
    var y = this.stream.getVarints();

    x = this.restoreSignBitFromLSB(x);
    y = this.restoreSignBitFromLSB(y);

    x += this.offsetX;
    y += this.offsetY;

    this.offsetX = x;
    this.offsetY = y;

    return [this.tx(x), this.ty(y)];
};

F2D.prototype.parserAssert = function(actualType, expectedType, functionName) {
    if (actualType != expectedType) {
        avp.logger.warn("Expect " + expectedType + "; actual type is " +
            actualType + "; in function " + functionName);
        this.error = true;
        return true;
    } else {
        return false;
    }
};

F2D.prototype.unhandledTypeWarning = function(inFunction, semanticType) {
    avp.logger.warn("Unhandled semantic type : " + semanticType + " in function " + inFunction);
};

F2D.prototype.parseObject = function() {
    var semantic_type = this.stream.getVarints();
    this.objectStack.push(semantic_type);
    //debug(semantic_type);
    switch (semantic_type) {
        case F2dSemanticType.st_sheet :
            this.objectNameStack.push("sheet");
            this.objectMemberQueue.unshift("paperColor");
            break;
        case F2dSemanticType.st_viewport :
            this.objectNameStack.push("viewport");
            this.objectMemberQueue.unshift("units", "transform");
            break;
        case F2dSemanticType.st_clip :
            this.objectNameStack.push("clip");
            this.objectMemberQueue.unshift("contourCounts", "points", "indices");
            break;
        case F2dSemanticType.st_polytriangle :
            this.objectNameStack.push("polyTriangle");
            this.objectMemberQueue.unshift("points", "indices", "colors");
            break;
        case F2dSemanticType.st_raster:
            this.objectNameStack.push("raster");
            this.objectMemberQueue.unshift("position", "width", "height", "imageId");
            break;
        case F2dSemanticType.st_text:
            this.currentStringNumber = this.strings.length;
            if (this.objectNumber === 0)
                this.objectNumber = this.currentFakeId--;
            this.currentStringBox.makeEmpty();
            this.objectNameStack.push("text");
            this.objectMemberQueue.unshift("string", "position", "height", "widthScale", "rotation", "oblique", "charWidths");
            break;
        case F2dSemanticType.st_font_def:
            this.objectNameStack.push("fontDef");
            this.objectMemberQueue.unshift("name", "fullName", "flags", "spacing", "panose");
            break;
        case F2dSemanticType.st_end_object : {
                this.objectStack.pop(); //pop the end_object we pushed at the beginning of the function

                if (!this.objectStack.length)
                    this.parserAssert(0,1, "parseEndObject (Stack Empty)");
                else {
                    //Do any end-of-object post processing depending on object type
                    var objType = this.objectStack.pop(); //pop the start object

                    switch (objType) {
                        case F2dSemanticType.st_polytriangle:   this.actOnPolyTriangle(); break;
                        case F2dSemanticType.st_viewport:       this.actOnViewport(); break;
                        case F2dSemanticType.st_clip:           this.actOnClip(); break;
                        case F2dSemanticType.st_raster:         this.actOnRaster(); break;
                        case F2dSemanticType.st_text:           this.actOnText(); break;
                        case F2dSemanticType.st_font_def:       this.actOnFontDef(); break;
                    }

                    //Zero out the state of the object we just finished processing
                    var name = this.objectNameStack.pop();
                    var state = this.parseObjState[name];
                    for (var p in state)
                        state[p] = null;
                }

                this.objectMemberQueue.length = 0;
            }
            break;
        default:
            this.objectNameStack.push("unknown");
            this.error = true;
            this.unhandledTypeWarning('parseObject', semantic_type);
            break;
    }
};


F2D.prototype.initSheet = function(paperColor) {

    this.bgColor = paperColor;

    if (this.hidePaper)
        return;

    if (this.metadata) {

        var pw = this.paperWidth;
        var ph = this.paperHeight;

        var vbb = this.currentVbb;

        var ss = pw * 0.0075;
        var shadowColor = 0xff555555;

        var points = [0,0, pw,0, pw,ph, 0,ph,
                      ss,-ss, pw+ss,-ss, pw+ss,0, ss,0,
                      pw,0, pw+ss,0, pw+ss,ph-ss, pw, ph-ss];
        var colors = [paperColor, paperColor, paperColor, paperColor,
                      shadowColor, shadowColor, shadowColor,shadowColor,
                      shadowColor, shadowColor, shadowColor,shadowColor];

        var indices = [0,1,2,0,2,3,
                       4,5,6,4,6,7,
                       8,9,10,8,10,11];

        var paperLayer = 0; //Put the paper the null layer so it won't get turned off.
        var paperDbId = -1;

        this.addPolyTriangle(points, colors, indices, 0xffffffff, paperDbId, paperLayer, false);

        //Page outline
        vbb.addSegment(0,0,pw,0,   0, 1e-6, 0xff000000, paperDbId, paperLayer, this.currentVpId);
        vbb.addSegment(pw,0,pw,ph, 0, 1e-6, 0xff000000, paperDbId, paperLayer, this.currentVpId);
        vbb.addSegment(pw,ph,0,ph, 0, 1e-6, 0xff000000, paperDbId, paperLayer, this.currentVpId);
        vbb.addSegment(0,ph,0,0,   0, 1e-6, 0xff000000, paperDbId, paperLayer, this.currentVpId);


        //Test pattern for line styles.
//        for (var i=0; i<39; i++) {
//            vbb.addSegment(0, ph + i * 0.25 + 1, 12, ph + i * 0.25 + 1, 0, -1 /* device space pixel width */, 0xff000000, 0xffffffff, 0, 0, i);
//        }

        //Test pattern for line styles.
//        for (var i=0; i<39; i++) {
//            vbb.addSegment(0, ph + (i+39) * 0.25 + 1, 12, ph + (i+39) * 0.25 + 1, 0, (1.0 / 25.4) /*1mm width*/, 0xff000000, 0xffffffff, 0, 0, i);
//        }

    }
};

F2D.prototype.setObjectMember = function(val) {
    if (!this.objectMemberQueue.length) {
        avp.logger.warn("Unexpected object member. " + val + " on object " + this.objectNameStack[this.objectNameStack.length-1]);
        return false;
    }

    var propName = this.objectMemberQueue.shift();
    var curObjName = this.objectNameStack[this.objectNameStack.length-1];

    //The paper color needs to be processed as soon as it comes in
    //because we want to initialize the page geometry first, before
    //adding any other geometry
    if (curObjName == "sheet" && propName == "paperColor") {
        this.initSheet(val);
        return true;
    }
    else if (curObjName) {
        this.parseObjState[curObjName][propName] = val;
        return true;
    }

    return false;
};


F2D.prototype.parseString = function() {
    var s = this.stream;
    var sema = s.getVarints();

    var len = s.getVarints();
    var ret = s.getString(len);

    switch (sema) {
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(ret))
                return;
            break;
        default: avp.logger.info("Unexpected opcode semantic type for string.");  break;
    }

    return ret;
};


F2D.prototype.actOnFontDef = function() {
    var fontDef = this.parseObjState.fontDef;
    this.fontDefs[++this.fontCount] = fontDef;
    this.fontId = this.fontCount;
};


F2D.prototype.parsePoint = function() {
    var s = this.stream;
    var sema = s.getVarints(); //skip past the semantics
    var ret = this.parsePointPositions();

    switch (sema) {
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(ret))
                return;
            break;
        default: avp.logger.info("Unexpected opcode semantic type for point.");  break;
    }

    return ret;
};


F2D.prototype.parsePointsArray = function() {

    var s = this.stream;

    var sema = s.getVarints();

    var count = s.getVarints(); // number of coordinates * 2
    if (!count) return;
    count = count / 2;

    var ret = [];
    var position;

    for (var i = 0; i < count; ++i) {
        position = this.parsePointPositions();
        ret.push(position[0]);
        ret.push(position[1]);
    }

    switch (sema) {
        case F2dSemanticType.st_polyline :
            this.actOnPolylinePointsArray(ret);
            return;
        case F2dSemanticType.st_dot:
            this.actOnDot(ret);
            return;
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(ret))
                return;
            break;
        default: avp.logger.info("Unexpected opcode semantic type for points array.");  break;
    }

    return ret;
};

F2D.prototype.parseIntArray = function() {
    var s = this.stream;
    var sema = s.getVarints();
    var count = s.getVarints(); // total number of elements in integer array.
    var retVal = [];
    for (var i = 0; i < count; ++i) {
        retVal.push(s.getUint32());
    }

    switch (sema) {
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(retVal))
                return;
            break;
        default:
            this.unhandledTypeWarning('parseIntArray', sema);
            break;
    }

    return retVal;
};

F2D.prototype.parseDoubleArray = function() {
    var s = this.stream;
    var sema = s.getVarints();
    var count = s.getVarints(); // total number of elements in integer array.
    var retVal = [];
    for (var i = 0; i < count; ++i) {
        retVal.push(s.getFloat64());
    }

    switch (sema) {
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(retVal))
                return;
            break;
        default:
            this.unhandledTypeWarning('parseDoubleArray', sema);
            break;
    }

    return retVal;
};

F2D.prototype.parseByteArray = function() {
    var s = this.stream;
    var sema = s.getVarints();
    var count = s.getVarints(); // total number of elements in byte array.
    var retVal = [];
    for (var i = 0; i < count; ++i) {
        retVal.push(s.getUint8());
    }

    switch (sema) {
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(retVal))
                return;
            break;
        default:
            this.unhandledTypeWarning('parseByteArray', sema);
            break;
    }

    return retVal;
};


F2D.prototype.parseVarintArray = function() {
    var s = this.stream;
    var sema = s.getVarints();

    var ret = [];

    // Total number of integers in array, not the total number of bytes.
    var count = s.getVarints();

    for (var i = 0; i < count; ++i) {
        ret.push(s.getVarints());
    }

    switch (sema) {
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(ret))
                return;
            break;
        default:
            this.unhandledTypeWarning('parseVarIntArray', sema);
            break;
    }

    return ret;
};


F2D.prototype.parseInt = function() {
    var s = this.stream;
    var sema = s.getVarints();
    var val = s.getUint32();

    switch (sema) {
        case F2dSemanticType.st_color:
            this.color = this.mapColor(val, false);
            break;
        case F2dSemanticType.st_fill:
            this.fill = true;
            this.fillColor = this.mapColor(val, true);
            break;
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(val))
                return;
        default:
            this.unhandledTypeWarning('parseInt', sema);
            break;
    }

    return val;
};

F2D.prototype.parseVoid = function() {
  var sema = this.stream.getVarints();
  switch (sema) {
      case F2dSemanticType.st_fill_off:
          this.fill = false;
          break;
      default:
          this.unhandledTypeWarning('parseVoid', sema);
          break;
  }
};

F2D.prototype.parseVarint = function() {
    var s = this.stream;
    var semantic_type = s.getVarints();
    var val = s.getVarints();

    switch (semantic_type) {
        case F2dSemanticType.st_line_weight:
            this.lineWeight = this.tx(val);
            break;
        case F2dSemanticType.st_object_id:
        case F2dSemanticType.st_markup_id:
            this.objectNumber = val;
            this.maxObjectNumber = Math.max(this.maxObjectNumber, val);
            break;
        case F2dSemanticType.st_layer:
            this.layer = this.layersMap[val];
            break;
        case F2dSemanticType.st_font_ref:
            this.fontId = val;
            break;
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(val))
                return;
            break;
        default:
            break;
    }

    return val;
};

F2D.prototype.parseFloat = function() {
    var s = this.stream;
    var semantic_type = s.getVarints();
    var val = s.getFloat32();

    switch (semantic_type) {
        case F2dSemanticType.st_miter_angle:
            break;
        case F2dSemanticType.st_miter_length:
            break;
        case F2dSemanticType.st_object_member:
            if (this.setObjectMember(val)) {
                return;
            }
            break;
        default:
            break;
    }

    return val;
};

F2D.prototype.parseCircularArc = function() {
    var s = this.stream;
    var sema = s.getVarints();
    if (this.parserAssert(sema, F2dSemanticType.st_arc, 'parseCircularArc')) return;

    var point = this.parsePointPositions();
    var major = s.getVarints(), /*rotation = s.getFloat32(),*/ start = s.getFloat32(), end = s.getFloat32();

    this.actOnCircularArc(point[0], point[1], start, end, this.sx(major));
};

F2D.prototype.parseCircle = function() {
    var s = this.stream;
    var sema = s.getVarints();
    if (this.parserAssert(sema, F2dSemanticType.st_arc, 'parseCircle')) return;

    var point = this.parsePointPositions();
    var major = s.getVarints();

    this.actOnCompleteCircle(point[0], point[1], this.sx(major));
};

F2D.prototype.parseArc = function() {
    var s = this.stream;
    var sema = s.getVarints();
    if (this.parserAssert(sema, F2dSemanticType.st_arc, 'parseArc')) return;

    // Relative positions.
    var point = this.parsePointPositions();

    var major = s.getVarints();
    var minor = s.getVarints();

    var rotation = s.getFloat32();
    var start = s.getFloat32();
    var end = s.getFloat32();

    this.actOnArc(point[0], point[1], start, end, this.sx(major), this.sy(minor), rotation);
};

F2D.prototype.parseDataType = function() {
    var data_type = this.stream.getVarints();

    switch (data_type) {
        case F2dDataType.dt_void:
            this.parseVoid();
            break;
        case F2dDataType.dt_int :
            this.parseInt();
            break;
        case F2dDataType.dt_object :
            this.parseObject();
            break;
        case F2dDataType.dt_varint :
            this.parseVarint();
            break;
        case F2dDataType.dt_point_varint :
            this.parsePoint();
            break;
        case F2dDataType.dt_float :
            this.parseFloat();
            break;
        case F2dDataType.dt_point_varint_array :
            this.parsePointsArray();
            break;
        case F2dDataType.dt_circular_arc :
            this.parseCircularArc();
            break;
        case F2dDataType.dt_circle :
            this.parseCircle();
            break;
        case F2dDataType.dt_arc :
            this.parseArc();
            break;
        case F2dDataType.dt_int_array:
            this.parseIntArray();
            break;
        case F2dDataType.dt_varint_array:
            this.parseVarintArray();
            break;
        case F2dDataType.dt_byte_array:
            this.parseByteArray();
            break;
        case F2dDataType.dt_string:
            this.parseString();
            break;
        case F2dDataType.dt_double_array:
            this.parseDoubleArray();
            break;
        default:
            this.error = true;
            avp.logger.info("Data type not supported yet: " + data_type);
            break;
    }
};

F2D.prototype.readHeader = function() {
    var stream = this.stream = new lmv.InputStream(this.data);

    // "F2D"
    var header = stream.getString(3);

    if (header != "F2D") {
        avp.logger.error("Invalid F2D header : " + header);
        return false;
    }

    var versionMajor = stream.getString(2);
    if (versionMajor != "01") {
        avp.logger.error("Only support f2d major version 1; actual version is : " + versionMajor);
        return false;
    }

    var dot = stream.getString(1);
    if (dot != ".") {
        avp.logger.error("Invalid version delimiter.");
        return false;
    }

    var versionMinor = stream.getString(2);
    return true;
}

F2D.prototype.parse = function() {
    // Read and check header
    if (!this.readHeader())
        return;

    var stream = this.stream;
    while (stream.offset < stream.byteLength) {
        this.parseDataType();
        if (this.error)
            break;
        this.opCount++;
    }

    this.flushBuffer(0, true);
    this.currentVbb = null;

    this.stream = null;
    this.data = null;

    avp.logger.info("F2d parse: data types count : " + this.opCount);
};

F2D.prototype.parseFrames = function(flush) {

    if (this.data) {
        var stream = this.stream = new lmv.InputStream(this.data);
        while (stream.offset < stream.byteLength) {
            this.parseDataType();
            if (this.error)
                break;
            this.opCount++;
        }
    } else if (!flush) {
        avp.logger.warn("Unexpected F2D parse state: If there is no data, we only expect a flush command, but flush was false.");
    }

    if (flush) {
        this.flushBuffer(0, true);
    }

    this.stream = null;
    this.data = null;
};

// ================= Semantic Analysis Pass ======================//

F2D.prototype.actOnPolylinePointsArray = function(points) {

    this.flushBuffer();
    this.numPolylines ++;

    // For now only consider this.fill == false case.
    // TODO: handle fill case.

    var count = points.length / 2;

    var totalLen = 0;
    var x0 = points[0];
    var y0 = points[1];
    for (var i = 1; i < count; ++i) {
        var x1 = points[2*i];
        var y1 = points[2*i+1];

        // TODO: make sure this function can be reused as is.
        this.currentVbb.addSegment(x0, y0, x1, y1, totalLen, this.lineWeight, this.color, this.objectNumber, this.layer, this.currentVpId);

        totalLen += Math.sqrt((x1-x0)*(x1-x0) + (y1-y0)*(y1-y0));

        x0 = x1;
        y0 = y1;
    }

    this.numLineSegs += count - 1;
};

F2D.prototype.actOnDot = function(points) {

    var x0 = points[0];
    var y0 = points[1];

    this.actOnCompleteCircle(x0, y0, this.sx(1));
};


F2D.prototype.actOnCompleteCircle = function(cx, cy, radius) {
    // Relative positions.
    this.flushBuffer();
    this.numCircles++;

    if (this.fill) {
        //A simple filled circle can be handled
        //as degenerate thick line segment -- lots of these
        //in line style grass clippings
        this.currentVbb.addSegment(cx, cy, cx, cy, 0, 2 * radius, this.color, this.objectNumber,
            this.layer, this.currentVpId, true, false, true);
    } else {
        this.currentVbb.addArc(cx, cy, 0, 2 * Math.PI, /*major*/radius, /*minor*/radius, /*tilt*/0.0,
            this.lineWeight, this.color, this.objectNumber, this.layer, this.currentVpId);
    }
};

F2D.prototype.actOnCircularArc = function(cx, cy, start, end, radius) {
    this.numCircles++;
    this.flushBuffer();

//    debug("circle " + start + " " + end + " c " + this.color.toString(16));

    this.currentVbb.addArc(cx, cy, start, end, /*major*/radius, /*minor*/radius, /*tilt*/0.0,
        this.lineWeight, this.color, this.objectNumber, this.layer, this.currentVpId);
};

F2D.prototype.actOnArc = function(cx, cy, start, end, major, minor, rotation) {
    this.numEllipses++;
    // TODO: need this?
    this.flushBuffer();
    this.currentVbb.addArc(cx, cy, start, end, major, minor, rotation,
        this.lineWeight, this.color, this.objectNumber, this.layer, this.currentVpId);
};

F2D.prototype.actOnRaster = function() {

    if (!this.manifestAvailable)
        return;

    this.flushBuffer(4, true);

    var ps = this.parseObjState.raster;

    var position = ps.position,
        imageId  = ps.imageId,
        imageUri = this.imageId2URI[imageId];

    var width  = this.sx(ps.width),
        height = this.sy(ps.height);

    var centerX = position[0] + 0.5 * width,
        centerY = position[1] - 0.5 * height;

    this.currentVbb.addTexturedQuad(centerX, centerY, width, height, /*rotation*/0, 0xff00ffff, this.objectNumber, this.layer, this.currentVpId);
    this.currentImage = { dataURI: imageUri };

    //We can do one image per Vertex Buffer, so flush the quad
    this.flushBuffer(0, true);
};

F2D.prototype.actOnClip = function() {

    var v = this.parseObjState.clip;
    this.parseObjState.clip = {};

    this.clips.push(v);
};

F2D.prototype.actOnText = function() {
    //TODO: text not currently used for rendering,
    //but we collect the strings for search/lookup purposes
    this.strings[this.currentStringNumber] = this.parseObjState.text.string;
    this.stringDbIds[this.currentStringNumber] = this.objectNumber;
    this.stringBoxes.push(this.currentStringBox.min.x, this.currentStringBox.min.y, this.currentStringBox.max.x, this.currentStringBox.max.y);
    this.currentStringBox.makeEmpty();
    this.currentStringNumber = -1;
    if (this.objectNumber < -1)
        this.objectNumber = 0; //reset the current object ID in case we were using a fake one for the text object
};


var _tmpVector = new LmvVector3();

//Polytriangle processing differs depending on whether
//we want edge antialiasing and whether the renderer is using
//hardware instancing or not, so it require a lot more
//work than other geometries before sending raw primitives to the
//vertex buffer.
F2D.prototype.addPolyTriangle = function(points, colors, inds, color, dbId, layer, antialiasEdges) {
    var me = this;
    var edgeMap = null;

    //For non-text geometry we get good looking results with
    //1 pixel outlines. For text, which is generally small and highly detailed,
    //a 0.5 pixel AA outline does better.
    var aaLineWeight = -1.0; //negative = in pixel units
    if (this.objectStack[this.objectStack.length-1] == F2dSemanticType.st_text)
        aaLineWeight = -0.5;


    function processEdge(iFrom, iTo) {
        if (iFrom > iTo) {
            var tmp = iFrom;
            iFrom = iTo;
            iTo = tmp;
        }

        if (!edgeMap[iFrom])
            edgeMap[iFrom] = [iTo];
        else {
            var adjacentVerts = edgeMap[iFrom];
            var idx = adjacentVerts.lastIndexOf(iTo);
            if (idx == -1)
                adjacentVerts.push(iTo); //first time we see this edge, so remember it as exterior edge
            else
                adjacentVerts[idx] = -1; //the second time we see an edge mark it as interior edge
        }
    }


    function addAllAntialiasEdges() {

        for (var i = 0, iEnd = edgeMap.length; i<iEnd; i++) {

            var adjacentVerts = edgeMap[i];
            if (!adjacentVerts)
                continue;

            for (var j=0; j<adjacentVerts.length; j++) {
                var iTo = adjacentVerts[j];
                if (iTo == -1)
                    continue; //an interior edge was here -- skip
                else {
                    //exterior edge -- add an antialiasing line for it
                    me.flushBuffer(4);
                    me.currentVbb.addSegment(points[2*i], points[2*i+1],
                                             points[2*iTo], points[2*iTo+1],
                                             0,
                                             aaLineWeight,
                                             me.mapColor(colors ? colors[i] : color, true),
                                             dbId, layer, me.currentVpId);
{
                    if (colors && (colors[i] != colors[iTo]))
                        avp.logger.warn("Gouraud triangle encountered. Will have incorrect antialiasing.");}
                }
            }
        }
    }

    function antialiasOneEdge(iFrom, iTo) {
        if (iFrom > iTo) {
            var tmp = iFrom;
            iFrom = iTo;
            iTo = tmp;
        }

        var adjacentVerts = edgeMap[iFrom];
        if (!adjacentVerts)
            return;

        var idx = adjacentVerts.indexOf(iTo);
        if (idx != -1) {
            //exterior edge -- add an antialiasing line for it
            me.flushBuffer(4);
            me.currentVbb.addSegment(points[2*iFrom], points[2*iFrom+1],
                                     points[2*iTo], points[2*iTo+1],
                                     0,
                                     aaLineWeight,
                                     me.mapColor(colors ? colors[iFrom] : color, true),
                                     dbId, layer, me.currentVpId);

            if (colors && (colors[iFrom] != colors[iTo]))
                avp.logger.warn("Gouraud triangle encountered. Will have incorrect antialiasing.");
        }
    }

    if (antialiasEdges) {
        edgeMap = new Array(points.length/2);

        for (var i= 0, iEnd = inds.length; i<iEnd; i+= 3) {
            var i0 = inds[i];
            var i1 = inds[i+1];
            var i2 = inds[i+2];

            processEdge(i0, i1);
            processEdge(i1, i2);
            processEdge(i2, i0);
        }
    }

    //If the polytriangle is part of tesselated text, add it to the current
    //text object bounding box
    if (this.currentStringNumber !== -1) {
        var count = points.length / 2; // number of vertices
        for (var i = 0; i < count; ++i) {
            _tmpVector.set(points[2*i], points[2*i+1], 0);
            this.currentStringBox.expandByPoint(_tmpVector);
        }
    }

    if (this.currentVbb.useInstancing) {
        var count = inds.length;
        for (var i = 0; i < count; i+=3) {
            var i0 = inds[i];
            var i1 = inds[i+1];
            var i2 = inds[i+2];

            this.flushBuffer(4);

            this.currentVbb.addTriangleGeom(points[2*i0], points[2*i0+1],
                                            points[2*i1], points[2*i1+1],
                                            points[2*i2], points[2*i2+1],
                                            this.mapColor(colors ? colors[i0] : color, true), dbId, layer, this.currentVpId);

            if (antialiasEdges) {
                antialiasOneEdge(i0, i1);
                antialiasOneEdge(i1, i2);
                antialiasOneEdge(i2, i0);
            }
        }
    }
    else {
        var count = points.length / 2; // number of vertices

        this.flushBuffer(count);
        var vbb = this.currentVbb;
        var vbase = vbb.vcount;

        for (var i = 0; i < count; ++i) {
            var x = points[2*i];
            var y = points[2*i+1];
            vbb.addVertexPolytriangle(x, y, this.mapColor(colors ? colors[i] : color, true), dbId, layer, this.currentVpId);
        }

        vbb.addIndices(inds, vbase);

        if (antialiasEdges) {
            addAllAntialiasEdges();
        }

    }
};

F2D.prototype.actOnPolyTriangle = function() {

    var ptri = this.parseObjState.polyTriangle;
    this.parseObjState.polyTriangle = {};

    //if (this.objectStack[this.objectStack.length-1] == F2dSemanticType.st_text)
    //    return;

    var points = ptri.points;
    var inds = ptri.indices;
    var colors = ptri.colors;

    if (!points || !inds) {
        avp.logger.warn("Malformed polytriangle.");
        return;
    }

    this.numPolytriangles++;
    this.numTriangles += inds.length / 3;

    this.addPolyTriangle(points, colors, inds, this.color, this.objectNumber, this.layer, true);
};

F2D.prototype.actOnViewport = function() {

    var v = this.parseObjState.viewport;
    this.parseObjState.viewport = {};

    this.viewports.push(v);
    this.currentVpId = this.viewports.length - 1;
};

F2D.prototype.createLayerGroups = function(layers) {

    // Temporary: build the layers tree. Eventually the extractor
    // should be the one doing this; we're incompletely faking it
    // by looking at the layer names.
    //
    var layersRoot = this.layersRoot = {name: 'root', id: 'root', childrenByName: {}, isLayer: false};
    var groupId = 0, layerId = 0;

    for (var l in layers) {

        var index = parseInt(l);
        var layerDef = layers[l];

        var name = (typeof layerDef === "string") ? layerDef : layerDef.name;

        if (!name)
            name = l; //won't get here...

        var path = name.split('|');
        var parent = layersRoot;

        if (path.length > 1) {
            for (var i = 0; i < path.length - 1; ++i) {
                var pathComponent = path[i];
                var item = parent.childrenByName[pathComponent];
                if (!item) {
                    item = {
                        name: pathComponent,
                        id: 'group-' + groupId++,
                        childrenByName: {},
                        isLayer: false
                    };
                    parent.childrenByName[pathComponent] = item;
                }
                parent = item;
            }
        }

        parent.childrenByName[name] = {
            name: name,
            index: index,
            id: layerId++,
            childrenByName: {},
            isLayer: true
        };
    }

    function sortLayers(parent) {
        var children = Object.keys(parent.childrenByName).map(function(k) {return parent.childrenByName[k];});
        delete parent.childrenByName;

        if (children.length) {
            parent.children = children;

            parent.childCount = 0;

            for (var i = 0; i < children.length; ++i) {
                parent.childCount += sortLayers(children[i]);
            }

            children.sort(function (a, b) {
                if (a.isLayer && !b.isLayer) {
                    return -1; // Layers before groups
                } else if (!a.isLayer && b.isLayer) {
                    return 1;
                }
                return a.name.localeCompare(b.name, undefined, {sensitivity: 'base', numeric: true}); // Sort layers and groups by name
            });
        }

        return parent.isLayer ? 1 : parent.childCount;
    }
    sortLayers(this.layersRoot);
};

lmv.F2D = F2D;
lmv.F2dDataType = F2dDataType;
lmv.F2dSemanticType = F2dSemanticType;

})();
;

(function() {

"use strict";

var av = Autodesk.Viewing,
    avp = av.Private;
var lmv = Autodesk.LMVTK;

function F2DOnDemand(metadata, manifest, basePath, options) {
    lmv.F2D.call(this, metadata, manifest, basePath, options);
}

F2DOnDemand.prototype = Object.create(lmv.F2D.prototype);
F2DOnDemand.prototype.constructor = F2DOnDemand;

F2DOnDemand.prototype.load = function(loadContext, fydoPack) {

    if (!(fydoPack instanceof Uint8Array))
        fydoPack = new Uint8Array(fydoPack);
    this.data = fydoPack;
    this.readHeader();
};

F2DOnDemand.prototype.loadFrames = function(loadContext) {

    this.loadContext = loadContext;
    this.acceptMeshCB = loadContext.acceptMeshCB;

    // If there was data left from previous parse, the do it
    if (this.stream == null) {
        // If there is data left, then we stopped before ending
        var data = loadContext.data;

        if (data) {
            if (!(data instanceof Uint8Array))
                data = new Uint8Array(data);
            this.data = data;
        } else if (loadContext.finalFrame) {
            this.data = null;

            if (this.stringBoxes.length) {
                var fbuf = new Float32Array(this.stringBoxes.length);
                fbuf.set(this.stringBoxes);
                this.stringBoxes = fbuf;
            }
        }
    }

    this.parseFrames(loadContext.finalFrame);

    loadContext.loadDoneCB(true);
};


F2DOnDemand.prototype.pushMesh = function(mesh) {
    if (!this.acceptMeshCB || this.acceptMeshCB(mesh)) {
        lmv.F2D.prototype.pushMesh.call(this, mesh);
    }
}

F2DOnDemand.prototype.parseFrames = function(flush) {

    if (this.data || this.stream) {
        if (!this.stream)
            this.stream = new lmv.InputStream(this.data);
        var stream = this.stream;
        while (stream.offset < stream.byteLength) {
            if (this.meshes.length > 0)
                return;
            this.parseDataType();
            if (this.error)
                break;
            this.opCount++;
        }
    } else if (!flush) {
        avp.logger.warn("Unexpected F2D parse state: If there is no data, we only expect a flush command, but flush was false.");
    }

    if (flush) {
        this.flushBuffer(0, true);
    }

    this.stream = null;
    this.data = null;
};

/**
  * Save the state of the F2D stream.
  * @returns {stateObject} the saved state
  */
F2DOnDemand.prototype.saveState = function() {
    var state = {};
    state.fontCount = this.fontCount;
    state.fontId = this.fontId;
    state.objectMemberQueue = [].concat(this.objectMemberQueue);    // Clone array of parse data
    state.viewportCount = this.viewports.length;    // Array is only appended to, so just need length
    state.currentVpId = this.currentVpId;
    state.clipsCount = this.clips.length;           // Array is only appended to, so just need length
    state.stringsCount = this.strings.length;       // Array is only appended to, so just need length
    state.currentStringNumber = this.currentStringNumber;
    state.currentStringBox = this.currentStringBox.clone();         // Clone bounding box
    state.objectNumber = this.objectNumber;
    state.currentFakeId = this.currentFakeId;
    state.maxObjectNumber = this.maxObjectNumber;
    state.objectStack = [].concat(this.objectStack);                // Clone arrays of parse data
    state.objectNameStack = [].concat(this.objectNameStack);        // Clone array of parse data

    // Clone the parseObjState. We just clone the known members, mostly because I read
    // that that was the fastest way to do it. We could use JSON or loops to do it.
    // The members of each subobject are named when added to the objectNameStack.
    var pstate = state.parseObjState = {};
    var polyTri = pstate.polyTriangle = {};
    polyTri.points = this.parseObjState.polyTriangle.points;
    polyTri.indices = this.parseObjState.polyTriangle.indices;
    polyTri.colors = this.parseObjState.polyTriangle.colors;
    var viewport = pstate.viewport = {};
    viewport.units = this.parseObjState.viewport.units;
    viewport.transform = this.parseObjState.viewport.transform;
    var clip = pstate.clip = {};
    clip.contourCounts = this.parseObjState.clip.contourCounts;
    clip.points = this.parseObjState.clip.points;
    clip.indices = this.parseObjState.clip.indices;
    var raster = pstate.raster = {};
    raster.position = this.parseObjState.raster.position;
    raster.width = this.parseObjState.raster.width;
    raster.height = this.parseObjState.raster.height;
    raster.imageId = this.parseObjState.raster.imageId;
    var text = pstate.text = {};
    text.string = this.parseObjState.text.string;
    text.position = this.parseObjState.text.position;
    text.height = this.parseObjState.text.height;
    text.widthScale = this.parseObjState.text.widthScale;
    text.rotation = this.parseObjState.text.rotation;
    text.oblique = this.parseObjState.text.oblique;
    text.charWidths = this.parseObjState.text.charWidths;
    var fontDef = pstate.fontDef = {};
    fontDef.name = this.parseObjState.fontDef.name;
    fontDef.fullName = this.parseObjState.fontDef.fullName;
    fontDef.flags = this.parseObjState.fontDef.flags;
    fontDef.spacing = this.parseObjState.fontDef.spacing;
    fontDef.panose = this.parseObjState.fontDef.panose;
    pstate.uknown = {};

    state.lineWeight = this.lineWeight;
    state.color = this.color;
    state.layer = this.layer;
    state.bgColor = this.bgColor;
    state.vbbCount = this.currentVbb.vcount;        // Need to keep track of whether partial buffer exists
    state.numCircles = this.numCircles;             // reset these to make sure they are consistent
    state.numEllipses = this.numEllipses;
    state.numPolylines = this.numPolylines;
    state.numLineSegs = this.numLineSegs;
    state.numPolytriangles = this.numPolytriangles;
    state.numTriangles = this.numTriangles;
    state.error = this.error;
    state.offsetX = this.offsetX;
    state.offsetY = this.offsetY;
    state.streamPosition = this.stream == null ? 0 : this.stream.offset;    // Save stream seek position
    return state;
}

/**
  * Restore the state of the F2D stream previously saved
  *
  * The restore assumes that we are keeping the same data buffers
  * all of the time. If we need to read data from the file again,
  * then we should keep track of the real position in the file, i.e.
  * the position in the stream plus the position at the start
  * of the data buffer and reverse that when restoring.
  *
  * @param {stateObject} state - the previously saved state
  * @param {Uint8Array} data - If data is not null, then an InputStream is created
  *                     data and the stream is position to the saved position. If data
  *                     is null and this.stream is not null, the this.stream's position
  *                     is set to the saved stream position. If both data and this.stream
  *                     are null, the the state cannot be restored.
  * @returns {boolean} True if the state was restored, or was already correct. false
  *                    if the state couldn't be restored.  
  */
F2DOnDemand.prototype.restoreState = function(state, data) {
    if (data || !this.stream || state.streamPosition != this.stream.offset) {
        if (data)
            this.stream = new lmv.InputStream(data);
        else if (!this.stream)
            return false;
        this.stream.seek(state.streamPosition);
        // We will toss the start buffer if state.vbbCount > 0, so don't worry
        // about initializing the other vbb values.
        this.currentVbb.reset(state.vbbCount);

        this.fontCount = state.fontCount;
        this.fontId = state.fontId;
        this.objectMemberQueue = [].concat(state.objectMemberQueue);
        this.viewports.length = state.viewportCount;
        this.currentVpId = state.currentVpId;
        this.clips.length = state.clipsCount;
        this.strings.length = state.stringsCount;
        this.currentStringNumber = state.currentStringNumber;
        this.currentStringBox = state.currentStringBox;
        this.objectNumber = state.objectNumber;
        this.currentFakeId = state.currentFakeId;
        this.maxObjectNumber = state.maxObjectNumber;
        this.objectStack = [].concat(state.objectStack);
        this.objectNameStack = [].concat(state.objectNameStack);

        // copy the saved parseObjState object back to the F2D stream
        // Again only the known members are copied for performance reasons
        // and the sub-object member names are pushed on the objectNameStack
        var pstate = this.parseObjState;
        var polyTri = pstate.polyTriangle;
        polyTri.points = state.parseObjState.polyTriangle.points;
        polyTri.indices = state.parseObjState.polyTriangle.indices;
        polyTri.colors = state.parseObjState.polyTriangle.colors;
        var viewport = pstate.viewport;
        viewport.units = state.parseObjState.viewport.units;
        viewport.transform = state.parseObjState.viewport.transform;
        var clip = pstate.clip;
        clip.contourCounts = state.parseObjState.clip.contourCounts;
        clip.points = state.parseObjState.clip.points;
        clip.indices = state.parseObjState.clip.indices;
        var raster = pstate.raster;
        raster.position = state.parseObjState.raster.position;
        raster.width = state.parseObjState.raster.width;
        raster.height = state.parseObjState.raster.height;
        raster.imageId = state.parseObjState.raster.imageId;
        var text = pstate.text;
        text.string = state.parseObjState.text.string;
        text.position = state.parseObjState.text.position;
        text.height = state.parseObjState.text.height;
        text.widthScale = state.parseObjState.text.widthScale;
        text.rotation = state.parseObjState.text.rotation;
        text.oblique = state.parseObjState.text.oblique;
        text.charWidths = state.parseObjState.text.charWidths;
        var fontDef = pstate.fontDef;
        fontDef.name = state.parseObjState.fontDef.name;
        fontDef.fullName = state.parseObjState.fontDef.fullName;
        fontDef.flags = state.parseObjState.fontDef.flags;
        fontDef.spacing = state.parseObjState.fontDef.spacing;
        fontDef.panose = state.parseObjState.fontDef.panose;
        
        this.lineWeight = state.lineWeight;
        this.color = state.color;
        this.layer = state.layer;
        this.bgColor = state.bgColor;
        this.numCircles = state.numCircles;
        this.numEllipses = state.numEllipses;
        this.numPolylines = state.numPolylines;
        this.numLineSegs = state.numLineSegs;
        this.numPolytriangles = state.numPolytriangles;
        this.numTriangles = state.numTriangles;
        this.error = state.error;
        this.offsetX = state.offsetX;
        this.offsetY = state.offsetY;
    }
    return true;
}

lmv.F2DOnDemand = F2DOnDemand;

})();
;

(function() {

"use strict";

var lmv = Autodesk.LMVTK;

function F2DProbe() {
    this.data = null;
    this.frameStart = 0;
    this.frameEnd = 0;
    this.stream = null;
    this.opCount = 0;
    this.marker = {frameStart : this.frameStart,
                   frameEnd : this.frameEnd};
}

F2DProbe.prototype.load = function(data) {
    this.data = data;
    this.frameStart = 0;

    if (!this.stream) {
        this.stream = new lmv.CheckedInputStream(this.data);
        // Skip headers.
        this.stream.seek(8);
        this.frameStart = 8;
        this.frameEnd = 8;
    }
    else {
        this.stream.reset(this.data);
        this.stream.seek(0);
        this.frameEnd = 0;
    }

    this.probe();
    this.marker.frameStart = this.frameStart;
    this.marker.frameEnd = this.frameEnd;
    return this.marker;
};

var F2dProbeDataType = lmv.F2dDataType;
var F2dProbeSemanticType = lmv.F2dSemanticType;

F2DProbe.prototype.readColor = function() {
    var s = this.stream;
    s.getVarints();// data type : dt_int 3
    s.getVarints(); // semantic type : st_object_member 0
    s.skipUint32(); // color
};

F2DProbe.prototype.parsePointPositions = function() {
    this.stream.getVarints();
    this.stream.getVarints();
};

F2DProbe.prototype.unhandledTypeWarning = function(inFunction, semanticType) {
    avp.logger.warn("Unhandled semantic type when probing F2d : " + semanticType + " in function " + inFunction);
};

F2DProbe.prototype.parseObject = function() {
    /*var semantic_type =*/ this.stream.getVarints();
    //debug("object parsing : type" + semantic_type);
};


F2DProbe.prototype.parseString = function() {
    var s = this.stream;
    s.getVarints();
    var len = s.getVarints();
    s.skipBytes(len);
};

F2DProbe.prototype.parsePoint = function() {
    this.stream.getVarints();
    this.parsePointPositions();
};

F2DProbe.prototype.parseVarintArray = function() {
    var s = this.stream;
    s.getVarints();

    var count = s.getVarints();
    for (var i = 0; i < count; ++i)
        s.getVarints();
};

F2DProbe.prototype.parseByteArray = function() {
    var s = this.stream;
    s.getVarints();
    var count = s.getVarints();
    s.skipBytes(count);
};

F2DProbe.prototype.parseEndOfObject = function() {
    var s = this.stream;
    s.getVarints();
    s.getVarints();
};

F2DProbe.prototype.parsePointsArray = function(context) {
    var s = this.stream;
    var sema = s.getVarints();
    var count = s.getVarints(); // number of coordinates * 2
    if (!count) return;
    count = count / 2;
    for (var i = 0; i < count; ++i)
        this.parsePointPositions();
};

F2DProbe.prototype.parsePoint = function(context) {
    var s = this.stream;
    var sema = s.getVarints();
    this.parsePointPositions();
};

F2DProbe.prototype.parseInt = function() {
    var s = this.stream;
    var sema = s.getVarints();

    switch (sema) {
        case F2dProbeSemanticType.st_color:
            s.skipUint32();
            break;
        case F2dProbeSemanticType.st_fill: {
            s.skipUint32();
            break;
        }
        default:
            s.skipUint32();
            this.unhandledTypeWarning('parseInt', sema);
            break;
    }
};

F2DProbe.prototype.parseVoid = function() {
    var sema = this.stream.getVarints();
    switch (sema) {
        case F2dProbeSemanticType.st_fill_off:
            break;
        default:
            this.unhandledTypeWarning('parseVoid', sema);
            break;
    }
};

F2DProbe.prototype.parseVarint = function() {
    this.stream.getVarints();
    this.stream.getVarints();
};

F2DProbe.prototype.parseIntArray = function() {
    var s = this.stream;
    s.getVarints();
    var count = s.getVarints();
    for (var i = 0; i < count; ++i)
        s.skipUint32();
};

F2DProbe.prototype.parseFloat = function() {
    var s = this.stream;
    s.getVarints();
    s.getFloat32();
};

F2DProbe.prototype.parseDoubleArray = function() {
    var s = this.stream;
    s.getVarints();
    var count = s.getVarints();
    for (var i = 0; i < count; ++i)
        s.skipFloat64();
};

F2DProbe.prototype.parseCircularArc = function() {
    var s = this.stream;
    s.getVarints();
    this.parsePointPositions();
    s.getVarints();
    s.getFloat32();
    s.getFloat32();
};

F2DProbe.prototype.parseCircle = function() {
    var s = this.stream;
    s.getVarints();
    this.parsePointPositions();
    s.getVarints();
};

F2DProbe.prototype.parseArc = function() {
    var s = this.stream;
    s.getVarints();
    this.parsePointPositions();
    s.getVarints();
    s.getVarints();
    s.getFloat32();
    s.getFloat32();
    s.getFloat32();
};

F2DProbe.prototype.parseDataType = function() {
    var data_type = this.stream.getVarints();

    switch (data_type) {
        case F2dProbeDataType.dt_void:
            this.parseVoid();
            break;
        case F2dProbeDataType.dt_int :
            this.parseInt();
            break;
        case F2dProbeDataType.dt_object :
            this.parseObject();
            break;
        case F2dProbeDataType.dt_varint :
            this.parseVarint();
            break;
        case F2dProbeDataType.dt_float :
            this.parseFloat();
            break;
        case F2dProbeDataType.dt_point_varint :
            this.parsePoint();
            break;
        case F2dProbeDataType.dt_point_varint_array :
            this.parsePointsArray();
            break;
        case F2dProbeDataType.dt_circular_arc :
            this.parseCircularArc();
            break;
        case F2dProbeDataType.dt_circle :
            this.parseCircle();
            break;
        case F2dProbeDataType.dt_arc :
            this.parseArc();
            break;
        case F2dProbeDataType.dt_varint_array:
            this.parseVarintArray();
            break;
        case F2dProbeDataType.dt_int_array:
            this.parseIntArray();
            break;
        case F2dProbeDataType.dt_byte_array:
            this.parseByteArray();
            break;
        case F2dProbeDataType.dt_string:
            this.parseString();
            break;
        case F2dProbeDataType.dt_double_array:
            this.parseDoubleArray();
            break;
        default:
            this.error = true;
            avp.logger.error("Bad op code encountered : " + data_type + " , bail out.");
            break;
    }

    if (!this.error)
        this.frameEnd = this.stream.offset;
};

F2DProbe.prototype.probe = function() {
    var stream = this.stream;
    var error = false;

    try {
        while (stream.offset < stream.byteLength) {
            this.parseDataType();
            if (this.error) {
                break;
            }
            this.opCount++;
        }
    } catch (exc) {
        // Typically caused by out of bounds access of data.
        var message = exc.toString();
        var stack = exc.stack ? exc.stack.toString() : "...";

        // Don't panic with this - we are supposed to hit out of bounds a couple of times when probing.
        //debug("Error in F2DProbe.prototype.probe : " + message + " with stack : " + stack);
    }
};

lmv.F2DProbe = F2DProbe;

})();;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;

// Similar as InputStream but with bounds checking.
// Throw exception when out of bounds access is / to be made.
function CheckedInputStream(buf) {
    this.buffer = buf;
    this.offset = 0;
    this.byteLength = buf.length;

    //We will use these shared memory arrays to
    //convert from bytes to the desired data type.
    this.convBuf = new ArrayBuffer(8);
    this.convUint8 = new Uint8Array(this.convBuf);
    this.convUint16 = new Uint16Array(this.convBuf);
    this.convInt32 = new Int32Array(this.convBuf);
    this.convUint32 = new Uint32Array(this.convBuf);
}

function OutOfBoundsBufferAccessException(offset) {
    this.offset = offset;
    this.message = "try to access an offset that is out of bounds: " + this.offset;
    this.toString = function() {
        return this.message;
    };
}

CheckedInputStream.prototype.boundsCheck = function(offset) {
    if (offset >= this.byteLength) {
        throw new OutOfBoundsBufferAccessException(offset);
    }
}

CheckedInputStream.prototype.seek = function(off) {
    this.boundsCheck(off);
    this.offset = off;
};

CheckedInputStream.prototype.getBytes = function(len) {
    this.boundsCheck(this.offset + len);
    var ret = new Uint8Array(this.buffer.buffer, this.offset, len);
    this.offset += len;
    return ret;
};

CheckedInputStream.prototype.skipBytes = function(len) {
    this.boundsCheck(this.offset + len);
    this.offset += len;
};


CheckedInputStream.prototype.getVarints = function () {
    var b;
    var value = 0;
    var shiftBy = 0;
    do {
        this.boundsCheck(this.offset);
        b = this.buffer[this.offset++];
        value |= (b & 0x7f) << shiftBy;
        shiftBy += 7;
    } while (b & 0x80);
    return value;
};

CheckedInputStream.prototype.getUint8 = function() {
    this.boundsCheck(this.offset + 1);
    return this.buffer[this.offset++];
};

CheckedInputStream.prototype.getUint16 = function() {
    this.boundsCheck(this.offset + 2);
    this.convUint8[0] = this.buffer[this.offset++];
    this.convUint8[1] = this.buffer[this.offset++];
    return this.convUint16[0];
};

CheckedInputStream.prototype.getInt16 = function() {
    var tmp = this.getUint16();
    //make negative integer if the ushort is negative
    if (tmp > 0x7fff)
        tmp = tmp | 0xffff0000;
    return tmp;
};

CheckedInputStream.prototype.getInt32 = function() {
    this.boundsCheck(this.offset + 4);
    var src = this.buffer;
    var dst = this.convUint8;
    var off = this.offset;
    dst[0] = src[off];
    dst[1] = src[off+1];
    dst[2] = src[off+2];
    dst[3] = src[off+3];
    this.offset += 4;
    return this.convInt32[0];
};

CheckedInputStream.prototype.getUint32 = function() {
    this.boundsCheck(this.offset + 4);
    var src = this.buffer;
    var dst = this.convUint8;
    var off = this.offset;
    dst[0] = src[off];
    dst[1] = src[off+1];
    dst[2] = src[off+2];
    dst[3] = src[off+3];
    this.offset += 4;
    return this.convUint32[0];
};

CheckedInputStream.prototype.skipUint32 = function() {
    this.boundsCheck(this.offset + 4);
    this.offset += 4;
};

CheckedInputStream.prototype.getFloat32 = function() {
    this.boundsCheck(this.offset + 4);
    this.offset += 4;
    return 0;
};

CheckedInputStream.prototype.getFloat64 = function() {
    this.boundsCheck(this.offset + 8);
    this.offset += 8;
    return 0;
};

CheckedInputStream.prototype.skipFloat64 = function() {
    this.boundsCheck(this.offset + 8);
    this.offset += 8;
};

CheckedInputStream.prototype.reset = function (buf) {
    this.buffer = buf;
    this.offset = 0;
    this.byteLength = buf.length;
};

lmv.CheckedInputStream = CheckedInputStream;

})();

;

(function() {

    "use strict";

    var av = Autodesk.Viewing,
        avp = av.Private;

    avp.inWorkerThread = (typeof self !== 'undefined') && (typeof window === 'undefined');

    var XhrConstructor;
    if (typeof XMLHttpRequest !== "undefined") {
        XhrConstructor = XMLHttpRequest;
    } else {
        //Node.js code path
        XhrConstructor = require("xhr2");

        //Patch xhr2 to allow Cookie headers so we can do auth against viewing.api.autodesk.com
        //by faking being a browser
        XhrConstructor.prototype._restrictedHeaders.cookie = false;
    }

    var ViewingService = {};

    var warnedGzip = false;

    // Simplify Unix style file path. For example, turn '/a/./b/../../c/' into "/c".
    // Required to deal with OSS crappy URNs where there are embedded '..'.
    function simplifyPath(path) {

        var elements = path.split('/');
        if (elements.length == 0)
            return path;

        var stack = [];
        for (var index = 0; index < elements.length; ++index) {
            var c = elements[index];
            if (c === '.') {
                continue;
            }  if (c === '..' && stack.length) {
                stack.pop();
            } else {
                stack.push(c);
            }
        }

        // Great, the path commits suicide.
        if (stack.length == 0)
            return '';

        return stack.join("/");
    }

    function textToArrayBuffer(textBuffer, startOffset) {
        var len = textBuffer.length - startOffset;
        var arrayBuffer = new ArrayBuffer(len);
        var ui8a = new Uint8Array(arrayBuffer, 0);
        for (var i = 0, j = startOffset; i < len; i++, j++)
            ui8a[i] = (textBuffer.charCodeAt(j) & 0xff);
        return ui8a;
    }


    ViewingService.OSS_PREFIX = "urn:adsk.objects:os.object:";

    ViewingService.getDirectOSSUrl = function(options, path) {
        // When we see a resource is hosted on OSS (by checking the urn prefix where it contain a specific signature),
        // we'll construct the full OSS url that can be used to call the OSS GET object API.
        // The construction process will extract the OSS bucket name (which is the payload between the signature and the first forward slash first enoutered afterwards),
        // and then the object name (which is the payload left). The object name has to be URL encoded because OSS will choke on forward slash.
        var ossIndex = path.indexOf(ViewingService.OSS_PREFIX);
        if (ossIndex !== -1) {
            var ossPath = path.substr(ossIndex + ViewingService.OSS_PREFIX.length);
            var bucket = ossPath.substr(0, ossPath.indexOf("/"));
            var object = ossPath.substr(ossPath.indexOf("/") + 1);
            object = simplifyPath(object);
            return av.makeOssPath(options.endpoint, bucket, object);
        }
    };

    /**
     * Construct full URL given a potentially partial viewing service "urn:" prefixed resource
     * @returns {string}
     */
    ViewingService.generateUrl = function (baseUrl, api, path) {

        path = simplifyPath(path);

        //Check if it's a viewing service item path
        //Public/static content will not have the urn: prefix.
        //So URL construction is a no-op
        if (decodeURIComponent(path).indexOf('urn:') !== 0)
            return path;

        //Remove "urn:" prefix when getting URN-based stuff (manifests and thumbnails)
        if (api !== 'items') {
            path = path.substr(4);
        }

        switch (api) {
            case "items": return av.getItemApi(baseUrl) + path;
            case "bubbles": return av.getManifestApi(baseUrl) + path;
            case "thumbnails": return av.getThumbnailApi(baseUrl) + path;
        }
    };

    function isRemotePath(baseUrl, path) {
        if (path.indexOf("file://") !== -1)
            return false;
        if (path.indexOf("://") !== -1)
            return true;
        if (baseUrl)
            return true;
    }

    function loadLocalFile(url, onSuccess, onFailure, options) {

        if (url.indexOf("file://") === 0)
            url = url.substr(7);

        function postProcess(data) {
            if (options.responseType == "json") {
                try {
                    return JSON.parse(data.toString("utf8"));
                } catch(e) {
                    onFailure(e);
                }
            }
            return data;
        }

        //Always use async on Node
        require('fs').readFile(url, function(error, data) {
            if (error) {
                onFailure(0,0,{httpStatusText:error, url:url});
            } else {
                if (data[0] == 31 && data[1] == 139) {
                    require('zlib').gunzip(data, null, function(error, data) {
                        if (error)
                            onFailure(0,0,{httpStatusText:error, url:url});
                        else {
                            data = postProcess(data);
                            if (options.ondata)
                                options.ondata(data);
                            onSuccess(data);
                        }
                    });
                } else {
                    data = postProcess(data);
                    if (options.ondata)
                        options.ondata(data);
                    onSuccess(data);
                 }
            }
        });
    }

    /**
     *  Performs a GET/HEAD request to Viewing Service.
     *
     * @param {string} viewingServiceBaseUrl - The base url for the viewing service.
     * @param {string} api - The api to call in the viewing service.
     *  @param {string} url - The url for the request.
     *  @param {function} onSuccess - A function that takes a single parameter that represents the response
     *                                returned if the request is successful.
     *  @param {function} onFailure - A function that takes an integer status code, and a string status, which together represent
     *                                the response returned if the request is unsuccessful, and a third data argument, which
     *                                has more information about the failure.  The data is a dictionary that minimally includes
     *                                the url, and an exception if one was raised.
     *  @param {Object=} [options] - A dictionary of options that can include:
     *                               headers - A dictionary representing the additional headers to add.
     *                               queryParams - A string representing the query parameters
     *                               responseType - A string representing the response type for this request.
     *                               {boolean} [encodeUrn] - when true, encodes the document urn if found.
     *                               {boolean} [noBody] - when true, will perform a HEAD request
     */
    ViewingService.rawGet = function (viewingServiceBaseUrl, api, url, onSuccess, onFailure, options) {

        var options = options ? options : {};

        //NODE
        if (av.isNodeJS && !isRemotePath(viewingServiceBaseUrl, url)) {
            loadLocalFile(url, onSuccess, onFailure, options);
            return;
        }

        //See if it can be mapped to a direct OSS path
        var ossUrl = ViewingService.getDirectOSSUrl(options, url);

        if (ossUrl)
            url = ossUrl;
        else
            url = ViewingService.generateUrl(viewingServiceBaseUrl, api, url);

        if (options.queryParams) {
            url = url + "?" + options.queryParams;
        }

        var request = new XhrConstructor();

        function onError(e) {
            if (onFailure)
                onFailure(request.status, request.statusText, {url: url});
        }

        function onLoad(e) {
            if (request.status === 200) {

                if (request.response
                    && request.response instanceof ArrayBuffer) {
                    var rawbuf = new Uint8Array(request.response);
                    // It's possible that if the Content-Encoding header is set,
                    // the browser unzips the file by itself, so let's check if it did.
                    // Return raw buffer if skip decompress is true
                    if (!options.skipDecompress && rawbuf[0] == 31 && rawbuf[1] == 139) {
                        if (!warnedGzip) {
                            warnedGzip = true;
                            avp.logger.warn("An LMV resource (" + url + ") was not uncompressed by the browser. This hurts performance. Check the Content-Encoding header returned by the server and check whether you're getting double-compressed streams. The warning prints only once but it's likely the problem affects multiple resources.");
                        }
                        try {
                            rawbuf = new Zlib.Gunzip(rawbuf).decompress();
                        } catch (err) {
                            onFailure(av.ErrorCodes.BAD_DATA,
                                      "Malformed data received when requesting file",
                                      { "url": url, "exception": err.toString(), "stack": err.stack });
                        }
                    }

                    onSuccess(rawbuf);
                }
                else {
                    onSuccess(request.response || request.responseText);
                }
            }
            else {
                onError(e);
            }
        }

        try {

            var async = options.hasOwnProperty('asynchronous') ? options.asynchronous : true;
            request.open(options.noBody ? 'HEAD' : 'GET', url, async);

            if (options.hasOwnProperty('responseType')) {
                request.responseType = options.responseType;
            }

            request.withCredentials = true;
            if (options.hasOwnProperty("withCredentials"))
                request.withCredentials = options.withCredentials;

            if (options.headers) {
                for (var header in options.headers) {
                    request.setRequestHeader(header, options.headers[header]);

                    // Disable withCredentials if header is Authorization type
                    // NOTE: using withCredentials attaches cookie data to request
                    if (header.toLocaleLowerCase() === "authorization") {
                        request.withCredentials = false;
                    }
                }
            }

            if (async) {
                request.onload = onLoad;
                request.onerror = onError;
                request.ontimeout = onError;

                if (options.ondata) {

                    //Set up incremental progress notification
                    //if needed. We have to do some magic in order
                    //to get the received data progressively.
                    //https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/Using_XMLHttpRequest
                    request.overrideMimeType('text/plain; charset=x-user-defined');
                    options._dlProgress = {
                        streamOffset: 0,
                        counter: 0
                    };

                    request.onreadystatechange = function() {

                        if (request.readyState > 2) {

                            var textBuffer = request.responseText;

                            // No new data coming in.
                            if (options._dlProgress.streamOffset >= textBuffer.length)
                                return;

                            var arrayBuffer = textToArrayBuffer(textBuffer, options._dlProgress.streamOffset);

                            options._dlProgress.streamOffset = textBuffer.length;

                            options.ondata(arrayBuffer);
                        }
                    };
                }
            }

            request.send();

            if (options.skipAssetCallback) {
            } else {
                if (avp.inWorkerThread) {
                    self.postMessage({assetRequest: [url, options.headers, null /* ACM session id, null in this case. */]});
                } else {
                    avp.assets.push([url, options.headers, null /* ACM session id, null in this case. */]);
                }
            }

            if (!async) {
                onLoad();
            }
        }
        catch (e) {
            onFailure(request.status, request.statusText, {url: url, exception: e});
        }
    };


    // Create the default failure callback.
    //
    ViewingService.defaultFailureCallback = function (httpStatus, httpStatusText, data) {
        if (httpStatus == 403) {
            this.raiseError(
                av.ErrorCodes.NETWORK_ACCESS_DENIED,
                "Access denied to remote resource",
                { "url": data.url, "httpStatus": httpStatus, "httpStatusText": httpStatusText });
        }
        else if (httpStatus == 404) {
            this.raiseError(
                av.ErrorCodes.NETWORK_FILE_NOT_FOUND,
                "Remote resource not found",
                { "url": data.url, "httpStatus": httpStatus, "httpStatusText": httpStatusText });
        }
        else if (httpStatus >= 500 && httpStatus < 600) {
            this.raiseError(
                av.ErrorCodes.NETWORK_SERVER_ERROR,
                "Server error when accessing resource",
                { "url": data.url, "httpStatus": httpStatus, "httpStatusText": httpStatusText });
        }
        else if (data.exception) {
            this.raiseError(
                av.ErrorCodes.NETWORK_FAILURE,
                "Network failure",
                { "url": data.url, "exception": data.exception.toString(), "stack": data.exception.stack});
        }
        else {
            this.raiseError(
                av.ErrorCodes.NETWORK_UNHANDLED_RESPONSE_CODE,
                "Unhandled response code from server",
                { "url": data.url, "httpStatus": httpStatus, "httpStatusText": httpStatusText, data:data });
        }
    };



    function copyOptions(loadContext, options) {

        //Those are the usual defaults when called from the LMV worker
        if (!options.hasOwnProperty("asynchronous"))
            options.asynchronous = true;
        else if (!options.asynchronous)
            avp.logger.warn("LMV: Sync XHR used. Performance warning.");

        if (!options.hasOwnProperty("responseType"))
            options.responseType = "arraybuffer";

        //Add options junk we got from the main thread context
        options.withCredentials = !!loadContext.auth;
        options.headers = loadContext.headers;
        options.queryParams = loadContext.queryParams;
        options.endpoint = loadContext.endpoint;
    }

    //Utility function called from the web worker to set up the options for a get request,
    //then calling ViewingService.get internally
    ViewingService.getItem = function (loadContext, url, onSuccess, onFailure, options) {

        options = options || {};

        copyOptions(loadContext, options);
        url = simplifyPath(url);

        // VIEWING V2 can only handle encoded URN
        var index1 = url.indexOf('urn:');
        var index2 = url.indexOf('?');
        if (index1 !== -1) {
            if (index2 !== -1) {
                url = url.substr(0, index1) + encodeURIComponent(url.substring(index1, index2)) + url.substr(index2);
            }
            else {
                url = url.substr(0, index1) + encodeURIComponent(url.substr(index1));
            }
        }

        ViewingService.rawGet(loadContext.endpoint, 'items', url, onSuccess, onFailure, options);

    };

    //Utility function called from the web worker to set up the options for a get request,
    //then calling ViewingService.get internally
    ViewingService.getManifest = function (loadContext, url, onSuccess, onFailure, options) {

        options = options || {};

        if (!options.hasOwnProperty("responseType"))
            options.responseType = "json";

        copyOptions(loadContext, options);

        ViewingService.rawGet(loadContext.endpoint, 'bubbles', url, onSuccess, onFailure, options);

    };

    //Utility function called from the web worker to set up the options for a get request,
    //then calling ViewingService.get internally
    ViewingService.getThumbnail = function (loadContext, url, onSuccess, onFailure, options) {

        options = options || {};

        copyOptions(loadContext, options);

        if (!options.queryParams) {
            var role = options.role || "rendered";
            var sz = options.size || 400;
            options.queryParams = "guid=" + encodeURIComponent(options.guid) + "&role=" + role + "&width=" + sz + "&height=" + sz;
        }

        ViewingService.rawGet(loadContext.endpoint, 'thumbnails', url, onSuccess, onFailure, options);

    };


    ViewingService.getACMSession = function (endpoint, acmProperties, onSuccess, onFailure) {

        var acmHeaders = {};
        var token;

        for (var key in acmProperties) {

            if (key === "oauth2AccessToken")
                token = acmProperties[key];

            else if (key.indexOf("x-ads-acm") !== -1)
                acmHeaders[key] = acmProperties[key];
                if (av.isMobileDevice()) av.HTTP_REQUEST_HEADERS = acmHeaders;
        }

        // The value of this can be anything. Required for some arcane reasons.
        acmHeaders.application = "autodesk";

        var xhr = new XMLHttpRequest();
        xhr.open("POST", endpoint + '/oss-ext/v2/acmsessions', true);
        xhr.setRequestHeader("Content-Type", "application/json");
        xhr.setRequestHeader("Authorization", "Bearer " + token);
        xhr.responseType = "json";

        xhr.onload = function () {
            if (xhr.status === 200 && xhr.response) {
                // If the response is a string (e.g. from IE), need to parse it to an object first
                var response = typeof(xhr.response) === 'string' ? JSON.parse(xhr.response) : xhr.response;

                if (response && response.acmsession) {
                    onSuccess(response.acmsession);
                }
                else {
                    onFailure(xhr.status, "Can't get acm session from response.");
                }

            } else {
                onFailure(xhr.status);
            }
        };

        xhr.onerror = onFailure;
        xhr.ontimeout = onFailure;
        xhr.send(JSON.stringify(acmHeaders));

        // "application" header is only required for OSS end point, and should not be passed
        // with normal requests because this header is not in allowed header sets of APIGEE.
        delete acmHeaders.application;

    };

    avp.ViewingService = ViewingService;

})();
;

(function() {

var av = Autodesk.Viewing,
    lmv = Autodesk.LMVTK,
    avp = av.Private;

function guardFunction(loadContext, f) {
    try {
        f();
    }
    catch (exc) {
        loadContext.raiseError(
            av.ErrorCodes.BAD_DATA, "Unhandled exception while reading pack file",
            { "url": loadContext.url, "exception": exc.toString(), "stack": exc.stack });
    }
}

function doGeomLoad(loadContext) {

    var _this = loadContext.worker;

    //Make a blocking request -- it's ok, because
    //we are in a worker thread.

    function onSuccess(arrayBuffer) {
        _this.postMessage({
            url: loadContext.url,
            workerId: loadContext.workerId,
            progress: 0.5
        }); //rough progress reporting -- can do better

        guardFunction(loadContext, function() {

            var pfr = new lmv.PackFileReader(arrayBuffer);

            var raisedError = false;

            var options = {
                estimateSizeOnly: true,
                packNormals: (typeof loadContext.packNormals !== "undefined") ? loadContext.packNormals : true
            };

            var estLength = 0;
            for (var i = 0, iEnd = pfr.getEntryCounts(); i<iEnd; i++)
            {
                var mesh = lmv.readGeometry(pfr, i, options);
                estLength += ((mesh && mesh.sharedBufferBytes) || 0);
            }

            var sharedBuffer = estLength? new ArrayBuffer(estLength) : null;
            var currentOffset = 0;

            var msg = { "packId": loadContext.packId,
                "workerId" : loadContext.workerId,
                "progress": 1,
                "meshes" : [],
                "sharedBuffer": sharedBuffer
            };

            var transferList = sharedBuffer ? [sharedBuffer] : [];

            options = {
                dstBuffer: sharedBuffer,
                startOffset: 0,
                estimateSizeOnly: false,
                packNormals: (typeof loadContext.packNormals !== "undefined") ? loadContext.packNormals : true
            };

            for (var i = 0, iEnd = pfr.getEntryCounts(); i<iEnd; i++)
            {
                options.startOffset = currentOffset;

                var mesh = lmv.readGeometry(pfr, i, options);

                if (mesh) {
                    currentOffset += (mesh.sharedBufferBytes || 0);
                    msg.meshes[i] = mesh;
                } else {
                    // it doesn't make much sense to raise an error for each entry that can't
                    // be read, because chances are they will all be unreadable after the
                    // first bad one.
                    if (!raisedError) {
                        _this.raiseError(
                            av.ErrorCodes.BAD_DATA, "Unable to load geometry",
                            { "url": loadContext.url });
                        raisedError = true;
                    }

                    // in this case, we still post the full message instead of just null;
                    // the mesh itself will be null, of course.
                    _this.postMessage(msg);
                }
            }

            _this.postMessage(msg, transferList);
        });

    }

    // With this option to control whether want to record assets request.
    // Skip it when on demand loading enabled.
    var options = {
        skipAssetCallback: loadContext.skipAssetCallback
    };
    avp.ViewingService.getItem(loadContext, loadContext.url, onSuccess, loadContext.onFailureCallback, options);

}

lmv.doGeomLoad = doGeomLoad;

})();
;

(function() {

"use strict";

var av = Autodesk.Viewing,
    avp = av.Private;
var lmv = Autodesk.LMVTK;


function guardFunction(loadContext, func)
{
    try {
        func();
    }
    catch (exc) {
        loadContext.worker.raiseError(
            av.ErrorCodes.BAD_DATA, "Unhandled exception while loading SVF",
            { "url": loadContext.url, "exception": exc.toString(), "stack": exc.stack });
        loadContext.worker.postMessage(null);
    }
}

function doLoadSvfContinued(loadContext)
{
    var _this = loadContext.worker;

    guardFunction(loadContext, function(){
        var svf = loadContext.svf;
        function loadDoneCallback(type, meshMessage) {
            if (type == "svf") {

                var msg, xfer;
                var frags = svf.fragments;
                var transferable = [
                    frags.transforms.buffer,
                    frags.packIds.buffer,
                    frags.entityIndexes.buffer,
                    frags.fragId2dbId.buffer
                ];

                if (svf.bvh) {
                    // BVH is posted together with svf,
                    // so can add more buffer to transfer.
                    xfer = {
                        nodes: svf.bvh.nodes.getRawData(),
                        primitives: svf.bvh.primitives,
                        useLeanNodes: (svf.bvh.nodes.bytes_per_node == 32)
                    };
                    transferable.push(xfer.nodes);
                    transferable.push(xfer.primitives.buffer);

                    // Then can safely transfer following buffers from fragments.
                    transferable.push(frags.boxes.buffer);
                    transferable.push(frags.polygonCounts.buffer);
                    transferable.push(frags.materials.buffer);

                    msg = { "svf" : svf, "bvh" : xfer, progress: 1.0 };
                }
                else {
                    msg = { "svf" : svf, progress: 0.8 };
                }

                _this.postMessage(msg, transferable);
            } else if (type == "bvh") {
                xfer = {
                    nodes: svf.bvh.nodes.getRawData(),
                    primitives: svf.bvh.primitives,
                    useLeanNodes: (svf.bvh.nodes.bytes_per_node == 32)
                };

                _this.postMessage( { "bvh" : xfer, basePath: svf.basePath, progress: 1.0 },
                                    [xfer.nodes, xfer.primitives.buffer] );

            } else if (type == "mesh") {

                var transferList = [];
                if (meshMessage.mesh)
                    transferList.push(meshMessage.mesh.vb.buffer);

                _this.postMessage(meshMessage, transferList);

            } else if (type == "done") {
                _this.postMessage( { progress: 1.0 } );
            }
            else {
                _this.raiseError(
                    av.ErrorCodes.BAD_DATA, "Failure while loading SVF",
                    { "url": loadContext.url });
                _this.postMessage(null);
            }
        }

        loadContext.loadDoneCB = loadDoneCallback;

        svf.loadRemainingSvf(loadContext);
    });
}

function doLoadSvf(loadContext) {

    var _this = loadContext.worker;

    _this.postMessage({progress:0.01}); //Tell the main thread we are alive

    var type = "svf";
    var url = loadContext.url.toLocaleLowerCase();
    if (url.lastIndexOf(".gltf") === url.length - 5)
        type = "gltf";
    if (url.lastIndexOf(".glb") === url.length - 4)
        type = "glb";

    function onSuccess(result) {

        _this.postMessage({progress:0.5}); //rough progress reporting -- can do better

        guardFunction(loadContext, function() {

            var svf;
            if (type === "gltf" || type === "glb") {
                // result is json
                svf = new lmv.GltfPackage(result);
            } else {
                // result is arraybuffer
                if (loadContext.perfOpt && 
                    loadContext.perfOpt.memoryOptimizedSvfLoading) {
                  svf = new lmv.PackageLess(new Uint8Array(result));
                }
                else {
                  svf = new lmv.Package(new Uint8Array(result));
                }
            }
            loadContext.svf = svf;
            svf.loadManifest(loadContext);


            if(loadContext.interceptManifest) {
                _this.postMessage({"manifest" : svf.manifest});
            } else {
                loadContext.manifest = svf.manifest;
                doLoadSvfContinued(loadContext);
            }
        });
    }

    var options = {
        responseType: (type === "gltf") ? "json" : "arraybuffer"
    };
    avp.ViewingService.getItem(loadContext, loadContext.url, onSuccess, loadContext.onFailureCallback, options);

    //Prefetch the first geometry pack (we assume there is one), to mask some latency
    //We intentionally ignore any errors here.
    avp.ViewingService.getItem(loadContext, loadContext.basePath + "0.pf", function(){}, function(){}, options);

}

lmv.doLoadSvf = doLoadSvf;
lmv.doLoadSvfContinued = doLoadSvfContinued;

})();
;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;
var av = Autodesk.Viewing,
    avp = av.Private;

function loadPropertyPacks(loadContext, dbId, onPropertyPackLoadComplete) {

    if (loadContext.worker.propdb) {
        onPropertyPackLoadComplete(loadContext.worker.propdb);
        return;
    }

    if (loadContext.worker.propdbFailed) {
        onPropertyPackLoadComplete(null);
        return;
    }

    var dbfiles = loadContext.propertydb;
    if (!dbfiles) {
        loadContext.worker.propdbFailed = true;
        onPropertyPackLoadComplete(null);
        return;
    }

    var loadedDbFiles = {
        ids : {},
        attrs : {},
        offsets : {},
        values: {},
        avs: {}
    };

    //Get the property files
    //TODO: If we start sharding, this has to fetch property file chunk corresponding to the database ID
    //we need the properties for
    var filesToRequest = [];
    filesToRequest.push({filename: dbfiles.attrs.length ? dbfiles.attrs[0] : "objects_attrs.json.gz", storage: loadedDbFiles.attrs});
    filesToRequest.push({filename: dbfiles.values.length ? dbfiles.values[0] : "objects_vals.json.gz", storage: loadedDbFiles.values});
    filesToRequest.push({filename: dbfiles.avs.length ? dbfiles.avs[0] : "objects_avs.json.gz", storage: loadedDbFiles.avs});
    filesToRequest.push({filename: dbfiles.offsets.length ? dbfiles.offsets[0] : "objects_offs.json.gz", storage: loadedDbFiles.offsets});
    filesToRequest.push({filename: dbfiles.ids.length ? dbfiles.ids[0] : "objects_ids.json.gz", storage: loadedDbFiles.ids});

    //Revit outputs backslashes in the
    //relative path. Until this is fixed on the
    //translation side, we have to handle it here.
    for (var i = 0; i < filesToRequest.length; i++) {
        filesToRequest[i].filename = filesToRequest[i].filename.replace(/\\/g, "/");
    }

    //TODO: The section below is temporarily there for AutoCAD, which
    //neither lists property db files in a manifest anywhere, nor compresses
    //them to .gz format so that the code above works... So we do a last
    //attempt to request non-compressed json files.
    var triedUncompressed = false;
    function getUncompressedFiles() {
        var uncompressedFilesToRequest = [];
        uncompressedFilesToRequest.push({filename: "objects_attrs.json", storage: loadedDbFiles.attrs});
        uncompressedFilesToRequest.push({filename: "objects_vals.json", storage: loadedDbFiles.values});
        uncompressedFilesToRequest.push({filename: "objects_avs.json", storage: loadedDbFiles.avs});
        uncompressedFilesToRequest.push({filename: "objects_offs.json", storage: loadedDbFiles.offsets});
        uncompressedFilesToRequest.push({filename: "objects_ids.json", storage: loadedDbFiles.ids});
        return uncompressedFilesToRequest;
    }

    var filesRemaining = filesToRequest.length;
    var filesFailed = 0;

    function onRequestCompletion(data) {

        filesRemaining--;

        if (!data)
            filesFailed++;

        // If all of the files we've requested have been retrieved, create the
        // property database.  Otherwise, request the next required file.
        //
        if (!filesRemaining) {
            if (filesFailed) {
                // When the file request is complete and there's no data, this means
                // that it failed.  Try requesting the uncompressed files, if we haven't
                // already.  If we have, remember that it failed and don't request any
                // more files.
                if (triedUncompressed) {
                    loadContext.worker.propdbFailed = true;
                    onPropertyPackLoadComplete(null);
                    return;
                } else {
                    //Give it another go with uncompressed file names
                    //This will only be the case for very old legacy LMV data.
                    triedUncompressed = true;
                    filesToRequest = getUncompressedFiles();
                    filesRemaining = filesToRequest.length;
                    filesFailed = 0;

                    filesToRequest.forEach(function(f) {
                        requestFile(f.filename, loadContext, onRequestCompletion, f.storage);
                    });
                }
            } else {
                //Store the property db instance to use in further calls to the same worker
                loadContext.worker.propdb = new lmv.PropertyDatabase(loadedDbFiles);
                onPropertyPackLoadComplete(loadContext.worker.propdb);
                loadContext.worker.propdbFailed = false;
                loadContext.worker.propdbURL = loadContext.url;
            }
        }
    }

    // Request the files.
    //
    filesToRequest.forEach(function(f) {
        requestFile(f.filename, loadContext, onRequestCompletion, f.storage);
    });
};


function requestFile(filename, loadContext, onRequestCompletion, storage) {

    function onFailure(status, statusText, data) {
        // We're explicitly ignoring missing property files.
        if (status !== 404) {
            loadContext.onFailureCallback(status, statusText, data);
        }
        onRequestCompletion(null);
    }

    var url = (loadContext.url || '') + filename;
    var onSuccess = function(response)
    {
        storage[filename] = response;
        onRequestCompletion(response);
    };

    avp.ViewingService.getItem(loadContext, url, onSuccess, onFailure);

}


function doPropertyGet(loadContext) {
    var dbId = loadContext.dbId;
    var dbIds = loadContext.dbIds;
    var propFilter = loadContext.propFilter;
    var ignoreHidden = loadContext.ignoreHidden;

    function onPropertyPackLoadComplete(propertyDb) {
        if (propertyDb) {
            if (typeof dbIds !== "undefined") {
                var results = [];
                if (dbIds && dbIds.length) {
                    for (var i=0; i<dbIds.length; i++) {
                        var result = propertyDb.getObjectProperties(dbIds[i], propFilter, ignoreHidden);
                        if (result)
                            results.push(result);
                    }
                } else { //If dbIds is empty, return results for all objects (i.e. no ID filter)
                    for (var i=1, last=propertyDb.getObjectCount(); i<=last; i++) {
                        var result = propertyDb.getObjectProperties(i, propFilter, ignoreHidden);
                        if (result)
                            results.push(result);
                    }
                }
                loadContext.worker.postMessage({cbId:loadContext.cbId, result: results});
            } else {
                var result = propertyDb.getObjectProperties(dbId, propFilter);
                loadContext.worker.postMessage({cbId:loadContext.cbId, result: result});
            }
        }
    }

    loadPropertyPacks(loadContext, dbId, onPropertyPackLoadComplete);
};

function computeTreeBBoxes(nodeAccess, dbId, fragBoxes) {

    var idx = nodeAccess.getIndex(dbId);
    var nodeBoxes = nodeAccess.nodeBoxes;

    function traverseChildren(child_dbId, parentDbID, parentIdx) {

        var childIdx = nodeAccess.getIndex(child_dbId);

        //Recurse, then add all child boxes to make this node's box
        computeTreeBBoxesRec(child_dbId, childIdx);

        var box_offset = parentIdx * 6;
        var child_box_offset = childIdx * 6;
        for (var k=0; k<3; k++) {
            if (nodeBoxes[box_offset+k] > nodeBoxes[child_box_offset+k])
                nodeBoxes[box_offset+k] = nodeBoxes[child_box_offset+k];
            if (nodeBoxes[box_offset+k+3] < nodeBoxes[child_box_offset+k+3])
                nodeBoxes[box_offset+k+3] = nodeBoxes[child_box_offset+k+3];
        }
    }

    function traverseFragments(fragId, dbId, idx){
        var frag_box_offset = fragId * 6;
        var box_offset = idx * 6;

        for (var k=0; k<3; k++) {
            if (nodeBoxes[box_offset+k] > fragBoxes[frag_box_offset+k])
                nodeBoxes[box_offset+k] = fragBoxes[frag_box_offset+k];
            if (nodeBoxes[box_offset+k+3] < fragBoxes[frag_box_offset+k+3])
                nodeBoxes[box_offset+k+3] = fragBoxes[frag_box_offset+k+3];
        }
    }

    function computeTreeBBoxesRec(dbId, idx) {

        var box_offset = idx * 6;
        nodeBoxes[box_offset]   = nodeBoxes[box_offset+1] = nodeBoxes[box_offset+2] =  Infinity;
        nodeBoxes[box_offset+3] = nodeBoxes[box_offset+4] = nodeBoxes[box_offset+5] = -Infinity;

        if (nodeAccess.getNumChildren(dbId)) {
            nodeAccess.enumNodeChildren(dbId, traverseChildren, true);
        }

        //Leaf node -- don't think it's possible for a node to have
        //both children and leaf fragments, but we do handle that here.
        if (nodeAccess.getNumFragments(dbId)) {
            nodeAccess.enumNodeFragments(dbId, traverseFragments);
        }

    }


    computeTreeBBoxesRec(dbId, idx);

}


function buildDbIdToFragMap(fragToDbId) {
    var ret = {};
    for (var i= 0, iEnd=fragToDbId.length; i<iEnd; i++) {

        var dbIds = fragToDbId[i];

        //In 2D drawings, a single fragment (consolidation mesh)
        //can contain multiple objects with different dbIds.
        if (!Array.isArray(dbIds)) {
            dbIds = [dbIds];
        }

        for (var j=0; j<dbIds.length; j++) {
            var dbId = dbIds[j];
            var frags = ret[dbId];
            if (frags === undefined) {
                //If it's the first fragments for this dbid,
                //store the index directly -- most common case.
                ret[dbId] = i;
            }
            else if (!Array.isArray(frags)) {
                //otherwise put the fragments that
                //reference the dbid into an array
                ret[dbId] = [frags, i];
            }
            else {
                //already is an array
                frags.push(i);
            }
        }
    }

    return ret;
}


function doObjectTreeParse(loadContext) {

    var _this = loadContext.worker;

    function onPropertyPackLoadComplete(propertyDb) {
        if(!propertyDb) {
            _this.postMessage({
                cbId: loadContext.cbId,
                error: { instanceTree:null, maxTreeDepth:0 }
            });
            return;
        }

        var dbToFrag;
        if (loadContext.fragToDbId)
            dbToFrag = buildDbIdToFragMap(loadContext.fragToDbId);

        //Find the root object:
        if (!loadContext.worker.rootsDone) {
            loadContext.worker.idroots = propertyDb.findRootNodes();
            loadContext.worker.objCount = propertyDb.getObjectCount();
            loadContext.worker.rootsDone = true;
        }

        var rootId;
        var maxDepth = [0];

        var transferList = [];
        var storage;

        //In the cases of 2D drawings, there is no meaningful
        //object hierarchy, so we don't build a tree.
        var idroots = loadContext.worker.idroots;
        if (idroots && idroots.length)
        {
            storage = new avp.InstanceTreeStorage(propertyDb.getObjectCount(), loadContext.fragToDbId ? loadContext.fragToDbId.length : 0);

            if (idroots.length == 1) {
                //Case of a single root in the property database,
                //use that as the document root.
                rootId = idroots[0];
                propertyDb.buildObjectTreeFlat(rootId, 0, dbToFrag, 0, maxDepth, storage);
            }
            else {
                //Case of multiple nodes at the root level
                //This happens in DWFs coming from Revit.
                //Create a dummy root and add all the other roots
                //as its children.
                rootId = 0;
                var childrenIds = [];

                for (var i=0; i<idroots.length; i++) {
                    propertyDb.buildObjectTreeFlat(idroots[i], 0, dbToFrag, 0, maxDepth, storage);
                    childrenIds.push(idroots[i]);
                }

                storage.setNode(0, 0, "", 0, childrenIds, false);
            }

            storage.flatten();
            transferList.push(storage.nodes.buffer);
            transferList.push(storage.children.buffer);

            //Now compute the bounding boxes for instance tree nodes
            if (loadContext.fragBoxes) {
                var nodeAccess = new avp.InstanceTreeAccess(storage, rootId);
                computeTreeBBoxes(nodeAccess, rootId, loadContext.fragBoxes);
                transferList.push(nodeAccess.nodeBoxes.buffer);
            }
        }

        _this.postMessage({ cbId:loadContext.cbId,
                            result : {
                               rootId: rootId,
                               instanceTreeStorage: storage,
                               instanceBoxes: (!!nodeAccess) ? nodeAccess.nodeBoxes : undefined,
                               maxTreeDepth:maxDepth[0],
                               objectCount:loadContext.worker.objCount
                               }
                          }, transferList);
    }

    loadPropertyPacks(loadContext, null, onPropertyPackLoadComplete);
}

function doPropertySearch(loadContext) {

    var _this = loadContext.worker;

    function onPropertyPackLoadComplete(propertyDb) {
        if (propertyDb) {
            var result = propertyDb.bruteForceSearch(loadContext.searchText, loadContext.attributeNames, loadContext.completeInfo);
            _this.postMessage({ cbId:loadContext.cbId, result:result });
        }
    }

    loadPropertyPacks(loadContext, null, onPropertyPackLoadComplete);
}

function doBuildExternalIdMapping(loadContext) {

    var _this = loadContext.worker;

    function onPropertyPackLoadComplete(propertyDb) {
        if (propertyDb) {
            var mapping = propertyDb.getExternalIdMapping();
            _this.postMessage({cbId : loadContext.cbId, result: mapping});
        }
    }

    loadPropertyPacks(loadContext, null, onPropertyPackLoadComplete);
}

lmv.doBuildExternalIdMapping = doBuildExternalIdMapping;
lmv.doPropertyGet = doPropertyGet;
lmv.doPropertySearch = doPropertySearch;
lmv.doObjectTreeParse = doObjectTreeParse;


})();
;
(function() {

"use strict";

var lmv = Autodesk.LMVTK;

//FUSION SPECIFIC

function doDecompressDelta(loadContext) {

    var _this = loadContext.worker;

    // Step1:decode the compressed data
    var compressData = base64.decode(loadContext.delta);
    compressData = compressData.split('').map(function(e) {
        return e.charCodeAt(0);
    });

    //Step2:decompress the data
    var inflate = new Zlib.Inflate(compressData);
    var output = inflate.decompress();

    //Step3:convert byte array to string
    var json = "";
    for (var i = 0; i < output.length; i++) {
        json += String.fromCharCode(output[i]);
    }

    //Step4:parse scene json
    json = JSON.parse(json);
    _this.postMessage({cbId:loadContext.cbId, index:loadContext.index,res:json});
}

lmv.doDecompressDelta = doDecompressDelta;

})();;

(function() {

"use strict";

var av = Autodesk.Viewing;
var lmv = Autodesk.LMVTK;

var MAX_BUFFER_COUNT = 1e20;    // Large number

function tryCatch(_this, f) {
    try {
        f();
    }
    catch (exc) {
        _this.raiseError(
            av.ErrorCodes.BAD_DATA, "",
            { "exception": exc.toString(), "stack": exc.stack });
        _this.postMessage(null);
    }
}

function restart(worker, initialLoadContext) {
    var parser = initialLoadContext.f2dLoadOptions.onDemandLoading ? lmv.F2DOnDemand : lmv.F2D;
    var f2d = worker.f2d = new parser(initialLoadContext.metadata, initialLoadContext.manifest, initialLoadContext.basePath, initialLoadContext.f2dLoadOptions);
    f2d.F2D_MESH_COUNT_OLD = 0;
    if (worker.onDemandLoading) {
        worker.nextFrame = 0;
        worker.queuedMeshes = [];
        if (!worker.useFrames)
            f2d.load(initialLoadContext, worker.frames[0]);
    }
    return f2d;
}

function reset(worker, initialLoadContext) {
    if (worker.onDemandLoading) {
        worker.requestQueue = [];
    }
    return restart(worker, initialLoadContext);
}

function doParseF2D(loadContext) {

    var _this = loadContext.worker;

    _this.postMessage({progress:0.01}); //Tell the main thread we are alive

    if (loadContext.data) {

        _this.postMessage({progress:0.5}); //rough progress reporting -- can do better

        if (loadContext.f2dLoadOptions.onDemandLoading) {
            var data = loadContext.data;
            if (!(data instanceof Uint8Array))
                data = new Uint8Array(data);
            _this.frames = [ data ];
            _this.nextFrame = 1;
            _this.finalFrame = true;
            _this.initialLoadContext = loadContext;
            _this.onDemandLoading = true;
            _this.streamStates = [];    // setup the stream state array
        }

        _this.totalBufferCount = MAX_BUFFER_COUNT;
        _this.useFrames = false;
        var f2d = reset(_this, loadContext);

        if (_this.onDemandLoading) {
            // First post needs to post entire F2D so we can set up bounding boxes, etc.
            var msg = { "f2dframe" : f2d };
            _this.postMessage(msg);
        } else {
            loadContext.loadDoneCB = function(success) {

                if (success) {
                    var msg = { "f2d" : f2d };
                    _this.postMessage(msg );
                }
                else {
                    _this.raiseError(av.ErrorCodes.BAD_DATA, "", {});
                    _this.postMessage(null);
                }
            };

            tryCatch(_this, function() {
                f2d.load(loadContext, loadContext.data);
            });
        }
    }
    else {
        _this.postMessage(null);
    }
}

function doParseF2DFrame(loadContext) {

    var _this = loadContext.worker;

    var f2d = _this.f2d;

    if (!f2d && loadContext.data) {
        _this.postMessage({progress:0.5}); //rough progress reporting -- can do better

        if (loadContext.f2dLoadOptions.onDemandLoading) {
            _this.frames = [];
            _this.finalFrame = false;
            _this.initialLoadContext = loadContext;
            _this.onDemandLoading = true;
            _this.streamStates = [];    // setup the stream state array
        }

        _this.totalBufferCount = MAX_BUFFER_COUNT;
        _this.useFrames = true;
        f2d = reset(_this, loadContext);

        // First post needs to post entire F2D so we can set up bounding boxes, etc.
        var msg = { "f2dframe" : f2d };
        _this.postMessage(msg);
    }

    function noLoadDoneCallback() {
    }

    // Save the stream state for a buffer.
    // dataBuffer is the index of the data buffer in this.frames.
    function saveStreamState(bufferId, dataBuffer) {
        var streamState = f2d.saveState();
        // Be careful with partial buffers
        _this.streamStates[bufferId + (streamState.vbbCount != 0)] = streamState;
        streamState.dataBuffer = dataBuffer;
    }

    // Restore the stream state
    function restoreStreamState(bufferId) {
        // Need to reposition the stream. If the buffer id is
        // past all states, then start at the last state entered.
        if (bufferId >= _this.streamStates.length)
            bufferId = _this.streamStates.length - 1;
        // Search for the first saved state before the requested id
        var state;
        for (var id = bufferId; !(state = _this.streamStates[id]); --id) {
            if (id <= 0) {
                f2d = restart(_this, _this.initialLoadContext);
                return;
            }
        }

        // Restore the state
        if (f2d.restoreState(state, state.dataBuffer == _this.nextFrame - 1 ? null : _this.frames[state.dataBuffer])) {
            // OK. it worked, clear the queued meshes, reset the mesh count and data buffer
            _this.queuedMeshes.length = 0;
            // If there was a partial buffer, when we saved the state, then we
            // decrement the buffer count so the partial buffer is discarded. 
            f2d.F2D_MESH_COUNT_OLD = id - (state.vbbCount != 0);
            _this.nextFrame = state.dataBuffer + 1;
        } else {
            // Restore failed, restart the stream and the beginning.
            f2d = restart(_this, _this.initialLoadContext);
        }
    }

    function acceptMeshCallback(mesh) {
        if (f2d.F2D_MESH_COUNT_OLD < loadContext.bufferId) {
            ++f2d.F2D_MESH_COUNT_OLD;
            return false;
        }
        return true;
    }

    function loadFrames() {
        if (_this.requestQueue.length == 0)
            return;
        loadContext = _this.requestQueue[0];
        loadContext.loadDoneCB = noLoadDoneCallback;
        loadContext.acceptMeshCB = acceptMeshCallback;
        // Save the state for buffer 0.
        if (_this.streamStates.length == 0)
            saveStreamState(0, 0);
        // Restore the stream state, if needed
        if (f2d && (loadContext.bufferId < f2d.F2D_MESH_COUNT_OLD
            || loadContext.bufferId > f2d.F2D_MESH_COUNT_OLD + _this.queuedMeshes.length)) {
            restoreStreamState(loadContext.bufferId);
        }

        // Remove skipped buffers from queuedMeshes
        f2d.F2D_MESH_COUNT_OLD += _this.queuedMeshes.splice(0, loadContext.bufferId - f2d.F2D_MESH_COUNT_OLD).length;

        if (loadContext.bufferId < f2d.F2D_MESH_COUNT_OLD + _this.queuedMeshes.length) {
            // Extract meshes for this message
            f2d.meshes = _this.queuedMeshes.splice(0, 1);
            // Mark the final frame when we get to the end of the F2D the first time
            loadContext.finalFrame = _this.finalFrame && _this.nextFrame == _this.frames.length
                && _this.queuedMeshes.length == 0 && f2d.stream == null
                && _this.totalBufferCount == MAX_BUFFER_COUNT;
            loadDoneCallback(true, true);
        } else {
            var startId = loadContext.bufferId;
            while (startId <= loadContext.bufferId) {
                if (f2d.stream == null) {
                    // If we loaded a single frame
                    // Need another frame
                    if (_this.nextFrame < _this.frames.length) {
                        // Got more frames, so get the next one
                        loadContext.data = _this.frames[_this.nextFrame++];
                    } else if (_this.finalFrame && _this.queuedMeshes.length == 0) {
                        // No more data. remove request
                        break;
                    } else {
                        // Need more data from the stream worker
                        return;
                    }
                }

                // Mark the last frame we process
                if (_this.nextFrame >= _this.frames.length)
                    loadContext.finalFrame = _this.finalFrame;

                tryCatch(_this, function() {
                    f2d.loadFrames(loadContext);
                });
                // Concatenate meshes with meshes from earlier parse
                _this.queuedMeshes = _this.queuedMeshes.concat(f2d.meshes);
                // Remove meshes before start buffer id
                f2d.F2D_MESH_COUNT_OLD += _this.queuedMeshes.splice(0, loadContext.bufferId - f2d.F2D_MESH_COUNT_OLD).length;
                // Extract meshes for this message
                f2d.meshes = _this.queuedMeshes.splice(0, 1);
                // Set the start of the current meshes
                if (f2d.meshes.length) {
                    // Mark the final frame when we get to the end of the F2D the first time
                    loadContext.finalFrame = _this.finalFrame && _this.nextFrame == _this.frames.length
                        && _this.queuedMeshes.length == 0 && f2d.stream == null
                        && _this.totalBufferCount == MAX_BUFFER_COUNT;
                    loadDoneCallback(true, true);
                    startId = f2d.F2D_MESH_COUNT_OLD;
                    // Save stream state so we can seek to it later
                    if (!_this.streamStates[f2d.F2D_MESH_COUNT_OLD + _this.queuedMeshes.length])
                        saveStreamState(f2d.F2D_MESH_COUNT_OLD + _this.queuedMeshes.length, _this.nextFrame - 1);
                }
            }
        }
        _this.requestQueue.shift();
        _this.timer = setTimeout(loadFrames, 2);
    }

    function loadDoneCallback(success, finalFlush) {
        if (success) {

            if (!f2d.meshes.length && !finalFlush) {
                // No new data coming in.
                // debug("F2D streaming : no new data coming in.");
                return;
            } else {

                var msg = { "f2dframe" : true,
                    "meshes" : f2d.meshes,
                    "baseIndex" : f2d.F2D_MESH_COUNT_OLD,
                    "bbox" : f2d.bbox
                 };
                f2d.F2D_MESH_COUNT_OLD += f2d.meshes.length;

                // Are we at the end of the file? finalFrame means we have received
                // the last frame from the file. nextFrame == frame.length means
                // we have or are parsing it. f2d.stream == null means the parsing is done
                if (loadContext.finalFrame) {

                    //Add f2d properties which are cumulative and their
                    //final values are not known until the end
                    msg.cumulativeProps = {
                        maxObjectNumber : f2d.maxObjectNumber,
                        viewports : f2d.viewports,
                        clips : f2d.clips,
                        strings: f2d.strings,
                        stringDbIds: f2d.stringDbIds,
                        stringBoxes: f2d.stringBoxes
                    };

                    msg.finalFrame = finalFlush;
                    _this.totalBufferCount = f2d.F2D_MESH_COUNT_OLD;

                    if (_this.onDemandLoading) {
                        // Before we know what the final buffer count is we can
                        // queue up requests outside of the buffer count.
                        // Remove any entries that are invalid and modify the restart
                        var queue = [];
                        _this.requestQueue.forEach( function(context) {
                            // request out of range, return
                            if (context.bufferId >= _this.totalBufferCount)
                                return;
                            queue.push(context);
                        });
                        _this.requestQueue = queue;
                    }
                }

                // User transferable objects to pass the array buffers used by mesh without deep copying.
                var transferList = [];
                for (var i = 0, e = f2d.meshes.length; i < e; ++i) {
                    transferList.push(f2d.meshes[i].vb.buffer);
                    transferList.push(f2d.meshes[i].indices.buffer);
                }
                _this.postMessage(msg, transferList);

                f2d.meshes = [];
            }
        }
        else {
            _this.raiseError(
                av.ErrorCodes.BAD_DATA, "",
                {});
            _this.postMessage(null);
        }
    }

    if (_this.onDemandLoading) {
        // Data just gets put on the frame list
        if (loadContext.data) {
            var data = loadContext.data;
            if (!(data instanceof Uint8Array))
                data = new Uint8Array(data);
            _this.frames.push(data);
            if (loadContext.finalFrame)
                _this.finalFrame = true;
        } else if (loadContext.finalFrame) {
        	_this.finalFrame = true;
        } else if (loadContext.cancel) {
            // restart the stream
            if (f2d)
                f2d = reset(_this, _this.initialLoadContext);
            _this.postMessage({ canceled: true });
        } else if (loadContext.bufferId >= 0 && loadContext.bufferId < _this.totalBufferCount) {
            // This should be a request for a buffer
            _this.requestQueue.push(loadContext);
        }
        if (f2d) {
            if (_this.timer)
                clearTimeout(_this.timer);
            _this.timer = setTimeout(loadFrames, 2);
        }
    } else {
        loadContext.loadDoneCB = loadDoneCallback;

        tryCatch(_this, function() {
            f2d.loadFrames(loadContext);
        });
    }
}

lmv.doParseF2D = doParseF2D;
lmv.doParseF2DFrame = doParseF2DFrame;


})();
;

(function() {

"use strict";

var av = Autodesk.Viewing,
    avp = av.Private;
var lmv = Autodesk.LMVTK;


var ENABLE_F2D_STREAMING_MODE = true;

function requestFileF2D(loadContext, filename, onSuccess) {
    var url = loadContext.basePath + filename;
    avp.ViewingService.getItem(loadContext, url, onSuccess, null);
}


// Stream loading f2d data and prepare parseable data frames.
function doStreamF2D(loadContext) {

    var _this = loadContext.worker;

    _this.postMessage({progress:0.01}); //Tell the main thread we are alive

    //Get the metadata and manifest first.
    var metadata;
    var manifest;
    var doneFiles = 0;

    requestFileF2D(loadContext, "metadata.json.gz", function(data) {
        try {
            metadata = JSON.parse(lmv.utf8ArrayToString(data));
            doneFiles++;
        } catch (e) {
            self.raiseError(
                av.ErrorCodes.BAD_DATA,
                "" /* does not matter what strings we put here since the final user facing error message is solely decided
                by ErrorCodes. Invent another code if we want a specific error message for this error. */
            );
        }

        if (doneFiles === 2)
            doStreamF2D_Continued(loadContext, manifest, metadata);
    });
    requestFileF2D(loadContext, "manifest.json.gz", function(data) {
        try {
            if (data)
                manifest = JSON.parse(lmv.utf8ArrayToString(data));
            //The F2D does not necessarily need a manifest file to load (some old F2Ds don't have that)
            doneFiles++;
        } catch (e) {}

        if (doneFiles === 2)
            doStreamF2D_Continued(loadContext, manifest, metadata);
    });
}

//Loads the F2D stream once the metadata and manifest files are fetched
function doStreamF2D_Continued(loadContext, manifest, metadata) {

    var _this = loadContext.worker;

    var url = loadContext.url;

    // Collect asset urls that to be send to main thread for mobile usage.
    var assets = [];

    var f2dSize;
    if (manifest && manifest.assets) {
        var a = manifest.assets;
        for (var i=0; i<a.length; i++) {
            if (url.indexOf(a[i].URI) != -1) {
                f2dSize = a[i].usize || 0;
                break;
            }
        }
    }

    var probe = new lmv.F2DProbe();

    var first = true;
    var accumulatedStream = new Uint8Array(65536);
    var accumulatedBytes = 0;
    var streamOffset = 0;
    var sentMetadata = false;

    function onSuccess(responseData) {
        // Send collected f2d resource urls to main thread.
        _this.postMessage({"type" : "F2DAssetURL", "urls" : assets});
        assets = null;

        if (ENABLE_F2D_STREAMING_MODE) {

            var  msg = {
                "type" : "F2DSTREAM",
                "finalFrame" : true,
                "finished" : true,
                "progress" : 1
            };

            if (!sentMetadata) {
                msg.manifest = manifest;
                msg.metadata = metadata;
                msg.basePath = loadContext.basePath;
                sentMetadata = true;
            }

            _this.debug("Total text bytes count : " + responseData.length);

            _this.postMessage(msg);

            //Streaming code path ends here -- we have already sent
            //the data back from the progress callback
            return;
        }

        //Non-streaming code path here
        if (accumulatedStream.length > accumulatedBytes)
            accumulatedStream = new Uint8Array(accumulatedStream.buffer.slice(0, accumulatedBytes));

        var view;
        if (accumulatedStream[0] == 31 && accumulatedStream[1] == 139) {
            try {
                view = new Uint8Array(accumulatedStream.buffer, 0, accumulatedBytes);
                view = new Zlib.Gunzip(view).decompress();
            } catch (e) {

            }
        }

        var msg = { "type" : "F2DBLOB",
            "metadata" : metadata,
            "manifest" : manifest,
            "basePath" : loadContext.basePath, // TODO: we might be able to infer this elsewhere.
            "progress" : 1,
            "buffer" : view.buffer};
        var transferList = [];
        transferList.push(view.buffer);
        _this.postMessage(msg, transferList);
    }

    function onData(partial) {

        //Add the new bytes to the accumulation buffer
        if (accumulatedStream.length < partial.length + accumulatedBytes) {
            var newlen = Math.max(accumulatedStream.length * 2, partial.length + accumulatedBytes);
            var ns = new Uint8Array(newlen);
            ns.set(accumulatedStream);
            accumulatedStream = ns;
        }
        accumulatedStream.set(partial, accumulatedBytes);
        accumulatedBytes += partial.length;

        if (!ENABLE_F2D_STREAMING_MODE)
            return;

        if (first) {
            first = false;

            // If the very first two bytes of the entire stream is GZIP magic number,
            // then we fall back on none streaming mode, because streaming mode only
            // work with browser decompression, and the presence of such magic number
            // implies browser decompression fails, for whatever reasons.
            if (accumulatedStream[0] == 31 && accumulatedStream[1] == 139) {
                avp.logger.error("F2D streaming broken by non-streaming unzip!");
                ENABLE_F2D_STREAMING_MODE = false;
                return;
            }
        }

        var view = new Uint8Array(accumulatedStream.buffer, streamOffset, accumulatedBytes - streamOffset);

        try {
            var marker = probe.load(view);

            if (marker.frameEnd > marker.frameStart) {
                var frames = accumulatedStream.buffer.slice(streamOffset + marker.frameStart, streamOffset + marker.frameEnd);
                streamOffset += marker.frameEnd;

                var transferList = [];
                transferList.push(frames);

                var msg = { "type" : "F2DSTREAM",
                    "frames" : frames,
                    "finalFrame" : false
                };

                if (f2dSize)
                    msg.progress = streamOffset / f2dSize;

                if (!sentMetadata) {
                    msg.manifest = manifest;
                    msg.metadata = metadata;
                    msg.basePath = loadContext.basePath;
                    sentMetadata = true;
                }

                _this.postMessage(msg, transferList);

            }
        } catch (e) {
            debug(e);
        }
    }

    avp.ViewingService.getItem(loadContext, url, onSuccess, loadContext.onFailureCallback, {
        ondata: onData,
        responseType: ""
    });

}


lmv.doStreamF2D = doStreamF2D;

})();
;

(function() {

var lmv = Autodesk.LMVTK;
var av = Autodesk.Viewing,
    avp = av.Private;

avp.stopCacheWorker = false;

function getItem(loadContext, path, responseType, callback, cacheOnly) {

	function onSuccess(result) {
		callback(null, result);
	}

	function onError(error) {
		callback(error);
	}

    avp.ViewingService.getItem(loadContext, path, onSuccess, onError,
                        {
	                        responseType: responseType,
	                        skipAssetCallback: true,
	                        noBody: cacheOnly
                        });

}


function getThumbnail(loadContext, urn, guid, callback, cacheOnly) {

	function onSuccess(result) {
		callback(null, result);
	}

	function onError(error) {
		callback(error);
	}

	var urlpath = "urn:" + urn; //HACK: Adding urn: makes the ViewingServiceXhr accept this as a viewing service request.

	avp.ViewingService.getThumbnail(loadContext, urlpath, onSuccess, onError,
                      {
                        asynchronous: true,
                        role: "rendered",
                        size: 400,
                        guid: guid,
                        skipAssetCallback: true,
                        noBody: cacheOnly
                        });

}


function extractPathsFromGraphicsUrn(urn, result) {

	if (urn.indexOf("$file$") !== -1)
		urn = urn.replace("$file$", "");

	var basePath = urn.slice(0, urn.lastIndexOf("/") + 1);
	var localPath = basePath.slice(basePath.indexOf("/")+1);
	//var urnBase = basePath.slice(0, basePath.indexOf("/"));

	//For supporting compound bubbles, we need to prefix
	//by sub-urn as well, otherwise files might clash.
	var localPrefix = "";//urnBase ? crypto.createHash('md5').update(urnBase).digest("hex") + "/" : "";

	result.urn = urn;
	result.basePath = basePath;
	result.localPath = localPrefix + localPath;
	result.rootFileName = urn.slice(urn.lastIndexOf("/") + 1);
}



function listAllDerivativeFiles(loadContext, bubble, callback, progressCallback) {

	//First get all the root derivative files from the bubble
	var res = [];
	(function traverse(node) {

		if (		node.role === "Autodesk.CloudPlatform.PropertyDatabase"
				|| 	node.role === "graphics"
				||  node.role === "Autodesk.CloudPlatform.DesignDescription") {

				var item = { mime: node.mime };

				extractPathsFromGraphicsUrn(node.urn, item);

				res.push(item);
		}

		if (node.type === "geometry") {

			//Why would we be sane and use real booleans??
			if (node.hasThumbnail === "true") {

				var item = {mime: "thumbnail", urn: bubble.urn, guid: node.guid};

				item.localPath = "thumbnails/";

				res.push(item);

			}

		}

		if (node.children) {

			node.children.forEach(function(child) {

				traverse(child);

			});

		}

	})(bubble, "");

	avp.logger.log("Manifests to process: ", res.length);
	var current = 0;
	var done = 0;
	var estSize = 0;
	var countedPropDb = {};


	var processOne = function() {

		function onProgress() {
			done++;
			//avp.logger.log("Manifests done ", done);
			if(done < res.length) {
				progressCallback(done / res.length);
				setTimeout(processOne, 0);
			} else if (done === res.length) {
				progressCallback(1.0);
				var result = {
					list:res,
					totalSize: estSize
				};
				callback(null, result);
			}
		}

		if (current >= res.length)
			return;

		var rootItem = res[current++];

		var basePath;
		var files = rootItem.files = [];

		if (rootItem.mime !== "thumbnail") {
			basePath = rootItem.basePath;
		}

		if (avp.stopCacheWorker) {
			current = res.length;
			done = res.length - 1;
			onProgress();
		} else if (rootItem.mime === "application/autodesk-db") {

			//The file list for property database files is fixed,
			//no need to go to the server to find out
			files.push("objects_attrs.json.gz");
			files.push("objects_vals.json.gz");
			files.push("objects_avs.json.gz");
			files.push("objects_offs.json.gz");
			files.push("objects_ids.json.gz");

			onProgress();
		} else if (rootItem.mime === "thumbnail") {

			rootItem.files.push(rootItem.guid + ".png");

			onProgress();

		} else if (rootItem.mime === "application/autodesk-svf") {

			var svfPath = rootItem.urn.slice(basePath.length);
			files.push(svfPath);

			//Closure to capture loop-variant variable for the getItem callback
			(function() {
				var myItem = rootItem;

				getItem(loadContext, rootItem.urn, "arraybuffer", function(error, success) {

					if (success) {

						var manifest;
						try {
						    var unzip = new Zlib.Unzip(new Uint8Array(success));
							var manifestJson = unzip.decompress("manifest.json");
							var jdr = new lmv.InputStream(manifestJson);
							manifest = JSON.parse(jdr.getString(manifestJson.byteLength));
						} catch (e) {
							avp.logger.error("SVF unzip", e.message);
						}

						if (manifest && manifest.assets) {

							for (var j=0; j<manifest.assets.length; j++) {

								var asset = manifest.assets[j];

								//Skip SVF embedded resources
								if (asset.URI.indexOf("embed:/") === 0)
									continue;

								//Skip non-local property db files
								//Those are listed explicitly in the bubble as property database role
								//so we will get them anyway
								if (asset.URI.indexOf("../") === 0) {

									//To get a correct bubble size estimate,
									//we get the property db file sizes from the SVF manifest,
									//because they are not available in the bubble itself.
									//It's ugly, but such is bubble life.
									//Also, this number seems to be the uncompressed size of the property db files,
									//so it's an overestimate, and we divide by 4 to get a more reasonable one.
									if (!countedPropDb[rootItem.basePath]) {
										estSize += asset.size / 4;
									}

									continue;
								}

								estSize += asset.size;

								myItem.files.push(asset.URI);

							}

						}

						countedPropDb[rootItem.basePath] = 1;

					}

					onProgress();
				});

			})();

		} else if (rootItem.mime === "application/autodesk-f2d") {

			files.push("manifest.json.gz");
			var manifestPath = basePath + "manifest.json.gz";

			//Closure to capture loop-variant variable for the getItem callback
			(function() {

				var myItem = rootItem;

				getItem(loadContext, manifestPath, "arraybuffer", function(error, success) {

					if (success) {

						estSize += success.byteLength;

						var manifest;
						try {
							var jdr = new lmv.InputStream(success);
							manifest = JSON.parse(jdr.getString(success.length));
						} catch (e) {
							avp.logger.error("Gunzip", e.message);
						}

						if (manifest && manifest.assets) {

							for (var j=0; j<manifest.assets.length; j++) {

								var asset = manifest.assets[j];

								//Skip non-local property db files
								//Those are listed explicitly in the bubble as property database role
								//so we will get them anyway
								if (asset.URI.indexOf("../") === 0)
									continue;

								estSize += asset.size;

								myItem.files.push(asset.URI);

							}

						}

					}

					onProgress();

				});

			})();
		} else {

			//All other files are assumed to be just the file listed in the bubble
			files.push(rootItem.rootFileName);

			onProgress();

		}

	};

	//Kick off 6 parallel jobs
	for (var k=0; k<6; k++)
		processOne();

}


function downloadAllDerivativeFiles(loadContext, fileList, callback, progressCallback) {

	var succeeded = 0;
	var failed = 0;

	var flatList = [];

	for (var i=0; i<fileList.length; i++) {
		var item = fileList[i];
		for (var j=0; j<item.files.length; j++) {

			var flatItem = {
				basePath : item.basePath,
				localPath : /*destDir +*/ item.localPath,
				fileName : item.files[j]
			};

			if (item.urn) {
				flatItem.urn = item.urn;
				flatItem.guid = item.guid;
				flatItem.mime = item.mime;
			}

			flatList.push(flatItem);
		}
	}

	avp.logger.log("Total items to download:", flatList.length);

	var current = 0;
	var done = 0;

	var downloadOneItem = function() {

		if (current >= flatList.length)
			return;

		var fi = flatList[current++];

		var downloadComplete = function(error, success) {

			if (error) {
				failed++;
				avp.logger.error("Failed to download file.", fi.localPath + fi.fileName, error);
			}
			else {
				succeeded++;
				//avp.logger.log("Downloaded", fi.localPath + fi.fileName);
			}
			done++;
			if (done < flatList.length) {
				progressCallback(done / flatList.length);
				setTimeout(downloadOneItem, 0);
			} else if (done === flatList.length) {
				progressCallback(1.0);
				callback(failed, succeeded);
			}
		};

		if(avp.stopCacheWorker) {
			current = flatList.length;
			done = flatList.length - 1;
			downloadComplete();
		}
		else if (fi.mime && fi.mime === "thumbnail")
			getThumbnail(loadContext, fi.urn, fi.guid, downloadComplete, true);
		else {
			getItem(loadContext, fi.basePath + encodeURIComponent(fi.fileName), null, downloadComplete, true);
		}

	};

	//Kick off 6 parallel jobs
	for (var k=0; k<6; k++)
		downloadOneItem();

};



function doPopulateCache(loadContext) {

	var bubble = loadContext.bubble;

	if (!loadContext.headers)
		loadContext.headers = {};

	if(bubble) {
		avp.stopCacheWorker = false;

		var _this = loadContext.worker;

		listAllDerivativeFiles(loadContext, bubble,
			function(error, fileList) {

				if(avp.stopCacheWorker) {
					_this.postMessage({type:"done", canceled: true });
				} else if (fileList) {

					avp.logger.log("Got file list, starting download");
					_this.postMessage(fileList);

					downloadAllDerivativeFiles(loadContext, fileList.list,
						function(loadsFailed, loadsSucceeded) {
							_this.postMessage({type:"done", canceled: avp.stopCacheWorker, failed:loadsFailed, succeeded: loadsSucceeded});
						},
						function(progress) {
							_this.postMessage({type:"progress", value: 0.2 + 0.8 * progress});
						}
					);
				} else {
					_this.postMessage({type:"done", error: error});
				}
			},
			function(progress) {
				_this.postMessage({type:"progress", value: 0.2 * progress});
			}
		);
	}
	else {
		avp.stopCacheWorker = true;
	}
}

lmv.doPopulateCache = doPopulateCache;

})();
;

(function() {

"use strict";

var av = Autodesk.Viewing;

av.EventDispatcher = function() {
};


av.EventDispatcher.prototype = {

    constructor: av.EventDispatcher,


    apply: function(object) {

		object.addEventListener = av.EventDispatcher.prototype.addEventListener;
		object.hasEventListener = av.EventDispatcher.prototype.hasEventListener;
		object.removeEventListener = av.EventDispatcher.prototype.removeEventListener;
		object.fireEvent = av.EventDispatcher.prototype.fireEvent;
		object.dispatchEvent = av.EventDispatcher.prototype.fireEvent;
    },

    /**
     * Adds an event listener.
     * @param {(string | type)} type
     * @param {function} listener
     */
    addEventListener : function(type, listener)
    {
        if (!type) return;
        if ( this.listeners === undefined ) this.listeners = {};

        if (typeof this.listeners[type] == "undefined"){
            this.listeners[type] = [];
        }

        this.listeners[type].push(listener);
    },

    /**
     * Returns true if the specified listener already exists, false otherwise.
     * @param {(string)} type
     * @param {function} listener
     */
    hasEventListener : function (type, listener) {

        if (!type) return false;
        if (this.listeners === undefined) return false;
        var listeners = this.listeners;
        if (listeners[ type ] !== undefined && listeners[ type ].indexOf(listener) !== -1) {
            return true;
        }

        return false;
    },


    /**
     * @param {(string)} type
     * @param {function} listener
     */
    removeEventListener : function(type, listener)
    {
        if (!type) return;
        if ( this.listeners === undefined ) this.listeners = {};

        if (this.listeners[type] instanceof Array){
            var li = this.listeners[type];
            for (var i=0, len=li.length; i < len; i++){
                if (li[i] === listener){
                    li.splice(i, 1);
                    break;
                }
            }
        }
    },


    /**
     * @param {(string | type)} event
     */
    fireEvent : function(event)
    {
		if ( this.listeners === undefined ) this.listeners = {};

        if (typeof event == "string"){
            event = { type: event };
        }
        if (!event.target){
            try {
                event.target = this;
            } catch (e) {}
        }

        if (!event.type){
            throw new Error("event type unknown.");
        }

        if (this.listeners[event.type] instanceof Array) {
            var typeListeners = this.listeners[event.type].slice();
            for (var i=0; i < typeListeners.length; i++) {
                    typeListeners[i].call(this, event);
            }
        }
    }

};



})();
;
/** @license Copyright (c) 2013 Autodesk Inc. */
/** Version : @buildnum@ */

(function() {

"use strict";

var av = Autodesk.Viewing;
var avp = av.Private;

var ModelUnits = {
    METER       : 'm',
    CENTIMETER  : 'cm',
    MILLIMETER  : 'mm',
    FOOT        : 'ft',
    INCH        : 'in'
};

av.ModelUnits = ModelUnits;

/**
 * Core class representing the geometry.
 *
 * @constructor
 * @memberof Autodesk.Viewing
 * @alias Autodesk.Viewing.Model
 * @category Core
 */
var Model = function( modelData )
{
    WGS.RenderModel.call(this);
    this.myData = modelData;
    this.sharedPath = null;
    this.propWorker = null;

    // RenderModel overrides

    /**
     * @returns {InstanceTree} Instance tree of the model if available, otherwise null.
     */
    this.getInstanceTree = function() {
        if (this.myData)
            return this.myData.instanceTree;
        return null;
    };

    /**
     * @returns {THREE.Box3} Bounding box of the model if available, otherwise null.
     */
    this.getBoundingBox = function() {
        if (this.myData)
            return this.myData.bbox;
        return null;
    };

    /**
     * @returns {boolean} Whether the model is 2D.
     */
    this.is2d = function() {
        return !!(this.myData && this.myData.is2d);
    };
};

/*
 * Don't set Model's prototype to RenderModel. It's not needed for now,
 * and we would also have to defer the initialization of the prototype
 * until WGS (an external dependency) is ready.
 */
//Model.prototype = Object.create(WGS.RenderModel.prototype);

av.EventDispatcher.prototype.apply( Model.prototype );
Model.prototype.constructor = Model;

/**
 * Set the geometry data.
 * @param {object} data - Data that represents the geometry.
 */
Model.prototype.setData = function( data )
{
    this.myData = data;
};

/**
 * Returns the geometry data.
 */
Model.prototype.getData = function()
{
    return this.myData;
};

/**
 * Returns an object wrapping the bubble/manifest entry for the
 * loaded geometry. Contains data such as the viewableID, guid, role...
 */
Model.prototype.getDocumentNode = function() {
    if (this.myData.loadOptions) {
        return this.myData.loadOptions.bubbleNode || null;
    }
    return null;
};

/**
 * Returns the root of the geometry node graph.
 * @returns {object} The root of the geometry node graph. Null if it doesn't exist.
 */
Model.prototype.getRoot = function()
{
    if (this.myData && this.myData.instanceTree)
        return this.myData.instanceTree.root;
    return null;
};

/**
 * Returns the root of the geometry node graph.
 * @returns {number} The ID of the root or null if it doesn't exist.
 */
Model.prototype.getRootId = function()
{
    if (this.myData && this.myData.instanceTree)
        return this.myData.instanceTree.getRootId();
    return 0;
};


/**
 * Returns the scale factor of model's distance unit to meters.
 * @returns {number} The scale factor of the model's distance unit to meters or unity if the units aren't known.
 */
Model.prototype.getUnitScale = function()
{
    var unit;

    if (!this.is2d()) {
        if (this.myData && this.myData.overriddenUnits) {
            // explicit override trumps all
            unit = this.myData.overriddenUnits;
        } else if(this.myData && this.myData.scalingUnit) {
            unit = this.myData.scalingUnit; // only using if scaling was actually applied
        } else {
            unit = this.getMetadata('distance unit', 'value', null);
        }
    }
    else {
        unit = this.getMetadata('page_dimensions', 'page_units', null);
    }

    if (unit)
        unit = unit.toLowerCase();

    //Why are translators not using standard strings for those?!?!?!?
    switch (unit) {
        case 'meter'      :
        case 'meters'     :
        case 'm'          : return 1.0;
        case 'feet and inches':
        case 'foot'       :
        case 'feet'       :
        case 'ft'         : return 0.3048;
        case 'inch'       :
        case 'inches'     :
        case 'in'         : return 0.0254;
        case 'centimeter' :
        case 'centimeters':
        case 'cm'         : return 0.01;
        case 'millimeter' :
        case 'millimeters':
        case 'mm'         : return 0.001;
        default: return 1.0;
    }
};

/**
 * Returns a standard string representation of the model's distance unit.
 * @returns {string} Standard representation of model's unit distance or null if it is not known.
 */
Model.prototype.getUnitString = function() {

    var unit;

    if (!this.is2d()) {
        // Check if there's an overridden model units in bubble.json (this happens in Revit 3D files)
        if (this.myData && this.myData.overriddenUnits) {
            // explicit override trumps all
            unit = this.myData.overriddenUnits;
        } else if(this.myData && this.myData.scalingUnit) {
            unit = this.myData.scalingUnit; // only using if scaling was actually applied
        } else {
            unit = this.getMetadata('distance unit', 'value', null);
        }
    }
    else {
        //We use paper units instead of model units here, because in 2D we measure in paper space
        //in the first place, then get the distance in model space by using the viewport(scale).
        unit = this.getMetadata('page_dimensions', 'page_units', null);
    }

    if (unit)
        unit = unit.toLowerCase();

    //Why are translators not using standard strings for those?!?!?!?
    switch (unit) {
        case 'meter'      :
        case 'meters'     :
        case 'm'          : return ModelUnits.METER;
        case 'feet and inches':
        case 'foot'       :
        case 'feet'       :
        case 'ft'         : return ModelUnits.FOOT;
        case 'inch'       :
        case 'inches'     :
        case 'in'         : return ModelUnits.INCH;
        case 'centimeter' :
        case 'centimeters':
        case 'cm'         : return ModelUnits.CENTIMETER;
        case 'millimeter' :
        case 'millimeters':
        case 'mm'         : return ModelUnits.MILLIMETER;
        default: return null;
    }
};

/**
 * Returns a standard string representation of the model's display unit.
 * @returns {string} Standard representation of model's display unit or null if it is not known.
*/
Model.prototype.getDisplayUnit = function() {
    var unit;

    if (!this.is2d()) {
        if(this.myData && this.myData.scalingUnit) {
             unit = this.myData.scalingUnit; // only using if scaling was actually applied
        } else {
            unit = this.getMetadata('distance unit', 'value', null);
        }
    }
    else {

        // When model units is not set, it should be assumed to be the same as paper units.
        unit = this.getMetadata('page_dimensions', 'model_units', null) || this.getMetadata('page_dimensions', 'page_units', null);
    }

    if (unit)
        unit = unit.toLowerCase();

    //Why are translators not using standard strings for those?!?!?!?
    switch (unit) {
        case 'meter'      :
        case 'meters'     :
        case 'm'          : return ModelUnits.METER;
        case 'feet and inches':
        case 'foot'       :
        case 'feet'       :
        case 'ft'         : return ModelUnits.FOOT;
        case 'inch'       :
        case 'inches'     :
        case 'in'         : return ModelUnits.INCH;
        case 'centimeter' :
        case 'centimeters':
        case 'cm'         : return ModelUnits.CENTIMETER;
        case 'millimeter' :
        case 'millimeters':
        case 'mm'         : return ModelUnits.MILLIMETER;
        default: return null;
    }
};

/**
 * Return metadata value.
 * @param {string} itemName - Metadata item name.
 * @param {string} [subitemName] - Metadata subitem name.
 * @param {*} [defaultValue] - Default value.
 * @returns {*} Metadata value, or defaultValue if no metadata or metadata item/subitem does not exist.
 */
Model.prototype.getMetadata = function (itemName, subitemName, defaultValue) {
    if (this.myData) {
        var metadata = this.myData.metadata;
        if (metadata) {
            var item = metadata[itemName];
            if (item !== undefined) {
                if (subitemName) {
                    var subitem = item[subitemName];
                    if (subitem !== undefined) {
                        return subitem;
                    }
                } else {
                    return item;
                }
            }
        }
    }
    return defaultValue;
};

/*
Model.prototype.displayMetadata = function () {
    avp.logger.log('metadata:');
    if (this.myData) {
        var metadata = this.myData.metadata;
        if (metadata) {
            for (itemName in metadata) {
                if (metadata.hasOwnProperty(itemName)) {
                    avp.logger.log('  ' + itemName);
                    var item = metadata[itemName];
                    if (item) {
                        for (subItemName in item) {
                            if (item.hasOwnProperty(subItemName)) {
                                avp.logger.log('    ' + subItemName + '=' + JSON.stringify(item[subItemName]));
                            }
                        }
                    }
                }
            }
        }
    }
};
*/

/**
 * Returns the default camera.
 */
Model.prototype.getDefaultCamera = function() {

    var myData = this.myData;

    if (!myData)
        return null;

    var defaultCamera = null;
    var numCameras = myData.cameras ? myData.cameras.length : 0;
    if (0 < numCameras) {
        // Choose a camera.
        // Use the default camera if specified by metadata.
        //
        var defaultCameraIndex = this.getMetadata('default camera', 'index', null);
        if (defaultCameraIndex !== null && myData.cameras[defaultCameraIndex]) {
            defaultCamera = myData.cameras[defaultCameraIndex];

        } else {

            // No default camera. Choose a perspective camera, if any.
            //
            for (var i = 0; i < numCameras; i++) {
                var camera = myData.cameras[i];
                if (camera.isPerspective) {
                    defaultCamera = camera;
                    break;
                }
            }

            // No perspective cameras, either. Choose the first camera.
            //
            if (!defaultCamera) {
                defaultCamera = myData.cameras[0];
            }
        }
    }

    return defaultCamera;
};

/**
 * Returns up vector as an array of 3.
 */
Model.prototype.getUpVector = function() {
    return this.getMetadata('world up vector', 'XYZ', null);
};

/**
 * Returns the polygon count.
 * @returns {number}
 */
Model.prototype.geomPolyCount = function() {

    var geomList = this.getGeometryList();
    if (!geomList) {
        return null;
    }

    return geomList.geomPolyCount;
};

/**
 * Returns the instanced polygon count.
 * @returns {number}
 */
Model.prototype.instancePolyCount = function() {

    var geomList = this.getGeometryList();
    if (!geomList) {
        return null;
    }

    return geomList.instancePolyCount;
};


/**
 * Returns the root of the layers tree.
 *
 * Not yet implemented in 3D.
 *
 * @returns {object} The root of the layers tree or null if it doesn't exist.
 */
Model.prototype.getLayersRoot = function () {
    if (!this.is2d()) {
        avp.logger.warn("Autodesk.Viewing.Model.getLayersRoot is not yet implemented for 3D");
        return null;
    }

    return this.myData ? this.myData.layersRoot : null;
};

/**
 * Returns true if the model with all its geometries has loaded.
 * @returns {boolean}
 */
Model.prototype.isLoadDone = function() {
    return !!(this.myData && this.myData.loadDone);
};

/**
 * Returns true if the frag to node id mapping is done.
 * @returns {boolean}
 */
Model.prototype.isObjectTreeCreated = function() {

    return !!(this.myData.instanceTree);

};


/**
 * Returns object properties.
 * @param {int} dbId - ID of the node to return the properties for.
 * @param {function} onSuccessCallback - This method that is called when request for property db succeeds.
 * @param {function} onErrorCallback - This method that is called when request for property db fails.
 */
Model.prototype.getProperties = function( dbId, onSuccessCallback, onErrorCallback )
{
    if (!this.myData || !this.myData.propWorker)
        return;

    // Negative dbIds will not have properties.
    // Negative dbIds are either paper (-1) or generated ids for 2d-texts
    // dbIds start at 1, so 0 can be skipped as well.
    if (dbId > 0) {
        this.myData.propWorker.getProperties( dbId, onSuccessCallback, onErrorCallback );
    }
};

/**
 * Returns properties for multiple objects with an optional filter on which properties to retrieve.
 *
 * @param {int[]} dbIds - IDs of the nodes to return the properties for.
 * @param {object|undefined} options - Dictionary with options.
 * @param {string[]} [options.propFilter] - Array of property names to return values for. Use null for no filtering.
 * Filter applies to "name" and "externalId" fields also.
 * @param {boolean} [options.ignoreHidden] - Ignore hidden properties
 * @param {function} onSuccessCallback - This method that is called when request for property db succeeds.
 * @param {function} onErrorCallback - This method that is called when request for property db fails.
 */
Model.prototype.getBulkProperties = function( dbIds, options, onSuccessCallback, onErrorCallback )
{
    if (Array.isArray(options)) {
        // backwards compatibility for when options was actually propFilter.
        options = { propFilter: options };
    }

    options = options || {};
    var propFilter = options.propFilter || null;
    var ignoreHidden = options.ignoreHidden || false;

    if (!this.myData || !this.myData.propWorker)
        return;

    this.myData.propWorker.getBulkProperties( dbIds, propFilter, onSuccessCallback, onErrorCallback, ignoreHidden );
};


/**
 * Returns an object with key values being dbNodeIds and values externalIds.
 * Useful to map LMV node ids to Fusion node ids.
 *
 * @param {function} onSuccessCallback - This method that is called when request for property db succeeds.
 * @param {function} onErrorCallback - This method that is called when request for property db fails.
 */
Model.prototype.getExternalIdMapping = function( onSuccessCallback, onErrorCallback )
{
    if (!this.myData)
        return;

    this.myData.propWorker.getExternalIdMapping( onSuccessCallback, onErrorCallback );
};

/**
 * Returns object tree.
 *
 * @param {function} onSuccessCallback - This method that is called when request for object tree succeeds.
 * @param {function} onErrorCallback - This method that is called when request for object tree fails.
 */
Model.prototype.getObjectTree = function( onSuccessCallback, onErrorCallback )
{
    if (!this.myData || !this.myData.propWorker) {
        if (onErrorCallback) {
            onErrorCallback();
        }
    } else {
        this.myData.propWorker.getObjectTree( onSuccessCallback, onErrorCallback );
    }
};

/**
 * Searches the object property database.
 *
 * @param {string} text - The search term (not case sensitive).
 * @param {function} onSuccessCallback - This method that is called when request for search succeeds.
 * @param {function} onErrorCallback - This method that is called when request for search fails.
 * @param {string[]} [attributeNames] - Restricts search to specific attribute names.
 */
Model.prototype.search = function(text, onSuccessCallback, onErrorCallback, attributeNames, completeInfo)
{
    var self = this;
    if (this.isLoadDone()) {
        this.myData.propWorker.searchProperties(text, attributeNames, onSuccessCallback, onErrorCallback, completeInfo);
    } else {
        this.getObjectTree( function() {
            self.myData.propWorker.searchProperties(text, attributeNames, onSuccessCallback, onErrorCallback, completeInfo);
        });
    }

};


//========================================================
// Utility functions used by page->model conversions below

var repairViewportMatrix = function(elements) {
    // Sometimes the rows of matrix are swapped
    var precision = 1e-3;
    var e = elements;
    if (Math.abs(e[0]) < precision) {
        if (Math.abs(e[4]) > precision) {
            // swap row 1 and row 2
            for (var i = 0; i < 4; i++) {
                var temp = e[i];
                e[i] = e[i + 4];
                e[i + 4] = temp;
            }
        }
        else {
            // swap row 1 and row 3
            for (var i = 0; i < 4; i++) {
                var temp = e[i];
                e[i] = e[i + 8];
                e[i + 8] = temp;
            }
        }
    }
    if (Math.abs(e[5]) < precision) {
        // swap row 2 and row 3
        for (var i = 4; i < 8; i++) {
            var temp = e[i];
            e[i] = e[i + 4];
            e[i + 4] = temp;
        }
    }
};


var pointInContour = function(x, y, cntr, pts) {
    var yflag0, yflag1;
    var vtx0X, vtx0Y, vtx1X, vtx1Y;

    var inside_flag = false;

    // get the last point in the polygon
    vtx0X = pts[cntr[cntr.length-1]].x;
    vtx0Y = pts[cntr[cntr.length-1]].y;

    // get test bit for above/below X axis
    yflag0 = (vtx0Y >= y);

    for (var j= 0, jEnd=cntr.length; j<jEnd; ++j)
    {
        vtx1X = pts[cntr[j]].x;
        vtx1Y = pts[cntr[j]].y;

        yflag1 = (vtx1Y >= y);

        // Check if endpoints straddle (are on opposite sides) of X axis
        // (i.e. the Y's differ); if so, +X ray could intersect this edge.
        // The old test also checked whether the endpoints are both to the
        // right or to the left of the test point.  However, given the faster
        // intersection point computation used below, this test was found to
        // be a break-even proposition for most polygons and a loser for
        // triangles (where 50% or more of the edges which survive this test
        // will cross quadrants and so have to have the X intersection computed
        // anyway).  I credit Joseph Samosky with inspiring me to try dropping
        // the "both left or both right" part of my code.
        if (yflag0 != yflag1)
        {
            // Check intersection of pgon segment with +X ray.
            // Note if >= point's X; if so, the ray hits it.
            // The division operation is avoided for the ">=" test by checking
            // the sign of the first vertex wrto the test point; idea inspired
            // by Joseph Samosky's and Mark Haigh-Hutchinson's different
            // polygon inclusion tests.
            if (((vtx1Y-y)*(vtx0X-vtx1X) >=
                (vtx1X-x)*(vtx0Y-vtx1Y)) == yflag1)
            {
                    inside_flag = !inside_flag;
            }
        }

        // move to the next pair of vertices, retaining info as possible
        yflag0 = yflag1;
        vtx0X = vtx1X;
        vtx0Y = vtx1Y;
    }

    return inside_flag;
};

Model.prototype.pointInPolygon = function(x, y, contours, points) {
    var inside = false;

    for (var i=0; i<contours.length; i++) {

        if (pointInContour(x, y, contours[i], points))
            inside = !inside;
    }

    return inside;
};




Model.prototype.getPageToModelTransform = function(vpId) {

    if (this.myData.pageToModelTransform) {
        return this.myData.pageToModelTransform;
    }

    var f2d = this.myData;
    var metadata = f2d.metadata;
    var pd = metadata.page_dimensions;

    var vp = f2d.viewports[vpId];
    if (!vp) {
      return new THREE.Matrix4();
    }

    if (!f2d.viewportTransforms)
        f2d.viewportTransforms = new Array(f2d.viewports.length);

    //See if we already cached the matrix
    var cached = f2d.viewportTransforms[vpId];
    if (cached)
        return cached;

    //Do the matrix composition in double precision using LmvMatrix,
    //which supports that optionally
    var pageToLogical = new LmvMatrix4(true).set(
      pd.logical_width/pd.page_width, 0, 0, pd.logical_offset_x,
      0, pd.logical_height/pd.page_height, 0, pd.logical_offset_y,
      0, 0, 1, 0,
      0, 0, 0, 1
    );

    var modelToLogicalArray = vp.transform.slice();

    repairViewportMatrix(modelToLogicalArray);

    var modelToLogical = new LmvMatrix4(true);
    modelToLogical.elements.set(modelToLogicalArray);

    var logicalToModel = new LmvMatrix4(true);
    logicalToModel.getInverse(modelToLogical);

    logicalToModel.multiply(pageToLogical);

    //Cache for future use
    f2d.viewportTransforms[vpId] = logicalToModel;

    return logicalToModel;
};


/**
 * Paper coordinates to Model coordinates
*/
Model.prototype.pageToModel = function( point1, point2, vpId ) {

    var PRECISION = 1e-2;

    var vpXform = this.getPageToModelTransform(vpId);

    var modelPt1 = new THREE.Vector3().set(point1.x, point1.y, 0).applyMatrix4(vpXform);
    var modelPt2 = new THREE.Vector3().set(point2.x, point2.y, 0).applyMatrix4(vpXform);

    //var paperDist = point1.distanceTo(point2);
    //var modelDist = modelPt1.distanceTo(modelPt2);
    //
    //// TODO: If the scale is 1:1, then it's paper viewport. (Still have double for that)
    //if (Math.abs(modelDist - paperDist) < PRECISION) {
    //    // viewport id is matched with clip id
    //    var indices = this.pointInClip(point1, vpId);
    //
    //    var oldModelPt1 = modelPt1.clone();
    //    var oldModelPt2 = modelPt2.clone();
    //
    //    for (var i = 0; i < indices.length; i++) {
    //
    //        var xform = this.getPageToModelTransform(indices[i]);
    //
    //        modelPt1.set(point1.x, point1.y, 0).applyMatrix4(xform);
    //        modelPt2.set(point2.x, point2.y, 0).applyMatrix4(xform);
    //
    //        modelDist = modelPt1.distanceTo(modelPt2);
    //        // TODO: If the scale is not 1:1, then it's model viewport. (Still have double for that)
    //        if (Math.abs(modelDist - paperDist) > PRECISION) {
    //            break;
    //        }
    //    }
    //
    //    // Don't find model viewport, then use its own viewport.
    //    if (i >= indices.length) {
    //        modelPt1 = oldModelPt1;
    //        modelPt2 = oldModelPt2;
    //    }
    //}

    point1.x = modelPt1.x;
    point1.y = modelPt1.y;
    point2.x = modelPt2.x;
    point2.y = modelPt2.y;

};


/**
 * Find the viewports that point lies in its bounds.
*/
Model.prototype.pointInClip = function(point, vpId) {

    var clips = this.myData.clips;
    var clipIds = []; // This will store ids of clip where point lies in

    // clip index starts at 1
    for (var i = 1; i < clips.length; i++) {
        // Don't need to check the point's own viewport's clip, it must be in that clip.
        if (i === vpId)
            continue;

        var contour = [];
        var contours = [];
        var contourCounts = clips[i].contourCounts;
        var points = clips[i].points;
        var index = 0;
        var pts = [];

        // Reorganize contour data
        for (var j = 0; j < contourCounts.length; j++) {
            for (var k = 0; k < contourCounts[j]; k++) {
                contour.push(index);
                index++;
            }
            contours.push(contour);
            contour = [];
        }
        for (var j = 0; j < points.length; j += 2) {
            var pt = {x: points[j], y: points[j+1]};
            pts.push(pt);
        }

        var inside = this.pointInPolygon(point.x, point.y, contours, pts);
        if (inside)
            clipIds.push(i);
    }

    return clipIds;
};

Model.prototype.getClip = function(vpId) {

    var clips = this.myData.clips;

    var contour = [];
    var contours = [];
    var contourCounts = clips[vpId].contourCounts;
    var points = clips[vpId].points;
    var index = 0;
    var pts = [];

    // Reorganize contour data
    for (var j = 0; j < contourCounts.length; j++) {
        for (var k = 0; k < contourCounts[j]; k++) {
            contour.push(index);
            index++;
        }
        contours.push(contour);
        contour = [];
    }
    for (var j = 0; j < points.length; j += 2) {
        var pt = {x: points[j], y: points[j+1]};
        pts.push(pt);
    }

    return { "contours" : contours, "points" : pts };
};


/**
 * Return topology index of the fragment.
 * @param {number} fragId - Fragment ID.
 * @returns {number} Topology index.
 */
Model.prototype.getTopoIndex = function( fragId ) {
    if (this.myData && this.myData.fragments) {
        var topoIndexes = this.myData.fragments.topoIndexes;
        if (topoIndexes) {
            return topoIndexes[fragId];
        }
    }
};

/**
 * Return topology data of one fragment.
 * @param {number} index - Topology index.
 * @returns {object} Topology data.
 */
Model.prototype.getTopology = function( index ) {
    if (this.myData) {
        var topology = this.myData.topology;
        if (topology) {
            var item = topology[index];
            if (item) {
                return item;
            }
        }
    }
};

Model.prototype.hasTopology = function() {
    if (this.myData) {
        var topology = this.myData.topology;
        if (topology) {
            return true;
        }
    }
    return false;
};

Model.prototype.hasGeometry = function() {
    if (this.myData){
        if (this.myData.isLeaflet) { // see LeafletLoader.js
            return true;
        }
        return this.myData.fragments.length > 0;
    }
    return false;
};


av.Model = Model;

})();
;
/** @license Copyright (c) 2013 Autodesk Inc. */
/** Version : @buildnum@ */

(function() {

"use strict";

var av = Autodesk.Viewing;
var avp = Autodesk.Viewing.Private;

/**
 * Core model data class for all items and collections.
 *
 * It allows the client to load the model data from the cloud, it
 * gives access to the root and provides a method for finding elements
 * by id.
 *
 * Typically, you load the document from the Viewing Service, parse it for
 * the required content (for example, 3d geometries), then pass this on to
 * the viewer to display.  You can also get some information about the document,
 * such as the number of views it contains and its thumbnail image.
 *
 * You can view the JSON structure of a {@link Autodesk.Viewing.Document} object
 * by requesting it from the Model Derivative APIs.
 *
 * @constructor
 * @memberof Autodesk.Viewing
 * @alias Autodesk.Viewing.Document
 * @param {object} dataJSON - JSON data representing the document.
 * @param {string} path - Path to the document.
 * @param {string} acmsession - ACM session ID.
 * @category Core
 */
var Document = function( dataJSON, path, acmsession )
{
    this.myPath = path;
    this.myData = dataJSON;
    this.myViewGeometry = {};
    this.myNumViews = {};
    this.myPropertyDb = null;
    this.acmSessionId = acmsession;

    // Search bubble for type="view" role="3d" children of type="geometry" role="3d" items.
    // Add count of view-3d items to parent geometry-3d items.
    // Collect geometry items of camera view items referenced by guid.
    //
    var self = this;

    function annotateViews(item) {
        if (!item) {
            return;
        }

        var childCount = item.children ? item.children.length : 0;
		var i;

        if (item.type === "geometry" && childCount) {
            var viewCount = 0;
            for (i = 0; i < childCount; i++) {
                var child = item.children[i];
                if (child && child.type === "view") {
                    self.myViewGeometry[child.guid] = item;
                    viewCount++;
                }
            }

            self.myNumViews[item.guid] = viewCount;

        } else if (item.mime == "application/autodesk-db" && item.urn) {
            //If there is a shared property database, remember its location

            //Of course, OSS is a storage system that mangles paths because why not,
            //so it needs special handling to extract the property database path
            if (item.urn.indexOf(avp.ViewingService.OSS_PREFIX) === 0)
                self.myPropertyDb = item.urn.substr(0, item.urn.lastIndexOf("%2F")+3);
            else
                self.myPropertyDb = item.urn.substr(0, item.urn.lastIndexOf("/")+1);

        } else if (0 < childCount) {
            for (i = 0; i < childCount; i++) {
                annotateViews(item.children[i]);
            }
        }
    }
    annotateViews(dataJSON);

    // Traverse the document and populate the parent pointers (for each node, store its parent).
    //
    function traverse( item ) {
        if (!item)
            return;

        var len = item.children ? item.children.length : 0;
        for(var i=0; i < len; i++)
        {
            item.children[i].parent = item;
            traverse(item.children[i]);
        }
    }
    traverse(this.myData);
};

Document.prototype.constructor = Document;

/**
 * Static method to load the model data from the cloud.
 *
 * @example
 *  // Load the model from the cloud
 *  var urn = 'dXJuOmFkc2suczM6ZGVyaXZlZC5maWxlOnRyYW5zbGF0aW9uXzI1X3Rlc3RpbmcvRFdGL0Nhci5kd2Y=';
 *  var seedFile  = "https://viewing-dev.api.autodesk.com/viewingservice/v1/" + urn;
 *  var jsonData = "";
 *  Autodesk.Document.load( seedFile, function( doc ) { jsonData=doc }, function( ) { } );
 *  var model = new Autodesk.Document(jsonData, 'path');
 *  var root  = model.getRootItem(); // top item of the hierarchy of the model data
 *  var item  = model.getItemById( "XXX02UUEs");
 *  var path = model.getFullPath(); // should be 'path'
 *
 * @param {string} documentId - The cloud URN of the file.
 * @param {function(object)} onSuccessCallback - A function that is called when load succeeds.
 * @param {function(int, string)} onErrorCallback - A function that is called when load fails.
 * @param {object} accessControlProperties - An optional list of key value pairs as access control properties,
 * which includes a list of access control header name and values, and an OAuth 2.0 access token.
 */
Document.load = function( documentId, onSuccessCallback, onErrorCallback, accessControlProperties )
{

    // The function signature was changed and we removed the need for the Auth parameter
    // Check what the second parameter is if its a non function assign the others correctly
    // this will also work in the case of missing arguments
    if (typeof(arguments[1]) !== 'function') {
        avp.logger.warn("Document.load called with deprecated (auth) parameter");
        if (typeof(arguments[2]) === 'function') {
            onSuccessCallback = arguments[2];
        }
        if (typeof(arguments[3]) === 'function') {
            onErrorCallback = arguments[3];
        }
     }

    function getDocumentPath(documentId)
    {
        // Handle local paths explicitly.
        //
        if(documentId.indexOf('urn:') === -1) {

            //Absolute URL
            if (documentId.indexOf("://") !== -1)
                return documentId;

            var relativePath = documentId;

            if (typeof window !== "undefined") {
                if(relativePath.indexOf('/') !== 0)
                    relativePath = '/' + relativePath;
                return window.location.protocol + "//" + window.location.host + relativePath;
            } else {
                return relativePath;
            }
        }
        return documentId;
    }

    function getViewableCount( modelDocument ) {
        var viewableItems = Document.getSubItemsWithProperties(modelDocument.getRootItem(), {'type':'folder','role':'viewable'}, true);
        var root = viewableItems[0];
        var geometryItems = Document.getSubItemsWithProperties(root, {'type':'geometry'}, true);
        return geometryItems.length;
    }

    function getGlobalMessages(data, nestedKey) {

      var collectedmessages = [];
      var translateFailedCount = 0;
      var translateProgressCount = 0;
      nestedKey = nestedKey || "children";

      var traverse = function (obj) {
        var children = obj[nestedKey] || [];
        var messages = obj.messages || [];

        var errorMessages = messages.filter(function(msg) {
          return msg.type === 'error';
        });

        if(errorMessages.length > 0) {
          translateFailedCount += 1;
        }

        if(obj.status === 'inprogress') {
          translateProgressCount += 1;
        }

        Array.prototype.push.apply(collectedmessages, messages.slice(0));
        for(var i = children.length; i--; traverse(children[i]));
      };

      traverse(data);

      var progress = 'translated';

      progress = translateFailedCount > 0 ? "failed" : progress;
      progress = translateProgressCount > 0 ? 'processing' : progress;

      for(var i = collectedmessages.length; i--; collectedmessages[i].$translation = progress);

      return collectedmessages;

    }

    function doLoad(acmsession) {

        var documentPath = getDocumentPath(documentId);
        var messages;

        function onSuccess(data) {
            var regex = /<[^>]*script/;
            if (regex.test(data)) {
                if (onErrorCallback)
                    onErrorCallback(av.ErrorCodes.BAD_DATA, "Malicious document content detected Abort loading");
                return;
            }

            var items = typeof(data) === 'string' ? JSON.parse(data) : data;
            var lmvDocument = new Document(items, documentPath, acmsession);
            var viewableCount = getViewableCount(lmvDocument);

            // Check if there are any viewables.
            if (viewableCount > 0) {
                messages = getGlobalMessages( lmvDocument.getRootItem() );
                if (onSuccessCallback) {
                    onSuccessCallback(lmvDocument, messages);
                }
            }
            else {
                // If there are no viewables, report an error.
                //
                if (onErrorCallback) {
                    messages = getGlobalMessages( lmvDocument.getRootItem() );
                    var errorCode =  av.ErrorCodes.BAD_DATA_NO_VIEWABLE_CONTENT;
                    var errorMsg  = "No viewable content";
                    onErrorCallback(errorCode, errorMsg, messages);
                }
            }
        }

        function onFailure(statusCode, statusText, data) {

            // If unauthorized and the first call for loading, will suppose third-party
            // cookies are disabled, and load again with token in request header.
            if (statusCode === 401 && LMV_THIRD_PARTY_COOKIE === undefined) {
                LMV_THIRD_PARTY_COOKIE = false;
                avp.refreshRequestHeader(avp.token.accessToken);
                doLoad(acmsession);
            }
            else {
                var messages = getGlobalMessages(data);
                if (onErrorCallback) {
                    var errorMsg = "Error: " + statusCode + " (" + statusText + ")";
                    var errorCode = av.Private.ErrorHandler.getErrorCode(statusCode);
                    onErrorCallback(errorCode, errorMsg, statusCode, statusText, messages);
                }
            }
        }

        var msg = {
            queryParams: acmsession ? "acmsession=" + acmsession : ""
        };

        avp.ViewingService.getManifest(avp.initLoadContext(msg), documentPath, onSuccess, onFailure);
    }

    if (accessControlProperties) {
        avp.ViewingService.getACMSession(av.getApiEndpoint(), accessControlProperties, doLoad, onErrorCallback);
    } else {
        doLoad();
    }
};

/**
 * This function is only used when Authorization is through Bearer token; aka when cookies are disabled.
 * @param {string} data - See {@link Autodesk.Viewing.Document#getThumbnailOptions}.
 * @param {function} onComplete - Node style callback function `callback(err, response)`.
 */
Document.requestThumbnailWithSecurity = function(data, onComplete) {

    var onSuccess = function(response){
        onComplete(null, response);
    };
    var onFailure = function(){
        onComplete('error', null);
    };

    var options = {
        responseType: 'blob',
        skipAssetCallback: true,
        size: data.width, //Ignore the height, they are the same.
        guid: data.guid
    };

    var urlpath = "urn:" + data.urn; //HACK: Adding urn: makes the ViewingServiceXhr accept this as a viewing service request.
    avp.ViewingService.getThumbnail(avp.initLoadContext(), urlpath, onSuccess, onFailure, options);
};

/**
 * Returns the full path to the given URN.
 * @param {string} urn - URN of the document.
 * @returns {string}
 */
Document.prototype.getFullPath = function(urn)
{

    if (!urn)
        return urn;

	var fullPath = urn;

    if (avp.offline) {
        fullPath = decodeURIComponent(av.Private.offlineResourcePrefix) + fullPath.substr(fullPath.indexOf('/'));
    } else if(urn.indexOf('urn') === 0)
    {
        // Use viewing service.
        fullPath = av.getItemApi() + urn;
    }
    // Handle local files.
    //
    else if(urn.indexOf('$file$') === 0 && this.myPath.indexOf('/bubble.json') !== -1) {
        fullPath = this.myPath.replace('/bubble.json', '') + urn.replace('$file$', '');
    }
    return fullPath;
};

/**
 * Returns a plain object with properties used to fetch a thumbnail image.
 * @param {object} item
 * @param {number} width
 * @param {number} height
 * @returns {object} `{urn: string, width: number, height: number, guid: string, acmsession: (string)}`
 */
Document.prototype.getThumbnailOptions = function(item, width, height) {
    var requestedWidth = width ? width : 200;
    var requestedHeight = height ? height : 200;
    return {
        urn: this.myData.urn,
        width: requestedWidth,
        height: requestedHeight,
        guid: encodeURIComponent(item.guid),
        acmsession: this.acmSessionId
    }
};

/**
 * Returns the path to the thumbnail of the item with the given ID.
 * @param {string} item - Document item.
 * @param {int} width - The requested thumbnail width.
 * @param {int} height - The requested thumbnail height.
 * @returns {string}
 */
Document.prototype.getThumbnailPath = function(item, width, height)
{
    var data = this.getThumbnailOptions(item, width, height);
    var ret = av.getThumbnailApi() + data.urn +
        "?guid=" + data.guid +
        "&width=" + data.width +
        "&height=" + data.height;

    if (data.acmsession) {
        ret += "&acmsession=" + data.acmsession;
    }
    return ret;
};

/**
 * Extracts leaflet loader params from an item (if any).
 * @param {object} outLoadOptions - Extracted params are stored in this object.
 * @param {object} geomItem - Geometry item with role '2d' that contains
 * the leaflet resource item.
 * @param {string} leafletItem - The resource item with role 'leaflet' that
 * contains the tile url pattern and some other params.
 */
function getLeafletParams(outLoadOptions, geomItem, leafletItem) {

    outLoadOptions.urlPattern  = leafletItem.urn;
    outLoadOptions.tileSize    = leafletItem.tileSize ?  leafletItem.tileSize : 512; // currently, bubbles use a fixed tile size of 512.
    outLoadOptions.texWidth    = leafletItem.resolution[0];
    outLoadOptions.texHeight   = leafletItem.resolution[1];
    outLoadOptions.paperWidth  = leafletItem.paperWidth;
    outLoadOptions.paperHeight = leafletItem.paperHeight;
    outLoadOptions.paperUnits  = leafletItem.paperUnits;

    // hierarchies produced by cloud translation service start with a 1x1 miplevel at the root.
    // therefore, we have to skip some levels.
    outLoadOptions.levelOffset = avp.LeafletLoader.computeLevelOffset(outLoadOptions.tileSize);

    // By default, the number of hierarchy levels is computed automatically from texWidth/texHeight.
    // (see computeMaxLevel() in ModelIteratorTexQuad.js). However, the leaflet item also
    // contains a maxLevel value, which is usually smaller than the computed one. The purpose
    // of this value is to specify the (reduced) number of levels that we use when viewing
    // the leaflet in offline mode on mobile devices. Otherwise, we let maxLevel undefined, so
    // that the full resolution is used.
    if (avp.offline && av.isMobileDevice()) {
        // maxLevel is stored in another resource item that references a zip-file with the tile-images.
        // the max_level value includes several levels with just one tile (1x1, 2x2, ...) which we skip.
        var items = Document.getSubItemsWithProperties(geomItem, { 'role': 'leaflet-zip' }, false);
        if (items.length > 0) {
            outLoadOptions.maxLevel = items[0].max_level - outLoadOptions.levelOffset;
        }
    }
};

/**
 * Returns the path to the viewable of the given item.
 * @param {object} item - The item whose viewable is requested.
 * @param {object} outLoadOptions - Output param: used to store some additional loader options.
 * Needed to extract leaflet params from a bubble item.
 * @returns {string}
 */
Document.prototype.getViewablePath = function(item, outLoadOptions)
{
    if(item.type === 'geometry') {
        var items = [];
        if(item.role === '3d') {
            items = Document.getSubItemsWithProperties(item, {
                'mime': 'application/autodesk-svf'
            }, false);
        }
        else if(item.role === '2d') {

            // check for a leaflet resource
            items = Document.getSubItemsWithProperties(item, {
                'role': 'leaflet'
            }, false);

            // found one? => extract its params
            if (items.length > 0 && outLoadOptions) {
                getLeafletParams(outLoadOptions, item, items[0]);
            };

            // if there is no leaflet...
            if (items.length === 0) {
                // check for vector and if does not exist for tiles.
                items = Document.getSubItemsWithProperties(item, {
                    'mime': 'application/autodesk-f2d'
                }, false);
            }
                // old file does not have f2d yet - so load tile viewer
            if (items.length === 0) {
                items = Document.getSubItemsWithProperties(item, {
                    'role': 'tileRoot'
                }, true);
            }
        }
        if(items.length > 0)
        {
            return this.getFullPath(items[0].urn);
        }
    }
    else if(item.type === 'view') {
        var geometryItem = this.getViewGeometry(item);
        if (geometryItem) {
            return this.getViewablePath(geometryItem);
        }
    }

    return '';
};

/**
 * Returns the root path to a shared (across all sheets/views) property database's JSON files.
 * @returns {string}
 */
Document.prototype.getPropertyDbPath = function()
{
    return this.myPropertyDb;
};

/**
 *  Returns the root of the model data hierarchy.
 *  @returns {object}
 */
Document.prototype.getRootItem = function()
{
    return this.myData;
};

/**
 *  Returns the id of this document.
 *  @returns {string}
 */
Document.prototype.getPath = function()
{
    return this.myPath;
};

/**
 * Returns an item from the model data hierarchy with the given id.
 * If the item is not found, null object is returned.
 * @param {string} id - ID of the item to be found.
 * @returns {object} Item with a given ID.
 */
Document.prototype.getItemById = function(id)
{
    function traverse( data ) {
        if (!data)
            return null;

        for (var key in data) {
            var val = data[key];
            if ( key === 'guid' && val === id )
                return data;

            if (val !== null && typeof(val) === "object" && key !== "parent") {
                //going on step down in the object tree!!
                var item = traverse( val );
                if (item)
                    return item;
            }
        }
        return null;
    }
    return traverse( this.myData );
};

/**
 * Static method that returns an array of all items with given properties.
 * @param {string} item - The document node to begin searching from.
 * @param {object} properties - map/list of the properties to search for.
 * @param {boolean} recursive - If true, searches recursively.
 * @returns {object} List of items that have given properties.
 * @example
 *  // search the document starting from the root element for all 2d geometry items
 *  geometryItems = Document.getSubItemsWithProperties(adocument.getRootItem(), {
 *      'type' : 'geometry',
 *      'role' : '2d'
 *  }, true);
 */
Document.getSubItemsWithProperties = function(item, properties, recursive)
{
  var subItems = [];
  if(!item) return [];

  function hasProperties(item, properties)
  {
    for(var p in properties)
    {
      if (!(p in item) || (properties[p] !== item[p]))
        return false;
    }
    return true;
  }

  var len = item.children ? item.children.length : 0;
  for(var i=0; i < len; i++)
  {
    // Check if this child has this key and value.
    //
    var child = item.children[i];
    if(hasProperties(child, properties))
    {
      subItems.push(child);
    }

    // Search the descendants if requested.
    //
    if(recursive)
    {
      subItems.push.apply(subItems, Document.getSubItemsWithProperties(child, properties, recursive));
    }
  }
  return subItems;
};

/**
 * Returns the parent geometry item for a given view item.
 * @param {object} item - View item.
 * @returns {object} The parent geometry item.
 */
Document.prototype.getViewGeometry = function (item) {
    return this.myViewGeometry[item.guid];
};

/**
 * Returns the number of view items underneath a geometry item.
 * @param {object} item - Geometry item.
 * @returns {number} The number of view items underneath the geometry item.
 */
Document.prototype.getNumViews = function (item) {
    return this.myNumViews[item.guid] || 0;
};

/**
 * @deprecated Simply use item.parent instead.
 * Returns parent ID of the given document node ID.
 * @param {string} item - The node ID.
 * @returns {string}
 */
Document.prototype.getParentId = function (itemId) {
    var item = this.getItemById(itemId);
    if (!item)
        return null;
    var parent = item.parent;
    return parent ? parent.guid : null;
};


/**
 * Returns messages (error and warning messages) associated with a given item.
 * It includes item's messages as well as messages of all its parents.
 * @param {string} itemId - GUID of the item.
 * @param {boolean} - If true, the top messages that apply to the whole file are excluded.
 * @returns {object} Returns an array of messages.
 */
Document.prototype.getMessages = function( item, excludeGlobal ) {

    var messages = [];
    if (!item)
        return messages;

    var root = null;
    if (excludeGlobal)
        root = this.getRootItem();

    var current = item;
    while (current) {

        if (excludeGlobal && parent===root)
            break;

        if (current.messages) {
            for (var i=0; i<current.messages.length; i++){
                messages.push( current.messages[i] );
            }
        }
        current = current.parent;
    }
    return messages;
};

av.Document = Document;


})();
;


(function() {

"use strict";

var av = Autodesk.Viewing,
    avp = Autodesk.Viewing.Private;

var TAU = Math.PI * 2;

//Constants duplicated from src/lmvtk/VertexBufferBuilder.js
var VBB_GT_TRIANGLE_INDEXED = 0,
    VBB_GT_LINE_SEGMENT     = 1,
    VBB_GT_ARC_CIRCULAR     = 2,
    VBB_GT_ARC_ELLIPTICAL   = 3,
    VBB_GT_TEX_QUAD         = 4,
    VBB_GT_ONE_TRIANGLE     = 5;

var VBB_INSTANCED_FLAG  = 0, // this is intentionally 0 for the instancing case!
    VBB_SEG_START_RIGHT = 0, // this starts intentionally at 0!
    VBB_SEG_START_LEFT  = 1,
    VBB_SEG_END_RIGHT   = 2,
    VBB_SEG_END_LEFT    = 3;

var VBB_COLOR_OFFSET    = 6,
    VBB_DBID_OFFSET     = 7,
    VBB_FLAGS_OFFSET    = 8,
    VBB_LAYER_VP_OFFSET = 9;

/**
 * Initializes a "view" into a compacted interleaved vertex buffer array using our custom 2D vertex layout.
 * See src/lmvtk/VertexBufferBuilder.js for more details.
 */
avp.VertexBufferReader = function(geometry, useInstancing)
{
    this.vb  = geometry.vb.buffer;
    this.vbf = new Float32Array(this.vb);
    this.vbi = new Int32Array(this.vb);

    this.stride = geometry.vbstride;
    this.vcount = this.vbf.length / this.stride;

    this.useInstancing = !!useInstancing;
};

avp.VertexBufferReader.prototype.getDbIdAt = function(vindex) {
    return this.vbi[vindex*this.stride + VBB_DBID_OFFSET];
};

avp.VertexBufferReader.prototype.getVertexFlagsAt = function(vindex) {
    return this.vbi[vindex*this.stride + VBB_FLAGS_OFFSET];
};

avp.VertexBufferReader.prototype.getLayerIndexAt = function(vindex) {
    return this.vbi[vindex*this.stride + VBB_LAYER_VP_OFFSET] & 0xffff;
};

avp.VertexBufferReader.prototype.getViewportIndexAt = function(vindex) {
    return (this.vbi[vindex*this.stride + VBB_LAYER_VP_OFFSET] >> 16) & 0xffff;
};

avp.VertexBufferReader.prototype.decodeLineAt = function(vindex, layer, vpId, callback)
{
    if (!callback.onLineSegment) { return; }

    var baseOffset = this.stride * vindex;
    var x0         = this.vbf[baseOffset];
    var y0         = this.vbf[baseOffset+1];
    var angle      = this.vbf[baseOffset+2];
    var distAlong  = this.vbf[baseOffset+3];

    var x1 = x0 + distAlong * Math.cos(angle);
    var y1 = y0 + distAlong * Math.sin(angle);

    callback.onLineSegment(x0, y0, x1, y1, vpId);
};

avp.VertexBufferReader.prototype.decodeCircularArcAt = function(vindex, layer, vpId, callback)
{
    if (!callback.onCircularArc) { return; }

    var baseOffset = this.stride * vindex;
    var cx         = this.vbf[baseOffset];
    var cy         = this.vbf[baseOffset+1];
    var start      = this.vbf[baseOffset+2];
    var end        = this.vbf[baseOffset+3];
    var radius     = this.vbf[baseOffset+5];

    callback.onCircularArc(cx, cy, start, end, radius, vpId);
};

avp.VertexBufferReader.prototype.decodeEllipticalArcAt = function(vindex, layer, vpId, callback)
{
    if (!callback.onEllipticalArc) { return; }

    var baseOffset = this.stride * vindex;
    var cx         = this.vbf[baseOffset];
    var cy         = this.vbf[baseOffset+1];
    var start      = this.vbf[baseOffset+2];
    var end        = this.vbf[baseOffset+3];
    var major      = this.vbf[baseOffset+5];
    var minor      = this.vbf[baseOffset+10];
    var tilt       = this.vbf[baseOffset+11];

    callback.onEllipticalArc(cx, cy, start, end, major, minor, tilt, vpId);
};

avp.VertexBufferReader.prototype.decodeTexQuadAt = function(vindex, layer, vpId, callback)
{
    if (!callback.onTexQuad) { return; }

    var baseOffset = this.stride * vindex;
    var centerX    = this.vbf[baseOffset];
    var centerY    = this.vbf[baseOffset+1];
    // yes, this is in a different order than output, following VertexBufferBuilder's order
    var rotation   = this.vbf[baseOffset+2];
    var width      = this.vbf[baseOffset+3];
    var height     = this.vbf[baseOffset+4];

    callback.onTexQuad(centerX, centerY, width, height, rotation, vpId);
};

avp.VertexBufferReader.prototype.decodeOneTriangleAt = function(vindex, layer, vpId, callback)
{
    if (!callback.onOneTriangle) { return; }

    var baseOffset = this.stride * vindex;
    var x1         = this.vbf[baseOffset];
    var y1         = this.vbf[baseOffset+1];
    var x2         = this.vbf[baseOffset+2];
    var y2         = this.vbf[baseOffset+3];
    var x3         = this.vbf[baseOffset+4];
    var y3         = this.vbf[baseOffset+5];

    callback.onOneTriangle(x1, y1, x2, y2, x3, y3, vpId);
};

avp.VertexBufferReader.prototype.decodeTriangleVertex = function(vindex, layer, vpId, callback)
{
    if (!callback.onTriangleVertex) { return; }

    var baseOffset = this.stride * vindex;
    var cx         = this.vbf[baseOffset];
    var cy         = this.vbf[baseOffset+1];

    callback.onTriangleVertex(cx, cy, vpId);
};

// used by the snapper and by the bounds finder
avp.VertexBufferReader.prototype.enumGeomsForObject = function(dbId, callback)
{
    var i = 0;
    while (i < this.vcount) {
        var flag = this.getVertexFlagsAt(i);

        //var vertexId    = (flag >>  0) & 0xff;        //  8 bit
        var geomType    = (flag >>  8) & 0xff;        //  8 bit
        //var linePattern = (flag >> 16) & 0xff;        //  8 bit
        var layerId     = this.getLayerIndexAt(i);    // 16 bit
        var vpId        = this.getViewportIndexAt(i); // 16 bit

        if (this.getDbIdAt(i) === dbId)
        {
            switch (geomType) {
                case VBB_GT_TRIANGLE_INDEXED:    this.decodeTriangleVertex( i, layerId, vpId, callback); break;
                case VBB_GT_LINE_SEGMENT:        this.decodeLineAt(         i, layerId, vpId, callback); break;
                case VBB_GT_ARC_CIRCULAR:        this.decodeCircularArcAt(  i, layerId, vpId, callback); break;
                case VBB_GT_ARC_ELLIPTICAL:      this.decodeEllipticalArcAt(i, layerId, vpId, callback); break;
                case VBB_GT_TEX_QUAD:            this.decodeTexQuadAt(      i, layerId, vpId, callback); break;
                case VBB_GT_ONE_TRIANGLE:        this.decodeOneTriangleAt(  i, layerId, vpId, callback); break;
                default:                         break;
            }
        }

        //Skip duplicate vertices (when not using instancing and the geometry is not a simple polytriangle,
        //each vertex is listed four times with a different vertexId flag
        i += (this.useInstancing || (geomType == VBB_GT_TRIANGLE_INDEXED)) ? 1 : 4;
    }

};


/**
 * Used by the bounds finder.
 * @param {array[number]} layerIdsVisible - list of layer ids that are visible
 * @param {function} callback
 * @private
 */
avp.VertexBufferReader.prototype.enumGeomsForVisibleLayer = function(layerIdsVisible, callback)
{
    var i = 0;
    while (i < this.vcount) {
        var flag = this.getVertexFlagsAt(i);

        //var vertexId    = (flag >>  0) & 0xff;        //  8 bit
        var geomType    = (flag >>  8) & 0xff;        //  8 bit
        //var linePattern = (flag >> 16) & 0xff;        //  8 bit
        var layerId     = this.getLayerIndexAt(i);    // 16 bit
        var vpId        = this.getViewportIndexAt(i); // 16 bit

        // Get the bounds of only the visible layers. Ignore layer 0, which is always the page.
        // If layerId visibility is not set, consider the layer visible.
        var layerIdVisibible = (layerIdsVisible.indexOf(layerId) !== -1);
        if ((layerId !== 0) && layerIdVisibible) {
            switch (geomType) {
                case VBB_GT_TRIANGLE_INDEXED:    this.decodeTriangleVertex( i, layerId, vpId, callback); break;
                case VBB_GT_LINE_SEGMENT:        this.decodeLineAt(         i, layerId, vpId, callback); break;
                case VBB_GT_ARC_CIRCULAR:        this.decodeCircularArcAt(  i, layerId, vpId, callback); break;
                case VBB_GT_ARC_ELLIPTICAL:      this.decodeEllipticalArcAt(i, layerId, vpId, callback); break;
                case VBB_GT_TEX_QUAD:            this.decodeTexQuadAt(      i, layerId, vpId, callback); break;
                case VBB_GT_ONE_TRIANGLE:        this.decodeOneTriangleAt(  i, layerId, vpId, callback); break;
                default:                         break;
            }
        }

        //Skip duplicate vertices (when not using instancing and the geometry is not a simple polytriangle,
        //each vertex is listed four times with a different vertexId flag
        i += (this.useInstancing || (geomType == VBB_GT_TRIANGLE_INDEXED)) ? 1 : 4;
    }

};

})();
;

(function() {
	'use strict';

var av = Autodesk.Viewing,
    avp = av.Private;

function loadTextureWithSecurity(path, mapping, callback, acmSessionId) {

    if (av.getUseCredentials()) {
        // TODO: We should actually ALSO consider the case where texture is being loaded from
        // the same domain as the SVF being served. With such a change, we will be taking into
        // account developers exposing SVF's through their own proxy servers.
        var useCredentials = path.indexOf('://') === -1 ||
            path.indexOf(window.location.host) !== -1 ||
            avp.urlIsApiViewingOrDev(path);

        if (useCredentials) { //if you're sending to your own host or to autodesk views and data api, then use credentials
            THREE.ImageUtils.crossOrigin = 'use-credentials';
        } else { //otherwise do not
            THREE.ImageUtils.crossOrigin = 'anonymous';
        }
    }

    var index = path.indexOf('urn:');
    if (index !== -1) {

        var domainParam = (av.getUseCredentials() && !av.isNodeJS) ? ("domain=" + encodeURIComponent(window.location.origin)) : "";
        var queryParam = domainParam;
        if (acmSessionId) {
            if (queryParam)
                queryParam += "&";
            queryParam += "acmsession=" + acmSessionId;
        }

        if (queryParam)
            path += "?" + queryParam;
    }

    // If the textures are stored on OSS, directly stream it from OSS instead of going through items API.
    var ossPath = avp.ViewingService.getDirectOSSUrl({endpoint:av.getApiEndpoint()}, path);
    if (ossPath)
        path = ossPath;

    if (path.slice(path.length-4).toLocaleLowerCase() === ".dds") {
        if(av.isIOSDevice()) {
            var pvrPath = path.slice(0, path.length - 4) + ".pvr";
             return new THREE.PVRLoader().load(pvrPath, callback);
        } else {
            return new THREE.DDSLoader().load(path, callback);
        }
    } else if (!LMV_THIRD_PARTY_COOKIE && useCredentials)
        return loadTextureWithToken(path, mapping, callback);
    else
        return THREE.ImageUtils.loadTexture(path, mapping, callback);
}

// For texture loading, three.js expects loadable URL for the image.
// When we put the token in request header instead of cookie, we need AJAX the
// texture and base64 encode it to create a data URI and feed it to three.js.
function loadTextureWithToken(path, mapping, callback) {

    var texture = new THREE.Texture( undefined, mapping );

    function onSuccess(data) {
        return loadTextureBinary(data, texture, callback);
    }

    function onFailure(statusCode, statusText, data) {
        var errorMsg = "Error: " + statusCode + " (" + statusText + ")";
        avp.logger.error(errorMsg);
    }

    avp.ViewingService.getItem(avp.initLoadContext(), path, onSuccess, onFailure);

    return texture;
}

function loadTextureBinary( data, texture, callback ) {

    function arrayBufferToDataUri( buffer ) {
        var binary = '';
        var bytes = new Uint8Array( buffer );
        var len = bytes.byteLength;
        for (var i = 0; i < len; i++) {
            binary += String.fromCharCode( bytes[ i ] );
        }

        var uri = "data:image/jpeg;base64," + window.btoa( binary );
        return uri;
    }

    var image = new Image();
    texture.image = image;

    image.onload = function () {
        texture.needsUpdate = true;
        if ( callback ) callback( texture );
    };
    image.onerror = function (e) {
        avp.logger.error(e);
    };

    image.src = arrayBufferToDataUri(data);

}

function resizeImage(img) {

    var ow = img.width;
    var oh = img.height;

    //It's a power of two already
    if ( ((ow & (ow - 1)) === 0) && ((oh & (oh - 1)) === 0)) {
        return img;
    }

    var w = 1; while (w*2 < ow) w*=2;
    var h = 1; while (h*2 < oh) h*=2;

    var canvas = document.createElement("canvas");
    var ctx = canvas.getContext("2d");
    canvas.width = w;
    canvas.height = h;

    ctx.drawImage(img, 0, 0, w, h);

    return canvas;

}

/** @constructor */
function MaterialManager(renderer)
{
    WGS.MaterialManager.call(this, renderer);

    var _this = this;
    var _super = WGS.MaterialManager.prototype;

    this.hasPrism = false;
    this.renderPrism = true; //matches the default preferences setting
    var _needsTwoSided = false;

    this.defaultMaterial = new THREE.MeshPhongMaterial({
                    ambient: 0x030303,
                    color: 0x777777,
                    specular: 0x333333,
                    shininess: 30,
                    shading: THREE.SmoothShading,
                    reflectivity: 0
                });


    this.dtor = function() {

        this.cleanup();
        THREE.Cache.clear();
        _this = null;

    };

    // Reports whether the manager has encountered a material that needs two-sided rendering.
    this.hasTwoSidedMaterials = function() {
        return _needsTwoSided;
    };

    /**
     * Finds material by name.
     * @param {RenderModel} [model] Optional model in which to look for the material.
     * @param {string} name Material name.
     * @returns Desired material, or a default material as a fallback.
     */
    this.findMaterial = function(model, name) {
        var mat = _super.findMaterial.call(this, this._getMaterialHash(model, name));

        //It's not expected that the material is null here, but in case
        //it is, warn and pick the first one available.
        if (!mat) {
            avp.logger.warn("Unknown material " + name + ". Using default.");
            mat = this.defaultMaterial;
        }

        return mat;
    };

    this.setRenderPrism = function (value) {
        this.renderPrism = value;
    };

    /**
     * Converts from LMV materials json to THREE.js materials.
     * @param {RenderModel} model
     */
    this.convertMaterials = function(model) {
        var svf = model.getData();

        if (!svf.materials) {
            return 0;
        }

        if (svf.gltfMaterials) {

            var gltfmats = svf.materials["materials"];
            for (var p in gltfmats) {

                var gltfMat = gltfmats[p];
                var phongMat = avp.MaterialConverter.convertMaterialGltf(gltfMat, svf);
                var matName = this._getMaterialHash(model, p);
                this.addMaterial(matName, phongMat, false);

            }

            return;
        }

        //TODO: The code below needs to be refactored, with functions like isPrismMaterial moved
        //to MaterialConverter. Decal processing also.

        // Get outer Protein materials block.
        // The way this works: there is always (supposed to be) a Materials.json file in SVF. This
        // is put into svf.materials["materials"]. There is also, optionally, a ProteinMaterials.json
        // file, read into svf.proteinMaterials["materials"]. We look through the Protein materials
        // (if present) and see which ones we can interpret (currently only PRISM materials). If we
        // can interpret it, great. Otherwise, we use the Materials.json file's version, which is
        // (always) a SimplePhong material.
        var mats = svf.materials["materials"];
        var prismmats = svf.proteinMaterials ? svf.proteinMaterials["materials"] : null;
        var _renderPrism = this.renderPrism;
        var totalAdded = 0;

        for (var p in mats) {

            var isPrism = false;

            if (prismmats) {
                isPrism = _renderPrism && avp.MaterialConverter.isPrismMaterial(prismmats[p]);
            }

            //If the definition is prism, use the prism object.
            var matObj = isPrism ? prismmats[p] : mats[p];

            var surfaceMat = avp.MaterialConverter.convertMaterial(matObj, isPrism);

            // We obey the double-sided global flag, but have asked ATF to minimize its use in the future.
            // Internet Explorer 11 has some bug with double-sided models not displaying correctly - may be fixed?
            if (!av.isIE11 && svf.doubleSided)
                surfaceMat.side = THREE.DoubleSide;

            // currently Fusion objects come in as double-sided. Once ATF and Fusion fix this, they
            // can come in as single-sided. For PRISM materials that are transparent, make these
            // always be double sided, so they render properly in two passes, back and front displayed.
            if ( isPrism && surfaceMat.transparent && (surfaceMat.side === THREE.FrontSide))
                surfaceMat.side = THREE.DoubleSide;

            // Add a flag that notes that two-pass transparency is to be used. This is meant for Fusion in
            // particular, where transparent objects are rendered in two passes, back faces then front faces.
            // This can cause problems with other, arbitrary geometry, such as found in
            // https://jira.autodesk.com/browse/LMV-1121.
            // If we want to extend this two-pass rendering method to all materials, we have to come up
            // with some rules for how to differentiate data here.
            if ( isPrism && surfaceMat.transparent && (surfaceMat.side === THREE.DoubleSide) && surfaceMat.depthTest)
                surfaceMat.twoPassTransparency = true;
            //else
            //    surfaceMat.twoPassTransparency = false;

            // last thing: add material to the materials array, performing any special processing needed.
            var matName = this._getMaterialHash(model, p);
            this.addMaterial(matName, surfaceMat, isPrism);
            totalAdded++;

            // Process decals
            if (matObj.decals) {
                surfaceMat.decals = [];
                for (var di = 0, dlen = matObj.decals.length; di < dlen; di++) {
                    var decal = matObj.decals[di];
                    isPrism = _renderPrism && avp.MaterialConverter.isPrismMaterial(decal.material);
                    var material = avp.MaterialConverter.convertMaterial(decal.material, isPrism);
                    surfaceMat.decals.push({
                        uv: decal.uv || 0,
                        material: material
                    });
                    this.addMaterial(matName + '|decal|' + di, material, isPrism);
                }
            }
        }

        return totalAdded;
    };


    /**
     * Loads texture for a specific material and model.
     * @param {object} material
     * @param {RenderModel} model
     */
    this.loadTexture = function(material, model) {
        var svf = model.getData();
        var loader = function(material, map, onReady) {
            var texName = _this._getTextureHash(model, map.uri, map.mapName);
            var texPath = null;

            //Of course, Prism uses a different CDN endpoint from Protein, so
            //we have to distinguish between the two...
            var isProteinMat = material.proteinType && material.proteinType.length;
            var isPrism = isProteinMat && (material.proteinType.indexOf("Prism") === 0);

            var isSharedTexture = (isPrism && PRISM_ROOT || isProteinMat && PROTEIN_ROOT) &&
                (map.uri.indexOf("1/Mats") === 0 || map.uri.indexOf("2/Mats") === 0 || map.uri.indexOf("3/Mats") === 0);

            if (isSharedTexture) {
                if (isPrism) {
                    texPath = PRISM_ROOT + map.uri;
                } else {
                    texPath = PROTEIN_ROOT + map.uri;
                }
            } else {
                for(var j=0; j<svf.manifest.assets.length; ++j)
                {
                    var asset = svf.manifest.assets[j];
                    if(asset.id == map.uri) {
                        texPath = avp.pathToURL(svf.basePath + asset.URI);
                        break;
                    }
                }
                if(!texPath) {
                    texPath = avp.pathToURL(svf.basePath + map.uri);
                }
            }

            var texture = loadTextureWithSecurity(texPath, THREE.UVMapping, function(tex) {
                //It's possible MaterialManager got destroyed before the texture loads
                if (!_this)
                    return;
                tex.image = resizeImage(tex.image);
                onReady(map, tex);
            }, svf.acmSessionId);

            return texture;
        };

        _super.loadMaterialTextures.call(this, model, material, svf.materials.scene.SceneUnit, loader);
    };


    /**
     * Loads all textures for a specific model.
     * Textures delayed until all geometry is loaded, hence not done in convertMaterials.
     * @param {RenderModel} model
     */
    this.loadTextures = function(model) {
        var hash = this._getModelHash(model);

        for (var p in this._materials) {

            //Prevent textures for already loaded models from being loaded
            //again. Not elegant, and we can somehow only process the materials
            //per model.
            if (p.indexOf(hash) == -1)
                continue;

            var material = this._materials[p];
            this.loadTexture(material, model);
        }
    };

    this.texturesLoaded = function() {
        return this._texturesToUpdate.length === 0;
    };

    this.create2DMaterial = function(model, material, isIdMaterial, isSelectionMaterial, onReady) {
        var svf = model ? model.getData() : null;

        //Create a hash string of the material to see if we have
        //already created it
        var name = "__lineMaterial__";
        if (material.image)
            name += "|image:" + material.image.name;
        if (material.clip)
            name += "|clip:" + JSON.stringify(material.clip);
        if (isIdMaterial)
            name += "|id";
        if (isSelectionMaterial)
            name += "|selection";
        if (material.skipEllipticals)
            name += "|skipEllipticals";
        if (material.skipCircles)
            name += "|skipCircles";
        if (material.skipTriangleGeoms)
            name += "|skipTriangleGeoms";
        if (material.useInstancing)
            name += "|useInstancing";

        var hash = this._getMaterialHash(model, name);

        if (!this._materials.hasOwnProperty(hash))
        {
            var avs = av.Shaders;
            var lineMaterial = avs.createShaderMaterial(avs.LineShader);
            lineMaterial.is2d = true;
            lineMaterial.transparent = true;
            lineMaterial.depthWrite = false;
            lineMaterial.depthTest = false;
            lineMaterial.side = THREE.DoubleSide;
            lineMaterial.blending = THREE.NormalBlending;

            if (isIdMaterial) {
                //Is the caller requesting the special case of
                //shader that outputs just IDs (needed when MRT not available)?
                lineMaterial.defines["ID_COLOR"] = 1;
                lineMaterial.blending = THREE.NoBlending;
            }
            else if (isSelectionMaterial) {
                this.setSelectionTexture(lineMaterial);
                lineMaterial.defines["SELECTION_RENDERER"] = 1;
                lineMaterial.uniforms["selectionColor"].value = new THREE.Vector4(0, 0, 1, 1);
            }
            else {
                if (renderer && renderer.supportsMRT()) {
                    //If the renderer can do MRT, enable it in the shader
                    //so we don't have to draw the ID buffer separately.
                    lineMaterial.mrtIdBuffer = this._mrtIdBuffer;
                }
            }

            if (!material.skipEllipticals) {
                lineMaterial.defines["HAS_ELLIPTICALS"] = 1;
            }

            if (!material.skipCircles) {
                lineMaterial.defines["HAS_CIRCLES"] = 1;
            }

            if (!material.skipTriangleGeoms) {
                lineMaterial.defines["HAS_TRIANGLE_GEOMS"] = 1;
            }

            if (material.useInstancing) {
                lineMaterial.defines["USE_INSTANCING"] = 1;
            }

            if (material.image) {

                //TODO:NODE.JS
                if (!av.isNodeJS) {

                    var scope = this;

                    var onTexLoad = function(texture) {
                        texture.image = resizeImage(texture.image);

                        texture.wrapS = THREE.ClampToEdgeWrapping;
                        texture.wrapT = THREE.ClampToEdgeWrapping;
                        texture.minFilter = THREE.LinearMipMapLinearFilter;
                        texture.magFilter = THREE.LinearFilter;
                        texture.anisotropy = 1; // renderer.getMaxAnisotropy();
                        texture.flipY = true;
                        texture.generateMipmaps = true;

                        texture.needsUpdate = true;

                        lineMaterial.defines["HAS_RASTER_QUADS"] = 1;
                        lineMaterial.uniforms["tRaster"].value = texture;
                        if (material.image.dataURI.indexOf("png") != -1)
                            lineMaterial.transparent = true;
                        lineMaterial.needsUpdate = true;
                        if (onReady) {
                            onReady(texture);
                        }
                    };

                    loadTextureWithSecurity(material.image.dataURI, THREE.UVMapping, onTexLoad, svf.acmSessionId);
                }
            }

            lineMaterial.modelScale = material.modelScale || 1;

            _super.addLineMaterial.call(this, hash, lineMaterial);
        }

        return name;
    };


    //TODO: unify this logic with inittMaterials
    this.addMaterial = function(name, mat, skipHeuristics) {

        //Using post-gamma luminance, since input colors are assumed to
        //have gamma (non-linearized).
        function luminance(c) {
            return (0.299 * c.r) + (0.587 * c.g) + (0.114 * c.b);
        }

        var proteinMaterial = mat.proteinMat ? mat.proteinMat : null;
        var isPrism = (mat.proteinType && mat.proteinType.indexOf("Prism") != -1);

        this.hasPrism = isPrism || this.hasPrism;

        //apply various modifications to fit our rendering pipeline
        if (!skipHeuristics){

            //This pile of crazy hacks maps the various flavors of materials
            //to the shader parameters that we can handle.

            if (mat.metal) {

                if (!mat.reflectivity) {
                    mat.reflectivity = luminance(mat.specular);
                }

                //Special handling for Protein and Prism metals
                if (proteinMaterial)
                {
                    //For Prism metals, reflectivity is set to 1 and
                    //the magnitude of the specular component acts
                    //as reflectivity.
                    if (mat.reflectivity === 1)
                        mat.reflectivity = luminance(mat.specular);

                    if (mat.color.r === 0 && mat.color.g === 0 && mat.color.b === 0) {
                        //Prism metals have no diffuse at all, but we need a very small
                        //amount of it to look reasonable
                        //mat.color.r = mat.specular.r * 0.1;
                        //mat.color.g = mat.specular.g * 0.1;
                        //mat.color.b = mat.specular.b * 0.1;
                    }
                    else {
                        //For Protein metals, we get a diffuse that is full powered, so we
                        //scale it down
                        mat.color.r *= 0.1;
                        mat.color.g *= 0.1;
                        mat.color.b *= 0.1;
                    }
                }
            }
            else {
                //Non-metal materials

                if (isPrism)
                {
                    var isMetallic = false;

                    if (mat.proteinType == "PrismLayered")
                    {
                        //For layered materials, the Prism->Simple translator
                        //stores something other than reflectivity in the
                        //reflectivity term. We also do special handling
                        //for paint clearcoat, and metallic paint. Longer term,
                        //the good solution is to add things we do support to the Simple
                        //representation, or failing that, support native Prism definitions.
                        mat.clearcoat = true;
                        mat.reflectivity = 0.06;

                        if (proteinMaterial) {
                            var matDef = proteinMaterial["materials"][proteinMaterial["userassets"][0]];
                            var cats = matDef.categories;
                            if (cats && cats.length && cats[0].indexOf("Metal") != -1)
                            {
                                isMetallic = true;
                            }
                        }
                    }

                    //De-linearize this value in case of Prism, since there it
                    //seems to be physical (unlike the color values)
                    mat.reflectivity = Math.sqrt(mat.reflectivity);

                    if (isMetallic)
                    {
                        //metallic paint has specular = diffuse in Prism.
                        mat.specular.copy(mat.color);
                    }
                    else
                    {
                        //Prism non-metals just leave the specular term as 1,
                        //relying on reflectivity alone, but our shader needs
                        //both in different code paths.
                        mat.specular.r = mat.reflectivity;
                        mat.specular.g = mat.reflectivity;
                        mat.specular.b = mat.reflectivity;
                    }
                }
                else
                {
                    //Get a reasonable reflectivity value if there isn't any
                    if (!mat.reflectivity) {
                        if (mat.color.r === 1 && mat.color.g === 1 && mat.color.b === 1 &&
                            mat.specular.r === 1 && mat.specular.g === 1 && mat.specular.b === 1 &&
                            (!mat.textureMaps || (!mat.textureMaps.map && !mat.textureMaps.specularMap)))
                        {
                            //This covers specific cases in DWF where metals get diffuse=specular=1.
                            mat.metal = true;
                            mat.reflectivity = 0.7;

                            mat.color.r *= 0.1;
                            mat.color.g *= 0.1;
                            mat.color.b *= 0.1;
                        } else {

                            //General case
                            //For non-metallic materials, reflectivity
                            //varies very little in the range 0.03-0.06 or so
                            //and is never below 0.02.
                            mat.reflectivity = 0.01 + 0.06 * luminance(mat.specular);

                            //For non-metals, reflectivity is either set
                            //correctly or we estimate it above, and the specular color
                            //just carries the hue
                            //Note: Protein (but not Prism) seems to have consistently high reflectivity
                            //values for its non-metals.
                            mat.specular.r *= mat.reflectivity;
                            mat.specular.g *= mat.reflectivity;
                            mat.specular.b *= mat.reflectivity;
                        }

                    } else  if (mat.reflectivity > 0.3) {
                        //If reflectivity is set explicitly to a high value, but metal is not, assume
                        //the material is metallic anyway and set specular=diffuse
                        //This covers specific cases in DWF.

                        mat.metal = true;
                        mat.specular.r = mat.color.r;
                        mat.specular.g = mat.color.g;
                        mat.specular.b = mat.color.b;

                        mat.color.r *= 0.1;
                        mat.color.g *= 0.1;
                        mat.color.b *= 0.1;
                    } else {
                        //For non-metals, reflectivity is either set
                        //correctly or we estimate it above, and the specular color
                        //just carries the hue
                        //Note: Protein (but not Prism) seems to have consistently high reflectivity
                        //values for its non-metals.
                        mat.specular.r *= mat.reflectivity;
                        mat.specular.g *= mat.reflectivity;
                        mat.specular.b *= mat.reflectivity;
                    }

                    //For transparent non-layered materials, the reflectivity uniform is
                    //used for scaling the Fresnel reflection at oblique angles
                    //This is a non-physical hack to make stuff like ghosting
                    //look reasonable, while having glass still reflect at oblique angles
                    if (mat.opacity < 1)
                        mat.reflectivity = 1.0;
                }
            }

            //Alpha test for materials with textures that are potentially opacity maps
            if (mat.transparent ||
                (mat.textureMaps && ((mat.textureMaps.map && mat.textureMaps.map.uri.toLowerCase().indexOf(".png") != -1) ||
                                      mat.textureMaps.opacityMap))) {
                mat.alphaTest = 0.01;
            }
        }

        if (mat.textureMaps && mat.textureMaps.normalMap)
        {
            var scale = mat.bumpScale;
            if (scale === undefined || scale >= 1)
                scale = 1;

            mat.normalScale = new THREE.Vector2(scale, scale);
        }
        else
        {
            if (mat.bumpScale === undefined && mat.textureMaps && (mat.textureMaps.map || mat.textureMaps.bumpMap))
                mat.bumpScale = 0.03; //seems like a good subtle default if not given
            else if (mat.bumpScale >= 1) //Protein generic mat sometimes comes with just 1.0 which can't be right...
                mat.bumpScale = 0.03;
        }

        if ( mat.shininess !== undefined )
        {
            //Blinn to Phong (for blurred environment map sampling)
            mat.shininess *= 0.25;
        }

        //if (mat.opacity < 1.0 || (mat.textureMaps && mat.textureMaps.opacityMap))
        //    mat.side = THREE.DoubleSide;

        if (mat.side == THREE.DoubleSide) {
            _needsTwoSided = true;
        }

        _super.addHDRMaterial.call(this, name, mat);
    };

    this.addMaterialNonHDR = function(name, mat) {
        _super.addNonHDRMaterial.call(this, name, mat);
    };

    this.togglePolygonOffset = function(state) {
        this.forEach(function(mat) {
            if (mat instanceof THREE.MeshPhongMaterial) {
                mat.polygonOffset = true;
                mat.polygonOffsetFactor = state ? 1 : 0;
                mat.polygonOffsetUnits = state ? 0.1 : 0;  // 1.0 is much too high, see LMV-1072; may need more adjustment
                if (mat.extraDepthOffset) {
                    mat.polygonOffsetFactor += mat.extraDepthOffset;
                }
                mat.needsUpdate = true;
            }
        });
    };

    //Certain material properties only become available
    //once we see a geometry that uses the material. Here,
    //we modify the material based on a given geometry that's using it.
    this.applyGeometryFlagsToMaterial = function(material, threegeom) {

        if (threegeom.attributes.color) {
            //TODO: Are we likely to get the same
            //material used both with and without vertex colors?
            //If yes, then we need two versions of the material.
            material.vertexColors = THREE.VertexColors;
            material.needsUpdate = true;
        }

        //If we detect a repeating texture in the geometry, we assume
        //it is some kind of material roughness pattern and reuse
        //the texture as a low-perturbation bump map as well.
        if (!material.proteinType && threegeom.attributes.uv && threegeom.attributes.uv.isPattern) {
            if (material.map && !material.bumpMap) {
                material.bumpMap = material.map;
                material.needsUpdate = true;
            }
            if (material.textureMaps && material.textureMaps.map && !material.textureMaps.bumpMap) {
                material.textureMaps.bumpMap = material.textureMaps.map;
                material.needsUpdate = true;
            }
        }

    };

    this.setCubeMapFromColors = function(ctop, cbot) {
        var texture = avp.CreateCubeMapFromColors(ctop, cbot);
        texture.isBgColor = true;
        _super.setReflectionMap.call(_this, texture);
        return _this._reflectionMap;
    };

    this.setCubeMap = function(path, exposure, onReady) {

        var self = this;

        var mapDecodeDone = function(map) {
            _super.setReflectionMap.call(self, map);
            if (onReady) {
                onReady(map);
            }
        };

        var texLoadDone = function(map) {

            if (map) {
                map.mapping = THREE.CubeReflectionMapping;
                map.LogLuv = path.indexOf("logluv") != -1;
                map.RGBM = path.indexOf("rgbm") != -1;

                // TODO: Turn on use of half-float textures for envmaps. Disable due to blackness on Safari.
                avp.DecodeEnvMap(map, exposure, false /*isMobileDevice() ? false : this.viewer.glrenderer().supportsHalfFloatTextures()*/, mapDecodeDone);
            } else {
                mapDecodeDone(map);
            }

        };

        if (Array.isArray(path)) {
             this._reflectionMap = THREE.ImageUtils.loadTextureCube(path, THREE.CubeReflectionMapping, texLoadDone);
             this._reflectionMap.format = THREE.RGBFormat;
        }
        else if (typeof path == "string") {
            if (path.toLowerCase().indexOf(".dds") != -1) {
                this._reflectionMap = new THREE.DDSLoader().load(path, texLoadDone);
            }
            else {
                this._reflectionMap = THREE.ImageUtils.loadTexture(path, THREE.SphericalReflectionMapping, mapDecodeDone);
                this._reflectionMap.format = THREE.RGBFormat;
            }
        } else if (path) {
            //here we assume path is already a texture object
            mapDecodeDone(path);
        }
        else {
            mapDecodeDone(null);
        }

        return self._reflectionMap;
    };


    this.setIrradianceMap = function(path, exposure, onReady) {

        var self = this;

        var mapDecodeDone = function(map) {
            _super.setIrradianceMap.call(self, map);
            if (onReady) {
                onReady(map);
            }
        };

        var texLoadDone = function(map) {
            if (map)
            {
                map.mapping = THREE.CubeReflectionMapping;
                map.LogLuv = path.indexOf("logluv") != -1;
                map.RGBM = path.indexOf("rgbm") != -1;

                // TODO: Turn on use of half-float textures for envmaps. Disable due to blackness on Safari.
                avp.DecodeEnvMap(map, exposure, false /*isMobileDevice() ? false : this.viewer.glrenderer().supportsHalfFloatTextures()*/, mapDecodeDone);

            }
            else
            {
                if (self._irradianceMap)
                    mapDecodeDone(null);
            }
        };

        THREE.ImageUtils.crossOrigin = "";

        if (Array.isArray(path)) {
             _this._irradianceMap = THREE.ImageUtils.loadTextureCube(path, THREE.CubeReflectionMapping, mapDecodeDone);
             _this._irradianceMap.format = THREE.RGBFormat;
        }
        else if (typeof path == "string") {
            if (path.toLowerCase().indexOf(".dds") != -1) {
                this._irradianceMap = new THREE.DDSLoader().load(path, texLoadDone);
            }
        } else if (path) {
            //here we assume path is already a texture object
            mapDecodeDone(path);
        }
        else {
            mapDecodeDone(null);
        }

        return self._irradianceMap;
    };

    this.init2DSelectionMaterial = function(model, use2dInstancing, onReady) {

        if (!this._selectionTex) {
            this.initSelectionTexture(model.myData.maxObjectNumber);
        }

        var name = this.create2DMaterial(model, { useInstancing: use2dInstancing }, false, true, onReady);
        var m = this._materials[this._getMaterialHash(model, name)];
        return m;
    };

    //Meshes for 2d drawings contain many objects in a single mesh.
    //So we use a mask texture to pick out which object specifically
    //to highlight or render in ghosted style. The shader samples this texture to deside whether
    //to draw or not.
    this.highlightObject2D = function(dbId, state) {
        var data = this._selectionTex.image.data;

        data[dbId] = state ? 0xff : 0;

        //TODO: partial texture update using TexSubImage possible?
        this._selectionTex.needsUpdate = true;
    };

    /**
     * Returns a copy of cut planes
     */
    this.getCutPlanes = function() {
        return this._cutplanes.slice();
    };
    this.getCutPlanesRaw = function() {
        return this._cutplanes;
    };

    // TODO: the signature of this method has changed, but the method doesn't seem to be used anywhere
    this.addSimpleMaterial = function(id, simpleMaterial, model) {
        var phongMat = avp.MaterialConverter.convertMaterial(simpleMaterial);
        var matName = this._getMaterialHash(model, id);
        this.addMaterial(matName, phongMat);
        this.loadTexture(phongMat, model);
    };

    //Register the default material
    this.addMaterial("__defaultMaterial__", this.defaultMaterial);

    //this.initLineStyleTexture();

    /** Apply shadow params to all materials
     *   @param {ShadowParams}
     */
    this.setShadowParams = function(params) {
        this.forEach(function(m) {
            params.apply(m);
        });
    };

};

// Helper function that postpones the setup of MaterialManager's prototype chain
// (because it depends on WGS.MaterialManager which is loaded as a dependency).
function createMaterialManager(renderer) {
    if (!avp.hasOwnProperty('MaterialManager')) {
        MaterialManager.prototype = new WGS.MaterialManager(renderer);
        MaterialManager.prototype.constructor = MaterialManager;
        avp.MaterialManager = MaterialManager;
    }
    return new avp.MaterialManager(renderer);
}

/**
 * Adds intancing support for override materials: It attaches an alternative variant
 * with instancing support, which is used by WebGLRenderer to render instanced shapes correctly.
 *
 *  NOTE: This function can only be used for simple override materials that have no
 *        other alternative variants yet.
 *
 *   @param {THREE.Material} material
 */
function addInstancingSupport(material) {

    // create material clone with instancing
    var instMat = material.clone();
    instMat.useInstancing = true;

    // Make this available as variant. Note that we generally store
    // material variants as an array member mat.variants, so that we have a uniform way to find them
    // (e.g. see MaterialManager.addOverrideMaterial), no matter if there are more variants or just one.
    material.variants = [instMat];

    // Make WebGLRenderer use the instancing material where needed
    material.getCustomOverrideMaterial = function(shapeMaterial) {
        if (shapeMaterial.useInstancing) {
            // use override material with instancing
            return this.variants[0];
        }
        // use default
        return null;
    };
};


Autodesk.Viewing.Private.createMaterialManager = createMaterialManager;

Autodesk.Viewing.Private.loadTextureWithSecurity = loadTextureWithSecurity;

Autodesk.Viewing.Private.addInstancingSupport = addInstancingSupport;

})();
;

(function() {

'use strict';

var av = Autodesk.Viewing,
    avp = av.Private;

function RenderContext() {

    var _renderer;
    var _depthMaterial;
    var _idMaterial;

    //The camera and lights used for an entire progressive pass (potentially several GL frames)
    var _camera;
    var _lights;
    var _fog;

    var _clearPass,
        _saoBlurPass,
        _saoPass,
        _saoMipPass,
        _saoMipFirstPass,
        _fxaaPass,
        _celPass,
        _blendPass,
        _copyPass;

    var _saoBufferValid = false;

    var _lastX, _lastY, _lastID, _lastModelID, _lastIDValid = false;

    var _depthTarget;
    var _depthMipMap = null;
    var _colorTarget = null;
    var _overlayTarget = null;
    var _postTarget1 = null;
    var _postTarget2 = null;
    var _idTargets = [];

    var _exposureBias = 0.0;
    var _envRotation = 0.0;
    var _tonemapMethod = 0;
    var _unitScale = 1.0;

    var _w, _h;
    var _warnedLeak = false;

    var _readbackBuffer = new Uint8Array(4);

    var _white = new THREE.Color().setRGB(1, 1, 1);
    var _black = new THREE.Color().setRGB(0, 0, 0);
    var _clearColor = null;
    var _isWeakDevice = false;

    var _mrtFloat32Works = false;
    var _mrtRGBA8Works = false;
    var _renderTargetFormat;

    var _lastObjTime = 0,
        _lastHighlightId = 0,
        _lastHighlightModelId = 0,
        _easeCurve = [0.42,0,1,1],
        _easeSpeed = 0.004;

    //Rendering options
    var _settings = {
        antialias: true,
        sao: false,
        useHdrTarget: false,
        haveTwoSided: false,
        useSSAA: false, /* Whether to use supersampled targets when antialiasing is used (default is FXAA) */
        idbuffer: true,
        customPresentPass: false,
        toonShaded: false,
        envMapBg: false,
        swapBlackAndWhite: false,
        numIdTargets: 1 //must be 1 or 2
    };

    var _oldSettings = {};

    var avs = Autodesk.Viewing.Shaders;


    //TODO: hide this once there is a way
    //to obtain the current pipeline configuration
    this.settings = _settings;


    this.init = function (glrenderer, width, height) {

        createRenderPasses();

        if (!glrenderer) {
            avp.logger.error("You need a gl context to make a renderer. Things will go downhill from here.");
            return;
        }

        //Rendering to RGB32F is broken as of Firefox 45, so we use alternative render target format until it works again.
        var isBrokenFF = window.navigator.userAgent.indexOf("Firefox") != -1;

        //RGB32F is not renderable on Firefox/Windows now, so we use RGBA instead.
        //NOTE: This assumes MRT does not work on Firefox/Windows with RGB32F target either. If it does, then
        //we have to use the same format for the color and id targets.
        _renderTargetFormat = isBrokenFF ? THREE.RGBAFormat : THREE.RGBFormat;

        _isWeakDevice = av.isMobileDevice();

        _settings.idbuffer = !_isWeakDevice;

        _w = width;
        _h = height;

        _renderer = glrenderer;

        //delayed until first begin frame
        //this.initPostPipeline(_settings.sao, _settings.antialias);

    };

    // Creates material for normal-depth shader - including alternative variants
    // for instancing and with/without cutplanes.
    function createDepthMaterial() {

        // create main/default override material first
        var depthShader = avs.NormalsShader;
        _depthMaterial = avs.createShaderMaterial(depthShader);
        _depthMaterial.blending = THREE.NoBlending;
        _depthMaterial.packedNormals = true;

        // Flags to define alternative depth material variants.
        var DepthMaterialFlags = {
            NoCutPlanes: 0x1, // Without cutplanes to render section caps
            Instancing:  0x2, // Using instancing
            Count     :  0x4
        };

        // create special-case material variants
        var variants = [];
        variants[0] = null; // index 0 = null (=use default depthMaterial)
        for (var i=1; i<DepthMaterialFlags.Count; i++) {
            var variant = _depthMaterial.clone();

            // cutplanes: with/without
            if (i & DepthMaterialFlags.NoCutPlanes) {
                variant.cutPlanes     = null;
                variant.blending      = THREE.NoBlending;
                variant.packedNormals = true;
                variant.doNotCut      = true; // make sure that cutplanes keep null (see MaterialManager.addMaterialNonHDR)
            }

            // instancing yes/no
            if (i & DepthMaterialFlags.Instancing) {
                variant.useInstancing = true;
            }

            variants[i] = variant;
        };

        _depthMaterial.variants = variants;

        // Define a custom override function: It decides for a shape
        // which depthMaterial variant will be used by WebGLRenderer.
        _depthMaterial.getCustomOverrideMaterial = function(shapeMaterial) {

            // If the original shape material has no cutplanes, use the alternative
            // _noCutplanesMaterial for normal/depth.
            var noCutPlanes = (!shapeMaterial.cutplanes || shapeMaterial.cutplanes.length == 0);

            // If the original material applies the instance transform, depthMaterial must do this as well.
            var instanced   = shapeMaterial.useInstancing;

            // return the appropriate material variant
            var index =
                (noCutPlanes ? DepthMaterialFlags.NoCutPlanes : 0) |
                (instanced   ? DepthMaterialFlags.Instancing  : 0);
            return this.variants[index];
        };
    }

    // Calls the cb for all depth material variants (including default)
    function forEachDepthMaterial(cb) {
        cb(_depthMaterial);
        for (var i=1; i<_depthMaterial.variants.length; i++) {
            cb(_depthMaterial.variants[i]);
        }
    };

    function createRenderPasses() {

        function setNoDepthNoBlend(pass) {
            pass.material.blending = THREE.NoBlending;
            pass.material.depthWrite = false;
            pass.material.depthTest = false;
        }

        createDepthMaterial();

        _saoPass = new avs.LmvShaderPass(avs.SAOShader);
        setNoDepthNoBlend(_saoPass);

        _saoBlurPass = new avs.LmvShaderPass(avs.SAOBlurShader);
        setNoDepthNoBlend(_saoBlurPass);

        _saoMipFirstPass = new avs.LmvShaderPass(avs.SAOMinifyFirstShader);
        setNoDepthNoBlend(_saoMipFirstPass);

        _saoMipPass = new avs.LmvShaderPass(avs.SAOMinifyShader);
        setNoDepthNoBlend(_saoMipPass);

        _fxaaPass = new avs.LmvShaderPass(avs.FXAAShader);
        setNoDepthNoBlend(_fxaaPass);

        _celPass = new avs.LmvShaderPass(avs.CelShader);
        setNoDepthNoBlend(_celPass);

        _blendPass = new avs.LmvShaderPass(avs.BlendShader);
        setNoDepthNoBlend(_blendPass);

        _clearPass = new avs.LmvShaderPass(avs.BackgroundShader);
        setNoDepthNoBlend(_clearPass);

        _copyPass = new avs.LmvShaderPass(avs.CopyShader);
        setNoDepthNoBlend(_copyPass);
    }


    function cubicBezier(p, t) {
        //var cx = 3.0 * p[0];
        //var bx = 3.0 * (p[2] - p[0]) - cx;
        //var ax = 1.0 - cx -bx;
        var cy = 3.0 * p[1];
        var by = 3.0 * (p[3] - p[1]) - cy;
        var ay = 1.0 - cy - by;

        //return ((ax * t + bx) * t + cx) * t;
        return ((ay * t + by) * t + cy) * t;
    }

    // note: highResTimer is not used
    this.overlayUpdate = function(highResTimer) {

        if (_lastHighlightId === 0 || _lastHighlightId === -1)
            return false;

        var old = _blendPass.uniforms.highlightIntensity.value;

        var t = ((performance.now() - _lastObjTime) * _easeSpeed);
        t = Math.min(t, 1.0);

        var current = cubicBezier(_easeCurve, t);

        if (old != current) {
            _blendPass.uniforms.highlightIntensity.value = current;
            return true;
        }

        return false;
    };

    this.beginScene = function (prototypeScene, camera, customLights, needClear) {
        _camera = camera;
        _fog = prototypeScene.fog;
        _lights = customLights;
        _saoBufferValid = false;
        _lastIDValid = false;

        if (!_colorTarget && _w) {
            this.initPostPipeline(_settings.sao, _settings.antialias);
        } else if (!_colorTarget && !_w) {
            if (!_warnedLeak) {
                avp.logger.error("Rendering to a canvas that was resized to zero. If you see this message you may be accidentally leaking a viewer instance.");
                _warnedLeak = true;
            }
            return;
        }

        //We need to render once with the "prototype" scene which
        //only contains the cameras and lights, so that their positions
        //and transforms get updated to the latest camera. Hence the
        //call to render instead of just clear.


        //Clear the color target
        if (needClear) {

            if (_clearColor && !_settings.envMapBg) {
                if (_settings.swapBlackAndWhite) {
                    var white = new THREE.Color(1, 1, 1);
                    var black = new THREE.Color(0, 0, 0);
                    if (_clearColor.equals(white)) {
                        _renderer.setClearColor(black, 1.0);
                    }
                    else if (_clearColor.equals(black)) {
                        _renderer.setClearColor(white, 1.0);
                    }
                    else {
                        _renderer.setClearColor(_clearColor, 1.0);
                    }
                }
                else {
                    _renderer.setClearColor(_clearColor, 1.0);
                }
                _renderer.clearTarget(_colorTarget, true, true, false); //clear color and depth buffer
            } else {

                _clearPass.uniforms['uCamDir'].value = _camera.worldUpTransform ? _camera.getWorldDirection().clone().applyMatrix4(_camera.worldUpTransform) : _camera.getWorldDirection();
                _clearPass.uniforms['uCamUp'].value = _camera.worldUpTransform ? _camera.up.clone().applyMatrix4(_camera.worldUpTransform) : _camera.up;
                _clearPass.uniforms['uResolution'].value.set(_w, _h);
                _clearPass.uniforms['uHalfFovTan'].value = Math.tan(THREE.Math.degToRad(_camera.fov * 0.5));

                _renderer.clearTarget(_colorTarget, false, true, false); //clear depth buffer
                _clearPass.render(_renderer, _colorTarget, null); //clear the color buffer
            }
        }

        //Clear the id buffer(s)
        for (var i=0; i<_idTargets.length; i++) {
            _renderer.setClearColor(_white, 1.0);
            _renderer.clearTarget(_idTargets[i], true, false, false);
        }

        //Clear the G-buffer target if needed and update the SSAO uniforms.
        if (_settings.sao || _settings.toonShaded) {

            if (needClear) {
                _renderer.setClearColor(_black, 0.0);
                //Skip clearing the depth buffer as it's shared with the color target
                _renderer.clearTarget(_depthTarget, true, false, false);
            }

            var near = camera.near;
            var far = camera.far;

            _saoPass.uniforms['cameraNear'].value = near;
            _saoPass.uniforms['cameraFar'].value = far;
            _celPass.uniforms['cameraNear'].value = near;
            _celPass.uniforms['cameraFar'].value = far;

            _saoMipFirstPass.uniforms['cameraNear'].value = near;
            _saoMipFirstPass.uniforms['cameraInvNearFar'].value = 1.0 / (near - far);

            var P = camera.projectionMatrix.elements;

            //Scaling factor needed to increase contrast of our SSAO.
            if (camera.isPerspective) {
                /*  vec4(-2.0f / (width*P[0][0]),
                 -2.0f / (height*P[1][1]),
                 ( 1.0f - P[0][2]) / P[0][0],
                 ( 1.0f + P[1][2]) / P[1][1])*/
                _saoPass.uniforms[ 'projInfo' ].value.set(
                    -2.0 / (_colorTarget.width * P[0]),
                    -2.0 / (_colorTarget.height * P[5]),
                    (1.0 - P[8]) / P[0],
                    (1.0 + P[9]) / P[5]);   //TODO: Not certain if we need + or - here for OpenGL off-center matrix (original is DX-style)
                                            //would have to verify if some day we have off-center projections.

                _celPass.uniforms[ 'projInfo'].value.copy(_saoPass.uniforms[ 'projInfo' ].value);

                _saoPass.uniforms[ 'isOrtho' ].value = 0.0;

                _celPass.uniforms[ 'isOrtho' ].value = 0.0;

            } else {
                _saoPass.uniforms[ 'projInfo' ].value.set(
                    -2.0 / (_colorTarget.width * P[0]),
                    -2.0 / (_colorTarget.height * P[5]),
                    (1.0 - P[12]) / P[0],
                    (1.0 - P[13]) / P[5]);

                _celPass.uniforms[ 'projInfo'].value.copy(_saoPass.uniforms[ 'projInfo' ].value);

                _saoPass.uniforms[ 'isOrtho' ].value = 1.0;

                _celPass.uniforms[ 'isOrtho' ].value = 1.0;

            }

            var hack_scale = 0.25;
            _saoPass.uniforms[ 'projScale' ].value = hack_scale * 0.5 * (_colorTarget.height * P[5]);

            // an approximation of the size of the world; relies on the camera's near and far being reasonable.
            // This is not a great solution, as orbiting changes this number. Better would be the length of
            // the diagonal of the whole world, or perhaps the *shortest* dimension (so that cities get SAO).
            // This method is variable on the camera's view. Better is to do this in Viewer3dImpl.addModel,
            // which is where we do this now.
            //this.setAOOptions( 0.05*(camera.far-camera.near) );
        }

        if (!_settings.sao)
        {
            // Ensure that any previous SSAO computation post-process target is not blended in.
            // This looks redundant with computeSSAO()'s code setting this blend off. However, it's
            // possible for computeSSAO() to not be executed if (a) smooth navigation and AO are both on
            // and (b) the scene is moving. In that case, smooth navigation turns off AO entirely in
            // Viewer3DImpl.js and computSSAO() is never called at all.
            _blendPass.uniforms['useAO'].value = 0;
        }

        //Render the prototype/pre-model scene, which may also contain some user added custom geometry.
        this.renderScenePart(prototypeScene, true, true, false, true);
    };


    //Called incrementally by the scene traversal, potentially
    //across several frames.
    this.renderScenePart = function (scene, want_colorTarget, want_saoTarget, want_idTarget, updateLights) {

        //console.time("renderScenePart");
        _saoBufferValid = false;
        _lastIDValid = false;
        var lights = updateLights ? _lights : undefined;
        //update scene with stored _fog shared from prototypeScene fog.
        scene.fog = _fog;

        //Three possibilities here -- MRT fully supported (Mac OS or native GL backends on Windows).
        //MRT supported only for targets that have exactly equal number of bitplanes and bpp (ANGLE on Windows)
        //MRT not supported at all. (Not sure --> some mobile platforms?).

        var oldMat;
        if (_mrtFloat32Works && _mrtRGBA8Works) {
            //You lucky dog! Fast code path for you.

            //In case of MRT, we ignore the which target flags, because
            //we assume the shaders are set up to write to the multiple targets anyway.
            //NOP: except idTarget, since hidden pass doesn't want that
            if (_settings.idbuffer && want_idTarget && (_settings.sao || _settings.toonShaded)) {
                _renderer.render(scene, _camera, [_colorTarget, _depthTarget].concat(_idTargets), false, lights);
            }
            else if ((_settings.sao || _settings.toonShaded)) {
                _renderer.render(scene, _camera, [_colorTarget, _depthTarget], false, lights);
            }
            else if (_settings.idbuffer && want_idTarget) {
                _renderer.render(scene, _camera, [_colorTarget].concat(_idTargets));
            }
            else /*if (_settings.antialias)*/ {
                _renderer.render(scene, _camera, _colorTarget, false, lights);
            }
            //else {
            //    _renderer.render(scene, _camera, null);
            //}

        } else if (_mrtRGBA8Works) {
            //It's something...

            if (_settings.idbuffer && want_idTarget) {
                _renderer.render(scene, _camera, [_colorTarget].concat(_idTargets), false, lights);
            }
            else /*if (_settings.antialias)*/ {
                _renderer.render(scene, _camera, _colorTarget, false, lights);
            }

            //Float target has to be rendered separately in case we can't
            //bind MRT with different bpp targets.
            if ((_settings.sao || _settings.toonShaded) && want_saoTarget) {
                //Render the depth pass
                oldMat = scene.overrideMaterial;

                scene.overrideMaterial = _depthMaterial;

                _renderer.render(scene, _camera, _depthTarget, false, undefined);

                scene.overrideMaterial = oldMat;
            }

        } else {
            //Poor sod. No MRT at all. Three passes.

            //Render the color target first -- actually this is slower
            //because the color shader is likely a lot slower than the
            //depth+normal shader, but if we render depth first, then
            //we lose stuff behind transparent objects (potentially).
            //So we cannot do this until the progressive render is split
            //into non-transparent and transparent worlds.
            if (want_colorTarget) {
                _renderer.render(scene, _camera, _colorTarget, false, lights);
            }

            //TODO: In 3D we really don't want to get into
            //this situation -- we don't have a reasonable ID material that
            //will work for e.g. cutout maps. We'd have to run basically a full
            //shader, or at least one that support opacity and alpha map checks.
            if (_settings.idbuffer && want_idTarget && _idMaterial) {

                oldMat = scene.overrideMaterial;

                scene.overrideMaterial = _idMaterial;

                //TODO: This code path does not work in case multiple id targets are attached
                //We need a second ID material that renders modelId instead of dbId.
                _renderer.render(scene, _camera, _idTargets[0], false, undefined);

                scene.overrideMaterial = oldMat;
            }

            if ((_settings.sao || _settings.toonShaded) && want_saoTarget) {
                //Render the depth pass
                oldMat = scene.overrideMaterial;

                scene.overrideMaterial = _depthMaterial;

                _renderer.render(scene, _camera, _depthTarget, false, undefined);

                scene.overrideMaterial = oldMat;
            }

        }

        //console.timeEnd("renderScenePart");
    };

    this.clearAllOverlays = function () {
        _renderer.clearTarget(_overlayTarget, true, false, false);
    };

    this.renderOverlays = function (overlays, lights) {
        var haveOverlays = 0;

        for (var key in overlays) {
            var p = overlays[key];
            var s = p.scene;
            var c = p.camera ? p.camera : _camera;
            if (s.children.length) {

                if (!haveOverlays) {
                    haveOverlays = 1;

                    //clear the overlay target once we see
                    //the first non-empty overlay scene
                    _renderer.setClearColor(_black, 0.0);
                    _renderer.clearTarget(_overlayTarget, true, false, false);
                }


                if (p.materialPre) {
                    s.overrideMaterial = p.materialPre;
                }
                _renderer.render(s, c, _overlayTarget, false, lights);

                if (p.materialPost) {
                    s.overrideMaterial = p.materialPost;
                    _renderer.context.depthFunc(_renderer.context.GREATER);
                    _renderer.render(s, c, _overlayTarget, false, lights);
                    _renderer.context.depthFunc(_renderer.context.LEQUAL);
                }

                s.overrideMaterial = null;
            }
        }

        _blendPass.uniforms['useOverlay'].value = haveOverlays;
    };


    this.computeSSAO = function(skipAOPass) {
        if (!skipAOPass && _settings.sao && !_settings.toonShaded) {

            //console.time("SAO");
            if (!_saoBufferValid) {
                //Create mip levels for the depth/normals target
                if (_depthMipMap) {
                    var prevMip = _depthMipMap[0];
                    _saoMipFirstPass.uniforms['resolution'].value.set(1.0 / prevMip.width, 1.0 / prevMip.height);
                    _saoMipFirstPass.render(_renderer, prevMip, _depthTarget);
                    for (var i = 1; i < _depthMipMap.length; i++) {
                        var curMip = _depthMipMap[i];
                        _saoMipPass.uniforms['resolution'].value.set(1.0 / curMip.width, 1.0 / curMip.height);
                        _saoMipPass.render(_renderer, curMip, prevMip);
                        prevMip = curMip;
                    }
                }

                _saoPass.render(_renderer, _postTarget2, _colorTarget);

                //console.timeEnd("SAO");
                //console.time("SAOblur");
                //Do the bilateral blur
                _saoBlurPass.uniforms['axis'].value.set(1, 0);
                _saoBlurPass.render(_renderer, _postTarget1, _postTarget2);
                _saoBlurPass.uniforms['axis'].value.set(0, 1);
                _saoBlurPass.render(_renderer, _postTarget2, _postTarget1);

                _saoBufferValid = true;
            }

            _blendPass.uniforms['useAO'].value = 1;
            //console.timeEnd("SAOblur");
        } else {
            // Ensure that any previous SSAO computation post-process target is not blended in.
            _blendPass.uniforms['useAO'].value = 0;
        }

    };

    this.presentBuffer = function (userFinalPass) {

        if (!_renderer)
            return;

        //See if the blend pass is trivial 1:1, in which
        //case we can just use the main color target for
        //the final pass and skip the blend pass.
        //NOTE: This needs to be adjusted if the blend pass ever
        //does the tone mapping again.
        //TODO: Another possible improvement is to support blending of the SAO
        //inside the FXAA pass, in case the blend pass is just modulating by the AO value.
        var canSkipBlendPass = !_settings.sao &&
                               !_blendPass.uniforms['useOverlay'].value &&
                               // idAtPixel can return -1 for the ID when nothing is there
                               (_lastHighlightId === 0 || _lastHighlightId === -1) &&
                               (_lastHighlightModelId === 0 || _lastHighlightModelId === -1);

        if (canSkipBlendPass) {

            if (_settings.antialias) {

                if (userFinalPass) {
                    _fxaaPass.render(_renderer, _postTarget1, _colorTarget);
                    userFinalPass.render(_renderer, null, _postTarget1);
                } else if (_settings.toonShaded) {
                    _celPass.render(_renderer, _postTarget1, _colorTarget);
                    _fxaaPass.render(_renderer, null, _postTarget1);
                } else {
                    _fxaaPass.render(_renderer, null, _colorTarget);
                }
            }
            else if (userFinalPass) {
                userFinalPass.render(_renderer, null, _colorTarget);
            } else if (_settings.toonShaded) {
                _celPass.render(_renderer, _postTarget1, _colorTarget);
                _copyPass.render(_renderer, null, _postTarget1);
            } else {
                _copyPass.render(_renderer, null, _colorTarget);
            }

        } else {

            //console.time("post");
            //If we have fxaa, do the blending into an offscreen target
            //then FXAA into the final target
            if (_settings.antialias) {
                _blendPass.render(_renderer, _postTarget1, _colorTarget);

                if (userFinalPass) {
                    _fxaaPass.render(_renderer, _postTarget2, _postTarget1);
                    userFinalPass.render(_renderer, null, _postTarget2);
                } else if (_settings.toonShaded) {
                    _celPass.render(_renderer, _postTarget2, _postTarget1);
                    _fxaaPass.render(_renderer, null, _postTarget2);
                } else {
                    _fxaaPass.render(_renderer, null, _postTarget1);
                }
            }
            else {
                if (userFinalPass) {

                    _blendPass.render(_renderer, _postTarget1, _colorTarget);
                    userFinalPass.render(_renderer, null, _postTarget1);

                } else {
                    if (_settings.toonShaded) {
                        _blendPass.render(_renderer, _postTarget1, _colorTarget);
                        _celPass.render(_renderer, _postTarget2, _postTarget1);
                        _copyPass.render(_renderer, null, _postTarget2);
                    } else {
                        _blendPass.render(_renderer, null, _colorTarget);
                    }
                }
            }
        }

    };


    this.composeFinalFrame = function (skipAOPass, skipPresent) {
        //Apply the post pipeline and then show to screen.
        //Note that we must preserve the original color buffer
        //so that we can update it progressively
        if (_settings.sao && !_settings.toonShaded)
            this.computeSSAO(skipAOPass);

        if (!skipPresent)
            this.presentBuffer();

        //console.timeEnd("post");

    };

    this.cleanup = function () {
        if (_colorTarget) {
            _colorTarget.dispose();
            _colorTarget = null;
        }

        if (_depthTarget) {
            _depthTarget.dispose();
            _depthTarget = null;
        }

        if (_overlayTarget) {
            _overlayTarget.dispose();
            _overlayTarget = null;
        }

        if (_postTarget1) {
            _postTarget1.dispose();
            _postTarget1 = null;
        }

        if (_postTarget2) {
            _postTarget2.dispose();
            _postTarget2 = null;
        }

        if (_depthMipMap) {
            for (var i=0; i<_depthMipMap.length; i++) {
                _depthMipMap[i].dispose();
            }

            _depthMipMap = [];
        }
    };

    this.setSize = function (w, h, force) {

        _w = w;
        _h = h;

        _settings.logicalWidth = w;
        _settings.logicalHeight = h;

        //Just a way to release the targets in cases when
        //we use a custom render context and don't need this one
        //temporarily
        if ((w === 0 && h === 0) || !_renderer) {
            this.cleanup();
            return;
        }

        var sw = 0 | (w * _renderer.getPixelRatio());
        var sh = 0 | (h * _renderer.getPixelRatio());

        _settings.deviceWidth = sw;
        _settings.deviceHeight = sh;

        _renderer.setSize(w, h);

        avp.logger.log("width: " + sw + " height: " + sh);

        var resX = 1.0 / sw;
        var resY = 1.0 / sh;

        //supersample antialiasing
        //Create a somewhat larger render target, that is power of 2 size and has mipmap
        if (_settings.useSSAA || (_settings.toonShaded && _renderer.getPixelRatio() <= 1)) {
            /*
                sw *= 3 / _renderer.getPixelRatio();
                sh *= 3 / _renderer.getPixelRatio();

                var w = 1;
                while (w < sw) w *= 2;
                var h = 1;
                while (h < sh) h *= 2;

                sw = w;
                sh = h;
                */
                sw *=2;
                sh *=2;

            force = true;
        }

        //Just the regular color target -- shares depth buffer
        //with the depth target.
        if (force || !_colorTarget || _colorTarget.width != sw || _colorTarget.height != sh) {

            avp.logger.log("Reallocating render targets.");
            this.cleanup();

            _colorTarget = new THREE.WebGLRenderTarget(sw, sh,
                {   minFilter: THREE.LinearFilter,
                    magFilter: THREE.LinearFilter,
                    format: THREE.RGBFormat,
                    type: _settings.useHdrTarget ? THREE.FloatType : THREE.UnsignedByteType,
                    //anisotropy: Math.min(this.getMaxAnisotropy(), 4),
                    stencilBuffer: false
                });
            // three.js has a flaw in its constructor: the generateMipmaps value is always initialized to true
            _colorTarget.generateMipmaps = false; 

            _overlayTarget = new THREE.WebGLRenderTarget(sw, sh,
                {  minFilter: THREE.NearestFilter,
                    magFilter: THREE.NearestFilter,
                    format: THREE.RGBAFormat,
                    stencilBuffer: false
                });
            _overlayTarget.generateMipmaps = false; 


            _overlayTarget.shareDepthFrom = _colorTarget;


            _depthTarget = null;
            _postTarget1 = null;
            _postTarget2 = null;
            _depthMipMap = [];
        }

        if (_settings.antialias || _settings.sao || _settings.customPresentPass || _settings.toonShaded)
        {
            if (force || !_postTarget1 || _postTarget1.width != sw || _postTarget1.height != sh) {
                //We need one extra post target if FXAA is on, so
                //to use as intermediate from Blend->FXAA pass.
                _postTarget1 = new THREE.WebGLRenderTarget(sw, sh,
                    {
                        minFilter: THREE.LinearFilter,
                        magFilter: THREE.LinearFilter,
                        format: THREE.RGBAFormat,
                        //anisotropy: 0,
                        //anisotropy: Math.min(this.getMaxAnisotropy(), 4),
                        stencilBuffer: false,
                        depthBuffer: false
                    });
                _postTarget1.generateMipmaps = false; 
           }
        }


        if (_settings.sao || _settings.toonShaded) {
            if (force || !_depthTarget || _depthTarget.width != sw || _depthTarget.height != sh) {

                var format = THREE.FloatType;
                if (av.isMobileDevice()) {
                    format = THREE.HalfFloatType;
                }

                _depthTarget = new THREE.WebGLRenderTarget(sw, sh,
                    { minFilter: THREE.NearestFilter,
                        magFilter: THREE.NearestFilter,
                        format: _renderTargetFormat,
                        type: format,
                        stencilBuffer: false});
                _depthTarget.shareDepthFrom = _colorTarget;

                //SSAO depth/normals mip maps. Those are "manually" created
                //because we use custom sampling. Also, they are separately bound into
                //the shader because there doesn't seem to be an easy way to load them
                //as mip levels of the same texture, in the case they were render buffers initially.
                _depthMipMap = [];
                for (var j = 0; j < 5; j++) {
                    var mip = new THREE.WebGLRenderTarget(0 | (sw / (2 << j)), 0 | (sh / (2 << j)),
                        {   minFilter: THREE.NearestFilter,
                            magFilter: THREE.NearestFilter,
                            format: THREE.RGBAFormat,
                            //type:THREE.FloatType,
                            depthBuffer: false,
                            stencilBuffer: false});
                    mip.generateMipmaps = false;
                    _depthMipMap.push(mip);
                    _saoPass.uniforms['tDepth_mip' + (j + 1)].value = mip;
                }

                //Re-check this when render targets change
                _mrtFloat32Works = _renderer.verifyMRTWorks([_colorTarget, _depthTarget]);

                //We only need a second post target if SAO is on.
                _postTarget2 = _postTarget1.clone();
            }

            if (!_postTarget2 && _settings.antialias && _settings.customPresentPass)
                _postTarget2 = _postTarget1.clone();

            _saoPass.uniforms[ 'size' ].value.set(sw, sh);
            _saoPass.uniforms[ 'resolution' ].value.set(resX, resY);
            _saoPass.uniforms[ 'tDepth' ].value = _depthTarget;

            _saoBlurPass.uniforms[ 'size' ].value.set(sw, sh);
            _saoBlurPass.uniforms[ 'resolution' ].value.set(resX, resY);

            _celPass.uniforms['tDepth'].value = _depthTarget;
        }

        if (_settings.idbuffer) {
            if (force || !_idTargets[0] || _idTargets[0].width != sw || _idTargets[0].height != sh) {
                _idTargets = [];
                for (var i=0; i<_settings.numIdTargets; i++) {
                    _idTargets[i] = new THREE.WebGLRenderTarget(sw, sh,
                        {   minFilter: THREE.NearestFilter,
                            magFilter: THREE.NearestFilter,
                            format: THREE.RGBFormat,
                            type: THREE.UnsignedByteType,
                            stencilBuffer: false
                        });
                    _idTargets[i].generateMipmaps = false; 

                    _idTargets[i].shareDepthFrom = _colorTarget;

                    //Set this flag to avoid checking frame buffer status every time we read
                    //a pixel from the ID buffer. We know the ID target is compatible with readPixels.
                    _idTargets[i].canReadPixels = true;
                }

                //Re-check this when render targets change
                _mrtRGBA8Works = _renderer.verifyMRTWorks([_colorTarget].concat(_idTargets));
                if (!_mrtRGBA8Works) {
                    avp.logger.warn("ID buffer requested, but MRT is not supported. Some features will not work.");
                }
            }

            _celPass.uniforms['tID'].value = _idTargets[0];

        } else if (_idTargets[0]) {
            for (var i=0; i<_idTargets.length; i++) {
                _idTargets[i].dispose();
                _idTargets[i] = null;
            }
        }


        _fxaaPass.uniforms[ 'uResolution' ].value.set(resX, resY);
        _celPass.uniforms[ 'resolution' ].value.set(resX, resY);

        _blendPass.uniforms[ 'tOverlay' ].value = _overlayTarget;
        _blendPass.uniforms[ 'tAO' ].value = _postTarget2;
        _blendPass.uniforms[ 'useAO' ].value = _settings.sao ? 1 : 0;
        _blendPass.uniforms[ 'resolution' ].value.set(resX, resY);
        _blendPass.uniforms[ 'tID' ].value = _idTargets[0];

    };

    this.getMaxAnisotropy = function () {
        return _renderer.getMaxAnisotropy();
    };

    // HACK: returns MRT flags required by this render context
    // so that the flags can be passed to the material manager
    this.mrtFlags = function() {
        return {
            mrtNormals: _mrtFloat32Works && (_settings.sao || _settings.toonShaded),
            mrtIdBuffer: (_mrtRGBA8Works && _settings.idbuffer) ? _settings.numIdTargets : undefined
        };
    };

    this.getAntialiasing = function () {
       return _settings.antialias;
    }

    this.initPostPipeline = function (useSAO, useFXAA) {

        //TODO: Do we want to move the IE check to higher level code?
        _settings.sao = useSAO && !av.isIE11;
        _settings.antialias = useFXAA && !av.isIE11;

        if (_settings.sao)
            _settings.toonShaded = false;

        if (_settings.haveTwoSided) {
            forEachDepthMaterial(function(mat){
                mat.side = THREE.DoubleSide;
            });
        }

        //TODO: do we really need to update all these or just the depthMaterial?
        forEachDepthMaterial(function(mat) {
            mat.needsUpdate = true;
        });
        _saoPass.material.needsUpdate = true;
        _saoBlurPass.material.needsUpdate = true;
        _saoMipFirstPass.material.needsUpdate = true;
        _saoMipPass.material.needsUpdate = true;
        _fxaaPass.material.needsUpdate = true;
        _celPass.material.needsUpdate = true;
        _blendPass.material.needsUpdate = true;
        _clearPass.material.needsUpdate = true;
        _copyPass.material.needsUpdate = true;

        //Also reallocate the render targets
        this.setSize(_w, _h);
    };

    this.setClearColors = function (colorTop, colorBot) {
        if (!colorBot) {
            _clearColor = colorTop.clone();
        }
        //If the gradient is trivial, we can use a simple clear instead.
        else if (colorTop.equals(colorBot) || _isWeakDevice) {
            _clearColor = new THREE.Color(
                0.5 * (colorTop.x + colorBot.x),
                0.5 * (colorTop.y + colorBot.y),
                0.5 * (colorTop.z + colorBot.z));
        } else {
            _clearColor = undefined;
        }

        if (!_clearColor) {
            _clearPass.uniforms.color1.value.copy(colorTop);
            _clearPass.uniforms.color2.value.copy(colorBot);
        }
    };


    this.setAOEnabled = function(enabled) {
        _settings.sao = enabled;
    };

    this.setAOOptions = function (radius, intensity) {
        
        if (radius !== undefined) {
            _saoPass.uniforms[ 'radius' ].value = radius;
            _saoPass.uniforms[ 'bias' ].value = radius * av.isMobileDevice() ? 0.1 : 0.01;
            _saoBlurPass.uniforms[ 'radius' ].value = radius;
        }
        if (intensity !== undefined) {
            _saoPass.uniforms[ 'intensity' ].value = intensity;
        }
        _saoBufferValid = false;
    };

    this.getAOEnabled = function() {
        return _settings.sao;
    };

    this.getAORadius = function () {
        return _saoPass.uniforms['radius'].value;
    };

    this.getAOIntensity = function() {
        return _saoPass.uniforms['intensity'].value;
    };

    this.setCubeMap = function(map) {
        _clearPass.material.envMap = map;
    };

    this.setEnvRotation = function(rotation) {
        _envRotation = rotation;
        _clearPass.material.envRotationSin = Math.sin(rotation);
        _clearPass.material.envRotationCos = Math.cos(rotation);
    };

    this.getEnvRotation = function() {
        return _envRotation;
    };

    this.setEnvExposure = function(exposure) {
        _clearPass.uniforms['envMapExposure'].value = Math.pow(2.0, exposure);

        //The renderer overwrites the uniform's value based on the material's
        //property in refreshUniformsIBL, so set it there too.
        _clearPass.material.envMapExposure = Math.pow(2.0, exposure);
        _clearPass.material.needsUpdate = true;
    };

    this.setTonemapExposureBias = function (bias) {
        _exposureBias = bias;

        _clearPass.uniforms['exposureBias'].value = Math.pow(2.0, bias);

        //_blendPass.uniforms['exposureBias'].value = Math.pow(2.0, bias);
    };

    this.getExposureBias = function () {
        return _exposureBias;
    };

    //Required for switching camera for stereo rendering
    this.setCamera = function (camera) {
        _camera = camera;
    }

    this.setTonemapMethod = function (value) {

        _tonemapMethod  = value;

        if (value === 0) {
        /*
            if (_settings.useHdrTarget) {
                //reallocate the render target if we are going from hdr to ldr
                _settings.useHdrTarget = false;
                this.setSize(_w, _h, true);
            }
            */
            _renderer.gammaInput = false;
        }
        else {
        /*
            if (!_settings.useHdrTarget) {
                //reallocate the render target if we are going from hdr to ldr
                _settings.useHdrTarget = true;
                this.setSize(_w, _h, true);
            }
        */
            //Tell the renderer to linearize all material colors
            _renderer.gammaInput = true;
        }

        _clearPass.material.tonemapOutput = _tonemapMethod;
        _clearPass.material.needsUpdate = true;

        // _blendPass.uniforms['toneMapMethod'].value = value;

    };

    this.getToneMapMethod = function () {
        return _tonemapMethod;
    };

    this.toggleTwoSided = function (isTwoSided) {

        //In case the viewer encounters two-sided materials
        //it will let us know, so that we can update
        //the override material used for the SAO G-buffer to also
        //render two sided.
        if (_settings.haveTwoSided != isTwoSided) {
            if (_depthMaterial) {
                forEachDepthMaterial(function(mat) {
                    mat.side = isTwoSided ? THREE.DoubleSide : THREE.FrontSide;
                    mat.needsUpdate = true;
                });
            }
        }
        _settings.haveTwoSided = isTwoSided;
    };

    this.toggleCelShading = function (value) {

        // This is a little odd: if cel shading is turned off, SAO is then turned on.
        // The assumption here is that SAO being on is the norm. Since cel shading is
        // experimental and not exposed in the normal UI, this is fine for now.
        _settings.sao = !value;
        _settings.toonShaded = value;
        _settings.idbuffer = value;

        this.initPostPipeline(_settings.sao, _settings.antialias);
    };

    this.toggleEnvMapBackground = function (value) {

        _settings.envMapBg = value;
        _clearPass.uniforms.envMapBackground.value = value;
    };

    this.toggleSwapBlackAndWhite = function (value) {

        _settings.swapBlackAndWhite = value;
    };

    this.enter2DMode = function(idMaterial) {
        _idMaterial = idMaterial;
        _oldSettings.sao = _settings.sao;
        _oldSettings.toonShaded = _settings.toonShaded;
        _oldSettings.antialias = _settings.antialias;
        _oldSettings.idbuffer = _settings.idbuffer;
        _settings.idbuffer = true;
        _settings.toonShaded = false;
        _blendPass.material.defines.IS_2D = "";
        this.initPostPipeline(false, false);
    };

    this.exit2DMode = function() {
        _idMaterial = null;
        _settings.idbuffer = _oldSettings.idbuffer;
        _settings.toonShaded = _oldSettings.toonShaded;
        delete _blendPass.material.defines.IS_2D;
        this.initPostPipeline(_oldSettings.sao, _oldSettings.antialias);
    };

    //Returns the value of the ID buffer at the given
    //viewport location. Note that the viewport location is in
    //OpenGL-style coordinates [-1, 1] range.
    //If the optional third parameter is passed in, it's assume to be a two integer array-like,
    //and the extended result of the hit test (including model ID) is stored in it.
    this.idAtPixel = function (vpx, vpy, res) {
        if (!_idTargets[0])
            return 0;

        var px = 0 | ((vpx + 1.0) * 0.5 * _idTargets[0].width);
        var py = 0 | ((vpy + 1.0) * 0.5 * _idTargets[0].height);

        if (_lastIDValid && px === _lastX && py === _lastY) {
            if (res) {
                res[0] = _lastID;
                res[1] = _lastModelID;
            }
            return _lastID;
        }

        _renderer.readRenderTargetPixels(_idTargets[0], px, py, 1, 1, _readbackBuffer);

        var id =  (_readbackBuffer[2] << 16) | (_readbackBuffer[1] << 8) | _readbackBuffer[0];
        var modelId = 0;

        if (_idTargets[1]) {
            _renderer.readRenderTargetPixels(_idTargets[1], px, py, 1, 1, _readbackBuffer);

            modelId = (_readbackBuffer[1] << 8) | _readbackBuffer[0];

            //recover negative values when going from 16 -> 32 bits.
            modelId = (modelId << 16) >> 16;

            //Upper byte of 32 bit dbId encoded in the 3rd byte of the model ID target.
            //id = id | (_readbackBuffer[2] << 24);
            //TODO: ouch, the above does not work for 2d sheets, because each mesh contains many objects.
            //Do something about it...
            id = (id << 8) >> 8;

        } else {
            //sign extend the upper byte to get back negative numbers (since we clamp 32 bit to 24 bit when rendering ids)
            id = (id << 8) >> 8;
        }

        _lastX = px;
        _lastY = py;
        _lastID = id;
        _lastModelID = modelId;
        _lastIDValid = true;

        if (res) {
            res[0] = id;
            res[1] = modelId;
        }

        return id;
    };

    this.idAtPixels = function (vpx, vpy, res, result) {
        if (!_idTargets[0])
            return 0;

        var px = (vpx + 1.0) * 0.5 * _idTargets[0].width - (res - 1) * 0.5;
        var py = (vpy + 1.0) * 0.5 * _idTargets[0].height - (res - 1) * 0.5;

        var readbackBuffer = new Uint8Array(4 * res * res);

        _renderer.readRenderTargetPixels(_idTargets[0], px, py, res, res, readbackBuffer);

        var readbackBuffer2 = undefined;
        if(result && _idTargets[1]) {
            readbackBuffer2 = new Uint8Array(4 * res * res);
            _renderer.readRenderTargetPixels(_idTargets[1], px, py, res, res, readbackBuffer2);
        }
        // Start the search at the center of the region and then spiral.
        function spiral() {

            var id;
            var x = 0, y = 0;
            var dx = 0, dy = -1;

            for (var i = 0; i < res * res; i++) {

                // Translate coordinates with top left as (0, 0)
                var tx = x + (res - 1) / 2;
                var ty = y + (res - 1) / 2;
                if (tx >= 0 && tx <= res && ty >= 0 && ty <= res) {
                    var index = tx + ty * res;
                    id = (readbackBuffer[4 * index + 2] << 16) | (readbackBuffer[4 * index + 1] << 8) | readbackBuffer[4 * index];

                    //sign extend the upper byte to get back negative numbers (since we clamp 32 bit to 24 bit when rendering ids)
                    id = (id << 8) >> 8;
                    if (id >= 0) {
                        if(readbackBuffer2) {
                            var modelId = (readbackBuffer2[4 * index + 1] << 8) | readbackBuffer2[4 * index];
                            //recover negative values when going from 16 -> 32 bits.
                            modelId = (modelId << 16) >> 16;

                            result[0] = id;
                            result[1] = modelId;
                        }
                        break;
                    }
                }

                if ( (x == y) || (x < 0 && x == -y) || (x > 0 && x == 1-y) ) {
                    var t = dx;
                    dx = -dy;
                    dy = t;
                }
                x += dx;
                y += dy;
            }

            return id;
        }

        return spiral();

    };

    this.readbackTargetId = function() {
        if (!_idTargets[0])
            return null;

        var readbackBuffer = new Uint8Array(4 * _idTargets[0].width * _idTargets[0].height);
        _renderer.readRenderTargetPixels(_idTargets[0], 0, 0, _idTargets[0].width, _idTargets[0].height, readbackBuffer);

        return {
            buffer: readbackBuffer,
            width: _idTargets[0].width,
            height: _idTargets[0].height
        };
    };

    /**
     * @private
     * Shows the content of a render target in a new browser window.
     * Check to make sure your popup blocker is not blocking the local host.
     * For debugging purposes only. Typical console command to dump target
     * to a new browser window:
     * NOP_VIEWER.impl.renderer().getRenderTargetPixels('color')
     *
     * @param targetName {string} Name of render target.
     *      Can be 'color', 'overlay', 'id', 'post1' or 'post2'.
     */
     /*
    this.getRenderTargetPixels = function(targetName) {
        var target;
        switch (targetName) {
            case 'color': target = _colorTarget; break;
            case 'overlay': target = _overlayTarget; break;
            case 'id': target = _idTargets[0]; break;
            case 'post1': target = _postTarget1; break;
            case 'post2': target = _postTarget2; break;
        }

        if (!target) {
            console.error('unknown target name');
        } else {
            var buffer = new Uint8Array(4 * target.width * target.height);
            _renderer.readRenderTargetPixels(target, 0, 0, target.width, target.height, buffer);
            var imgdata = new ImageData(new Uint8ClampedArray(buffer), target.width, target.height);
            var canvas = document.createElement('canvas');
            canvas.width = target.width;
            canvas.height = target.height;
            var context = canvas.getContext('2d');
            context.putImageData(imgdata, 0, 0);
            window.open(canvas.toDataURL());
        }
    };
    */

    this.rolloverObjectViewport = function (vpx, vpy, dbIds) {
        var objId = dbIds ? dbIds[0] : this.idAtPixel(vpx, vpy);
        return this.rolloverObjectId(objId, dbIds);
    };

    this.rolloverObjectId = function(objId, dbIds, modelId) {

        modelId = modelId || 0;

        if (objId === _lastHighlightId && modelId === _lastHighlightModelId)
            return false;

        _blendPass.uniforms['highlightIntensity'].value = 0;
        _blendPass.uniforms['objID'].value = objId;

        _lastObjTime = performance.now();

        _lastHighlightId = objId;
        _lastHighlightModelId = modelId;

        // When dbIds is provided, highlight nodes in a range
        if (dbIds) {

            if (dbIds.length > 1)
                dbIds.shift();
            _blendPass.uniforms['highlightRange'].value = 1;
            _blendPass.uniforms['objIDStart'].value = dbIds[0];
            _blendPass.uniforms['objIDEnd'].value = dbIds[dbIds.length - 1];
        }
        else {

            _blendPass.uniforms['highlightRange'].value = 0;

            //Check if nothing was at that pixel -- 0 means object
            //that has no ID, ffffff (-1) means background, and both result
            //in no highlight.
            if (objId <= 0) {
                objId = 0;
            }

            _blendPass.uniforms['objIDv3'].value.set((objId & 0xFF) / 255,
                                                    ((objId >> 8) & 0xFF) / 255,
                                                    ((objId >> 16) & 0xFF) / 255);
        }

        return true;
    };

    this.setUnitScale = function(metersPerUnit) {
        _unitScale = metersPerUnit;
    };

    this.getUnitScale = function() {
        return _unitScale;
    };

    this.getBlendPass = function() {
        return _blendPass;
    };

    this.getClearPass = function() {
        return _clearPass;
    };

    // TODO_NOP: hack expose colorTarget so shadow/reflection can draw into
    this.getColorTarget = function() {
        return _colorTarget;
    };

    // TODO_NOP: hack expose depthMaterial to register with matman for cutplanes
    this.getDepthMaterial = function() {
        return _depthMaterial;
    };
}

avp.RenderContext = RenderContext;

})();
;

(function() {

'use strict';

var av = Autodesk.Viewing,
    avp = Autodesk.Viewing.Private,
    lmv = Autodesk.LMVTK;

avp.DefaultLightPreset = 1; // "Sharp Highlights"
avp.DefaultLightPreset2d = 0;   // "Simple Grey"

avp.ModelSettingsEnvironment = null; // env. settings provided by the last call to setLightPresetFromFile

    avp.BackgroundPresets = {
        "Fusion Grey":      [230, 230, 230, 150, 150, 150],
        "Sky Blue":         [226, 244, 255, 156, 172, 180],
        "Snow":             [181, 186, 199, 181, 186, 199],
        "Midnight":         [ 41,  76, 120,   1,   2,   3],
        "White":            [255, 255, 255, 255, 255, 255],
        "AutoCADModel":     [ 30,  40,  48,  30,  40,  48],
        "Dark Grey":        [ 51,  51,  51,  51,  51,  51],
        "Dark Sky":         [ 51,  51,  51,  51,  51,  51],
        "Infinity Pool":    [255, 255, 255, 255, 255, 255],
        "Tranquility":      [  0,  84, 166,   0,  84, 166],
        "Grey Room":        [129, 129, 129, 129, 129, 129],
        "Photo Booth":      [237, 237, 237, 237, 237, 237],
        "RaaS SBS":         [  1,   1,   1,  90,  90,  90],
        "Plaza":            [ 79, 102, 130,  79, 102, 130],

        //This will get modified when the user changes the background
        //using the color picker.
        "Custom":           [230, 230, 230, 150, 150, 150]
    };

    var bg = avp.BackgroundPresets;

    avp.LightPresets = [
        //Notes: tonemap = which tone map method to use. Any tonemap method other than zero will cause colors to be linearized before use.
        //              0 = None, 1 = Prism Cannon-Lum (color preserving), 2 = OGC Cannon RGB (non-color preserving)
        //       exposure = exponential bias to use as pre-tonemap multiplier for all rendered colors, including background
        //       lightMultiplier = linear scale of direct light intensity (diffuse only, not ambient)
        //       bgColorGradient = which background color preset to use as default for the environment map
        //       illuminance     = cosine-weighted integral of the upper-hemisphere (i.e., actual lux)

        //Image-based lighting from RaaS. Initial exposure is empirically obtained.
        //These do not normally require any extra lights, because they have the lights fully baked into
        //the environment maps.

        //Simple ***non-HDR*** environment.
        {
            name: "Simple Grey",    // localized in viewer-environments.loc.json
            path:null,
            tonemap:0,
            E_bias:0,
            directLightColor: [1.0, 0.84, 0.67],
            ambientColor:     [0.8*0.25, 0.9*0.25,  1.0*0.25],
            lightMultiplier: 1.0,
            bgColorGradient: bg["Fusion Grey"],
            darkerFade: false,
            rotation: 0.0
        },

        //Fusion Environments which require extra lights

        // The E_bias value for the Fusion render-space environments is setup such that
        // the default values match the preset values of brightness (in lux) and EV.
        // The EV value from Fusion follows the Canon standard for luminance and middle-gray
        // https://en.wikipedia.org/wiki/Exposure_value#EV_as_a_measure_of_luminance_and_illuminance [September 2015]
        //
        // Rationale (using the canon tonemap as a guide, based on documentation by Adam Arbree):
        // 1. BaseExposure (B) in the canon tonemap is the negative log2 luminance of the
        //    white point (W) so B = -log2(W)
        // 2. To match the target illuminance from Fusion, the environment needs
        //    to be scaled by the ratio between the target and its actual illuminance, thus
        //    S = target_illuminance / actual_illuminance
        // 3. Then by the definition of middle grey W = L / (0.18*S) where L is the middle grey
        //    luminance and 0.18 is the standard reflection of middle grey.
        // 4. As per the Wikipedia entry, we have L = 2^(EV-3)
        // 5. Putting this all together we have
        //      B = -log2( 2^(EV-3) / (0.18*S))
        //        = log2(0.18) + log2(S) – (EV – 3)
        //        = (3+log2(0.18)) – EV + log2(S)
        //        = 0.526069 – EV + log2(S)

        {
            name: "Sharp Highlights",    // localized in viewer-environments.loc.json
            path:"SharpHighlights",
            type:"logluv",
            tonemap:1,
            // illuminance currently is not used elsewhere in LMV, its effect is folded into E_bias.
            //illuminance: 1000.0,
            E_bias:-9.0, // EV 9.526, 1000.0 lux (target)
            directLightColor: [0.5,0.5,0.5],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.0,
            lightDirection: [0.5, -0.2, -0.06],
            bgColorGradient: bg["Photo Booth"],
            darkerFade: true,
            rotation: 0.0
        },

        {
            name: "Dark Sky",     // "Dark Sky", localized in viewer-environments.loc.json
            path:"DarkSky",
            type:"logluv",
            tonemap:1,
            E_bias:-1,
            directLightColor: [1,1,1],
            ambientColor: [0.25/8,0.25/8,0.25/8], //0.25 with gain of 0.125
            lightMultiplier: 1.0,
            lightDirection: [0.1, -0.55, -1.0],
            bgColorGradient: bg["Dark Sky"],
            darkerFade: false,
            rotation: 0.0
        },

        {
            name: "Grey Room",    // "Grey Room", localized in viewer-environments.loc.json
            path:"GreyRoom",
            type:"logluv",
            tonemap:1,
            E_bias:-1,
            directLightColor: [1,1,1],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.5,
            lightDirection: [0.1, -0.55, -1.0],
            bgColorGradient: bg["Grey Room"],
            darkerFade: true,
            rotation: 0.0
        },

        {
            name: "Photo Booth",     // "Photo Booth", localized in viewer-environments.loc.json
            path:"PhotoBooth",
            type:"logluv",
            tonemap:1,
            E_bias:0,
            directLightColor: [1,1,1],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.5,
            lightDirection: [0.1, -0.55, -1.0],
            bgColorGradient: bg["Photo Booth"],
            darkerFade: true,
            rotation: 0.0
        },

        {
            name: "Tranquility",     // "Tranquility", localized in viewer-environments.loc.json
            path:"TranquilityBlue",
            type:"logluv",
            tonemap:1,
            E_bias:-1,
            directLightColor: [1,1,1],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.5,
            lightDirection: [0.1, -0.55, -1.0],
            bgColorGradient: bg["Tranquility"],
            darkerFade: false,
            rotation: 0.0
        },

        {
            name: "Infinity Pool",     // "Infinity Pool", localized in viewer-environments.loc.json
            path: "InfinityPool",
            type:"logluv",
            tonemap:1,
            E_bias:-1,
            directLightColor: [1.0, 0.84, 0.67],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.5,
            lightDirection: [0.1, -0.55, -1.0],
            bgColorGradient: bg["Infinity Pool"],
            darkerFade: false,
            rotation: 0.0
        },

        // Non fusion environments

        //White background, no HDR -- for cases like SIM360 models
        {
            name: "Simple White",     //"Simple White", localized in viewer-environments.loc.json
            path:null,
            tonemap:0,
            E_bias:0,
            directLightColor: [1,1,1],
            ambientColor: [0.25, 0.25, 0.25],
            lightMultiplier: 1.0,
            bgColorGradient: bg["White"],
            saoRadius: 0.06,
            saoIntensity: 0.15,
            darkerFade: true,
            rotation: 0.0
        },
/*
        {
            name: "Simple Black",
            path:null,
            tonemap:0,
            E_bias:0,
            directLightColor: [1.0, 0.84, 0.67],
            ambientColor:     [0.8, 0.9,  1.0],
            lightMultiplier: 1.0,
            bgColorGradient: bg["AutoCADModel"],
            darkerFade: false
        },
  */
        //RaaS environments
        {
            name: "Riverbank",     // "Riverbank", localized in viewer-environments.loc.json
            path:"riverbank",
            type:"logluv",
            tonemap:1,
            E_bias:-5.7,
            directLightColor: [1,1,1],
            lightMultiplier: 0.0,
            bgColorGradient: bg["Sky Blue"],
            darkerFade: false,
            rotation: 0.0
        },

        {
            name: "Contrast",     // "Contrast", localized in viewer-environments.loc.json
            path:"IDViz",
            type:"logluv",
            tonemap:1,
            E_bias:0,
            directLightColor: [1,1,1],
            lightMultiplier: 0.0,
            bgColorGradient: bg["Midnight"],
            darkerFade: false,
            rotation: 0.0
        },

        {
            name: "Rim Highlights",     //  localized in viewer-environments.loc.json
            path:"RimHighlights",
            type:"logluv",
            tonemap:1,
            //illuminance: 1000.0,
            E_bias:-9.0, // EV 9.526, 1000.0 lux (target)
            directLightColor: [0.5,0.5,0.5],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.0,
            lightDirection: [0.35, -0.35, -0.5],
            bgColorGradient: bg["Photo Booth"],
            darkerFade: true,
            rotation: 0.0
        },
        {
            name: "Cool Light",     // "Cool Light", localized in viewer-environments.loc.json
            path:"CoolLight",
            type:"logluv",
            tonemap:1,
            //illuminance: 1000.0,
            E_bias:-9.0, // EV 9.526, 1000.0 lux (target)
            directLightColor: [1,1,1],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.0,
            lightDirection: [-0.0, -0.15, -0.5],
            bgColorGradient: bg["Fusion Grey"],
            darkerFade: true,
            rotation: 0.0
        },

        {
            name: "Warm Light",     // "Warm Light", localized in viewer-environments.loc.json
            path:"WarmLight",
            type:"logluv",
            tonemap:1,
            //illuminance: 1000.0,
            E_bias:-9.0, // EV 9.526, 1000.0 lux (target)
            directLightColor: [1,1,1],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.0,
            lightDirection: [-0.0, -0.15, -0.5],
            bgColorGradient: bg["Fusion Grey"],
            darkerFade: true,
            rotation: 0.0
        },

        {
            name: "Soft Light",     // "Soft Light", localized in viewer-environments.loc.json
            path:"SoftLight",
            type:"logluv",
            tonemap:1,
            //illuminance: 1000.0,
            E_bias:-9.0, // EV 9.526, 1000.0 lux (target)
            directLightColor: [1,1,1],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.0,
            lightDirection: [-0.5, -0.5, 0.0],
            bgColorGradient: bg["Fusion Grey"],
            darkerFade: true,
            rotation: 0.0
        },

        {
            name: "Grid Light",     // "Grid Light", localized in viewer-environments.loc.json
            path:"GridLight",
            type:"logluv",
            tonemap:1,
            //illuminance: 1000.0,
            E_bias:-9.0, // EV 9.526, 1000.0 lux (target)
            directLightColor: [1,1,1],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.0,
            lightDirection: [-0.5, -0.6, 0.0],
            bgColorGradient: bg["Fusion Grey"],
            darkerFade: true,
            rotation: 0.0
        },

        {
            name: "Plaza",             //  "Plaza", localized in viewer-environments.loc.json
            path:"Plaza",
            type:"logluv",
            tonemap:1,
            //illuminance: 24157.736,
            E_bias: -14.0, // FIXME: EV 14.526, 50000.0 lux in the GUI, yet it does not seem to use illuminance
            directLightColor: [0.9, 0.9, 1],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.0, //8000.0, Turned off -- until we support world space light positioning.
            lightDirection: [-0.2, -0.18, 0.72],
            bgColorGradient: bg["Plaza"],
            darkerFade: false,
            rotation: 0.0
        },

        {
            name: "Snow Field",            //  "Snow Field", localized in viewer-environments.loc.json
            path:"SnowField",
            type:"logluv",
            tonemap:1,
            //illuminance: 4302.7773,
            E_bias: -10.461343,  // EV 14.526, 50000.0 lux (target)
            directLightColor: [1,1,1],
            ambientColor: [0.25/8,0.25/8,0.25/8],
            lightMultiplier: 0.0, //800.0, Turned off -- until we support world space light positioning.
            lightDirection: [0.0, -1.0, 0.0],
            bgColorGradient: bg["Snow"],
            darkerFade: false,
            rotation: 0.0
        }
    ];

    avp.DebugEnvironments = [
             //More RaaS ones

            {
                name: "Field",            //  "Field", localized in viewer-environments.loc.json
                path:"field",
                type:"logluv",
                tonemap:1,
                E_bias:-2.9,
                directLightColor: [1,1,1],
                lightMultiplier: 0.0,
                bgColorGradient: bg["Sky Blue"],
                darkerFade: false,
                rotation: 0.0
            },
            {
                name: "Crossroads",         //  "Crossroads", localized in viewer-environments.loc.json
                path:"crossroads",
                type:"logluv",
                tonemap:1,
                E_bias:-5.5,
                directLightColor: [1,1,1],
                lightMultiplier: 0.0,
                bgColorGradient: bg["Sky Blue"],
                darkerFade: false,
                rotation: 0.0
            },

            {
                name: "Seaport",            //  "Seaport", localized in viewer-environments.loc.json
                path:"seaport",
                type:"logluv",
                tonemap:1,
                E_bias:-6.5,
                directLightColor: [1,1,1],
                lightMultiplier: 0.0,
                bgColorGradient: bg["Sky Blue"],
                darkerFade: false,
                rotation: 0.0
            },

            {
                name: "Glacier",            //  "Glacier", localized in viewer-environments.loc.json
                path:"glacier",
                type:"logluv",
                tonemap:1,
                E_bias:0,
                directLightColor: [1,1,1],
                lightMultiplier: 0.0,
                bgColorGradient: bg["Midnight"],
                darkerFade: false,
                rotation: 0.0
            },

            {
                name: "Boardwalk",           //  "Boardwalk", localized in viewer-environments.loc.json
                path:"boardwalk",
                type:"logluv",
                tonemap:1,
                E_bias:-7.0,
                directLightColor: [1,1,1],
                lightMultiplier: 0.0,
                bgColorGradient: bg["Sky Blue"],
                darkerFade: false,
                rotation: 0.0
            },

            {
                name: "RaaS Test Env",      // localized in viewer-environments.loc.json
                path:"Reflection",
                type:"logluv",
                tonemap:2,
                E_bias:-1.5,
                directLightColor: [1,1,1],
                lightMultiplier: 0.0,
                bgColorGradient: bg["RaaS SBS"],
                darkerFade: false,
                rotation: 0.0
            }
    ];

    if (avp.ENABLE_DEBUG) {
        avp.LightPresets = avp.LightPresets.concat(avp.DebugEnvironments);
    }

    /**
     * Copies properties from a Preset (src) into a user provided preset (env)
     * Ideally, this function is used with avp.ModelSettingsEnvironment
     */
    avp.copyLightPreset = function(src, env) {
        env.name = src.name + " (copy)";
        env.path = src.path;
        env.type = src.type;
        env.tonemap = src.tonemap;
        env.E_bias = src.E_bias;
        env.directLightColor = src.directLightColor;
        env.ambientColor = src.ambientColor;
        env.lightMultiplier = src.lightMultiplier;
        env.bgColorGradient = src.bgColorGradient;
        env.darkerFade = src.darkerFade;
        env.rotation = src.rotation;
    };


    avp.CreateCubeMapFromColors = function(ctop, cbot) {
        var r1 = ctop.x * 255, g1 = ctop.y * 255, b1 = ctop.z * 255,
            r2 = cbot.x * 255, g2 = cbot.y * 255, b2 = cbot.z * 255;

        var pixelsTop = new Uint8Array(16);
        var pixelsBot = new Uint8Array(16);
        var pixelsSide = new Uint8Array(16);

        for (var i=0; i<4; i++) {
            pixelsTop[i*4] = r1;
            pixelsTop[i*4+1] = g1;
            pixelsTop[i*4+2] = b1;
            pixelsTop[i*4+3] = 255;

            pixelsBot[i*4] = r2;
            pixelsBot[i*4+1] = g2;
            pixelsBot[i*4+2] = b2;
            pixelsBot[i*4+3] = 255;

            // was this, which is wild: if (0 | (i / 2)) {
            if ( i > 1 ) {
				// color sides 2 and 3 with the first color
                pixelsSide[i*4] = r1;
                pixelsSide[i*4+1] = g1;
                pixelsSide[i*4+2] = b1;
                pixelsSide[i*4+3] = 255;
            }
            else {
				// color sides 0 and 1 with the second color
                pixelsSide[i*4] = r2;
                pixelsSide[i*4+1] = g2;
                pixelsSide[i*4+2] = b2;
                pixelsSide[i*4+3] = 255;
            }
        }

        var x_neg = new THREE.DataTexture( pixelsSide, 2, 2, THREE.RGBAFormat );
        var x_pos = new THREE.DataTexture( pixelsSide, 2, 2, THREE.RGBAFormat );
        var y_neg = new THREE.DataTexture( pixelsBot, 2, 2, THREE.RGBAFormat );
        var y_pos = new THREE.DataTexture( pixelsTop, 2, 2, THREE.RGBAFormat );
        var z_neg = new THREE.DataTexture( pixelsSide, 2, 2, THREE.RGBAFormat );
        var z_pos = new THREE.DataTexture( pixelsSide, 2, 2, THREE.RGBAFormat );

        var texture = new THREE.Texture(null, THREE.CubeReflectionMapping,
                                        THREE.RepeatWrapping, THREE.RepeatWrapping,
                                        THREE.LinearFilter, THREE.LinearFilter,
                                        //THREE.NearestFilter, THREE.NearestFilter,
                                        THREE.RGBAFormat);
        texture.image = [x_pos, x_neg, y_pos, y_neg, z_pos, z_neg];
        texture.needsUpdate = true;

        return texture;
    };


    var M = [6.0014, -2.7008, -1.7996, -1.3320,  3.1029, -5.7721, 0.3008, -1.0882,  5.6268];

    function LogLuvDecode(dst, src) {

        var Le = src[2] * 255.0 + src[3];
        var Xp_Y_XYZp_y = Math.pow(2.0, (Le - 127.0) / 2.0);
        var Xp_Y_XYZp_z = Xp_Y_XYZp_y / (src[1]);
        var Xp_Y_XYZp_x = (src[0]) * Xp_Y_XYZp_z;

        var r = M[0] * Xp_Y_XYZp_x + M[3] * Xp_Y_XYZp_y + M[6] * Xp_Y_XYZp_z;
        var g = M[1] * Xp_Y_XYZp_x + M[4] * Xp_Y_XYZp_y + M[7] * Xp_Y_XYZp_z;
        var b = M[2] * Xp_Y_XYZp_x + M[5] * Xp_Y_XYZp_y + M[8] * Xp_Y_XYZp_z;

        if (r < 0) r = 0;
        if (g < 0) g = 0;
        if (b < 0) b = 0;

        dst[0] = r;
        dst[1] = g;
        dst[2] = b;
    }

    function RGBMEncode(dst, src, expScale) {

        var r = Math.sqrt(src[0]*expScale)*0.0625; // 1/16 = 0.0625
        var g = Math.sqrt(src[1]*expScale)*0.0625;
        var b = Math.sqrt(src[2]*expScale)*0.0625;

        var maxL = Math.max( Math.max(r, g), Math.max(b, 1e-6));
        if (maxL > 1.0)
            maxL = 1.0;

        var w = Math.ceil( maxL * 255.0 ) / 255.0;

        if (r > 1.0)
            r = 1.0;
        if (g > 1.0)
            g = 1.0;
        if (b > 1.0)
            b = 1.0;

        dst[3] = w;
        var a = 1.0 / w;

        dst[0] = r * a;
        dst[1] = g * a;
        dst[2] = b * a;
    }

    function RGB16Encode(dst, src, expScale) {

        var r = Math.sqrt(src[0]*expScale);
        var g = Math.sqrt(src[1]*expScale);
        var b = Math.sqrt(src[2]*expScale);

        //That's pretty unlikely to happen...
        var MAX_HALF = 65504;
        if (r > MAX_HALF)
            r = MAX_HALF;
        if (g > MAX_HALF)
            g = MAX_HALF;
        if (b > MAX_HALF)
            b = MAX_HALF;

        dst[0] = r;
        dst[1] = g;
        dst[2] = b;

    }


    var tmpSrc = new Float32Array(4);
    var tmpDst = new Float32Array(4);

    //Converts incoming environment cube maps to image format suitable for use by the shader.
    avp.DecodeEnvMap = function(map, exposure, useHalfFloat, callback) {

        if (!map.LogLuv) {
            avp.logger.warn("Environment map expected to be in LogLuv format.");
            return;
        }

        var scale = Math.pow(2.0, exposure);

		// if `map.image` is an array, use it as it is, otherwise create an array with single item (`map.image`) in it
        var images = Array.isArray(map.image) ? map.image : [map.image];

        for (var i=0; i<images.length; i++) {

            var image = images[i];

            for (var j=0; j<image.mipmaps.length; j++) {

                var mipmap = image.mipmaps[j];

                var src = mipmap.data;

                var dst;
                if (useHalfFloat) {
                    //var dst = new Float32Array(src.length / 4 * 3);
                    dst = new Uint16Array(src.length / 4 * 3);
                    mipmap.data = dst;
                }
                else
                    dst = src.buffer;

                var m=0;

                for (var k=0; k<src.length; k+=4) {

                    tmpSrc[0] = src[k] / 255.0;
                    tmpSrc[1] = src[k+1] / 255.0;
                    tmpSrc[2] = src[k+2] / 255.0;
                    tmpSrc[3] = src[k+3] / 255.0;

                    LogLuvDecode(tmpDst, tmpSrc);

                    if (useHalfFloat) {
                        //Use sqrt to gamma-compress the data to help the texture filtering
                        //hardware.
                        RGB16Encode(tmpSrc, tmpDst, scale);
                        dst[m++] = avp.FloatToHalf(tmpSrc[0]);
                        dst[m++] = avp.FloatToHalf(tmpSrc[1]);
                        dst[m++] = avp.FloatToHalf(tmpSrc[2]);
                    } else {
                        //Temporary: decode incoming LogLUV environments and convert them
                        //to RGBM format for use by the shader. Eventually we will use half-float format
                        //instead, but that has to be better tested.
                        RGBMEncode(tmpSrc, tmpDst, scale);

                        src[k] = Math.round(tmpSrc[0] * 255.0);
                        src[k+1] = Math.round(tmpSrc[1] * 255.0);
                        src[k+2] = Math.round(tmpSrc[2] * 255.0);
                        src[k+3] = Math.round(tmpSrc[3] * 255.0);
                    }
                }

            }

        }

        map.LogLuv = false;

        if (useHalfFloat) {
            map.type = THREE.HalfFloatType;
            map.format = THREE.RGBFormat;
            map.RGBM = false;
            map.GammaEncoded = true;
        }
        else
            map.RGBM = true;

        if (callback)
            callback(map);
    };


    //web worker used for image processing, etc.
    avp.imageWorker = null;
    var messageId = 1;

    function getTransferables(map) {

        var res = [];

        // if `map.image` is an array, use it as it is, otherwise create an array with single item (`map.image`) in it
        var images = Array.isArray(map.image) ? map.image : [map.image];

        for (var i=0; i<images.length; i++) {

            var image = images[i];

            for (var j=0; j<image.mipmaps.length; j++) {

                var mipmap = image.mipmaps[j];

                res.push(mipmap.data.buffer);
            }
        }

        return res;
    }

    avp.DecodeEnvMapAsync = function(map, exposure, useHalfFloat, callback) {

        if (!map.LogLuv) {
            avp.logger.warn("Environment map expected to be in LogLuv format.");
            return;
        }

        if (!avp.imageWorker)
            avp.imageWorker = avp.createWorker();

        var id = messageId++;

        var onMessage = function(msg) {

            if (msg.data.id !== id)
                return;

            avp.imageWorker.removeEventListener("message", onMessage);

            var mapWorker = msg.data.map;
            map.image = mapWorker.image;

            map.LogLuv = false;

            if (useHalfFloat) {
                map.type = THREE.HalfFloatType;
                map.format = THREE.RGBFormat;
                map.RGBM = false;
                map.GammaEncoded = true;
            }
            else
                map.RGBM = true;

            callback(map);
        };

        avp.imageWorker.addEventListener("message", onMessage);

        avp.imageWorker.postMessage({
            operation: "DECODE_ENVMAP",
            map: map,
            exposure: exposure,
            useHalfFloat: useHalfFloat,
            id: id
        }, getTransferables(map));
    };


    lmv.doDecodeEnvmap = function(loadContext) {

        avp.DecodeEnvMap(loadContext.map, loadContext.exposure, loadContext.useHalfFloat);

        self.postMessage({ map: loadContext.map, id: loadContext.id }, getTransferables(loadContext.map));
    };

})();
;

(function() {
	'use strict';

var av = Autodesk.Viewing,
    avp = av.Private;

avp.init_UnifiedCamera = function(THREE) {

if (typeof av.UnifiedCamera !== "undefined")
    return;

var UnifiedCamera = function ( clientWidth, clientHeight)
{
    THREE.Camera.call( this );

    this.fov = 45;
    this.near = 0.1;
    this.far = 100000;
    this.aspect = clientWidth / clientHeight;

    this.left = -clientWidth / 2;
    this.right = clientWidth / 2;
    this.top = clientHeight / 2;
    this.bottom = -clientHeight / 2;
    this.clientWidth = clientWidth;
    this.clientHeight = clientHeight;

    this.target  = new THREE.Vector3(0, 0, -1);
    this.worldup = new THREE.Vector3(0, 1, 0);

    this.orthographicCamera = new THREE.OrthographicCamera( this.left, this.right, this.top, this.bottom,  this.near, this.far );
    this.perspectiveCamera = new THREE.PerspectiveCamera( this.fov, this.aspect, this.near, this.far);

    this.zoom = 1;

    this.toPerspective();
};

//Constant FOV used to make math right for Ortho cameras.
UnifiedCamera.ORTHO_FOV = (2 * Math.atan(0.5)) * 180.0 / Math.PI;

UnifiedCamera.prototype = Object.create( THREE.Camera.prototype );

UnifiedCamera.prototype.clone = function ()
{
	var camera = new UnifiedCamera(this.right * 2.0, this.top * 2.0);

	THREE.Camera.prototype.clone.call( this, camera );

    camera.position.copy(this.position);
    camera.up.copy(this.up);
    if( this.target )
        camera.target = this.target.clone();
    if( this.worldup )
        camera.worldup = this.worldup.clone();
    if( this.worldUpTransform )
        camera.worldUpTransform = this.worldUpTransform.clone();

	camera.left = this.left;
	camera.right = this.right;
	camera.top = this.top;
	camera.bottom = this.bottom;

	camera.near = this.near;
	camera.far = this.far;
    camera.fov = this.fov;
    camera.aspect = this.aspect;
    camera.zoom = this.zoom;

    camera.isPerspective = this.isPerspective;

    this.updateProjectionMatrix();

	return camera;
};

UnifiedCamera.prototype.__computeFovPosition = function(fov)
{
    if( Math.abs(this.fov - fov)  <= 0.0001 )
        return this.position.clone();

    var eye = this.target.clone().sub( this.position );

    var oldFOV = THREE.Math.degToRad(this.fov);
    var newFOV = THREE.Math.degToRad(fov);

    var distance = eye.length() * Math.tan(oldFOV * 0.5) / Math.tan(newFOV * 0.5);
    var offset = eye.normalize().multiplyScalar( -distance );

    return this.target.clone().add(offset);
};

UnifiedCamera.prototype.toPerspective = function()
{
    // Switches to the Perspective Camera

    if( !this.isPerspective && this.saveFov ) {
        this.position.copy(this.__computeFovPosition(this.saveFov));
        this.fov = this.saveFov;
    }

    this.perspectiveCamera.aspect = this.aspect;
    this.perspectiveCamera.near = this.near;
    this.perspectiveCamera.far = this.far;

    this.perspectiveCamera.fov = this.fov / this.zoom ;
    this.perspectiveCamera.updateProjectionMatrix();

    this.projectionMatrix = this.perspectiveCamera.projectionMatrix;

    this.isPerspective = true;
};

UnifiedCamera.prototype.toOrthographic = function()
{
    if( this.isPerspective ) {
        this.saveFov = this.fov;
        var newFov = UnifiedCamera.ORTHO_FOV;
        this.position.copy(this.__computeFovPosition(newFov));
        this.fov = newFov;
    }

    this.orthoScale = this.target.clone().sub(this.position).length();

    var halfHeight = this.orthoScale * 0.5;
    var halfWidth = halfHeight * this.aspect;

    this.left   = this.orthographicCamera.left   = -halfWidth;
    this.right  = this.orthographicCamera.right  =  halfWidth;
    this.top    = this.orthographicCamera.top    =  halfHeight;
    this.bottom = this.orthographicCamera.bottom = -halfHeight;

    this.orthographicCamera.near = this.near;
    this.orthographicCamera.far = this.far;

    this.orthographicCamera.updateProjectionMatrix();

    this.projectionMatrix = this.orthographicCamera.projectionMatrix;

    this.isPerspective = false;
};

UnifiedCamera.prototype.updateProjectionMatrix = function()
{
    if ( this.isPerspective ) {
        this.toPerspective();
    } else {
        this.toOrthographic();
    }
};

UnifiedCamera.prototype.setSize = function( width, height )
{
    this.aspect = width / height;
    this.left = -width / 2;
    this.right = width / 2;
    this.top = height / 2;
    this.bottom = -height / 2;

};


UnifiedCamera.prototype.setFov = function( fov )
{
    this.fov = fov;
    this.updateProjectionMatrix();
};

/*
* Uses Focal Length (in mm) to estimate and set FOV
* 35mm (fullframe) camera is used if frame size is not specified;
* Formula based on http://www.bobatkins.com/photography/technical/field_of_view.html
*/
UnifiedCamera.prototype.setLens = function ( focalLength, frameHeight )
{
    if ( frameHeight === undefined ) frameHeight = 24;

    var fov = 2 * THREE.Math.radToDeg( Math.atan( frameHeight / ( focalLength * 2 ) ) );

    this.setFov( fov );

    return fov;
};


UnifiedCamera.prototype.getCameraChangedEvent = function() {
    return {type: av.CAMERA_CHANGE_EVENT, camera: this};
};

av.UnifiedCamera = UnifiedCamera;

}

})();;

(function() {

'use strict';

var av = Autodesk.Viewing,
    avp = av.Private;

function Selector(viewer, model) {

    //Selection support
    var _this = this;
    this.selectedObjectIds = {};
    this.selectionCount = 0;
    this.selectionMode = av.SelectionMode.LEAF_OBJECT;

    var selectedParentMap = {};

    function getInstanceTree() {
        return model.getData().instanceTree;
    }

    function fireSelectionChangedEvent() {
        //Nothing here, events are done by the MultiModelSelector now.
    }


    function unmarkObject(dbId) {

        var it = getInstanceTree();

        if (selectedParentMap[dbId] > 0) {
            selectedParentMap[dbId]--;
            if (selectedParentMap[dbId] == 0) {
                viewer.highlightObjectNode(model, dbId, false);
            }

        } else if (selectedParentMap[dbId] < 0) {
            throw ("Selection State machine broken. Negatively selected object!");
        }

        if (it) {
            it.enumNodeChildren(dbId, function(childId) {
                unmarkObject(childId);
            }, false);
        }
    }
    

    function markObject(dbId, isChild) {

        var it = getInstanceTree();

        if (selectedParentMap[dbId]) {
            selectedParentMap[dbId]++;
        } else {
            viewer.highlightObjectNode(model, dbId, true, isChild);
            selectedParentMap[dbId] = 1;
        }
        
        if (it) {
            it.enumNodeChildren(dbId, function(childId) {
                markObject(childId, true);
            }, false);
        }
    }

    function isSelected(dbId) {

        if ((dbId !== undefined) && _this.selectedObjectIds[dbId])
            return true;
    }


    function select(dbId) {

        var it = getInstanceTree();
        if (it) {
            dbId = it.findNodeForSelection(dbId, _this.selectionMode);

            if (!it.isNodeSelectable(dbId))
                return;
        }

        var found = isSelected(dbId);
        if (!found) {
            _this.selectedObjectIds[dbId] = dbId;
            _this.selectionCount++;
            markObject(dbId);
        }
    }

    function deselect(dbId) {

        var found = isSelected(dbId);
        if (found) {
            unmarkObject(dbId);
            _this.selectedObjectIds[dbId] = 0;
            _this.selectionCount--;
        }
    }

    function selectionIsEqual(dbNodeArray) {
        if( _this.selectionCount !== dbNodeArray.length )
            return false;

        for (var i = 0; i < dbNodeArray.length; i++) {
            if (!isSelected(dbNodeArray[i]))
                return false;
        }
        return true;
    }


    this.getInstanceTree = getInstanceTree;

    this.getSelectionLength = function() {
        return _this.selectionCount;
    };


    this.getSelection = function() {
        var ret = [];
        var sset = _this.selectedObjectIds;
        for (var p in sset) {
            if (sset[p]) {
                var dbId = parseInt(p);
                ret.push(dbId);
            }
        }

        return ret;
    };

    this.clearSelection = function(nofire) {
        if (this.selectionCount > 0) {
            var sset = _this.selectedObjectIds;
            for (var p in sset) {
                var dbId = parseInt(p);
                if (dbId !== undefined)
                    unmarkObject(dbId);
            }
            _this.selectedObjectIds = {};
            _this.selectionCount = 0;

            if( !nofire )
                fireSelectionChangedEvent();
        }
    };

    this.deselectInvisible = function() {
        var changed = false;

        var sset = _this.selectedObjectIds;
        var it = getInstanceTree();
        var visMan = viewer.visibilityManager;
        for (var p in sset) {
            var dbId = parseInt(p);
            if (dbId && !visMan.isNodeVisible(model, dbId)) {
                deselect(dbId);
                changed = true;
            }
        }

        if (changed) {
            fireSelectionChangedEvent();
        }

        return changed;
    };


    // TODO: Optimize this so both select and toggleSelection don't have to lookup the node index.
    this.toggleSelection = function(dbId) {

        if (!dbId) {
            avp.logger.error("Attempting to select node 0.");
            return;
        }

        if (!isSelected(dbId)) {
            select(dbId);
        } else {
            deselect(dbId);
        }
        fireSelectionChangedEvent();
    };


    this.setSelectionMode = function(mode) {
        this.clearSelection(true);
        this.selectionMode = mode;
    };

    this.setSelection = function(dbNodeArray) {

        if( selectionIsEqual( dbNodeArray ) )
            return;

        this.clearSelection(true);

        if (dbNodeArray == null || dbNodeArray.length === 0)
            return;

        for (var i = 0; i < dbNodeArray.length; i++) {
            select(dbNodeArray[i]);
        }

        fireSelectionChangedEvent();
    };


    this.getSelectionBounds = function() {
        var bounds = new THREE.Box3();
        var box = new THREE.Box3();

        var instanceTree = getInstanceTree();
        var fragList = model.getFragmentList();
        
        var sset = _this.selectedObjectIds;
        for (var p in sset) {
            var dbId = parseInt(p);
            instanceTree.enumNodeFragments(dbId, function(fragId) {
                fragList.getWorldBounds(fragId, box);
                bounds.union(box);
            }, true);
        }
        
        return bounds;
    };

    this.getSelectionVisibility = function () {
        var hasVisible = false,
            hasHidden = false;

        var sset = _this.selectedObjectIds;
        for (var p in sset) {
            var dbId = parseInt(p);
            if (dbId) {
                var it = getInstanceTree();
                if (!it || !it.isNodeHidden(dbId)) {
                    hasVisible = true;
                } else {
                    hasHidden = true;
                }
                if (hasVisible && hasHidden) {
                    break;
                }
            }
        }

        return { 
            hasVisible: hasVisible, 
            hasHidden: hasHidden,
            model: model
        };
    };

    this.dtor = function () {
        this.selectedObjectIds = null;
    };

}

avp.Selector = Selector;


function MultiModelSelector(viewer) {

    var _models = [];

    this.addModel = function(model) {
        if (_models.indexOf(model) == -1) {
            model.selector = new Selector(viewer, model);
            _models.push(model);
        }
    };

    this.removeModel = function(model) {
        var idx = _models.indexOf(model);

        // make sure that we don't keep any highlighting proxy
        var selected = model.selector.getSelection();
        model.selector.clearSelection();
        model.selector = null;
        _models.splice(idx, 1);
    };

    function warn() {
        if (_models.length > 1) {
            avp.logger.warn("This selection call does not yet support multiple models.");
        }
    }

    function fireAggregateSelectionChangedEvent() {

        var perModel = [];

        for (var i=0; i<_models.length; i++) {
            var dbIdArray = [];
            var fragIdsArray = [];

            var sset = _models[i].selector.selectedObjectIds;
            var it = _models[i].selector.getInstanceTree();
            for (var p in sset) {
                if (sset[p]) {
                    var dbId = parseInt(p);
                    if (dbId) {
                        dbIdArray.push(dbId);

                        if (it) {
                            it.enumNodeFragments(dbId, function (fragId) {
                                fragIdsArray.push(fragId);
                            }, false);
                        }
                    }
                }
            }

            if (dbIdArray.length) {
                perModel.push({
                    fragIdsArray: fragIdsArray,
                    dbIdArray: dbIdArray,
                    nodeArray: dbIdArray,
                    model: _models[i]
                });
            }
        }

        var event;

        //For backwards compatibility, fire the old selection change event
        //when there is just one model in the scene
        if (_models.length === 1) {
            event = {
                type: av.SELECTION_CHANGED_EVENT,
                fragIdsArray: perModel[0] ? perModel[0].fragIdsArray : [],
                dbIdArray: perModel[0] ? perModel[0].dbIdArray : [],
                nodeArray: perModel[0] ? perModel[0].dbIdArray : [],
                model: _models[0]
            };
            viewer.api.fireEvent(event);
        }

        //Always fire the aggregate selection changed event
        event = {
            type: av.AGGREGATE_SELECTION_CHANGED_EVENT,
            selections: perModel
        };
        viewer.api.fireEvent(event);

    }


    function deselectInvisible() {

        var changed = false;

        for (var i=0; i<_models.length; i++) {
            changed = _models[i].selector.deselectInvisible() || changed;
        }

        if (changed)
            fireAggregateSelectionChangedEvent();
    }


    this.getSelectionLength = function() {
        var total = 0;

        for (var i=0; i<_models.length; i++) {
            total += _models[i].selector.getSelectionLength();
        }

        return total;
    };

    this.getSelection = function() {
        warn();
        if (_models.length > 1)
            avp.logger.warn("Use getAggregateSelection instead of getSelection when there are multiple models in the scene.");
        return _models[0].selector.getSelection();
    };

    this.getAggregateSelection = function() {
        var res = [];
        for (var i=0; i<_models.length; i++) {
            var selset = _models[i].selector.getSelection();
            if (selset && selset.length)
                res.push( { model:_models[i], selection:selset } );
        }

        return res;
    };

    this.clearSelection = function(nofire) {
        for (var i=0; i<_models.length; i++)
            _models[i].selector.clearSelection(nofire);

        if (!nofire)
            fireAggregateSelectionChangedEvent();
    };

    this.toggleSelection = function(dbId, model) {
        if (!model) {
            warn();
            model = _models[0];
        }
        model.selector.toggleSelection(dbId);

        fireAggregateSelectionChangedEvent();
    };

    this.setSelectionMode = function(mode) {
        for (var i=0; i<_models.length; i++)
            _models[i].selector.setSelectionMode(mode);
    };

    this.setSelection = function(dbNodeArray, model) {
        if (!dbNodeArray || dbNodeArray.length === 0)
            this.clearSelection();
        else {
            if (!model) {
                warn();
                model = _models[0];
            } else {
                for (var i=0; i<_models.length; i++)
                    if (_models[i] !== model)
                         _models[i].selector.clearSelection();
            }
            model.selector.setSelection(dbNodeArray);
        }

        fireAggregateSelectionChangedEvent();
    };

    this.getSelectionBounds = function() {
        if (_models.length == 1)
            return _models[0].selector.getSelectionBounds();
        else {
            var bbox = new THREE.Box3();
            for (var i=0; i<_models.length; i++) {
                var tmp = _models[i].selector.getSelectionBounds();
                bbox.union(tmp);
            }
            return bbox;
        }
    };

    this.getSelectionVisibility = function () {

        var res = { 
            // Aggregated results
            hasVisible: false, 
            hasHidden: false,
            // per model specifics 
            details: [] 
        };
        for (var i=0; i<_models.length; i++) {
            var subRes = _models[i].selector.getSelectionVisibility();
            res.hasVisible = res.hasVisible || subRes.hasVisible;
            res.hasHidden = res.hasHidden || subRes.hasHidden;
            res.details.push(subRes);
        }
        return res;
    };

    this.dtor = function () {
        for (var i=0; i<_models.length; i++)
            _models[i].selector.dtor();
    };


    viewer.api.addEventListener( av.ISOLATE_EVENT, function(event) {
        deselectInvisible();
    });

    viewer.api.addEventListener( av.HIDE_EVENT, function(event) {
        deselectInvisible();
    });


}

avp.MultiModelSelector = MultiModelSelector;


})();
;

(function() {

    'use strict';

    var av = Autodesk.Viewing,
        avp = av.Private;

    var VisibilityManager = function (viewerImpl, model) {
        this.viewerImpl = viewerImpl;

        //Currently the visibility manager works on a single model only
        //so we make this explicit here.
        this.model = model;

        // Keep track of isolated nodes
        this.isolatedNodes = [];

        // Keeps track of hidden nodes. Only applies when there's no isolated node being tracked.
        this.hiddenNodes = [];
    };

    VisibilityManager.prototype.getInstanceTree = function () {
        if (this.model)
            return this.model.getData().instanceTree;
        else
            return null;
    };

    VisibilityManager.prototype.getIsolatedNodes = function () {
        return this.isolatedNodes.slice(0);
    };

    VisibilityManager.prototype.getHiddenNodes = function () {
        return this.hiddenNodes.slice(0);
    };

    /** @params {bool} - visible flag applied to all dbIds/fragments. */
    VisibilityManager.prototype.setAllVisibility = function (visible) {

        var root = this.model ? this.model.getRootId() : null;
        if (root) {
            // if we have an instance tree, we call setVisible on the root node
            this.setVisibilityOnNode(root, visible);
        }

        // 2D datasets may need to call setAllVisibility on the model. This can have two possible reasons:
        //  a) they may have no instance tree, so that setting visibility on root (as above) is not possible.
        //  b) even if they have an instance tree, setting visibility on root node will only reach selectable ids.
        //     2D datasets may also contain unselectable objects with id <=0. In this case, the call below
        //     is needed to hide/show these as well when using isolate/show-all.
        var is2d = this.model.getData().is2d;
        if (is2d) {
            this.model.setAllVisibility(visible);
        }
    }

    VisibilityManager.prototype.isNodeVisible = function(dbId) {
        var it = this.getInstanceTree();
        if (it) {
            // get visibility from instance tree
            return !it.isNodeHidden(dbId);
        } else {
            // If there is no instance tree, we have ids, but no hierarchy.
            // Therefore, an id is only hidden if it appears in hiddenNodes or
            // if there are isolated nodes and dbId is not among these.
            return (this.hiddenNodes.indexOf(dbId)==-1 && (this.isolatedNodes.length==0 || this.isolatedNodes.indexOf(dbId)!=-1));
        }
    }

    VisibilityManager.prototype.isolate = function (node) {
        var it     = this.getInstanceTree();
        var rootId = (it ? it.getRootId() : null);
        var isRoot = (typeof node == "number" && node === rootId)
            || (typeof node == "object" && node.dbId === rootId);

        if (node && !isRoot) {
            this.isolateMultiple(Array.isArray(node) ? node : [node]);
        } else {
            this.isolateNone();
        }
    };

    VisibilityManager.prototype.isolateNone = function () {

        this.model.setAllVisibility(true);
        this.viewerImpl.sceneUpdated(true);

        this.setAllVisibility(true);

        this.hiddenNodes = [];
        this.isolatedNodes = [];
        this.viewerImpl.invalidate(true);

        var event = {type: av.ISOLATE_EVENT, nodeIdArray: [], model: this.model};
        this.viewerImpl.api.fireEvent(event);
    };

//Makes the children of a given node visible and
//everything else not visible
    VisibilityManager.prototype.isolateMultiple = function (nodeList) {

        //If given nodelist is null or is an empty array or contains the whole tree
        if (!nodeList || nodeList.length == 0) {
            this.isolateNone();
        }
        else {

            this.setAllVisibility(false);

            // For 3D, visibility is controlled via MESH_VISIBLE flag.
            // For 2D, visibility can only be contolled via a texture in MaterialManager. This already
            // happens in the setVisibilityOnNode(..) call above.
            if (!this.model.getData().is2d) {
                this.model.setAllVisibility(false);
                this.viewerImpl.sceneUpdated(true);
            }

            // Needs to happen after setVisibilityOnNode(root).
            this.isolatedNodes = nodeList.slice(0);
            this.hiddenNodes = [];

            for (var i = 0; i < nodeList.length; i++) {
                this.setVisibilityOnNode(nodeList[i], true);
            }

            var event = {type: av.ISOLATE_EVENT, nodeIdArray: nodeList, model: this.model};
            this.viewerImpl.api.fireEvent(event);
        }

        //force a repaint and a clear
        this.viewerImpl.invalidate(true);
    };


//Makes the children of a given node visible and
//everything else not visible
    VisibilityManager.prototype.hide = function (node) {
        
        var event;
        
        if (Array.isArray(node)) {
            for (var i = 0; i < node.length; ++i) {
                this.setVisibilityOnNode(node[i], false);
            }

            if (node.length > 0) {
                event = {type: av.HIDE_EVENT, nodeIdArray: node};
            }
        } else {
            this.setVisibilityOnNode(node, false);
            event = {type: av.HIDE_EVENT, nodeIdArray: [node]};
        }

        if (event)
            this.viewerImpl.api.fireEvent(event);
    };

    VisibilityManager.prototype.show = function (node) {
        
        var event;
        
        if (Array.isArray(node)) {
            for (var i = 0; i < node.length; ++i) {
                this.setVisibilityOnNode(node[i], true);
            }
    
            if (node.length > 0) {
                event = {type: av.SHOW_EVENT, nodeIdArray: node};
            }        
        } else {
            this.setVisibilityOnNode(node, true);
            event = {type: av.SHOW_EVENT, nodeIdArray: [node]};
        }

        if (event)
            this.viewerImpl.api.fireEvent(event);
    };

    VisibilityManager.prototype.toggleVisibility = function (node) {
        var hidden = this.getInstanceTree().isNodeHidden(node);
        this.setVisibilityOnNode(node, hidden); //Note -- toggle visibility, so we want !!hidden => hidden

        var event = {type: hidden ? av.SHOW_EVENT : av.HIDE_EVENT, nodeIdArray: [node]};
        this.viewerImpl.api.fireEvent(event);
    };

    VisibilityManager.prototype.setVisibilityOnNode = function (node, visible) {

        var viewer = this.viewerImpl;
        var model = this.model;
        var instanceTree = this.getInstanceTree();
        var hidden = !visible;
        var is2d   = model.getData().is2d;
        var matMan = this.viewerImpl.matman();

        if (instanceTree) {
            //Recursively process the tree under the root (recursion is inclusive of the root)
            instanceTree.enumNodeChildren(node, function (dbId) {

                instanceTree.setNodeHidden(dbId, hidden);

                if (is2d) {
                    model.getFragmentList().setObject2DGhosted(dbId, !visible);
                } else {
                    instanceTree.enumNodeFragments(dbId, function (fragId) {
                        model.setVisibility(fragId, visible);
                    }, false);
                }
            }, true);
        } else {
            //No instance tree, assume fragId = dbId
            if (is2d) {
                model.getFragmentList().setObject2DGhosted(node, !visible);
            } else {
                model.setVisibility(node, visible);
            }
        }

        viewer.sceneUpdated(true);
        this.updateNodeVisibilityTracking(node, visible);
    };

    VisibilityManager.prototype.updateNodeVisibilityTracking = function(node, visible) {

        // Update hidden tracking array.
        var toVisible = visible;
        if (this.isolatedNodes.length > 0) {
            var isoIndex = this.isolatedNodes.indexOf(node);
            if (toVisible && isoIndex === -1) {
                this.isolatedNodes.push(node);
            }
            else if (!toVisible && isoIndex !== -1) {
                this.isolatedNodes.splice(isoIndex, 1);
            }
        } else {
            var hidIndex = this.hiddenNodes.indexOf(node);
            if (!toVisible && hidIndex === -1) {
                this.hiddenNodes.push(node);
            }
            else if (toVisible && hidIndex !== -1) {
                this.hiddenNodes.splice(hidIndex, 1);
            }
        }

        // When operating with the node, we can get simplify stuff.
        var instanceTree = this.getInstanceTree();
        if (instanceTree && instanceTree.root && instanceTree.root.dbId === node) {
            if (visible) {
                this.isolatedNodes = [];
                this.hiddenNodes = [];
            } else {
                this.isolatedNodes = [];
                this.hiddenNodes = [node];
            }
        }
    };

    VisibilityManager.prototype.setNodeOff = function (node, isOff) {
        var viewer = this.viewerImpl;
        var model = this.model;
        var instanceTree = this.getInstanceTree();
        var is2d   = model.getData().is2d;

        if (instanceTree) {
            //Recursively process the tree under the root (recursion is inclusive of the root)
            instanceTree.enumNodeChildren(node, function (dbId) {

                instanceTree.setNodeOff(dbId, isOff);

                if (is2d) {
                    model.getFragmentList().setObject2DVisible(dbId, !isOff);
                } else {
                    instanceTree.enumNodeFragments(dbId, function (fragId) {
                        model.getFragmentList().setFragOff(fragId, isOff);
                    }, false);
                }

            }, true);
        } else {
            if (is2d) {
                model.getFragmentList().setObject2DVisible(node, !isOff);
            } else {
                model.getFragmentList().setFragOff(node, isOff);
            }
        }

        viewer.sceneUpdated(true);
    };


    av.Private.VisibilityManager = VisibilityManager;
    
    
    
    function MultiModelVisibilityManager(viewer) {
    
        this.viewer = viewer;
        this.models = [];
    
    }
    
    MultiModelVisibilityManager.prototype.addModel = function(model) {
        if (this.models.indexOf(model) == -1) {
            model.visibilityManager = new VisibilityManager(this.viewer, model);
            this.models.push(model);
        }
    };

    MultiModelVisibilityManager.prototype.removeModel = function(model) {
        var idx = this.models.indexOf(model);

        // clear visibility states (revert all ghosting)
        model.visibilityManager.isolateNone();

        model.visibilityManager = null;
        this.models.splice(idx, 1);
    };

    MultiModelVisibilityManager.prototype.warn = function() {
        if (this.models.length > 1) {
            avp.logger.warn("This selection call does not yet support multiple models.");
        }
    };

    
    MultiModelVisibilityManager.prototype.getIsolatedNodes = function (model) {
        if (!model) {
            this.warn();
            model = this.models[0];
        }
        return model.visibilityManager.getIsolatedNodes();
    };

    MultiModelVisibilityManager.prototype.getHiddenNodes = function (model) {
        if (!model) {
            this.warn();
            model = this.models[0];
        }
        return model.visibilityManager.getHiddenNodes();
    };

    MultiModelVisibilityManager.prototype.isNodeVisible = function(model, dbId) {
        if (!model) {
            this.warn();
            model = this.models[0];
        }
        return model.visibilityManager.isNodeVisible(dbId);
    };

    MultiModelVisibilityManager.prototype.isolate = function (node, model) {
        var models = model ? [model] : this.models;
        models.forEach(function(mod){
            mod.visibilityManager.isolate(node);
        });
    };

//Makes the children of a given node visible and
//everything else not visible
    MultiModelVisibilityManager.prototype.hide = function (node, model) {
        if (!model) {
            this.warn();
            model = this.models[0];
        }
        model.visibilityManager.hide(node);
    };

    MultiModelVisibilityManager.prototype.show = function (node, model) {
        if (!model) {
            this.warn();
            model = this.models[0];
        }
        model.visibilityManager.show(node);
    };

    MultiModelVisibilityManager.prototype.toggleVisibility = function (node, model) {
        if (!model) {
            this.warn();
            model = this.models[0];
        }
        model.visibilityManager.toggleVisibility(node);        
    };

    MultiModelVisibilityManager.prototype.setVisibilityOnNode = function (node, visible, model) {
        if (!model) {
            this.warn();
            model = this.models[0];
        }
        model.visibilityManager.setVisibilityOnNode(node, visible);
    };

    MultiModelVisibilityManager.prototype.setNodeOff = function (node, isOff, model) {
        if (!model) {
            this.warn();
            model = this.models[0];
        }
        model.visibilityManager.setNodeOff(node, isOff);
    };

    
    
    av.Private.MultiModelVisibilityManager = MultiModelVisibilityManager;

})();
;
/** @license Copyright (c) 2013 Autodesk Inc. */
/** Version : @buildnum@ */

(function() {

	'use strict';

var av = Autodesk.Viewing,
    avp = av.Private;

/**
 * This is the core interface to camera controls and navigation. The active navigation object can normally be obtained from the "navigation" property of the Viewer3D instance. Client implementations should not normally instantiate this class directly.
 *  @class
 *  @param {THREE.Camera} camera - The main camera object used to render the scene.
 *  @constructor
 */
function Navigation(camera)
{
    var kMinFOV  = 6.88; // 200 mm
    var kMaxFOV  = 100;  // 10 mm
    var kEpsilon = 0.000001;
    var kDefaultMinDistance = 0.00001;

    this.__options = {
        dollyToPivot: false,
        orbitPastPoles: true,
        reverseDolly: false,
        reverseHorizontalLook: false,
        reverseVerticalLook: false,
        useLeftHandedInput: false,
        usePivotAlways: false,
        lockNavigation: false
    };

    // which actions are allowed when navigation is locked
    this.__lockSettings = {
        orbit: false,
        pan: false,
        zoom: false,
        roll: false,
        fov: false,
        gotoview: false,
        walk: false
    };

    // Change these constants to alter the margin ratios (think, percentages/100).
    // The margins are how much to add above and below. For example, setting the
    // margin to 25% (0.25) would give a margin of 25% above, 50% in the middle for
    // content, and 25% below. This value should never be >= 0.50, as that would
    // leave no area for the content to display.
    // The offsets are how much to shift the view. For example, shifting 50% (0.50)
    // vertically would move the displayed area such that only the bottom half of
    // the drawing area would be seen.
    this.FIT_TO_VIEW_VERTICAL_MARGIN = 0.05;
    this.FIT_TO_VIEW_VERTICAL_OFFSET = 0.00;
    this.FIT_TO_VIEW_HORIZONTAL_MARGIN = 0.05;
    this.FIT_TO_VIEW_HORIZONTAL_OFFSET = 0.00;

    this.__pivotIsSetFlag = false;
    this.__fitToViewRequested = false;
    this.__homeViewRequested = false;
    this.__transitionActive = false;
    this.__destinationView = null;
    this.__is2D = false;
    this.__isTouchDevice = false;
    this.__kEpsilon = kEpsilon;
    this.__minDistance = kDefaultMinDistance;

    // Only for 2D: Optional constraints to keep data within the view.
    var _maxViewRegion    = undefined;  // {THREE.Box3} restrict zoom-out/pan to keep it well visible (only xy used)
    var _maxPixelsPerUnit = undefined;  // Restrict zoom-in so that a world-space unit does not exceed a given
                                        // number of pixels on screen.
    var _maxDistanceFactor = 2.0;

    var _camera = null;

    var _viewport = { left: 0, top: 0, width: 1, height: 1 };

    this.uninitialize = function()
    {
        this.setCamera(null);
    };

    /**
     * Set or unset the current camera used for navigation. Normally set via the constructor.
     * The camera should be of type Autodesk.Viewing.UnifiedCamera.
     *  @param {Autodesk.Viewing.UnifiedCamera} camera - the current camera object.
     */
    this.setCamera = function(camera)
    {
        if( camera !== _camera )
        {
            _camera = camera;
            if( camera )
            {
                if( !camera.hasOwnProperty("target") )
                    camera.target = new THREE.Vector3(0, 0, 0);

                if( !camera.hasOwnProperty("pivot") )
                    camera.pivot = new THREE.Vector3(0, 0, 0);

                camera.worldup = camera.up.clone();  // Initial assumption!!
                camera.dirty = true;
            }
        }
    };

    /**
     *  @returns {THREE.Camera} - the current camera object.
     */
    this.getCamera = function()
    {
        return _camera;
    };

    /**
     * Set the current canvas viewport in screen coordinates.
     * Invoked internally on canvas resize.
     *  @param {Object} viewport - Rectangle with properties left, top, width, height.
     */
    this.setScreenViewport = function( viewport )
    {
        _viewport = viewport;
    };

    /**
     * Get the current canvas viewport in screen coordinates.
     *  @returns {Object} with properties left, top, width, height.
     */
    this.getScreenViewport = function()
    {
        return _viewport;
    };

    this.__setUp = function(up)
    {
        if( up && _camera )
        {
            var upCheck = up.clone().normalize();
            var diff = upCheck.sub( _camera.worldup );
            if( diff.lengthSq() !== 0.0 )
            {
                _camera.worldup.copy(up).normalize();
                _camera.dirty = true;
                return true;
            }
        }
        return false;
    };

    this.__getUp = function()
    {
        return _camera ? _camera.worldup : new THREE.Vector3(0, 1, 0);
    };

    /**
     * Sets the cameras position and view direction.
     *  @param {THREE.Vector3} position - the new position for the camera in world space.
     *  @param {THREE.Vector3} target - the point in world space that the camera should look towards.
     */
    this.setView = function( position, target )
    {
        if( _camera && position && target )
        {
            _camera.position.copy(position);
            _camera.target.copy(target);
            _camera.dirty = true;
        }
    };

    /**
     * Orient the camera's up direction with the current world up direction
     */
    this.orientCameraUp = function()
    {
        if( _camera && this.isActionEnabled('roll') )
        {
            _camera.up.copy(this.getAlignedUpVector()); // New up aligned with world up
            _camera.dirty = true;
        }
    };

    /**
     *  @returns {THREE.Vector3} the world space position of the pivot point for orbit navigation.
     */
    this.getPivotPoint = function()
    {
        return _camera ? _camera.pivot.clone() : new THREE.Vector3(0, 0, 0);
    };

    /**
     * Sets the Vector3 world space position of the pivot point for orbit navigation.
     *  @param {THREE.Vector3} pivot - the new pivot position.
     */
    this.setPivotPoint = function( pivot )
    {
        if( _camera && pivot )
        {
            _camera.pivot.copy(pivot);
            _camera.dirty = true;
        }
    };

    /**
     *  @returns {THREE.Vector3} the world space position of the camera.
     */
    this.getPosition = function()
    {
        return _camera ? _camera.position.clone() : new THREE.Vector3(0, 0, 1);
    };

    /**
     * Sets the Vector3 world space position of camera.
     *  @param {THREE.Vector3} pos - the new camera position.
     */
    this.setPosition = function( pos )
    {
        if( _camera && pos )
        {
            _camera.position.copy(pos);
            _camera.dirty = true;
        }
    };

    /**
     * Sets the Vector3 world space position towards which the camera should be pointing.
     *  @param {THREE.Vector3} target - the new camera look at point.
     */
    this.setTarget = function(target)
    {
        if( _camera && target )
        {
            _camera.target.copy(target);
            _camera.dirty = true;
        }
    };

    /**
     *  @returns {THREE.Vector3} the world space position towards which the camera is pointing.
     */
    this.getTarget = function()
    {
        return _camera ? _camera.target.clone() : new THREE.Vector3(0, 0, 0);
    };

    /**
     * Get the current camera view vector. This vector is not normalized and its
     * length is the distance between the camera position and the camera look at point.
     *  @returns {THREE.Vector3} the current camera view vector in world space.
     */
    this.getEyeVector = function ()
    {
        return _camera ? _camera.target.clone().sub( _camera.position ) : new THREE.Vector3(0, 0, -1);
    };

    /**
     *  @returns {number} the minimum allowed vertical field of view in degrees.
     */
    this.getFovMin = function()
    {
        return kMinFOV;
    };

    /**
     *  @returns {number} the maximum allowed vertical field of view in degrees.
     */
    this.getFovMax = function()
    {
        return kMaxFOV;
    };

    /**
     * Returns true if the point is visible.
     *
     * @param {THREE.Vector3} point - The point in world coordinates.
     *
     * @returns {boolean} - True if the point is within the camera's frustum.
     */
    this.isPointVisible = function(point)
    {
        var cameraFrustum = new THREE.Frustum().setFromMatrix(_camera.projectionMatrix.clone().multiply(_camera.matrixWorldInverse));
        return cameraFrustum.containsPoint(point);
    };

    /**
     * Set the current vertical field of view.
     *  @param {number} fov - the new field of view in degrees (value is clamped to the minimum and maximum field of view values).
     *  @param {boolean} adjustPosition - If true, the camera position will be modified to keep either the world space area
     *                                    of the view at the pivot point unchanged (if it is set and visible) or the world
     *                                    space area of view at the camera look at point unchanged.
     */
    this.setVerticalFov = function(fov, adjustPosition)
    {
        // If camera is not perspective don't allow fov change
        if( _camera && !_camera.isPerspective)
            return;

        if( fov < kMinFOV ) fov = kMinFOV;
        else if( fov > kMaxFOV ) fov = kMaxFOV;

        if( _camera && this.isActionEnabled('fov') )
        {
            if( Math.abs(_camera.fov - fov)  <= kEpsilon )
                return;

            if( adjustPosition )
            {
                var usePivot = this.__pivotIsSetFlag && this.isPointVisible(this.getPivotPoint());

                var pos = this.getPosition();
                var eye = this.getEyeVector();

                var oldFOV = THREE.Math.degToRad(_camera.fov);
                var newFOV = THREE.Math.degToRad(fov);

                var oldDistance = usePivot ? this.getPivotPlaneDistance() : eye.length();
                var newDistance = oldDistance * Math.tan(oldFOV * 0.5) / Math.tan(newFOV * 0.5);

                var delta = eye.normalize().multiplyScalar(oldDistance - newDistance);
                this.setPosition(pos.add(delta));

                if (usePivot) {
                    this.setTarget(this.getTarget().add(delta));
                }
            }
            _camera.setFov(fov);
            _camera.dirty = true;
        }
    };

    /**
     * Compute camera position and look at point which will fit the given bounding box in the view frustum at the given field of view angle.
     *  @param {THREE.Vector3} oldpos - existing camera position
     *  @param {THREE.Vector3} oldcoi - existing camera look at point
     *  @param {number} fov - field of view (in degrees) to use for fit calculation in degrees
     *  @param {THREE.Box3} bounds - bounding box to fit
     *  @param {number} aspect - optional aspect ratio of window, horizontal/vertical
     *  @returns {Object} Object with properties "position" and "target".
     */
    this.computeFit = function(oldpos, oldcoi, fov, bounds, aspect)
    {
        if( !bounds || bounds.empty() )
            return {position: oldpos, target: oldcoi};

        aspect = (aspect === undefined) ? 1.0 : aspect;

        var coi  = bounds.center();
        var size = bounds.size();

        var eye = oldpos.clone().sub(oldcoi).normalize();

        var fovHalfWorldWidth = Math.tan(THREE.Math.degToRad(fov * 0.5));
        var fitToViewDistance = 0.0;
        // make sure up is orthogonal to eye view direction
        var up = this.computeOrthogonalUp(oldpos, oldcoi);
        var right = eye.clone().cross(up).normalize();

        var v1 = new THREE.Vector3();
        // if size.z is 0.0 (normal for 2D), we only go to 4, as we need only the four corners of a square.
        var corners = (size.z === 0.0) ? 4 : 8;
        for (var i = 0; i < corners; i++) {
            // get the Nth corner of the bounding box, centered around its center
            v1.set(
                ((i&0x1)==0) ? -0.5*size.x : 0.5*size.x,
                ((i&0x2)==0) ? -0.5*size.y : 0.5*size.y,
                ((i&0x4)==0) ? -0.5*size.z : 0.5*size.z
            );

            // Fit each bounds and find that distance, also depending on the aspect ratio.
            // The eyeDot distance brings our 2d test plane to where the corner is located
            // along the z axis, so is indeed a signed distance.
            // The other two distances, computed with up and right vectors, are positive,
            // which is why Math.abs is used.

            // Dot product with the eye vector is how far to move the 2D viewing plane
            // to contain the point. Matters only for perspective camera.
            var eyeDot = 0.0;
            if( camera.isPerspective ) {
                eyeDot = v1.dot(eye);
            }
            var upDot = Math.abs(v1.dot(up));
            var rightDot = Math.abs(v1.dot(right));

            // vertical distance used to compute how far back to move the camera
            var testDistance = eyeDot +
                (1.0 + ( 2.0 * this.FIT_TO_VIEW_VERTICAL_MARGIN / ( 1.0 - 2.0 * this.FIT_TO_VIEW_VERTICAL_MARGIN ))) * 
                upDot / fovHalfWorldWidth;
            if ( fitToViewDistance < testDistance )
                fitToViewDistance = testDistance;

            // horizontal distance used to compute how far back to move the camera
            testDistance = eyeDot +
                (1.0 + ( 2.0 * this.FIT_TO_VIEW_HORIZONTAL_MARGIN / ( 1.0 - 2.0 * this.FIT_TO_VIEW_HORIZONTAL_MARGIN ))) *
                rightDot / (aspect * fovHalfWorldWidth);
            if ( fitToViewDistance < testDistance )
                fitToViewDistance = testDistance;
        }

        // adjust coi by vertical percentage, which keeps it centered above the view controls
        coi.add( up.multiplyScalar(-fitToViewDistance*this.FIT_TO_VIEW_VERTICAL_OFFSET));
        coi.add( right.multiplyScalar(fitToViewDistance*this.FIT_TO_VIEW_HORIZONTAL_OFFSET));

        eye.multiplyScalar( fitToViewDistance );

        var pos = coi.clone().add( eye );
        return {position: pos, target: coi};
    };

    /**
     * Compute a vector which is orthogonal to the given view and aligned with the world up direction.
     *  @param {THREE.Vector3} pos - view position
     *  @param {THREE.Vector3} coi - center of interest (view look at point)
     *  @returns {THREE.Vector3} up direction orthogonal to the given view
     */
    this.computeOrthogonalUp = function(pos, coi)
    {
        var worldUp = this.__getUp();
        var eye = coi.clone().sub(pos);
        if( eye.lengthSq() === 0.0 )    // Invalid view?
            return eye.copy(worldUp);

        var right = eye.clone().cross(worldUp);
        if( right.lengthSq() === 0 )
        {
            // If eye and up are colinear, perturb eye
            // to get a valid result:
            if( worldUp.z > worldUp.y )
                eye.y -= 0.0001;
            else
                eye.z -= 0.0001;

            right.crossVectors( eye, worldUp );
        }
        return right.cross(eye).normalize();
    };

    /**
     * Causes the current camera position to be changed in order to fit the given bounds into the current view frustum.
     *  @param {boolean} immediate - if false the camera position will animate to the new location.
     *  @param {THREE.Box3} bounds - bounding box to fit
     *  @param {boolean} reorient - if true the camera up direction will be reoriented with the world up.
     *  @returns {Object} Object with properties "position" and "target".
     */
    this.fitBounds = function(immediate, bounds, reorient)
    {
        var oldcoi = this.getTarget();
        var pos    = this.getPosition();

        if( !this.isActionEnabled('gotoview') || !bounds || bounds.empty() )
            return {position: pos, target: oldcoi};

        var fov = this.getVerticalFov();
        var fit = this.computeFit(pos, oldcoi, fov, bounds, _camera.aspect);
        var up  = reorient ? this.computeOrthogonalUp(pos, oldcoi) : _camera.up;

        if( immediate )
        {
            _camera.up.copy(up);
            this.setView(fit.position, fit.target);
        }
        else
        {
            this.setRequestTransitionWithUp( true, fit.position, fit.target, fov, up );
        }
        this.setPivotPoint(fit.target);
        this.setPivotSetFlag(true);

        return fit;
    };

    // Compute the minimum required distance to keep _maxViewRegion fully visible at once.
    this.computeOverviewDistance = function(bounds) {
        if (this.__is2D) {
            var size       = bounds.size();
            var aspect     = _camera.aspect;

            // Restrict zoom-out, so that it stops if maxViewRegion fits into the canvas
            // For ortho-cameras, we have (see UnififiedCamera.toOrthographic)
            //  frustumHeight == orthoScale == distance
            //  frustumWidth                == distance * aspect
            // Therefore, the distances at which the x/y-extent of the model matches the canvas is:
            var maxDistX = size.x / aspect;
            var maxDistY = size.y;

            // allow enough zoom-out that neither x nor y is cropped
            return Math.max(maxDistX, maxDistY);
        }
        else {
            var fov = this.getVerticalFov();
            var size = bounds.size();
            var radius = 0.5 * size.length();

            if( radius === 0.0 )
                radius = 1.0;
            }

            return (radius / Math.tan(THREE.Math.degToRad(fov * 0.5)));
    }

    // Helper function used to for dolly operations:
    // It adjusts the given scaleFactor if needed to preserve zoom-in/out restrictions.
    //
    //  @param {Number} scaleFactor - Distance scale factor going to be applied by a dolly interaction
    //  @param {THREE.Box3} bounds - bounding box to fit
    //  @returns adjustedScaleFactor
    this.applyDollyConstraint = function(scaleFactor, bounds) {

        // default: just return identity if no constraint is active
        if (!(_maxViewRegion || _maxPixelsPerUnit || _maxDistanceFactor)) {
            return scaleFactor;
        }

        var adjustedScaleFactor = scaleFactor;


            // restrict max distance, only if zooming out.
            if ((_maxViewRegion || (_maxDistanceFactor && bounds)) && scaleFactor > 1) {
                var viewVec = this.getEyeVector();

                var maxDist;
                if(_maxViewRegion)
                    // stop zoom-out if the whole viewRegion becomes smaller than half of the screen
                    maxDist = _maxDistanceFactor * this.computeOverviewDistance(_maxViewRegion);
                else
                    // stop zoom-out if the model's bounding box becomes smaller than half (_maxDistanceFactor) of the screen
                    maxDist = _maxDistanceFactor * this.computeOverviewDistance(bounds);

                // restrict scale-factor, so that viewVec.z doesn't exceed maxDist
                var maxScaleFactor = Math.abs(maxDist / viewVec.length());


                // after changing canvas width, the maxDist constraint may be temporarily broken.
                // we don't want to jump the camera back in this case - only avoid zooming out even more.
                // Therefore, we never force a scaleFactor below 1.0 (=no change).
                maxScaleFactor = Math.max(maxScaleFactor, 1.0);

                // apply zoom-out restriction
                adjustedScaleFactor = Math.min(adjustedScaleFactor, maxScaleFactor);
            }
        

        // restrict zoom-in, so that a single world-space unit does not exceed maxPixelsPerUnit.
        if (_maxPixelsPerUnit && this.__is2D) {

            // At a given distance d, the world-space size to match the canvas height is the frustum height.
            // Therefore, the pixel size of a world-space unit (ppu) is:
            //  ppu = canvasHeight / frustumHeight = canvasHeight / distance
            // Therefore, the distance at which we reach ppu == maxPixelsPerUnit is:
            var minDist = _camera.clientHeight / _maxPixelsPerUnit;

            // restrict scale-factor, so that viewVec.z doesn't fall below minDist
            var minScaleFactor = minDist / -viewVec.z;

            // Just restrict movement, but don't let the camera jump (see maxScaleFactor comment above)
            minScaleFactor = Math.min(minScaleFactor, 1.0);

            // apply zoom-in restriction
            adjustedScaleFactor = Math.max(adjustedScaleFactor, minScaleFactor);
        }

        return adjustedScaleFactor;
    }

    // If a _maxViewRegion is set (only for 2D mode), this function adjusts
    // the given panning offset, so that the camera keeps within the given view region (in xy).
    //  @param {THREE.Vector3} offsetVector to be added by panning movement
    this.applyPanningConstraint2D = function(inOutOffset) {

        // default: just do nothing unless we are using 2D with _maxViewRegion constraint
        if (!this.__is2D || !_maxViewRegion) {
            return;
        }

        // compute new camera pos after offset + constraint
        var newPosX = (_camera.position.x + inOutOffset.x);
        var newPosY = (_camera.position.y + inOutOffset.y);
        newPosX = THREE.Math.clamp(newPosX, _maxViewRegion.min.x, _maxViewRegion.max.x);
        newPosY = THREE.Math.clamp(newPosY, _maxViewRegion.min.y, _maxViewRegion.max.y);

        // compute resulting adjusted offset
        var offsetX = newPosX - _camera.position.x;
        var offsetY = newPosY - _camera.position.y;

        // We only want to restrict the panning movement, but don't jump suddenly
        // back if the camera is already outside. Therefore, we restrict
        // the adjusted offset to be within 0.0 (= no change) and the initial one.
        var offsetXMin = Math.min(inOutOffset.x, 0.0);
        var offsetYMin = Math.min(inOutOffset.y, 0.0);
        var offsetXMax = Math.max(inOutOffset.x, 0.0);
        var offsetYMax = Math.max(inOutOffset.y, 0.0);
        offsetX = THREE.Math.clamp(offsetX, offsetXMin, offsetXMax);
        offsetY = THREE.Math.clamp(offsetY, offsetYMin, offsetYMax);

        // replace offsetVector.xy by adjusted values
        inOutOffset.x = offsetX;
        inOutOffset.y = offsetY;
    }

    /**
     * Update the current camera projection matrix and orient the camera to the current look at point.
     * Invoked internally prior to rendering a new frame with the current camera.
     */
    this.updateCamera = function()
    {
        if( _camera )
        {
            _camera.updateProjectionMatrix();
            this.orient( _camera, _camera.target, _camera.position, _camera.up );
            _camera.dirty = false;
        }
    };

    this.setCamera(camera);

    // Only possible for 2D mode: Optional restriction of zooming and panning:
    //
    // @param {THREE.Box3}       [viewRegion]      - in world space. If specified, navigation is restricted so that this region
    //                                               always spans >= half of the screen extent in x and y.
    // @param {maxPixelPerUnit]  [maxPixelPerUnit] - Restrict zoom-In, so that a single unit in world-space never
    //                                               exceeds maxPixelPerUnit on screen.
    this.setConstraints2D = function(viewRegion, maxPixelPerUnit) {
        _maxViewRegion    = viewRegion;
        _maxPixelsPerUnit = maxPixelPerUnit;
    }
};

Navigation.prototype.constructor = Navigation;


Navigation.prototype.setIs2D = function( state )
{
    this.__is2D = !!state;
};

Navigation.prototype.getIs2D = function()
{
    return this.__is2D;
};

Navigation.prototype.setIsTouchDevice = function( state )
{
    this.__isTouchDevice = !!state;
};

Navigation.prototype.getIsTouchDevice = function()
{
    return this.__isTouchDevice;
};

/**
 * Rotate the given object so that its negative Z axis is directed towards the given point in world space. Used internally to orient the camera towards the target look at point. This is a modified version of the Object3D.lookAt method that uses different solution for the singular case when (view X up) == 0.
 *  @method
 *  @param {THREE.Object3D} object - the object to be oriented
 *  @param {THREE.Vector3} target - the world space point to orient towards
 *  @param {THREE.Vector3} from - the world space position of the object being rotated
 *  @param {THREE.Vector3} up - the direction to align the objects Y axis with
 */
Navigation.prototype.orient = function()
{
    var m1;
    var x;
    var y;
    var z;

    function init_three() {
        if (m1)
            return;

        m1 = new THREE.Matrix4();
        x = new THREE.Vector3();
        y = new THREE.Vector3();
        z = new THREE.Vector3();
    }

    return function ( object, target, from, up )
    {
        init_three();

        var te = m1.elements;

        z.subVectors( from, target ).normalize();
        if ( z.lengthSq() === 0 ) {
            z.z = 1;
        }
        x.crossVectors( up, z ).normalize();
        if ( x.lengthSq() === 0 ) {
            // If Z is up then cross with Y to get X
            // otherwize cross with Z to get X.
            if( up.z > up.y )
                z.y -= 0.0001;
            else
                z.z += 0.0001;

            x.crossVectors( up, z ).normalize();
        }
        y.crossVectors( z, x );

        te[0] = x.x; te[4] = y.x; te[8] = z.x;
        te[1] = x.y; te[5] = y.y; te[9] = z.y;
        te[2] = x.z; te[6] = y.z; te[10] = z.z;

        object.setRotationFromMatrix( m1 );
    };
}();

/**
 * Convert a vertical field of view angle in degrees to a 35mm camera focal length value.
 *  @param {number} fov - vertical field of view in degrees
 *  @returns {number} focal length in millimeters
 */
Navigation.prototype.fov2fl = function ( fov )
{
    // Note: the size of the 35mm camera back is 36x24mm.  Since we are setting and
    // getting the vertical FOV, we need to use the vertical measurement of 24mm, or
    // rather half of that (12.0) in our calculations.
    var k35mmVerticalCameraBackSize = 12.0;

    // Given a vertical field-of-view, return the focal length in millimeters
    // that it corresponds to in a 35mm film camera.
    var rads = THREE.Math.degToRad(fov);
    if (rads <= 0.0)
        rads = 0.0001;
    return Math.round( k35mmVerticalCameraBackSize / Math.tan(rads * 0.5) );
};

/**
 * Convert a 35mm camera focal length value to a vertical field of view angle in degrees.
 *  @param {number} fl - focal length in millimeters
 *  @returns {number} vertical field of view in degrees
 */
Navigation.prototype.fl2fov = function ( fl )
{
    // Note: the size of the 35mm camera back is 36x24mm.  Since we are setting and
    // getting the vertical FOV, we need to use the vertical measurement of 24mm, or
    // rather half of that (12.0) in our calculations.
    var k35mmVerticalCameraBackSize = 12.0;

    // Given a focal length, return the vertical field of view that
    // this would correspond to in a 35mm camera.
    if (fl <= 0)
        fl = 0.0001;

    var rads = 2.0 * Math.atan(k35mmVerticalCameraBackSize / fl);
    return THREE.Math.radToDeg(rads);
};

/**
 * Set the up direction for the camera. The given vector should be orthogonal to the current view direction.
 *  @method
 *  @param {THREE.Vector3} up - the new up direction vector
 */
Navigation.prototype.setCameraUpVector = function(up)
{
    if( this.isActionEnabled('roll') )
    {
        var camera = this.getCamera();
        camera.up.copy(up);
        camera.dirty = true;
    }
};

/**
 * Get the world space vector which is the current cameras up direction.
 *  @method
 *  @returns {THREE.Vector3} the current camera up direction (normalized)
 */
Navigation.prototype.getCameraUpVector = function()
{
    var right = this.getCameraRightVector(false);
    var eye   = this.getEyeVector();
    return right.cross(eye).normalize();
};

/**
 * Get the world space vector which is the orthogonal to the view direction and aligned with the world up direction.
 *  @method
 *  @returns {THREE.Vector3} the current camera up direction (normalized)
 */
Navigation.prototype.getAlignedUpVector = function()
{
    var right = this.getCameraRightVector(true);
    var eye   = this.getEyeVector();
    return right.cross(eye).normalize();
};

/**
 * Get the world space vector which is the right side direction of the current camera.
 *  @method
 *  @param {boolean} worldAligned - if true get the right vector aligned with the world up, otherwise use the current camera's up direction.
 *  @returns {THREE.Vector3} the current camera right direction, orthogonal to view and up (normalized)
 */
Navigation.prototype.getCameraRightVector = function(worldAligned)
{
    var right = new THREE.Vector3();
    var up  = worldAligned ? this.getWorldUpVector() : this.getCamera().up;
    var eye = this.getEyeVector();
    right.crossVectors(eye, up);
    if( right.lengthSq() === 0 )
    {
        // If eye and up are colinear, perturb eye
        // to get a valid result:
        if( up.z > up.y )
            eye.y -= 0.0001;
        else
            eye.z += 0.0001;

        right.crossVectors(eye, up);
    }
    return right.normalize();
};

/**
 * Change the current world up direction.
 *  @param {THREE.Vector3} up - the new world up direction
 *  @param {boolean} reorient - if true, make sure the camera up is oriented towards the world up direction.
 */
Navigation.prototype.setWorldUpVector = function(up, reorient)
{
    if( this.isActionEnabled('roll') )
    {
        this.__setUp(up);

        if( reorient )
            this.orientCameraUp();
    }
};

/**
 * Get the current world up direction.
 *  @returns {THREE.Vector3} the current world up direction (normalized)
 */
Navigation.prototype.getWorldUpVector = function()
{
    return this.__getUp().clone();
};

/**
 * Compute a world right direction based on the current world up direction. This will return the normalized cross product of the current up direction with one of the major axes to provide a usable world right direction.
 *  @method
 *  @returns {THREE.Vector3} the computed world right direction
 */
Navigation.prototype.getWorldRightVector = function()
{
    var right = new THREE.Vector3();
    right.copy(this.__getUp());

    if (Math.abs(right.z) <= Math.abs(right.y))
    {
        // Cross(Vertical, ZAxis)
        right.set(right.y, -right.x, 0);
    }
    else if (right.z >= 0)
    {
        // Cross(YAxis, Vertical)
        right.set(right.z, 0, -right.x);
    }
    else
    {
        // Cross(Vertical, YAxis)
        right.set(-right.z, 0, right.x);
    }
    return right.normalize();
};

/**
 *  @returns {number} the current camera vertical field of view in degrees
 */
Navigation.prototype.getVerticalFov = function()
{
    return this.getCamera().fov;
};

/**
 *  @returns {number} the current camera horizontal field of view in degrees
 */
Navigation.prototype.getHorizontalFov = function()
{
    var viewport = this.getScreenViewport();
    return this.getCamera().fov * (viewport.width / viewport.height);
};

/**
 *  @returns {number} the current camera focal length based on a 35mm camera lens model
 */
Navigation.prototype.getFocalLength = function()
{
    return this.fov2fl(this.getVerticalFov());
};

/**
 * Set the current cameras field of view using a 35mm camera focal length value
 *  @param {number} millimeters - focal length in millimeters
 *  @param {boolean} adjustPosition - If true, the camera position will be modified to keep either the world space area
 *                                    of the view at the pivot point unchanged (if it is set and visible) or the world
 *                                    space area of view at the camera look at point unchanged.
 */
Navigation.prototype.setFocalLength = function(millimeters, adjustPosition)
{
    this.setVerticalFov(this.fl2fov(millimeters), adjustPosition);
};

/**
 * Set or unset a view navigation option to reverse the default direction for camera dolly (zoom) operations.
 *  @param {boolean} state - value of the option, true for reverse, false for default
 */
Navigation.prototype.setReverseZoomDirection = function( state )
{
    this.__options.reverseDolly = !!state;
};

/**
 * Set or unset a view navigation option to reverse the default direction for horizontal look operations.
 *
 * Not applicable to 2D.
 *
 *  @param {boolean} state - value of the option, true for reverse, false for default
 */
Navigation.prototype.setReverseHorizontalLookDirection = function( state )
{
    if( this.getIs2D() )
    {
        avp.logger.warn("Autodesk.Viewing.Navigation.setReverseHorizontalLookDirection is not applicable to 2D");
        return;
    }

    this.__options.reverseHorizontalLookDirection = !!state;
};

/**
 * Set or unset a view navigation option to reverse the default direction for vertical look operations.
 *
 * Not applicable to 2D.
 *
 *  @param {boolean} state - value of the option, true for reverse, false for default
 */
Navigation.prototype.setReverseVerticalLookDirection = function( state )
{
    if( this.getIs2D() )
    {
        avp.logger.warn("Autodesk.Viewing.Navigation.setReverseVerticalLookDirection is not applicable to 2D");
        return;
    }

    this.__options.reverseVerticalLookDirection = !!state;
};

/**
 * Get the state of the view navigation option which requests the reversal of the default direction for camera dolly (zoom) operations.
 *  @returns {boolean} - value of the option, true for reverse, false for default
 */
Navigation.prototype.getReverseZoomDirection = function()
{
    return this.__options.reverseDolly;
};

/**
 * Get the state of the view navigation option which requests the reversal of the default horizontal look direction
 *
 * Not applicable to 2D.
 *
 *  @returns {boolean} value of the option, true for reverse, false for default
 */
Navigation.prototype.getReverseHorizontalLookDirection = function()
{
    if( this.getIs2D() )
    {
        avp.logger.warn("Autodesk.Viewing.Navigation.getReverseHorizontalLookDirection is not applicable to 2D");
        return false;
    }

    return this.__options.reverseHorizontalLookDirection;
};

/**
 * Get the state of the view navigation option which requests the reversal of the default vertical look direction
 *
 * Not applicable to 2D.
 *
 *  @returns {boolean} value of the option, true for reverse, false for default
 */
Navigation.prototype.getReverseVerticalLookDirection = function()
{
    if( this.getIs2D() )
    {
        avp.logger.warn("Autodesk.Viewing.Navigation.getReverseVerticalLookDirection is not applicable to 2D");
        return false;
    }

    return this.__options.reverseVerticalLookDirection;
};

/**
 * Set or unset a view navigation option to request the default direction for camera dolly (zoom) operations to be towards the camera pivot point. If unset the default direction would normally be towards the cursor position.
 *  @param {boolean} state - value of the option, true for towards the pivot, false for default
 */
Navigation.prototype.setZoomTowardsPivot = function( state )
{
    this.__options.dollyToPivot = !!state;
};

/**
 * Get the state of the view navigation option that requests the default direction for camera dolly (zoom) operations to be towards the camera pivot point.
 *  @returns {boolean} - value of the option, true for towards the pivot, false for default
 */
Navigation.prototype.getZoomTowardsPivot = function()
{
    return this.__options.dollyToPivot;
};

/**
 * Set or unset a view navigation option to allow the orbit controls to move the camera beyond the north and south poles (world up/down direction). In other words, when set the orbit control will allow the camera to rotate into an upside down orientation. When unset orbit navigation should stop when the camera view direction reaches the up/down direction.
 *
 * Not applicable to 2D.
 *
 *  @param {boolean} state - value of the option, true to allow orbiting past the poles.
 */
Navigation.prototype.setOrbitPastWorldPoles = function( state )
{
    if( this.getIs2D() )
    {
        avp.logger.warn("Autodesk.Viewing.Navigation.setOrbitPastWorldPoles is not applicable to 2D");
        return;
    }

    this.__options.orbitPastPoles = !!state;
};

/**
 * Get the state of the view navigation option that allows orbit controls to continue past the world up/down direction.
 *
 * Not applicable to 2D.
 *
 *  @returns {boolean} - value of the option, true if orbiting past the poles is allowed.
 */
Navigation.prototype.getOrbitPastWorldPoles = function()
{
    if( this.getIs2D() )
    {
        avp.logger.warn("Autodesk.Viewing.Navigation.orbitPastWorldPoles is not applicable to 2D");
        return false;
    }

    return this.__options.orbitPastPoles;
};

/**
 * Set or unset a view navigation option which requests that orbit controls always orbit around the currently set pivot point.
 *  @param {boolean} state - value of the option, true to request use of the pivot point. When false some controls may pivot around the center of the view. (Currently applies only to the view-cube orbit controls.)
 */
Navigation.prototype.setUsePivotAlways = function( state )
{
    this.__options.usePivotAlways = !!state;
};

/**
 * Get the state of the view navigation option that requests full use of the pivot point.
 *  @returns {boolean} - value of the option, if the pivot should be used as the orbit origin.
 */
Navigation.prototype.getUsePivotAlways = function()
{
    return this.__options.usePivotAlways;
};

/**
 * Set or unset a view navigation option which requests that mouse buttons be reversed from their default assignment. i.e. Left mouse operation becomes right mouse and vice versa.
 *  @param {boolean} state - value of the option, true to request reversal of mouse button assignments.
 */
Navigation.prototype.setUseLeftHandedInput = function( state )
{
    this.__options.useLeftHandedInput = !!state;
};

/**
 * Get the state of the view navigation option that requests mouse button reversal.
 *  @returns {boolean} - value of the option, true if reversal is requested.
 */
Navigation.prototype.getUseLeftHandedInput = function()
{
    return this.__options.useLeftHandedInput;
};

/**
 * Lock or unlock view modification operations.
 * For a more granular control of locked operations, see {@link setLockSettings}.
 *  @param {boolean} state - when true changes to the current camera parameters are not allowed.
 */
Navigation.prototype.setIsLocked = function( state )
{
    this.__options.lockNavigation = !!state;
};

/**
 * Get the state of the current view modification lock.
 * For a more granular control of locked operations, see {@link setLockSettings}.
 *  @returns {boolean} - true if view modifications are not currently allowed.
 */
Navigation.prototype.getIsLocked = function()
{
    return this.__options.lockNavigation;
};

/**
 * Set the availability of specific camera actions when navigation is locked using {@link setIsLocked}.
 *  @param {object} settings Map of <action>:<bool> pairs specifying whether the given camera
 *  action is *enabled* even when the navigation is locked.
 *  The configurable actions are 'orbit', 'pan', 'zoom', 'roll', 'fov', or 'gotoview'.
 *  By default, none of the camera actions are available when the navigation is locked.
 */
Navigation.prototype.setLockSettings = function(settings)
{
    for (var action in this.__lockSettings) {
        if (settings.hasOwnProperty(action)) {
            this.__lockSettings[action] = settings[action];
        }
    }
};

/**
 * Get the availability of specific camera actions when navigation is locked using {@link setIsLocked}.
 *  @returns {object} Map of <action>:<bool> pairs specifying whether the given camera
 *  action is *enabled* even when the navigation is locked.
 */
Navigation.prototype.getLockSettings = function()
{
    var settings = {};
    for (var action in this.__lockSettings) {
        settings[action] = this.__lockSettings[action];
    }
    return settings;
};

/**
 * Check the availability of a camera action.
 *  @param {string} action Camera action.
 *  @returns {boolean} True if the camera action is currently enabled.
 */
Navigation.prototype.isActionEnabled = function(action) {
    return !this.__options.lockNavigation || this.__lockSettings[action] === true;
};

/**
 * Set or unset a view navigation option which indicates that the pivot camera parameter is set and can be used for orbit and zoom controls.
 *  @param {boolean} state - value of the option. When not set orbit and zoom operations should occur at the look at position in the center of the current view.
 */
Navigation.prototype.setPivotSetFlag = function( state )
{
    this.__pivotIsSetFlag = !!state;
};

/**
 * Get the state of the view navigation option that indicates the pivot is set.
 *  @returns {boolean} - value of the option, true if pivot may be used.
 */
Navigation.prototype.getPivotSetFlag = function()
{
    return this.__pivotIsSetFlag;
};

/**
 * Issue a request to change the current cameras view position to fit the active model data into the current view frustum.
 *  @param {boolean} state - value of the requst. Set to true in order to request the change of view.
 */
Navigation.prototype.setRequestFitToView = function( state )
{
    if( this.isActionEnabled('gotoview') )
        this.__fitToViewRequested = !!state;
};

/**
 * Get the state of the view navigation option requesting a camera repositioning to fit the active model data. Value will be false if a request has not been made or if having been made has been received and acted upon.
 *  @returns {boolean} - current state of the request.
 */
Navigation.prototype.getRequestFitToView = function()
{
    return this.__fitToViewRequested;
};

/**
 * Issue a request to change the current cameras view to the current "home" view. The home view includes position, view direction, world up direction and field of view.
 *  @param {boolean} state - value of the requst. Set to true in order to request the change of view.
 */
Navigation.prototype.setRequestHomeView = function( state )
{
    if( this.isActionEnabled('gotoview') )
        this.__homeViewRequested = !!state;
};

/**
 * Get the state of the view navigation option requesting a camera change to the current "home" view. Value will be false if a request has not been made or if having been made has been received and acted upon.
 *  @returns {boolean} - current state of the request.
 */
Navigation.prototype.getRequestHomeView = function()
{
    return this.__homeViewRequested;
};

/**
 * Issue a request to transition the current cameras view to that specified by the parameters.
 *  @param {boolean} state - value of the requst. Set to true in order to request the change of view.
 *  @param {THREE.Vector3} pos - the new camera position in world space
 *  @param {THREE.Vector3} coi - the point in world space that the camera should look towards.
 *  @param {number} fov - vertical field of view in degrees
 *  @param {boolean} reorient - set to true to recalculate up vector
 *  @param {THREE.Vector3} pivot - the new pivot point
 */
Navigation.prototype.setRequestTransition = function( state, pos, coi, fov, reorient, pivot )
{
    if( state )
    {
        this.__destinationView = {
            position: pos.clone(),
                 coi: coi.clone(),
                 fov: fov,
                  up: this.getCamera().up.clone(),
             worldUp: this.getWorldUpVector(),
            reorient: reorient,
               pivot: pivot ? pivot.clone() : coi.clone()
        };
    }
    else
        this.__destinationView = null;
};

/**
 * Issue a request to transition the current cameras view to that specified by the parameters which inlude both the camera up direction and optionally the world up direction.
 *  @param {boolean} state - value of the requst. Set to true in order to request the change of view.
 *  @param {THREE.Vector3} pos - the new camera position in world space
 *  @param {THREE.Vector3} coi - the point in world space that the camera should look towards.
 *  @param {number} fov - vertical field of view in degrees
 *  @param {THREE.Vector3} up -  use this as the target camera up direction
 *  @param {THREE.Vector3} worldUp - (optional) use this as the target world up direction
 *  @param {THREE.Vector3} pivot - the new pivot point
 */
Navigation.prototype.setRequestTransitionWithUp = function( state, pos, coi, fov, up, worldUp, pivot )
{
    if( state )
    {
        this.__destinationView = {
            position: pos.clone(),
                 coi: coi.clone(),
                 fov: fov,
                  up: up.clone(),
             worldUp: worldUp ? worldUp : this.getWorldUpVector(),
            reorient: false,
               pivot: pivot ? pivot.clone() : coi.clone()
        };
    }
    else
        this.__destinationView = null;
};

/**
 * Get the state of the view navigation option requesting a camera transition to a new view.
 *  @returns {Object} - If a transition request is active, an object with properties "position" (Vector3), "coi" (Vector3), "fov" (Number), "up" (Vector3), "worldUp" (Vector3), "reorient" (boolean). Returns null when no transition is active.
 *  @see setRequestTransitionWithUp
 */
Navigation.prototype.getRequestTransition = function()
{
    return this.__destinationView;
};

/**
 * Set a status indicating that the current camera view is in a transitioning state.
 * Used internally to indicate that a transition is active.
 *  @param {boolean} state - value of the transtion status
 */
Navigation.prototype.setTransitionActive = function( state )
{
    this.__transitionActive = !!state;
};

/**
 *  Check the status of a view transition request.
 *  @returns {boolean} - value of the transtion status
 */
Navigation.prototype.getTransitionActive = function()
{
    return this.__transitionActive;
};

/**
 *  @param {number} atDistance - Distance from the camera at which to compute the view frustum size.
 *  @returns {THREE.Vector2} The size of the view frustum at this distance from the camera.
 */
Navigation.prototype.getWorldSize = function(atDistance)
{
    var viewport = this.getScreenViewport();
    var aspect = viewport.width / viewport.height;
    var worldHeight = 2.0 * atDistance * Math.tan(THREE.Math.degToRad(this.getCamera().fov * 0.5));
    var worldWidth  = worldHeight * aspect;

    return new THREE.Vector2(worldWidth, worldHeight);
};

/**
 *  Get a world point from normalized screen coordinates by projecting to the plane at the pivot point.
 *  @param {number} x - Normalized screen X coordinate in [0, 1] range (left == 0)
 *  @param {number} y - Normalized screen Y coordinate in [0, 1] range (top == 0)
 *  @returns {THREE.Vector3} - Point in world space
 */
Navigation.prototype.getWorldPoint = function(x, y)
{
    /*
    var x = (mouseX - this.viewport.left) / this.viewport.width;
    var y = (mouseY - this.viewport.top) / this.viewport.height;
    */
    y = 1.0 - y;    // Invert Y so 0 == bottom and map to [-1, 1]
    x = x * 2.0 - 1.0;
    y = y * 2.0 - 1.0;
    var camera = this.getCamera();
    var clickPoint;

    if( camera.isPerspective )
    {
        clickPoint = new THREE.Vector3(x, y, 1.0);
        clickPoint = clickPoint.unproject(camera);
    }
    var view     = this.getEyeVector();
    var position = this.getPosition();
    var direction, distance;

    if( !camera.isPerspective || isNaN(clickPoint.x) )
    {
        // Calculate a point based on the view...
        var xysize = this.getWorldSize(view.length());
        var trackX = this.getCameraRightVector(false).multiplyScalar( (x * 0.5) * xysize.x );
        var trackY = this.getCameraUpVector().multiplyScalar( (y * 0.5) * xysize.y );
        direction = view.clone().add(trackX).add(trackY).normalize();
        // avp.logger.log("GWP: ALT(" + direction.x.toFixed(3) + ", "+ direction.y.toFixed(3) + ", "+ direction.z.toFixed(3) + ")" + x + ", " + y);
    }
    else
    {
        direction = clickPoint.sub(position).normalize();
        // avp.logger.log("GWP: DIR(" + direction.x.toFixed(3) + ", "+ direction.y.toFixed(3) + ", "+ direction.z.toFixed(3) + ")");
    }
    var pivot = this.getPivotPoint();
    var usePivot = this.__pivotIsSetFlag && (this.getIs2D() || (camera.isPerspective && this.isPointVisible(pivot)));
    if( usePivot )
    {
        var denominator = direction.dot(view);
        distance = (denominator !== 0.0)
                 ? Math.abs(pivot.sub(position).dot(view)) / denominator
                 : pivot.sub(position).length();
    }
    else
    {
        distance = camera.isPerspective ? (camera.near + camera.far) * 0.5
                                        : camera.orthoScale;
    }
    return direction.multiplyScalar(distance).add(position);
};

/**
 * @returns {number} - The perpendicular distance from the camera to the plane containing the pivot point.
 */
Navigation.prototype.getPivotPlaneDistance = function()
{
    var pivot = this.getPivotPoint();
    var view  = this.getEyeVector();
    var position = this.getPosition();

    return pivot.sub(position).dot(view.normalize());
};

/**
 * Pan the camera a relative distance up/down or left/right.
 *  @param {number} deltaX - Normalized X distance to pan left/right (negative/positive).
 *  @param {number} deltaY - Normalized Y distance to pan down/up (negative/positive).
 *  @param {number} atDistance - Pan distance is scaled by the size of the view frustum at this distance from the camera.
 */
Navigation.prototype.panRelative = function( deltaX, deltaY, atDistance )
{
    if (!this.isActionEnabled('pan')) {
        return;
    }

    var trackSpeed = this.getWorldSize(atDistance);
    var offsetX = deltaX * trackSpeed.x;
    var offsetY = deltaY * trackSpeed.y;

    var trackX = this.getCameraRightVector(false).multiplyScalar( offsetX );
    var trackY = this.getCameraUpVector().multiplyScalar( offsetY );

    var offsetVector = trackX.add(trackY);

    // restrict panning if we use 2D mode with constraints
    this.applyPanningConstraint2D(offsetVector);

    this.setView( this.getPosition().add(offsetVector), this.getTarget().add(offsetVector) );
};

/**
 * Dolly the camera a distance along the vector from a given point to its current position. The dolly distance is clamped to not go past the point.
 *  @param {number} distance - World space distance to move the camera by.
 *  @param {THREE.Vector3} point - World space position used to define the dolly direction.
 */
Navigation.prototype.dollyFromPoint = function( distance, point , bounds)
{
    if( !this.isActionEnabled('zoom') || Math.abs(distance) <= this.__kEpsilon )
        return;

    var position = this.getPosition();
    var dollyVec = point.clone().sub(position);
    var oldLength = dollyVec.length();
    var newLength = oldLength + distance;
    if( newLength < this.__minDistance )
        newLength = this.__minDistance;

    var scaleFactor = newLength / oldLength;

    // restrict min/max distance if a viewRegion or maxPixelPerUnit constraint is set.
    scaleFactor = this.applyDollyConstraint(scaleFactor, bounds);

    if( Math.abs(scaleFactor - 1.0) > this.__kEpsilon )
    {
        dollyVec.multiplyScalar( scaleFactor );
        dollyVec.set(-dollyVec.x, -dollyVec.y, -dollyVec.z);
        var newPosition = dollyVec.add(point);

        // Compute a new look at point from the new position:
        var viewVec = this.getEyeVector();

        // For ortho cameras we must scale the view vector to actually
        // perform an ortho zoom operation:
        if( !this.getCamera().isPerspective )
            viewVec.multiplyScalar( scaleFactor );

        this.setView( newPosition, viewVec.add(newPosition) );
    }
};

/**
 *  Change current camera to perspective camera.
 *
 *  Not applicable to 2D.
 */
Navigation.prototype.toPerspective = function()
{
    if( this.getIs2D() )
    {
        avp.logger.warn("Autodesk.Viewing.Navigation.toPerspective is not applicable to 2D");
        return;
    }

    var camera = this.getCamera();

    if( !camera.isPerspective )
    {
        camera.toPerspective();
        camera.dirty = true;
    }
};

/**
 *  Change current camera to orthographic camera
 */
Navigation.prototype.toOrthographic = function()
{
    var camera = this.getCamera();

    if( camera.isPerspective )
    {
        camera.toOrthographic();
        camera.dirty = true;
    }
};


Navigation.snapToAxis = function(v) {
    var absv = new THREE.Vector3(Math.abs(v.x), Math.abs(v.y), Math.abs(v.z));

    if (absv.x > absv.y && absv.x > absv.z)
        v.set(v.x > 0 ? 1 : -1, 0, 0);
    else if (absv.y > absv.x && absv.y > absv.z)
        v.set(0, v.y > 0 ? 1 : -1, 0);
    else
        v.set(0, 0, v.z > 0 ? 1 : -1);

    return v;
};

Autodesk.Viewing.Navigation = Navigation;

})();
;

(function() {

"use strict";

var av = Autodesk.Viewing,
    avp = av.Private;


/**
 * The ExtensionManager manages a set of extensions available to the viewer.
 * Register, retrieve, and unregister your extension using the singleton theExtensionManager.
 *
 * You can load/unload your registered extension into a Viewer by calling
 * {@link Autodesk.Viewing.Viewer#loadExtension|viewer.loadExtension(id, options)} and
 * {@link Autodesk.Viewing.Viewer#unloadExtension|viewer.unloadExtension(id)}, respectively.
 * @constructor
 */
var ExtensionManager = function () {
    var extensions = {};

    /**
     * Registers a new extension with the given id.
     *
     * @param {string} extensionId - The string id of the extension.
     * @param {Extension} extension - The Extension-derived class representing the extension.
     * @returns {boolean} - True if the extension was successfully registered.
     */
    function registerExtension(extensionId, extension) {
        if (!extensions.hasOwnProperty(extensionId)) {
            extensions[extensionId] = extension;
            return true;
        }
        return false;
    }

    /**
     * Returns the class representing the extension with the given id.
     *
     * @param {string} extensionId - The string id of the extension.
     * @returns {!Extension} - The Extension-derived class if one was registered; null otherwise.
     */
    function getExtension(extensionId) {
        if (extensions.hasOwnProperty(extensionId)) {
            return extensions[extensionId];
        }
        return null;
    }

    /**
     * Unregisters an existing extension with the given id.
     *
     * @param {string} extensionId - The string id of the extension.
     * @returns {boolean} - True if the extension was successfully unregistered.
     */
    function unregisterExtension(extensionId) {
        if (extensions.hasOwnProperty(extensionId)) {
            delete extensions[extensionId];
            return true;
        }
        return false;
    }

    return {
        registerExtension: registerExtension,
        getExtension: getExtension,
        unregisterExtension: unregisterExtension
    };
};

var theExtensionManager =  new ExtensionManager();

/***
 * Augments a class by extension load/unload functionality.
 */
var ExtensionMixin = function() {};

ExtensionMixin.prototype = {

    /**
     * Loads the extension with the given id and options.
     * For internal use only.
     *
     * @param {string} extensionId - The string id of the extension.
     * @param {Object} options - An optional dictionary of options.
     *
     * @returns {boolean} - True if the extension was successfully loaded.
     */
    loadExtension : function (extensionId, options) {

        if (!this.loadedExtensions)
            this.loadedExtensions = {};

        var success = false;
        if (!this.getExtension(extensionId)) {
            var extensionClass = theExtensionManager.getExtension(extensionId);
            if (extensionClass) {
                var extension = new extensionClass(this, options);
                extension.id = extensionId;
                success = extension.load();
                if (success) {
                    this.loadedExtensions[extensionId] = extension;
                    avp.logger.info('Extension loaded: ' + extensionId);
                    this.fireEvent({ type: av.EXTENSION_LOADED_EVENT, extensionId: extensionId });
                }
            } else {
                avp.logger.warn('Extension not found: ' + extensionId);
            }
        } else {
            avp.logger.info('Extension already loaded: ' + extensionId);
        }
        return success;
    },

    /**
     * Returns the loaded extension.
     * @param {string} extensionId - The string id of the extension.
     * @returns {?Object} - Extension.
     */
    getExtension : function (extensionId) {
        return (this.loadedExtensions && extensionId in this.loadedExtensions) ? this.loadedExtensions[extensionId] : null;
    },

    /**
     * Unloads the extension with the given id.
     * For internal use only.
     *
     * @param {string} extensionId - The string id of the extension.
     * @returns {boolean} - True if the extension was successfully unloaded.
     */
    unloadExtension : function (extensionId) {
        var success = false;
        var ext = this.getExtension(extensionId);
        if (ext) {
            success = ext.unload();
            avp.logger.info('Extension unloaded: ' + extensionId);
            delete this.loadedExtensions[extensionId];
            this.fireEvent({ type: av.EXTENSION_UNLOADED_EVENT, extensionId: extensionId });
        } else {
            avp.logger.warn('Extension not found: ' + extensionId);
        }
        return success;
    },


    apply : function(object) {

        var me = ExtensionMixin.prototype;

        object.loadExtension = me.loadExtension;
        object.getExtension = me.getExtension;
        object.unloadExtension = me.unloadExtension;
    }

};


Autodesk.Viewing.theExtensionManager = theExtensionManager;
Autodesk.Viewing.ExtensionMixin = ExtensionMixin;

})();
;

(function() {

"use strict";

var av = Autodesk.Viewing,
    avp = av.Private;

var fsNames = ['fullscreenchange', 'mozfullscreenchange', 'webkitfullscreenchange', 'MSFullscreenChange'];

function addListener(listener) {
    for (var i=0; i<fsNames.length; ++i)
        document.addEventListener(fsNames[i], listener, false);
}

function removeListener(listener) {
    for (var i=0; i<fsNames.length; ++i)
        document.removeEventListener(fsNames[i], listener, false);
}


/**
 * List of available screen modes: normal, full browser, and full screen.
 * @readonly
 * @memberof Autodesk.Viewing
 * @enum {number}
 */
av.ScreenMode = {kNormal: 0, kFullBrowser: 1, kFullScreen: 2};


/**
 * Virtual base class for screen mode manipulation.
 *
 * Derive from this class and use it to allow viewer to go full screen.
 * @constructor
 * @param {Autodesk.Viewing.Viewer3D} viewer - Viewer instance.
 * @memberof Autodesk.Viewing
 * @alias Autodesk.Viewing.ScreenModeDelegate
 * @category Core
 */
function ScreenModeDelegate(viewer) {
    this.viewer = viewer;
    this.bindFullscreenEventListener = this.fullscreenEventListener.bind(this);

    if (this.getMode() === av.ScreenMode.kFullScreen) {
        addListener(this.bindFullscreenEventListener);
    }
}

av.ScreenModeDelegate = ScreenModeDelegate;

/**
 * Perform any cleanup required for a {@link Autodesk.Viewing.ScreenModeDelegate} instance.
 */
ScreenModeDelegate.prototype.uninitialize = function () {

    removeListener(this.bindFullscreenEventListener);
    this.viewer = null;
};

/**
 * Is screen mode supported?
 * Returning false for normal mode means no screen mode changes are supported.
 * @param {Autodesk.Viewing.ScreenMode} mode - Desired screen mode.
 * @returns {boolean} True if screen mode is supported.
 */
ScreenModeDelegate.prototype.isModeSupported = function (mode) {
    return true;
};

/**
 * Set new screen mode.
 * @param {Autodesk.Viewing.ScreenMode} mode - New screen mode.
 * @returns {boolean} True if screen mode was changed.
 */
ScreenModeDelegate.prototype.setMode = function (mode) {
    var currentMode = this.getMode();
    if ((mode !== currentMode) && this.isModeSupported(mode)) {
        this.doScreenModeChange(currentMode, mode);
        this.onScreenModeChanged(currentMode, mode);
        return true;
    }
    return false;
};

/**
 * Override this method to get the current screen mode.
 * @returns {Autodesk.Viewing.ScreenMode} Current screen mode.
 */
ScreenModeDelegate.prototype.getMode = function () {
    throw 'Implement getMode() in derived class';
};

/**
 * Return next screen mode in sequence.
 * Depending on what modes are supported, this may be a toggle or a 3-state.
 * @returns {Autodesk.Viewing.ScreenMode|undefined} Next screen mode in sequence or undefined if no change.
 */
ScreenModeDelegate.prototype.getNextMode = function () {
    var currentMode = this.getMode(),
        newMode;

    var SM = av.ScreenMode;

    if (currentMode === SM.kNormal &&
        this.isModeSupported(SM.kFullBrowser)) {

        newMode = SM.kFullBrowser;

    } else if (currentMode === SM.kNormal &&
        this.isModeSupported(SM.kFullScreen)) {

        newMode = SM.kFullScreen;

    } else if (currentMode === SM.kFullBrowser &&
        this.isModeSupported(SM.kFullScreen)) {

        newMode = SM.kFullScreen;

    } else if (currentMode === SM.kFullBrowser &&
        this.isModeSupported(SM.kNormal)) {

        newMode = SM.kNormal;

    } else if (currentMode === SM.kFullScreen &&
        this.isModeSupported(SM.kNormal)) {

        newMode = SM.kNormal;

    } else if (currentMode === SM.kFullScreen &&
        this.isModeSupported(SM.kFullBrowser)) {

        newMode = SM.kFullBrowser;
    }
    return newMode;
};

/**
 * Return new screen mode on escape.
 * @returns {Autodesk.Viewing.ScreenMode|undefined} New screen mode or undefined if no change.
 */
ScreenModeDelegate.prototype.getEscapeMode = function () {
    return (this.getMode() !== av.ScreenMode.kNormal) ?
        av.ScreenMode.kNormal : undefined;
};

/**
 * Full screen event listener.
 */
ScreenModeDelegate.prototype.fullscreenEventListener = function () {
    if (av.inFullscreen()) {
        this.viewer.resize();
    } else {
        var ScreenMode = av.ScreenMode;
        this.doScreenModeChange(ScreenMode.kFullScreen, ScreenMode.kNormal);
        this.onScreenModeChanged(ScreenMode.kFullScreen, ScreenMode.kNormal);
    }
};

/**
 * Override this method to make the screen mode change occur.
 * @param {Autodesk.Viewing.ScreenMode} oldMode - Old screen mode.
 * @param {Autodesk.Viewing.ScreenMode} newMode - New screen mode.
 */
ScreenModeDelegate.prototype.doScreenModeChange = function (oldMode, newMode) {
    throw 'Implement doScreenModeChange() in derived class';
};

/**
 * Called after the screen mode changes.
 * @param {Autodesk.Viewing.ScreenMode} oldMode - Old screen mode.
 * @param {Autodesk.Viewing.ScreenMode} newMode - New screen mode.
 */
ScreenModeDelegate.prototype.onScreenModeChanged = function (oldMode, newMode) {
    if (oldMode === av.ScreenMode.kFullScreen) {
        removeListener(this.bindFullscreenEventListener);
    } else if (newMode === av.ScreenMode.kFullScreen) {
        addListener(this.bindFullscreenEventListener);
    }

    this.viewer.resize();
    this.viewer.fireEvent({type: av.FULLSCREEN_MODE_EVENT, mode: newMode});
};





/**
 * Screen mode delegate allowing the viewer to go full screen.
 *
 * Unlike ViewerScreenModeDelegate class, this delegate
 * doesn't use the full browser state, and it takes the entire page full screen, not just
 * the viewer.
 * @constructor
 * @extends Autodesk.Viewing.ScreenModeDelegate
 * @memberof Autodesk.Viewing
 * @alias Autodesk.Viewing.AppScreenModeDelegate
 * @param {Autodesk.Viewing.Viewer3D} viewer - Viewer instance.
 * @category Core
 */
av.AppScreenModeDelegate = function (viewer) {
    av.ScreenModeDelegate.call(this, viewer);
};

av.AppScreenModeDelegate.prototype = Object.create(av.ScreenModeDelegate.prototype);
av.AppScreenModeDelegate.prototype.constructor = av.AppScreenModeDelegate;

av.AppScreenModeDelegate.prototype.isModeSupported = function (mode) {
    return mode !== av.ScreenMode.kFullBrowser;
};

av.AppScreenModeDelegate.prototype.getMode = function () {
    return av.inFullscreen() ?
        av.ScreenMode.kFullScreen :
        av.ScreenMode.kNormal;
};

av.AppScreenModeDelegate.prototype.doScreenModeChange = function (oldMode, newMode) {
    var container = this.viewer.container;
    if (newMode === av.ScreenMode.kNormal) {
        container.classList.remove('viewer-fill-browser');
        av.exitFullscreen();
    } else if (newMode === av.ScreenMode.kFullScreen) {
        container.classList.add('viewer-fill-browser');
        av.launchFullscreen(container);
    }
};

// Keep the old class name for backwards compatibility
av.ApplicationScreenModeDelegate = av.AppScreenModeDelegate;


/**
 * Screen mode delegate with no full screen functionality.
 * @constructor
 * @extends Autodesk.Viewing.ScreenModeDelegate
 * @memberof Autodesk.Viewing
 * @alias Autodesk.Viewing.NullScreenModeDelegate
 * @param {Autodesk.Viewing.Viewer3D} viewer - Viewer instance.
 * @category Core
 */
av.NullScreenModeDelegate = function (viewer) {
    av.ScreenModeDelegate.call(this, viewer);
};

av.NullScreenModeDelegate.prototype = Object.create(av.ScreenModeDelegate.prototype);
av.NullScreenModeDelegate.prototype.constructor = av.ScreenModeDelegate;


av.NullScreenModeDelegate.prototype.isModeSupported = function (mode) {
    return false; // No screen modes supported
};

av.NullScreenModeDelegate.prototype.getMode = function () {
    return av.ScreenMode.kNormal;
};





av.ScreenModeMixin = function() {
};


av.ScreenModeMixin.prototype = {

    /**
     * Set new screen mode delegate.
     * @param {Autodesk.Viewing.ScreenModeDelegate} delegate - New screen mode delegate class.
     */
    setScreenModeDelegate : function (delegate) {
        if (this.screenModeDelegate) {
            this.screenModeDelegate.uninitialize();
            this.screenModeDelegate = null;
        }

        // null -> Fullscreen not available
        // undefined -> Use default AppScreenModeDelegate
        //
        if (delegate) {
            this.screenModeDelegateClass = delegate;
        } else if (delegate === null) {
            this.screenModeDelegateClass = av.NullScreenModeDelegate;
        } else { // undefined
            this.screenModeDelegateClass = av.AppScreenModeDelegate;
        }
    },

    /**
     * Get current screen mode delegate.
     * If no screen mode delegate has been set, then use {@link Autodesk.Viewing.ViewerScreenModeDelegate}.
     * @returns {Autodesk.Viewing.ScreenModeDelegate} Current screen mode delegate.
     */
    getScreenModeDelegate : function () {
        if (!this.screenModeDelegate) {
            this.screenModeDelegate = new this.screenModeDelegateClass(this);
        }
        return this.screenModeDelegate;
    },


    /**
     * Is specified screen mode supported?
     * @param {Autodesk.Viewing.ScreenMode} mode - Desired screen mode.
     * @returns {boolean} True if screen mode is supported.
     */
    isScreenModeSupported : function (mode) {
        return this.getScreenModeDelegate().isModeSupported(mode);
    },

    /**
     * Is changing screen modes supported?
     * @returns {boolean} True if viewer supports changing screen modes.
     */
    canChangeScreenMode :  function () {
        return this.isScreenModeSupported(Autodesk.Viewing.ScreenMode.kNormal);
    },

    /**
     * Set new screen mode.
     * @param {Autodesk.Viewing.ScreenMode} mode - New screen mode.
     * @returns {boolean} True if screen mode was changed.
     */
    setScreenMode : function (mode) {
        var msg = {
            category: "screen_mode",
            value: mode
        };
        avp.logger.track(msg);

        return this.getScreenModeDelegate().setMode(mode);
    },

    /**
     * Get current screen mode.
     * @returns {Autodesk.Viewing.ScreenMode} Current screen mode.
     */
    getScreenMode : function () {
        return this.getScreenModeDelegate().getMode();
    },

    /**
     * Set screen mode to next in sequence.
     * @returns {boolean} True if screen mode was changed.
     */
    nextScreenMode : function () {
        var mode = this.getScreenModeDelegate().getNextMode();
        return (mode !== undefined) ? this.setScreenMode(mode) : false;
    },

    /**
     * Screen mode escape key handler.
     * @returns {boolean} True if screen mode was changed.
     */
    escapeScreenMode : function () {
        var mode = this.getScreenModeDelegate().getEscapeMode();
        return (mode !== undefined) ? this.setScreenMode(mode) : false;
    },


    apply : function(object) {

        var p = av.ScreenModeMixin.prototype;
        object.setScreenModeDelegate = p.setScreenModeDelegate;
        object.getScreenModeDelegate = p.getScreenModeDelegate;
        object.isScreenModeSupported = p.isScreenModeSupported;
        object.canChangeScreenMode = p.canChangeScreenMode;
        object.setScreenMode = p.setScreenMode;
        object.getScreenMode = p.getScreenMode;
        object.nextScreenMode = p.nextScreenMode;
        object.escapeScreenMode = p.escapeScreenMode;
    }

};



})();
;
/** @license Copyright (c) 2013 Autodesk Inc. */
/** Version : @buildnum@ */

// Viewer3D offers public methods for developers to use.
// Viewer3DImpl is the implementation file for Viewer3D and is only used by Viewer3D.js
// 
// Viewer3D does things like parameter validation.
// Viewer3DImpl does the actual work, by interfacing with other internal components, such as the MaterialManager.

(function() {

    "use strict";

    var av = Autodesk.Viewing,
        avp = av.Private;

    // Event types supported by this class.

    /**
     * Fired when the ESC key is pressed.
     * @event Autodesk.Viewing.Viewer3D#ESCAPE_EVENT
     */
    av.ESCAPE_EVENT                   = 'escape';
    /**
     * Fired repeatedly throughout the process of opening a model/drawing.
     * @event Autodesk.Viewing.Viewer3D#PROGRESS_UPDATE_EVENT
     * @property {number} percent - Estimated progress.
     */
    av.PROGRESS_UPDATE_EVENT          = 'progress';
    /**
     * Fired when the screen mode changes.
     * @event Autodesk.Viewing.Viewer3D#FULLSCREEN_MODE_EVENT
     * @property {Autodesk.Viewing.ScreenMode} mode - New screen mode.
     */
    av.FULLSCREEN_MODE_EVENT          = 'fullScreenMode';
    /**
     * Fired then the navigation tool changes.
     * @event Autodesk.Viewing.Viewer3D#NAVIGATION_MODE_CHANGED_EVENT
     * @property {string} id - Tool identifier.
     */
    av.NAVIGATION_MODE_CHANGED_EVENT  = 'navmode';
    /**
     * Fired when the viewer state is restored.
     * @event Autodesk.Viewing.Viewer3D#VIEWER_STATE_RESTORED_EVENT
     * @property {bool} value - Success of the state restoration.
     */
    av.VIEWER_STATE_RESTORED_EVENT    = 'viewerStateRestored';
    /**
     * Fired when the viewer size changes.
     * @event Autodesk.Viewing.Viewer3D#VIEWER_RESIZE_EVENT
     * @property {number} width - New width of the viewer.
     * @property {number} height - New height of the viewer.
     */
    av.VIEWER_RESIZE_EVENT            = 'viewerResize';
    /**
     * Fired when the viewer is fully initialized.
     * @event Autodesk.Viewing.Viewer3D#VIEWER_INITIALIZED
     */
    av.VIEWER_INITIALIZED             = 'viewerInitialized';
    /**
     * Fired when the viewer is fully uninitialized.
     * @event Autodesk.Viewing.Viewer3D#VIEWER_UNINITIALIZED
     */
    av.VIEWER_UNINITIALIZED           = 'viewerUninitialized';

    /**
     * Fired when the viewer receives and parses the initial model manifest.
     * @event Autodesk.Viewing.Viewer3D#MODEL_ROOT_LOADED_EVENT
     * @property {object} svf - Parsed SVF/F2D JSON.
     * @property {object} model - Model data.
     */
    av.MODEL_ROOT_LOADED_EVENT        = 'svfLoaded';
    /**
     * Fired when the model/drawing finishes loading.
     * @event Autodesk.Viewing.Viewer3D#GEOMETRY_LOADED_EVENT
     * @property {object} model - Model data.
     */
    av.GEOMETRY_LOADED_EVENT          = 'geometryLoaded';
    /**
     * Fired when the instance tree is successfully created.
     * @event Autodesk.Viewing.Viewer3D#OBJECT_TREE_CREATED_EVENT
     * @property {object} svf - Parsed SVF/F2D JSON.
     * @property {object} model - Model data.
     */
    av.OBJECT_TREE_CREATED_EVENT      = 'propertyDbLoaded';
    /**
     * Fired when there's an error while parsing the instance tree.
     * @event Autodesk.Viewing.Viewer3D#OBJECT_TREE_UNAVAILABLE_EVENT
     * @property {object} svf - Parsed SVF/F2D JSON.
     * @property {object} model - Model data.
     */
    av.OBJECT_TREE_UNAVAILABLE_EVENT  = 'propertyDbUnavailable';
    /**
     * Fired when a model is removed from the viewer.
     * @event Autodesk.Viewing.Viewer3D#MODEL_UNLOADED_EVENT
     * @property {object} model - Model data.
     */
    av.MODEL_UNLOADED_EVENT           = 'modelUnloaded';
    /**
     * Fired when a viewer extension is successfully loaded.
     * @event Autodesk.Viewing.Viewer3D#EXTENSION_LOADED_EVENT
     * @property {string} extensionId - Extension identifier.
     */
    av.EXTENSION_LOADED_EVENT         = 'extensionLoaded';
    /**
     * Fired when a viewer extension is successfully unloaded.
     * @event Autodesk.Viewing.Viewer3D#EXTENSION_UNLOADED_EVENT
     * @property {string} extensionId - Extension identifier.
     */
    av.EXTENSION_UNLOADED_EVENT       = 'extensionUnloaded';

    /**
     * Fired when the list of selected objects changes.
     * @event Autodesk.Viewing.Viewer3D#SELECTION_CHANGED_EVENT
     * @property {number[]} fragIdsArray - Fragment IDs of selected objects.
     * @property {number[]} dbIdArray - dbIDs of selected objects.
     * @property {number[]} nodeArray - Same as dbIdArray.
     * @property {object} model - Model data.
     */
    av.SELECTION_CHANGED_EVENT     = 'selection';
    /**
     * Fired when the list of selected objects changes in a multi-model context.
     * @event Autodesk.Viewing.Viewer3D#AGGREGATE_SELECTION_CHANGED_EVENT
     * @property {object[]} selections - List of objects containing the typical selection properties
     *   of {@link Autodesk.Viewing.Viewer3D#SELECTION_CHANGED_EVENT} for each model.
     */
    av.AGGREGATE_SELECTION_CHANGED_EVENT = 'aggregateSelection';
    /**
     * Fired when the viewer isolates a set of objects (i.e., makes everything else invisible or ghosted).
     * @event Autodesk.Viewing.Viewer3D#ISOLATE_EVENT
     * @property {number[]} nodeIdArray - List of isolated node IDs.
     * @property {object} model - Model data.
     */
    av.ISOLATE_EVENT               = 'isolate';
    /**
     * Fired when the viewer hides a set of objects.
     * @event Autodesk.Viewing.Viewer3D#HIDE_EVENT
     * @property {number[]} nodeIdArray - List of hidden node IDs.
     */
    av.HIDE_EVENT                  = 'hide';
    /**
     * Fired when the viewer shows a set of objects.
     * @event Autodesk.Viewing.Viewer3D#SHOW_EVENT
     * @property {number[]} nodeIdArray - List of shown node IDs.
     */
    av.SHOW_EVENT                  = 'show';

    /**
     * Fired when a camera changes.
     * @event Autodesk.Viewing.Viewer3D#CAMERA_CHANGE_EVENT
     * @property {object} camera - Affected camera.
     */
    av.CAMERA_CHANGE_EVENT         = 'cameraChanged';
    /**
     * Fired whenever the Explode tool is used.
     * @event Autodesk.Viewing.Viewer3D#EXPLODE_CHANGE_EVENT
     * @property {number} scale - Scale of the current exploded state.
     */
    av.EXPLODE_CHANGE_EVENT        = 'explodeChanged';
    /**
     * Fired when a fitToView operation is applied.
     * Available from version 2.12.
     * @event Autodesk.Viewing.Viewer3D#FIT_TO_VIEW_EVENT
     * @property {boolean} immediate - True if the change was immediate.
     * @property {number[]} nodeIdArray - List of node IDs fitted. Array is empty when fitting to the whole model. 
     * @property {object} model - Model data.
     */
    av.FIT_TO_VIEW_EVENT           = 'fitToView';
    /**
     * Fired when the cutting planes change.
     * @event Autodesk.Viewing.Viewer3D#CUTPLANES_CHANGE_EVENT
     * @property {object[]} planes - List of cutplanes.
     */
    av.CUTPLANES_CHANGE_EVENT      = 'cutplanesChanged';
    /**
     * Fired when a tool is activated or deactivated.
     * @event Autodesk.Viewing.Viewer3D#TOOL_CHANGE_EVENT
     * @property {string} toolName - Name of a specific mode of a tool.
     * @property {object} tool - Tool object.
     * @property {bool} active - Current status of the tool.
     */
    av.TOOL_CHANGE_EVENT           = 'toolChanged';
    /**
     * Fired when rendering options change.
     * @event Autodesk.Viewing.Viewer3D#RENDER_OPTION_CHANGED_EVENT
     */
    av.RENDER_OPTION_CHANGED_EVENT = 'renderOptionChanged';
    /**
     * Fired when the render frame shown by the viewer is final or completed (it has
     * no more pending geometry or post processing effects delayed for incoming frames).
     * It's also been fired when the viewer stops showing final frames.
     * @event Autodesk.Viewing.Viewer3D#FINAL_FRAME_RENDERED_CHANGED_EVENT
     * @property {object[]} planes - List of cutplanes.
     */
    av.FINAL_FRAME_RENDERED_CHANGED_EVENT = 'finalFrameRenderedChanged';
    /**
     * Fired when visibility of a 2D layer changes.
     * @event Autodesk.Viewing.Viewer3D#LAYER_VISIBILITY_CHANGED_EVENT
     */
    av.LAYER_VISIBILITY_CHANGED_EVENT  = 'layerVisibility';
    /**
     * Fired when a model is reset to its initial configuration.
     * @deprecated
     * @event Autodesk.Viewing.Viewer3D#RESET_EVENT
     */
    av.RESET_EVENT                    = 'reset';

    /**
     * Fired when a user preference property changes.
     * @event Autodesk.Viewing.Viewer3D#PREF_CHANGED_EVENT
     * @property {string} name - Property name.
     * @property {object} value - New property value.
     */
    av.PREF_CHANGED_EVENT = 'PrefChanged';
    /**
     * Fired when a user preference property is reset.
     * @event Autodesk.Viewing.Viewer3D#PREF_RESET_EVENT
     * @property {string} name - Property name.
     * @property {object} value - New property value.
     */
    av.PREF_RESET_EVENT = 'PrefReset';

    /**
     * Fired when animations are successfully initialized.
     * @event Autodesk.Viewing.Viewer3D#ANIMATION_READY_EVENT
     */
    av.ANIMATION_READY_EVENT = 'animationReady';

    /**
     * Fired when user clicks on a hyperlink embedded in the model.
     * @event Autodesk.Viewing.Viewer3D#HYPERLINK_EVENT
     * @property {object} data - Hyperlink data.
     */
    av.HYPERLINK_EVENT = 'hyperlink';

    av.LOAD_GEOMETRY_EVENT = 'load_geometry';

    /**
     * Navigation mode constants.
     *
     * These constants are used to define the Navigation mode.
     *
     * @enum {number}
     * @readonly
     * @deprecated
     */
    av.NAVIGATION_MODE = {
        ORBIT:  0,
        PAN:    1,
        DOLLY:  2,
        ROLL:   3,
        FOV:    4,
        TOUCH_PAN_DOLLY: 5,
        TOUCH_ROLL:      6,
        OTHER:           7
    };


    var isMobile = av.isMobileDevice();

    var nextViewerId = 0;

    av.DefaultSettings = {
        "ambientShadows": true,
        "antialiasing": !isMobile,
        "groundShadow": true,
        "groundReflection": false,
        "progressiveRendering": true,
        "swapBlackAndWhite": false,
        "openPropertiesOnSelect": false,
        "ghosting": true,
        "viewCube": !isMobile,
        "lineRendering": true,
        "pointRendering": true,
        "lightPreset": avp.DefaultLightPreset,
        "backgroundColorPreset": null,
        "reverseMouseZoomDir": false,
        "reverseHorizontalLookDirection": false,
        "reverseVerticalLookDirection": false,
        "alwaysUsePivot": false,
        "zoomTowardsPivot": false,
        "orbitPastWorldPoles": true,
        "leftHandedMouseSetup": false,
        "clickToSetCOI": false,
        "optimizeNavigation": isMobile,
        "fusionOrbit": true,
        "fusionOrbitConstrained": true,
        "useFirstPersonNavigation" : true, // Replaces the "Walk" tool with the "First Person" tool
        "envMapBackground" : false,
        "renderPrism" : true,
        "firstPersonToolPopup" : true
    };



    /**
     * Base class for all viewer implementations.
     *
     * It contains everything that is needed to connect to the Autodesk viewing service and display 3D models.
     * It also includes basic navigation support, and context menu and extension APIs.
     * @constructor
     * @param {HTMLElement} container - The viewer container.
     * @param {object} config - The initial settings object.
     * @param {boolean} [config.startOnInitialize=true] - Set this to false if you want to defer the run to a later time
     * by calling run() explicitly.
     * @property {Autodesk.Viewing.Navigation} navigation - The navigation api object.
     * @property {Autodesk.Viewing.ToolController} toolController - The tool controller object.
     * @property {Autodesk.Viewing.ViewingUtilities} utilities - The viewing utilities object.
	 * @alias Autodesk.Viewing.Viewer3D
     * @category Core
     */
    var Viewer3D = function(container, config)
    {
        if (typeof THREE === 'undefined') {
            avp.logger.warn('Initializing LMV without the THREE.js dependency is not supported.',
                'Call Autodesk.Viewing.Initializer() first or preload the dependencies manually.');
        }

        if (container) {
            this.clientContainer = container;
            this.container = document.createElement("div");
            this.container.className = "adsk-viewing-viewer";
            this.container.style.height = "100%";
            this.container.style.width = "100%";
            this.container.style.overflow = "hidden";

            this.container.classList.add( av.isTouchDevice() ? "touch" : "notouch");

            this.clientContainer.appendChild(this.container);

            this.config = config;


            this.contextMenu = null;
            this.contextMenuCallbacks = {};
            this.__firefoxLMBfix = false;
            this.started = false;


            // Create the canvas if it doesn't already exist
            if ( this.container.nodeName === "CANVAS") {
                throw 'Viewer must be initialized on a div [temporary]';
            }
            else
            {
                this.canvasWrap = document.createElement("div");
                this.canvasWrap.classList.add("canvas-wrap");

                this.canvas = document.createElement("canvas");
                this.canvas.tabIndex = 0;

                this.canvasWrap.appendChild(this.canvas);
                this.container.appendChild(this.canvasWrap);
            }

            this.canvas.viewer = this; //store a pointer to the viewer in the canvas

            var prefOptions = {
                // Preferences. Prefix is a bit odd, but a legacy result after refactoring.
                prefix: 'Autodesk.Viewing.Private.GuiViewer3D.SavedSettings.',
                localStorage: true
            };
            this.prefs = new avp.Preferences(this, prefOptions);

        }

        this.extensionCache = null; // Reference passed from ViewingApplication
        this.running = false;
        this._pushedTool = '';
        this._defaultNavigationTool = '';
        this.id = nextViewerId++;
        this.impl = new avp.Viewer3DImpl(this.canvas, this);
    };

    Viewer3D.prototype.constructor = Viewer3D;

    av.EventDispatcher.prototype.apply( Viewer3D.prototype );
    av.ScreenModeMixin.prototype.apply( Viewer3D.prototype );
    av.ExtensionMixin.prototype.apply( Viewer3D.prototype );


    /**
     * @deprecated
     * Use {@link Autodesk.Viewing.ScreenMode} instead.
     */
    Viewer3D.ScreenMode = av.ScreenMode;

    /**
     * Default (and supported) values for how the viewer canvas will respond to click interaction.
     * If also provides a location to disable certain canvas features, such as:
     * "disableSpinner", "disableMouseWheel" and "disableTwoFingerSwipe".
     *
     * Refer to setCanvasClickBehavior() for additional info.
     */
    Viewer3D.kDefaultCanvasConfig = {
        "click": {
            "onObject": ["selectOnly"],
            "offObject": ["deselectAll"]
        },
        "clickAlt": {
            "onObject": ["setCOI"],
            "offObject": ["setCOI"]
        },
        "clickCtrl": {
            "onObject": ["selectToggle"]
            // don't deselect if user has control key down https://jira.autodesk.com/browse/LMV-1852
            //"offObject": ["deselectAll"]
        },
        "clickShift": {
            "onObject": ["selectToggle"]
            // don't deselect if user has shift key down https://jira.autodesk.com/browse/LMV-1852
            //"offObject": ["deselectAll"]
        },

        // Features that support disabling
        "disableSpinner": false,
        "disableMouseWheel": false,
        "disableTwoFingerSwipe": false
    };


    /**
     * Initializes the viewer and loads any extensions specified in the constructor's
     * config parameter. If the optional parameters are specified, the start() function will
     * use an optimized initialization sequence that results in faster model load.
     * The parameters are the same as the ones for Viewer3D.loadModel and you do not need to call loadModel
     * subsequently if the model is loaded via the call to start().
     *
     * @param {string} [url] - Optional URN or filepath to load on start.
     * @param {string} [options] - Optional path to shared property database.
     * @param {function} [onSuccessCallback] - Method that gets called when initial loading is done
     * and streaming starts.
     * @param {function} [onErrorCallback] - Method that gets called when initial loading ends with an error.
     * @returns {number} 0 if the viewer has started, an error code (same as that returned by initialize()) otherwise.
     */
    Viewer3D.prototype.start = function (url, options, onSuccessCallback, onErrorCallback) {
        if (this.started) {
            return 0;
        }
        this.started = true;

        var viewer = this;

        // Initialize the renderer and related stuff
        var result = viewer.initialize();
        if (result !== 0) {
            if (onErrorCallback) {
                setTimeout(function(){ onErrorCallback(result) }, 1);
            }
            return result;
        }

        //load extensions and set navigation overrides, etc.
        //Delayed so that it runs a frame after the long initialize() call.
        setTimeout(function() {viewer.setUp(viewer.config);}, 1);

        //If a model URL was given, kick off loading first, then initialize, otherwise just continue
        //with initialization immediately.
        if (url)
            this.loadModel(url, options, onSuccessCallback, onErrorCallback);

        return 0;
    };


    Viewer3D.prototype.registerUniversalHotkeys = function()
    {
        var self = this;

        var onPress;
        var onRelease;
        var previousTool;
        var keys = av.theHotkeyManager.KEYCODES;

        // Add Fit to view hotkey
        onPress = function() {
            self.navigation.setRequestFitToView(true);
            return true;
        };
        av.theHotkeyManager.pushHotkeys("Autodesk.FitToView", [
            {
                keycodes: [keys.f],
                onPress: onPress
            }
        ]);

        // Add home hotkey
        onPress = function() {
            self.navigation.setRequestHomeView(true);
            return true;
        };
        av.theHotkeyManager.pushHotkeys("Autodesk.Home", [
            {
                keycodes: [keys.h],
                onPress: onPress
            },
            {
                keycodes: [keys.HOME],
                onPress: onPress
            }
        ]);

        // Escape
        onRelease = function() {
            // handle internal GUI components before firing the event to the client
            if (self.objectContextMenu && self.objectContextMenu.hide()) {
                return true;
            }

            // TODO: Could this all be unified somehow? If event listeners had priorities,
            //       we could intersperse listeners from the client and the viewer, which
            //       I think will eventually be required.

            self.fireEvent({ type: av.ESCAPE_EVENT });
            return true;
        };

        av.theHotkeyManager.pushHotkeys("Autodesk.Escape", [
            {
                keycodes: [keys.ESCAPE],
                onRelease: onRelease
            }
        ]);

        // Pan
        onPress = function() {
            previousTool = self.getActiveNavigationTool();
            return self.setActiveNavigationTool("pan");
        };
        onRelease = function() {
            return self.setActiveNavigationTool(previousTool);
        };
        var hotkeys = [
            {
                keycodes: [keys.SHIFT],
                onPress: onPress,
                onRelease: onRelease
            },
            {
                keycodes: [keys.SPACE],
                onPress: onPress,
                onRelease: onRelease
            }];
        av.theHotkeyManager.pushHotkeys("Autodesk.Pan", hotkeys, {tryUntilSuccess: true});
    };

    Viewer3D.prototype.createControls = function( ) {
        var self = this;
        var impl = self.impl;

        self.navigation = new av.Navigation(impl.camera);
        self.__initAutoCam(impl);

        self.utilities = new av.ViewingUtilities(impl, self.autocam, self.navigation);
        self.clickHandler = new av.DefaultHandler(impl, self.navigation, self.utilities);
        self.toolController = new av.ToolController(impl, self, self.autocam, self.utilities, self.clickHandler);
        self.toolController.registerTool( new av.GestureHandler(self) );

        self.toolController.registerTool( av.theHotkeyManager );
        self.toolController.activateTool( av.theHotkeyManager.getName() );

        self.registerUniversalHotkeys();

        self.toolController.registerTool( new av.OrbitDollyPanTool(impl, self) );
        self.toolController.activateTool( "gestures" );

        return self.toolController;
    };



    /**
     * Create any DOM and canvas elements, and setup WebGL.
     *
     * @returns {number} 0 if initialization was successful, {@link Autodesk.Viewing.ErrorCode} otherwise.
     */
    Viewer3D.prototype.initialize = function()
    {

        //Set up the private viewer implementation
        this.setScreenModeDelegate(this.config ? this.config.screenModeDelegate : undefined);

        var dimensions = this.getDimensions();
        this.canvas.width = dimensions.width;
        this.canvas.height = dimensions.height;

        // For Safari and WKWebView and UIWebView on ios device with retina display,
        // needs to manually rescale our canvas to get the right scaling. viewport metatag
        // alone would not work.
        if (av.isIOSDevice() && window.devicePixelRatio) {
            this.canvas.width /= window.devicePixelRatio;
            this.canvas.height /= window.devicePixelRatio;
        }

        //Call this after setting canvas size above...
        this.impl.initialize();

        //Only run the WebGL failure logic if the renderer failed to initialize (otherwise
        //we don't have to spend time creating a GL context here, since we know it worked already
        if (!this.impl.glrenderer()) {
            var webGL = av.detectWebGL();
            if (webGL <= 0) {  // WebGL error.
                return webGL === -1 ? av.ErrorCodes.BROWSER_WEBGL_NOT_SUPPORTED : av.ErrorCodes.BROWSER_WEBGL_DISABLED;
            }
        }

        var self = this;

        // Add a callback for the panels to resize when the viewer resizes.
        //
        // Note, we can't pass viewer.resize() as the callback - it will not evaluate
        // 'this' as the viewer when it's called.  We save the viewer here as a closure
        // variable ensuring resize() is called on the viewer.
        //
        this.onResizeCallback = function(e) {
            self.resize();
        };
        window.addEventListener('resize', this.onResizeCallback, false);


        this.initContextMenu();

        // Localize the viewer.
        this.localize();


        this.impl.controls = this.createControls();
        this.setDefaultNavigationTool( "orbit" );
        this.model = null;

        if( this.impl.controls )
            this.impl.controls.setAutocam(this.autocam);

        var canvasConfig = (this.config && this.config.canvasConfig) ? this.config.canvasConfig : Viewer3D.kDefaultCanvasConfig;
        this.setCanvasClickBehavior(canvasConfig);

        // Allow clients not load the spinner. This is needed for embedding viewer in a WebView on mobile,
        // where the spinner makes the UI looks less 'native'.
        if (!canvasConfig.disableSpinner) {

            // Create a div containing an image: this will be a
            // spinner (aka activity indicator) that tells the user
            // that the file is loading.
            //
            this.loadSpinner = document.createElement("div");
            this.loadSpinner.className = "spinner";
            this.container.appendChild(this.loadSpinner);

            // Generate circles for spinner
            for (var i=1; i<=3; i++) {
                var spinnerContainer = document.createElement("div");
                spinnerContainer.className = "bounce" + i;
                this.loadSpinner.appendChild(spinnerContainer);
            }
        }

        // Setup of AO, Ghosting, Env Lighting etc.
        this.initSettings();

        // Auxiliary class to get / restore the viewer state.
        this.viewerState = new avp.ViewerState( this );

        // The default behavior is to run the main loop immediately, unless startOnInitialize
        // is provided and is false.
        //
        if (!this.config || !this.config.hasOwnProperty("startOnInitialize") || this.config.startOnInitialize)
        {
            this.run();
        }

        window.NOP_VIEWER = this;

        this.fireEvent(av.VIEWER_INITIALIZED);

        return 0;   // No Error initializing.
    };

    Viewer3D.prototype.setUp = function (config) {

        this.config = config;

        // Load the extensions specified in the config.
        //
        if (this.config && this.config.hasOwnProperty('extensions')) {
            var extensions = this.config.extensions;
            for (var i = 0; i < extensions.length; ++i) {
                this.loadExtension(extensions[i], this.config);
            }
        }

        var canvasConfig = (this.config && this.config.canvasConfig) ? this.config.canvasConfig : Viewer3D.kDefaultCanvasConfig;
        this.setCanvasClickBehavior(canvasConfig);
    };

    Viewer3D.prototype.tearDown = function () {
        this.clearSelection();

        if (this.loadedExtensions) {
            for (var extensionId in this.loadedExtensions) {
                try {
                    // Extensions that fail to unload will end up terminating
                    // the viewer tearDown process.  Thus we protect from it
                    // here and log it (if available).
                    this.unloadExtension(extensionId);
                } catch (err) {
                    avp.logger.error("Failed to unload extension: " + extensionId, err);
                    avp.logger.track(
                        {
                            category:"error_unload_extension",
                            extensionId: extensionId,
                            error_message: err.message,
                            call_stack: err.stack
                        });
                }
            }
            this.loadedExtensions = null;
        }

        avp.logger.reportRuntimeStats(true);

        if (this.loadSpinner)
            this.loadSpinner.style.display = "block";
        this.model = null;

        if (this.liveReviewClient) {
            this.liveReviewClient.destroy();
            this.liveReviewClient = null;
        }

        this.impl.unloadCurrentModel();
    };

    Viewer3D.prototype.run = function()
    {
        if( !this.running ) {
            this.resize();
            this.running = true;
            this.impl.run();
        }
    };


    /**
     * Localize the viewer. This method can be overwritten so that the subclasses
     * can localize any additional elements.
     */
    Viewer3D.prototype.localize = function()
    {
        av.i18n.localize();
    };

    Viewer3D.prototype.__initAutoCam = function(impl)
    {
        var self = this;

        var ourCamera = impl.camera;

        if( !ourCamera.pivot )
            ourCamera.pivot = new THREE.Vector3(0, 0, 0);

        if( !ourCamera.target )
            ourCamera.target = new THREE.Vector3(0, 0, 0);

        if( !ourCamera.worldup )
            ourCamera.worldup = ourCamera.up.clone();

        function autocamChange(upChanged)
        {
            if( self.autocamCamera.isPerspective !== ourCamera.isPerspective )
            {
                if( self.autocamCamera.isPerspective )
                    self.navigation.toPerspective();
                else
                    self.navigation.toOrthographic();
            }
            self.navigation.setVerticalFov(self.autocamCamera.fov, false);
            self.navigation.setView(self.autocamCamera.position, self.autocamCamera.target);
            self.navigation.setPivotPoint(self.autocamCamera.pivot);
            self.navigation.setCameraUpVector(self.autocamCamera.up);
            if( upChanged )
                self.navigation.setWorldUpVector(self.autocamCamera.worldup);

            self.impl.syncCamera(upChanged);
        }

        function pivotDisplay(state)
        {
            if( self.utilities )
                self.utilities.pivotActive(state, false);
            else
                self.impl.controls.pivotActive(state, false);
        }

        self.autocamCamera = ourCamera.clone();
        self.autocamCamera.target = ourCamera.target.clone();
        self.autocamCamera.pivot  = ourCamera.pivot.clone();
        self.autocamCamera.worldup = ourCamera.worldup.clone();

        self.autocam  = new avp.Autocam(self.autocamCamera, self.navigation);
        self.autocam.cameraChangedCallback = autocamChange;
        self.autocam.pivotDisplayCallback = pivotDisplay;
        self.autocam.canvas = self.canvas;

        self.addEventListener("cameraChanged", function(evt)
        {
            var ourCamera = evt.camera;
            self.autocam.sync(ourCamera);
        });

        self.autocam.sync(ourCamera);
    };


    /**
     * Removes all created DOM elements and performs any GL uninitialization that is needed.
     */
    Viewer3D.prototype.uninitialize = function()
    {

        window.removeEventListener('resize', this.onResizeCallback, false);
        this.onResizeCallback = null;


        this.canvas.parentNode.removeChild(this.canvas);
        this.canvas.viewer = null;
        this.canvas = null;
        this.canvasWrap = null;

        this.viewerState = null;

        avp.logger.reportRuntimeStats();
        avp.logger.track({category:"viewer_destroy"}, true);

        if( this.toolController ) {
            this.toolController.uninitialize();
            this.toolController = null;
            this.clickHandler = null;
            this.utilities = null;
        }

        if (this.navigation) {
            this.navigation.uninitialize();
            this.navigation = null;
        }

        if (this.impl){
            this.impl.dtor();
            this.impl = null;
        }

        this.loadSpinner = null;
        this.model = null;
        this.prefs = null;

        this.autocam.dtor();
        this.autocam = null;
        this.autocamCamera = null;

        av.theHotkeyManager.popHotkeys("Autodesk.FitToView");
        av.theHotkeyManager.popHotkeys("Autodesk.Home");
        av.theHotkeyManager.popHotkeys("Autodesk.Escape");
        av.theHotkeyManager.popHotkeys("Autodesk.Pan");
        av.theHotkeyManager.popHotkeys("Autodesk.Orbit");



        if (this.onDefaultContextMenu) {
            this.container.removeEventListener('contextmenu', this.onDefaultContextMenu, false);
            this.onDefaultContextMenu = null;
        }

        if (this.screenModeDelegate) {
            this.screenModeDelegate.uninitialize();
            this.screenModeDelegate = null;
        }

        this.extensionCache = null;
        this.clientContainer = null;
        this.config = null;
        this.listeners = {};
        this.contextMenu = null;
        this.contextMenuCallbacks = null;

        if (this.viewCubeUi) {
            this.viewCubeUi.uninitialize();
            this.viewCubeUi = null;
        }

        if (this.container && this.container.parentNode)
            this.container.parentNode.removeChild(this.container);
        this.container = null;

        this.fireEvent(av.VIEWER_UNINITIALIZED);

        //forget all event listeners
        this.listeners = {};

        avp.logger.log("viewer destroy");
    };


    /**
     * Unloads any loaded extensions and then uninitializes the viewer.
     */
    Viewer3D.prototype.finish = function() {
        this.tearDown();
        this.uninitialize();
    };


    /**
     * @deprecated Use {@link Autodesk.Viewing.Viewer3D#loadModel} instead.
     * Load the file from the cloud or locally.
     * Asynchronously loads the document given its svfURN.
     * - on success: calls onDocumentLoadedCallback.
     * - on error: displays an error AlertBox.
     * @param {string} svfURN - The URN or filepath to load.
     * @param {string} [sharedPropertyDbPath] - Optional path to shared property database.
     * @param {function} [onSuccessCallback] - Method that gets called when initial loading is done
     * and streaming starts.
     * @param {function} [onErrorCallback] - Method that gets called when initial loading ends with an error.
     * @param {object} [loadOptions] - Optional load options passed to the model loader.
     */
    Viewer3D.prototype.load = function(svfURN, sharedPropertyDbPath, onSuccessCallback, onErrorCallback, acmSessionId, loadOptions)
    {
        avp.logger.warn('viewer.load() is deprecated. Please use viewer.loadModel() instead.');
        var options = {
            ids: null,
            sharedPropertyDbPath: sharedPropertyDbPath,
            acmSessionId: acmSessionId,
            loadOptions: loadOptions
        };
        return this.loadModel(svfURN, options, onSuccessCallback, onErrorCallback);
    };


    /**
     * Loads a model into the viewer.
     * @param {string} url - The url to the model.
     * @param {object} [options] - An optional dictionary of options.
     * @param {Autodesk.Viewing.FileLoader} [options.fileLoader] - The file loader to use for this url.
     * @param {object} [options.loadOptions] - May contain params that are specific for certain loaders/filetypes.
     * @param {string} [options.sharedPropertyDbPath] - Optional path to shared property database.
     * @param {string} [options.ids] - A list of object IDs to load.
     * @param {function} [onSuccessCallback] - A method that gets called when initial loading is done
     * and streaming starts.
     * @param {function} [onErrorCallback] - A method that gets called when loading fails.
     */
    Viewer3D.prototype.loadModel = function(url, options, onSuccessCallback, onErrorCallback, onWorkerStart)
    {
        var self = this;

        options = options || {};

        function registerDimensionSpecificHotkeys() {
            if (!av.theHotkeyManager)
                return;

            if (self.model.is2d()) {
                // Remove 3D specific hotkeys
                av.theHotkeyManager.popHotkeys("Autodesk.Orbit");
            } else {
                // Add 3D specific hotkeys
                // Orbit
                var previousTool;
                var onPress = function() {
                    previousTool = self.getActiveNavigationTool();
                    return self.setActiveNavigationTool("orbit");
                };
                var onRelease = function() {
                    return self.setActiveNavigationTool(previousTool);
                };
                var hotkeys = [
                    {
                        keycodes: [av.theHotkeyManager.KEYCODES.ALT],
                        onPress: onPress,
                        onRelease: onRelease
                    }];
                av.theHotkeyManager.pushHotkeys("Autodesk.Orbit", hotkeys, {tryUntilSuccess: true});
            }
        }

        function onSuccess( model ) {
            var isFirstModel = false;
            if (!self.model) {
                self.model = model;
                isFirstModel = true;
            }
            self.impl.addModel(model);

            if (self.loadSpinner)
                self.loadSpinner.style.display = "None";

            if (isFirstModel) {
                if (model.is2d()) {
                    self.activateLayerState("Initial");
                }
                registerDimensionSpecificHotkeys();
            }

            if (onSuccessCallback) {
                onSuccessCallback(model);
            }
        }

        function onError( errorCode, errorMessage, statusCode, statusText ) {
            if (self.loadSpinner)
                self.loadSpinner.style.display = "None";
            if (onErrorCallback)
                onErrorCallback( errorCode, errorMessage, statusCode, statusText );
        }

        // Force a repaint when a file is fully done loading
        function forceRepaint() {
            self.impl.needsRender = true;
            self.removeEventListener(av.GEOMETRY_LOADED_EVENT, forceRepaint);
        }
        this.addEventListener(av.GEOMETRY_LOADED_EVENT, forceRepaint);

        var match = url.toLowerCase().match(/\.([a-z0-9]+)(\?|$)/),
            fileExtension = match ? match[1] : null;

        var loader;
        if (options && options.fileLoader) {
            loader = options.fileLoader;
        } else {
            loader = av.FileLoaderManager.getFileLoaderForExtension(fileExtension);
        }

        // if there's no loader, don't try to create it and cause an error.
        if (!loader) {
            avp.logger.error("File extension not supported:" + fileExtension);
            onError(av.ErrorCodes.UNSUPORTED_FILE_EXTENSION, "File extension not supported", 0, fileExtension);
            return false;
        }

        return new loader(this.impl).loadFile(url, options, onSuccess, onError, onWorkerStart );
    };


    /**
     * @returns {object} Client rectangle bounds.
     */
    Viewer3D.prototype.getDimensions = function() {
        if (this.container) {
            // NB: Getting dimensions of the client container instead of the container.
            //     At least in IE11, getting dimensions on the dynamically created
            //     child of the dynamically created parent returns a 0 height.
            var rect = {};
            if (this.getScreenMode() === av.ScreenMode.kFullScreen) {
                rect.width = screen.width;
                rect.height = screen.height;
            } else {
                rect = this.container.getBoundingClientRect();
            }

            return {
                width: rect.width,
                height: rect.height
            };
        }

        return null;
    };


    /**
     * Resizes the viewer.
     */
    Viewer3D.prototype.resize = function()
    {
        return this.impl.resize(this.container.clientWidth, this.container.clientHeight);
    };

    /**
     * Gets the camera so it can be modified by the client.
     * @returns {THREE.Camera} The active camera.
     */
    Viewer3D.prototype.getCamera = function()
    {
        return this.impl.camera;
    };

    /**
     * Gets the view state as a plain object.
     *
     * @param {object} [filter] - Specifies which viewer values to get.
     * @returns {object} Viewer state.
     */
    Viewer3D.prototype.getState = function( filter ) {
        return this.viewerState.getState(filter);
    };

    /**
     * Restores the viewer state from a given object.
     * @param {Object} viewerState
     * @param {Object} [filter] - Similar in structure to viewerState used to filter out values
     * that should not be restored.
     * @param {boolean} [immediate] - Whether the new view is applied with (true) or without transition (false).
     * @returns {boolean} True if restore operation was successful.
     */
    Viewer3D.prototype.restoreState = function (viewerState, filter, immediate)  {
        var success = this.viewerState.restoreState(viewerState, filter, immediate);
        if (success) {
            this.fireEvent({ type: av.VIEWER_STATE_RESTORED_EVENT, value: success });
        }
        return success;
    };

    /**
     * Sets the view from an array of parameters.
     * @param {array} params - View parameters:
     * - position-x
     * - position-y
     * - position-z
     * - target-x
     * - target-y
     * - target-z
     * - up-x
     * - up-y
     * - up-z
     * - aspect
     * - fov (radians)
     * - orthoScale
     * - isPerspective (0=perspective, 1=ortho)
     */
    Viewer3D.prototype.setViewFromArray = function(params, name)
    {
        this.setActiveNavigationTool("orbit");

        //TODO: It might be best to get rid of the setViewFromArray API as it's not
        //very descriptive, and move the params->camera conversion to the bubble-reading
        //logic in ViewingApplication.

        //Make sure to apply any internal translation offset to the input camera
        var off = this.model ? this.model.getData().globalOffset : { x:0, y:0, z:0 };
        var camera = {
            position: new THREE.Vector3(params[0] - off.x, params[1] - off.y, params[2] - off.z),
            target: new THREE.Vector3(params[3] - off.x, params[4] - off.y, params[5] - off.z),
            up: new THREE.Vector3(params[6], params[7], params[8]),
            aspect: params[9],
            fov: THREE.Math.radToDeg(params[10]),
            orthoScale: params[11],
            isPerspective: !params[12]
        };

        this.impl.setViewFromCamera(camera);
    };

    /**
     * Sets the view from an array representing a view box.
     *
     * Not applicable to 3D.
     *
     * @param {array} viewbox - View parameters:
     * - min-x
     * - min-y
     * - max-x
     * - max-y
     * @param {string} [name] - Optional named view name to also set the layer visibility state
     * associated with this view.
     */
    Viewer3D.prototype.setViewFromViewBox = function (viewbox, name)
    {
        var model = this.model;

        if( model && !model.is2d() )
        {
            avp.logger.warn("Viewer3D.setViewFromViewBox is not applicable to 3D");
            return;
        }

        //set the layer state if any
        //It's annoying to search the views and states as arrays,
        //but this is the only place we do this, so converting them
        //to hashmaps is not necessary (yet).
        if (name && name.length) {
            var metadata = model.getData().metadata;
            var views = metadata.views;

            var i;
            for (i=0; i<views.length; i++) {
                if (views[i].name == name)
                    break;
            }

            if (i < views.length) {
                var state_name = views[i].layer_state;
                if (state_name)
                    this.activateLayerState(state_name);
            }
        }

        //Finally set the camera
        this.impl.setViewFromViewBox(this.model, viewbox, name, false);
    };

    /**
     * Changes the active layer state.
     * Get a list of all available layerStates and their active status through
     * {@link Autodesk.Viewing.Viewer3D#getLayerStates}.
     *
     * @param {string} stateName - Name of the layer state to activate.
     */
    Viewer3D.prototype.activateLayerState = function(stateName)
    {
        if (stateName && stateName.length) {
            var metadata = this.model.getData().metadata;
            var states = (metadata ? metadata.layer_states : null);
            if (!states) {
                return;
            }

            var j;
            for (j=0; j<states.length; j++) {
                if (states[j].name == stateName)
                    break;
            }

            if (j < states.length) {
                var layer_state = states[j];
                var visible = layer_state.visible_layers;

                var visMap = {};
                if (visible && 0 < visible.length) {
                    for (var k=0; k<visible.length; k++)
                        visMap[visible[k]] = 1;
                }

                var onlayers = [];
                var offlayers = [];

                for (var l in metadata.layers) {
                    var lname = metadata.layers[l].name;
                    if (visMap[lname] === 1) {
                        onlayers.push(l);
                    } else {
                        offlayers.push(l);
                    }
                }

                this.impl.setLayerVisible(onlayers, true);
                this.impl.setLayerVisible(offlayers, false);

                this.fireEvent({type: av.LAYER_VISIBILITY_CHANGED_EVENT});
            }
        }
    };

    /**
     * Returns information for each layer state: name, description, active.
     * Activate a state through {@link Autodesk.Viewing.Viewer3D#activateLayerState}.
     * @returns {array}
     */
    Viewer3D.prototype.getLayerStates = function () {
        var model = this.model,
            metadata = model ? model.getData().metadata : null,
            layers = metadata ? metadata.layers : null,
            layer_states = metadata ? metadata.layer_states : null;

        // No layers or no layer states? Nothing to do.
        //
        if (!layers || !layer_states) {
            return null;
        }

        // Which layers are currently visible?
        //
        var layerName,
            layerNames = {},
            currentVisibleLayers = {};

        for (var layer in layers) {
            if (layers.hasOwnProperty(layer)) {
                var index = parseInt(layer),
                    defn = layers[layer];

                layerName = (typeof defn === 'string') ? defn : defn.name;
                layerNames[layerName] = true;

                if (this.impl.isLayerVisible(index)) {
                    currentVisibleLayers[layerName] = true;
                }
            }
        }

        // Shallow equal()
        //
        function equal(a, b) {
            var aProps = Object.getOwnPropertyNames(a),
                bProps = Object.getOwnPropertyNames(b);

            if (aProps.length !== bProps.length) {
                return false;
            }

            for (var i = 0; i < aProps.length; ++i) {
                var propName = aProps[i];
                if (a[propName] !== b[propName]) {
                    return false;
                }
            }

            return true;
        }

        var layerStates = [],
            i, j;

        for (i = 0; i < layer_states.length; ++i) {
            var layer_state = layer_states[i],
                visible_layers = layer_state.visible_layers,
                layerStateVisibleLayers = {};

            if (!layer_state.hidden) { // Ignore hidden layer states
                if (visible_layers && 0 < visible_layers.length) {
                    for (j = 0; j < visible_layers.length; ++j) {
                        layerName = visible_layers[j];
                        if (layerNames.hasOwnProperty(layerName)) { // Ignore layers we don't know about
                            layerStateVisibleLayers[layerName] = true;
                        }
                    }
                }

                layerStates.push({
                    name: layer_state.name,
                    description: layer_state.description,
                    active: equal(currentVisibleLayers, layerStateVisibleLayers)
                });
            }
        }
        return (0 < layerStates.length) ? layerStates : null;
    };

    /**
     * Sets the view using the default view in the source file.
     */
    Viewer3D.prototype.setViewFromFile = function()
    {
        this.setActiveNavigationTool();
        this.impl.setViewFromFile(this.model);
    };

    /**
     * Gets the properties for an ID. Once the properties are returned,
     * the method raises a onPropertiesReady event.
     * @param {number} dbid
     * @param {function} [onSuccessCallback] - Call this callback once the properties are found.
     * @param {function} [onErrorCallback] - Call this callback if the properties are not found,
     * or another error occurs.
     */
    Viewer3D.prototype.getProperties = function(dbid, onSuccessCallback, onErrorCallback)
    {
        avp.logger.track({ name: 'get_props_count', aggregate: 'count' });

        if (this.model) {
            this.model.getProperties(dbid, onSuccessCallback, onErrorCallback);
        }
        else {
            if (onErrorCallback)
                onErrorCallback(av.ErrorCodes.BAD_DATA, "Properties failed to load since model does not exist");
        }
    };

    /**
     * Gets the viewer model object tree. Once the tree is received it will invoke the specified callback function.
     *
     * You can use the model object tree to get information about items in the model.  The tree is made up
     * of nodes, which correspond to model components such as assemblies or parts.
     *
     * @param {function} [onSuccessCallback] - Call this callback once the object tree is loaded.
     * @param {function} [onErrorCallback] - Call this callback if the object tree is not found.
     */
    Viewer3D.prototype.getObjectTree = function(onSuccessCallback, onErrorCallback)
    {
        if (this.model) {
            this.model.getObjectTree(onSuccessCallback, onErrorCallback);
        }
        else {
            if (onErrorCallback)
                onErrorCallback(av.ErrorCodes.BAD_DATA, "ObjectTree failed to load since model does not exist");
        }
    };

    /**
     * Sets the click behavior on the canvas to follow config.
     * This is used to change the behavior of events such as selection or COI changed.
     * @example
     *  {
     *       "click": {
     *           "onObject": [ACTIONS],
     *           "offObject": [ACTIONS]
     *       },
     *       "clickCtrl": {
     *           "onObject": [ACTIONS],
     *           "offObject": [ACTIONS]
     *       },
     *       "clickShift": {
     *           ...
     *       },
     *       "clickCtrlShift": {
     *           ...
     *       },
     *       "disableSpinner": BOOLEAN
     *       "disableMouseWheel": BOOLEAN,
     *       "disableTwoFingerSwipe": BOOLEAN
     *  }
     *
     * Actions can be any of the following:
     * - selectOnly
     * - selectToggle
     * - deselectAll
     * - isolate
     * - showAll
     * - setCOI
     * - focus
     * - hide
     * @param {object} config - Parameter object that meets the above layout.
     */
    Viewer3D.prototype.setCanvasClickBehavior = function(config)
    {
        if (this.impl.controls.hasOwnProperty("setClickBehavior"))
            this.impl.controls.setClickBehavior(config);

        if( this.clickHandler )
            this.clickHandler.setClickBehavior(config);

        if (config && config.disableMouseWheel) {
            this.toolController.setMouseWheelInputEnabled(false);
        }

        if (config && config.disableTwoFingerSwipe) {
            var gestureHandler = this.toolController.getTool("gestures");
            if (gestureHandler) {
                gestureHandler.disableTwoFingerSwipe();
            }
        }
    };

    /**
     * Searches the elements for the given text. When the search is complete,
     * the callback onResultsReturned(idArray) is invoked.
     * @param {string} text - The search term (not case sensitive).
     * @param {function} onSuccessCallback - The callback to invoke when search is complete.
     * @param {function} onErrorCallback - The callback to invoke when search is complete.
     * @param {string[]} [attributeNames] - Restricts search to specific attribute names.
     */
    Viewer3D.prototype.search = function(text, onSuccessCallback, onErrorCallback, attributeNames, completeInfo)
    {
        this.searchText = text;

        if (this.model) {
            this.model.search(text, onSuccessCallback, onErrorCallback, attributeNames, completeInfo);
        }
        else {
            if (onErrorCallback)
                onErrorCallback(av.ErrorCodes.BAD_DATA, "Search failed since model does not exist");
        }
    };

    /**
     * Returns an Array of the IDs of the currently hidden nodes.
     * When isolation is in place, there are no hidden nodes returned because
     * all nodes that are not isolated are considered hidden.
     *
     * @returns {array} Array of nodes that are currently hidden, when no isolation is in place.
     */
    Viewer3D.prototype.getHiddenNodes = function () {
        return this.impl.visibilityManager.getHiddenNodes();
    };

    /**
     * Returns an array of the IDs of the currently isolated nodes.
     *
     * Not yet implemented for 2D.
     *
     * @returns {array} Array of nodes that are currently isolated.
     */
    Viewer3D.prototype.getIsolatedNodes = function () {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.getIsolatedNodes is not yet implemented for 2D");
            return [];
        }

        return this.impl.visibilityManager.getIsolatedNodes();
    };

    /**
     * Isolates one of many sub-elements. You can pass in a node or an array of nodes to isolate.
     * Pass in null to reset isolation.
     *
     * @param {number[]|number} node - A node ID or array of node IDs from the model tree {@link BaseViewer#getObjectTree}.
     */
    Viewer3D.prototype.isolate = function(node)
    {
        if (!this.model) {
            // Silently abort //
            return;
        }

        var data = this.model.getData();
        if (data && data.is2d && data.loadDone && 'hasObjectProperties' in data) {
            // some 2d datasets have no instance-tree, but just a flat list of object properties.
            // Here, we can call isolate directly without requesting the instanceTree first.
            this.impl.visibilityManager.isolate(node);
        } else {
            // request instance tree first
            var self = this;
            this.model.getObjectTree(function () {
                self.impl.visibilityManager.isolate(node);
            });
        }
    };


    /**
     * @deprecated Isolates one of many sub-elements. You can pass in a dbid or an array of dbid to isolate.
     *
     * Not yet implemented for 2D.
     *
     * @param {array|number} dbids - Either an array or a single integer.
     */
    Viewer3D.prototype.isolateById = function(dbIds) {

        avp.logger.warn("isolateById() is deprecated. Use isolate() instead.");
        return this.isolate(dbIds);

    };

    /**
     * Sets the background color.
     * @param {number} red
     * @param {number} green
     * @param {number} blue
     * @param {number} red2
     * @param {number} green2
     * @param {number} blue2
     */
    Viewer3D.prototype.setBackgroundColor = function(red, green, blue, red2, green2, blue2)
    {
        this.impl.setClearColors(red, green, blue, red2, green2, blue2);
    };

    /**
     * Toggles the selection for a given dbid.
     * If it was unselected, it is selected.
     * If it was selected, it is unselected.
     *
     * Not yet implemented for 2D.
     *
     * @param {number} dbid
     */
    Viewer3D.prototype.toggleSelect = function(dbid)
    {
        if( this.model && this.model.is2d() )
        {
            // Fails because Model.getNodeById is not supported.
            avp.logger.warn("Viewer3D.toggleSelect is not yet implemented for 2D");
            return;
        }

        this.impl.selector.toggleSelection(dbid);
    };

    /**
     * Selects the array of ids. You can also just pass in a single id instead of an array.
     * @param {number[]|number} dbids
     */
    Viewer3D.prototype.select = function(dbids)
    {
        if (typeof dbids === "number") {
            dbids = [dbids];
        }

        this.impl.selector.setSelection(dbids);
    };


    /**
     * Clears the selection.
     */
    Viewer3D.prototype.clearSelection = function()
    {
        this.impl.selector.clearSelection();
    };

    /**
     * Returns information about the visibility of the current selection.
     * @returns {object} `{hasVisible:boolean, hasHidden:boolean}`
     */
    Viewer3D.prototype.getSelectionVisibility = function () {
        return this.impl.selector.getSelectionVisibility();
    };

    /**
     * Returns the number of nodes in the current selection.
     * @returns {number}
     */
    Viewer3D.prototype.getSelectionCount = function () {
        return this.impl.selector.getSelectionLength();
    };

    /**
     * Sets selection granularity mode. Supported values are:
     * - Autodesk.Viewing.SelectionMode.LEAF_OBJECT
     *   - Always select the leaf objects in the hierarchy.
     * - Autodesk.Viewing.SelectionMode.FIRST_OBJECT
     *   - For a given node, selects the first non-composite (layer, collection, model)
     *   on the path from the root to the given node, and all children.
     * - Autodesk.Viewing.SelectionMode.LAST_OBJECT
     *   - For a given node, selects the nearest ancestor composite node and all children.
     *   Selects the input node itself in case there is no composite node in the path to the root node.
     */
    Viewer3D.prototype.setSelectionMode = function (mode) {
        this.impl.selector.setSelectionMode(mode);
    };


    /**
     * Returns the current selection.
     * @returns {number[]} Array of the IDs of the currently selected nodes.
     */
    Viewer3D.prototype.getSelection = function () {
        return this.impl.selector.getSelection();
    };

    /**
     * Returns the selected items from all loaded models.
     * @param {function} [callback] - Optional callback to receive enumerated pairs of model and dbId
     * for each selected object. If no callback is given, an array of objects is returned.
     * @returns {object[]} An array of objects with a model and selectionSet properties for each model
     * that has selected items in the scene.
     */
    Viewer3D.prototype.getAggregateSelection = function(callback) {
        var res = this.impl.selector.getAggregateSelection();

        if (callback) {
            for (var i=0; i<res.length; i++) {
                for (var j=0; j<res[i].selection.length; j++) {
                    callback(res[i].model, res[i].selection[j]);
                }
            }
        }

        return res;
    };

    /**
     * Ensures the passed in dbid / ids are hidden.
     *
     * @param {number[]|number} node
     */
    Viewer3D.prototype.hide = function(node)
    {
        avp.logger.track({ name: 'hide', aggregate: 'count' });

        this.impl.visibilityManager.hide(node);
    };

    /**
     * @deprecated Use {@link Autodesk.Viewing.Viewer3D#hide} instead.
     *
     * @param {number} nodeId
     */
    Viewer3D.prototype.hideById = function(nodeId)
    {
        this.hide(nodeId);
    };

    /**
     * Ensures the passed in dbid / ids are shown.
     *
     * @param {number[]|number} node
     */
    Viewer3D.prototype.show = function(node)
    {
        this.impl.visibilityManager.show(node);
    };

    /**
     * Ensures everything is visible. Clears all node isolation (3D) and turns on all layers (2D).
     */
    Viewer3D.prototype.showAll = function()
    {
        this.impl.visibilityManager.isolate();
        if (this.model.is2d()) {
            this.setLayerVisible(null, true);
        }
    };


    /**
     * Toggles the visibility of the given node.
     *
     * Not yet implemented for 2D.
     *
     * @param {number} node
     */
    Viewer3D.prototype.toggleVisibility = function(node)
    {
        this.impl.visibilityManager.toggleVisibility(node);
    };

    /**
     * Returns true if every node is visible.
     * @returns {boolean}
     */
    Viewer3D.prototype.areAllVisible = function() {
        return this.impl.isWholeModelVisible(this.model);
    };

    /**
     * Explodes the model from the center of gravity.
     *
     * Not applicable to 2D.
     *
     * @param {number} scale - A value from 0.0-1.0 to indicate how much to explode.
     */
    Viewer3D.prototype.explode = function( scale)
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.explode is not applicable to 2D");
            return;
        }

        avp.logger.track({ name: 'explode_count', aggregate: 'count' });

        this.impl.explode(scale);
    };

    /**
     * Returns the explode scale.
     *
     * Not applicable to 2D.
     *
     * @returns {number} - A value from 0.0-1.0 indicating how exploded the model is.
     */
    Viewer3D.prototype.getExplodeScale = function()
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.getExplodeScale is not applicable to 2D");
            return 0;
        }

        return this.impl.getExplodeScale();
    };


    /**
     * Enables or disables the high quality rendering settings.
     *
     * Not applicable to 2D.
     *
     * @param {boolean} useSAO - True or false to enable screen space ambient occlusion.
     * @param {boolean} useFXAA - True or false to enable fast approximate anti-aliasing.
     */
    Viewer3D.prototype.setQualityLevel = function(useSAO, useFXAA)
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setQualityLevel is not applicable to 2D");
            return;
        }

        this.prefs.set('ambientShadows', useSAO);
        this.prefs.set('antialiasing', useFXAA);
        this.impl.togglePostProcess(useSAO, useFXAA);
    };


    /**
     * Toggles ghosting during search and isolate.
     *
     * Not applicable to 2D.
     *
     * @param {boolean} value - Indicates whether ghosting is on or off.
     */
    Viewer3D.prototype.setGhosting = function(value)
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setGhosting is not applicable to 2D");
            return;
        }

        this.prefs.set('ghosting', value);
        this.impl.toggleGhosting(value);
    };

    /**
     * Toggles ground shadow.
     *
     * Not applicable to 2D.
     *
     * @param {boolean} value - Indicates whether shadow is on or off.
     */
    Viewer3D.prototype.setGroundShadow = function(value)
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setGroundShadow is not applicable to 2D");
            return;
        }

        this.prefs.set('groundShadow', value);
        this.impl.toggleGroundShadow(value);
    };

    /**
     * Toggles ground reflection.
     *
     * Not applicable to 2D.
     *
     * @param {boolean} value - Indicates whether reflection is on or off.
     */
    Viewer3D.prototype.setGroundReflection = function(value)
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setGroundReflection is not applicable to 2D");
            return;
        }

        this.prefs.set('groundReflection', value);
        this.impl.toggleGroundReflection(value);
    };

    /**
     * Toggles environment map for background.
     *
     * Not applicable to 2D.
     *
     * @param {boolean} value - Indicates whether environment map for background is on or off.
     */
    Viewer3D.prototype.setEnvMapBackground = function(value)
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setEnvMapBackground is not applicable to 2D");
            return;
        }

        this.prefs.set('envMapBackground', value);
        this.impl.toggleEnvMapBackground(value);
    };

    /**
     * Toggles Prism Material rendering.
     *
     * Not applicable to 2D.
     *
     * @param {boolean} value - Indicates whether Prism Material rendering is on or off.
     */
    Viewer3D.prototype.setRenderPrism = function (value) {
        if (this.model && this.model.is2d()) {
            avp.logger.warn("Viewer3D.setRenderPrism is not applicable to 2D");
            return;
        }

        this.prefs.set('renderPrism', value);
        this.impl.toggleRenderPrism(value);
    };

    /**
     * Toggles first person tool popup.
     *
     * Not applicable to 2D.
     *
     * @param {boolean} value - Indicates whether first person tool popup is showed or not.
     */
    Viewer3D.prototype.setFirstPersonToolPopup = function(value)
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setFirstPersonToolPopup is not applicable to 2D");
            return;
        }

        this.prefs.set('firstPersonToolPopup', value);
    };

    /**
     * Returns the state of first person tool popup
     *
     * Not applicable to 2D.
     *
     * @returns {boolean} value is indicating whether first person tool popup is showed or not
     */
    Viewer3D.prototype.getFirstPersonToolPopup = function()
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.getFirstPersonToolPopup is not applicable to 2D");
            return;
        }

        return this.prefs.firstPersonToolPopup;
    };

    /**
     * Toggles whether progressive rendering is used. Warning: turning progressive rendering off
     * will have serious performance implications.
     * @param {boolean} value whether it is on or off
     */
    Viewer3D.prototype.setProgressiveRendering = function(value)
    {
        this.prefs.set('progressiveRendering', value);
        this.impl.toggleProgressive(value);
    };

    /**
     * AutoCAD drawings are commonly displayed with white lines on a black background. Setting reverse swaps (just)
     * these two colors.
     * @param {boolean} value whether it is on or off
     */
    Viewer3D.prototype.setSwapBlackAndWhite = function(value)
    {
        this.prefs.set('swapBlackAndWhite', value);
        this.impl.toggleSwapBlackAndWhite(value);
    };

    /**
     * Toggles whether the navigation should be optimized for performance. If set
     * to true, anti-aliasing and ambient shadows will be off while navigating.
     *
     * Not applicable to 2D.
     *
     * @param {boolean} value whether it is on or off
     */
    Viewer3D.prototype.setOptimizeNavigation = function(value)
    {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setOptimizeNaviation is not applicable to 2D");
            return;
        }

        this.prefs.set('optimizeNavigation', value);
        this.impl.setOptimizeNavigation(value);
    };

    /**
     * Locks or unlocks navigation controls.
     *
     * When navigation is locked, certain operations (for example, orbit, pan, or fit-to-view)
     * are disabled.
     *
     * @param {boolean} value True if the navigation should be locked.
     *
     * @see {@link Autodesk.Viewing.Viewer3D#setNavigationLockSettings}
     */
    Viewer3D.prototype.setNavigationLock = function(value)
    {
        if (this.navigation.getIsLocked() !== value) {
            this.navigation.setIsLocked(value);
            this.fireEvent({ type: av.NAVIGATION_MODE_CHANGED_EVENT, id: this.getActiveNavigationTool() });
        }
    };

    /**
     * Gets the current state of the navigation lock.
     * @returns {boolean} True if the navigation controls are currently locked.
     */
    Viewer3D.prototype.getNavigationLock = function()
    {
        return this.navigation.getIsLocked();
    };

    /**
     * Updates the configuration of the navigation lock,
     * i.e., which actions are available when navigation is locked.
     *
     * The configurable actions are 'orbit', 'pan', 'zoom', 'roll', 'fov', 'walk', or 'gotoview'.
     * By default, none of the actions are enabled when the navigation is locked.
     *
     * @param {object} settings Map of <action>:<boolean> pairs specifying
     * whether the given action is *enabled* even when the navigation is locked.
     *
     * @see {@link Autodesk.Viewing.Viewer3D#setNavigationLock}
     */
    Viewer3D.prototype.setNavigationLockSettings = function(settings)
    {
        this.navigation.setLockSettings(settings);
        this.fireEvent({ type: av.NAVIGATION_MODE_CHANGED_EVENT, id: this.getActiveNavigationTool() });
    };

    /**
     * Gets the current configuration of the navigation lock.
     *  @returns {object} Map of <action>:<boolean> pairs specifying
     * whether the given action is *enabled* even when the navigation is locked.
     */
    Viewer3D.prototype.getNavigationLockSettings = function()
    {
        return this.navigation.getLockSettings();
    };

    /**
     * Swaps the current navigation tool for the tool with the provided name.
     * Will trigger NAVIGATION_MODE_CHANGED event if the mode actually changes.
     *
     * @param {string} [toolName] - The name of the tool to activate. By default it will switch to the default tool.
     *
     * @returns {boolean} - True if the tool was set successfully. False otherwise.
     *
     * @see {@link Viewer3D#getActiveNavigationTool|getActiveNavigationTool()}
     */
    Viewer3D.prototype.setActiveNavigationTool = function(toolName)
    {
        if(toolName === this._pushedTool || (!toolName && !this._pushedTool))
            return true;

        if( this._pushedTool ) {
            if( !this.impl.controls.deactivateTool(this._pushedTool) ) {
                return false;
            }

            // Need to reset the activeName of the default tool, since "orbit",
            // "freeorbit", "dolly" and "pan" share the same instance.
            this.impl.controls.setToolActiveName(this.getDefaultNavigationToolName());
            this._pushedTool = null;
        }

        var isDefault = !toolName || toolName === this.getDefaultNavigationToolName();

        if (isDefault && this._pushedTool === null) {
            this.fireEvent({ type: av.NAVIGATION_MODE_CHANGED_EVENT, id: this.getDefaultNavigationToolName() });
            return true;
        }

        if( this.impl.controls.activateTool(toolName) ) {
            this._pushedTool = toolName;
            this.fireEvent({ type: av.NAVIGATION_MODE_CHANGED_EVENT, id: this._pushedTool });
            return true;
        }

        return false;
    };

    /**
     * Returns the name of the active navigation tool.
     * @returns {string} - The tool's name.
     *
     * @see {@link Viewer3D#setActiveNavigationTool|setActiveNavigationTool()}
     */
    Viewer3D.prototype.getActiveNavigationTool = function()
    {
        return this._pushedTool ? this._pushedTool : this._defaultNavigationTool;
    };

    /**
     * Sets the default navigation tool. This tool will always sit beneath the navigation tool on the tool stack.
     *
     * @param {string} toolName - The name of the new default navigation tool.
     */
    Viewer3D.prototype.setDefaultNavigationTool = function(toolName)
    {
        if (this._defaultNavigationTool) {
            this.impl.controls.deactivateTool(this._defaultNavigationTool);
        }

        if (this._pushedTool) {
            this.impl.controls.deactivateTool(this._pushedTool);
        }

        this.impl.controls.activateTool(toolName);
        this._defaultNavigationTool = toolName;

        if (this._pushedTool) {
            this.impl.controls.activateTool(this._pushedTool);
        }
    };

    /**
     * Returns the default navigation tool
     *
     * @returns {Object} - The default navigation tool.
     */
    Viewer3D.prototype.getDefaultNavigationToolName = function()
    {
        return this._defaultNavigationTool;
    };

    /**
     * Gets the current camera vertical field of view.
     * @returns { number } - the field of view in degrees.
     */
    Viewer3D.prototype.getFOV = function()
    {
        return this.navigation.getVerticalFov();
    };

    /**
     * Sets the current cameras vertical field of view.
     * @param { number } degrees - Field of view in degrees.
     */
    Viewer3D.prototype.setFOV = function(degrees)
    {
        this.navigation.setVerticalFov(degrees, true);
    };

    /**
     * Gets the current camera focal length.
     * @returns { number } - the focal length in millimetres.
     */
    Viewer3D.prototype.getFocalLength = function()
    {
        return this.navigation.getFocalLength();
    };

    /**
     * Sets the current cameras focal length.
     * @param { number } mm - Focal length in millimetres
     */
    Viewer3D.prototype.setFocalLength = function(mm)
    {
        this.navigation.setFocalLength(mm, true);
    };

    /**
     * Hides all lines in the scene.
     * @param {boolean} hide
     */
    Viewer3D.prototype.hideLines = function(hide){
        this.prefs.set('lineRendering', !hide);
        var that = this;

        function onGeometryLoaded() {
            that.impl.hideLines(hide);
            that.removeEventListener(av.GEOMETRY_LOADED_EVENT, onGeometryLoaded);
        }

        if (!this.impl.hideLines(hide)) {
            this.addEventListener(av.GEOMETRY_LOADED_EVENT, onGeometryLoaded);
        }
    };

    /**
     * Hides all points in the scene.
     * @param {boolean} hide
     */
    Viewer3D.prototype.hidePoints = function(hide){
        this.prefs.set('pointRendering', !hide);
        var that = this;

        function onGeometryLoaded() {
            that.impl.hidePoints(hide);
            that.removeEventListener(av.GEOMETRY_LOADED_EVENT, onGeometryLoaded);
        }

        if (!this.impl.hidePoints(hide)) {
            this.addEventListener(av.GEOMETRY_LOADED_EVENT, onGeometryLoaded);
        }
    };

    /**
     * @deprecated
     * Applies the camera to the current viewer's camera.
     * @param {THREE.Camera} camera - the camera to apply.
     * @param {boolean} [fit=false] - Do a fit to view after transition.
     */
    Viewer3D.prototype.applyCamera = function(camera, fit) {
        this.impl.setViewFromCamera(camera, true);
        if (fit)
            this.fitToView();
    };

    /**
     * Fits camera to objects by ID - Fits entire model if no id is provided.
     * @param {array| int} [objectIds] array of Ids, or null.
     * @param {Model} [model] - The model containing the objectIds.
     */
    Viewer3D.prototype.fitToView = function(objectIds, model){

        model = model || this.model;
        if (model.isLoadDone()){
            this.impl.fitToView(objectIds, model);
        } else {
            var that = this;
            that.addEventListener(av.GEOMETRY_LOADED_EVENT, function _doFit(){
                that.removeEventListener(av.GEOMETRY_LOADED_EVENT, _doFit());
                that.impl.fitToView(objectIds, model);
            });
        }
        // Event gets fired from `impl`        
    };

    /**
     * Modifies a click action configuration entry.
     * @param {string} what - which click config to modify (one of "click", "clickAlt", "clickCtrl", "clickShift", "clickCtrlShift").
     * @param {string} where - hit location selector (one of "onObject", "offObject").
     * @param {Array|string} newAction - action list (containing any of "setCOI", "selectOnly", "selectToggle", "deselectAll", "deselectAll", "isolate", "showAll", "hide", "focus").
     * @returns {boolean} False if specified entry is not found, otherwise true.
     */
    Viewer3D.prototype.setClickConfig = function(what, where, newAction)
    {
        var config = this.clickHandler ? this.clickHandler.getClickBehavior()
            : this.impl.controls.getClickBehavior();

        if( what in config )
        {
            var actions = config[what];
            if( where in actions )
            {
                actions[where] = newAction;
                return true;
            }
        }
        return false;
    };

    /**
     * Fetch a click action configuration entry.
     * @param {string} what - which click config to fetch (one of "click", "clickAlt", "clickCtrl", "clickShift", "clickCtrlShift").
     * @param {string} where - hit location selector (one of "onObject", "offObject").
     * @returns {Array} action list for the given entry or null if not found.
     */
    Viewer3D.prototype.getClickConfig = function(what, where)
    {
        var config = this.clickHandler ? this.clickHandler.getClickBehavior()
            : this.impl.controls.getClickBehavior();

        if( what in config )
        {
            var actions = config[what];
            if( where in actions )
                return actions[where];
        }
        return null;
    };

    /**
     * Modify the default click behaviour for the viewer.
     * @param {boolean} state - If true the default is to set the center of interest. If false the default is single select.
     * @param {boolean} [updatePrefs=true] - If true, the user preferences will be updated.
     */
    Viewer3D.prototype.setClickToSetCOI = function(state, updatePrefs)
    {
        if (updatePrefs !== false)
            this.prefs.set('clickToSetCOI', state);

        var currentOn = this.getClickConfig("click", "onObject");
        if( state )
        {
            if( currentOn.indexOf("setCOI") === -1 ) // Not already set?
            {
                this.setClickConfig("click", "onObject",  [ "setCOI" ]);
            }
        }
        else if( currentOn.indexOf("setCOI") >= 0 ) // Is currently set?
        {
            this.setClickConfig("click", "onObject",  [ "selectOnly" ]);
        }
    };


    /**
     * Initializes all gui settings to their defaults or to the session stored setting
     * This gives session stored settings priority
     */
    Viewer3D.prototype.initSettings = function() {

        this.prefs.load(av.DefaultSettings);

        this.prefs.tag('3d');
        this.prefs.tag('2d');
        this.prefs.untag('2d', [ // 3d only
            'viewCube',
            'alwaysUsePivot',
            'zoomTowardsPivot',
            'reverseHorizontalLookDirection',
            'reverseVerticalLookDirection',
            'orbitPastWorldPoles',
            'clickToSetCOI',
            'ghosting',
            'optimizeNavigation',
            'ambientShadows',
            'antialiasing',
            'groundShadow',
            'groundReflection',
            'lineRendering',
            'lightPreset',
            'envMapBackground',
            'renderPrism',
            'firstPersonToolPopup'
        ]);
        this.prefs.untag('3d', [ // 2d only
            'swapBlackAndWhite'
        ]);

        // Apply settings
        this.setQualityLevel(this.prefs.ambientShadows, this.prefs.antialiasing);
        this.setGroundShadow(this.prefs.groundShadow);
        this.setGroundReflection(this.prefs.groundReflection);
        this.setGhosting(this.prefs.ghosting);
        this.setProgressiveRendering(this.prefs.progressiveRendering);
        this.setSwapBlackAndWhite(this.prefs.swapBlackAndWhite);
        this.setClickToSetCOI(this.prefs.clickToSetCOI);
        this.setOptimizeNavigation(this.prefs.optimizeNavigation);
        this.hideLines(!this.prefs.lineRendering);
        this.hidePoints(!this.prefs.pointRendering);
        this.setEnvMapBackground(this.prefs.envMapBackground);
        this.setRenderPrism(this.prefs.renderPrism);
        this.setFirstPersonToolPopup(this.prefs.firstPersonToolPopup);

        this.navigation.setUsePivotAlways(this.prefs.alwaysUsePivot);
        this.navigation.setReverseZoomDirection(this.prefs.reverseMouseZoomDir);
        this.navigation.setReverseHorizontalLookDirection(this.prefs.reverseHorizontalLookDirection);
        this.navigation.setReverseVerticalLookDirection(this.prefs.reverseVerticalLookDirection);
        this.navigation.setZoomTowardsPivot(this.prefs.zoomTowardsPivot);
        this.navigation.setOrbitPastWorldPoles(this.prefs.orbitPastWorldPoles);
        this.navigation.setUseLeftHandedInput(this.prefs.leftHandedMouseSetup);

        var bacStr = this.prefs.backgroundColorPreset;
        if (bacStr) {
            try {
                var bac = JSON.parse(bacStr);
                this.impl.setClearColors(bac[0],bac[1],bac[2],bac[3],bac[4],bac[5]);
            } catch(e) {
                this.prefs.set("backgroundColorPreset", null);
            }
        }

        // done last, so that if the environment has a background color, it
        // overrides any previous background color preference.
        var lightPreset = /*viewer.model.is2d() ? avp.DefaultLightPreset2d :*/ this.prefs.lightPreset;
        this.impl.setLightPreset(lightPreset);
    };

    /**
     * Sets the Light Presets (Environments) for the Viewer.
     *
     * Not applicable to 2D.
     *
     * Sets the preference in the UI
     * @param {Number} index - where
     * - 0 Simple Grey
     * - 1 Sharp Highlights
     * - 2 Dark Sky
     * - 3 Grey Room
     * - 4 Photo Booth
     * - 5 Tranquility
     * - 6 Infinity Pool
     * - 7 Simple White
     * - 8 Riverbank
     * - 9 Contrast
     * - 10 Rim Highlights
     * - 11 Cool Light
     * - 12 Warm Light
     * - 13 Soft Light
     * - 14 Grid Light
     * - 15 Plaza
     * - 16 Snow Field
     * @note this list is copied from the ones in Environments.js
     */

    Viewer3D.prototype.setLightPreset = function (index) {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setLightPreset is not applicable to 2D");
            return;
        }

        this.prefs.set('lightPreset', index);

        this.impl.setLightPreset(index);
    };

    /**
     *  Set or unset a view navigation option which requests that orbit controls always orbit around the currently set pivot point.
     *
     *  Sets the preference in the UI
     *  @param {boolean} value - value of the option, true to request use of the pivot point. When false some controls may pivot around the center of the view. (Currently applies only to the view-cube orbit controls.)
     */
    Viewer3D.prototype.setUsePivotAlways = function (value) {
        this.prefs.set('alwaysUsePivot', value);
        this.navigation.setUsePivotAlways(value);
    };

    /**
     * Set or unset a view navigation option to reverse the default direction for camera dolly (zoom) operations.
     *
     *  Sets the preference in the UI
     *  @param {boolean} value - value of the option, true for reverse, false for default
     */
    Viewer3D.prototype.setReverseZoomDirection = function (value) {
        this.prefs.set('reverseMouseZoomDir', value);
        this.navigation.setReverseZoomDirection(value);
    };

    /**
     * Set or unset a view navigation option to reverse the default direction for horizontal look operations.
     *
     * Not applicable to 2D.
     *
     *  Sets the preference in the UI
     *  @param {boolean} value - value of the option, true for reverse, false for default
     */
    Viewer3D.prototype.setReverseHorizontalLookDirection = function (value) {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setReverseHorizontalLookDirection is not applicable to 2D");
            return;
        }

        this.prefs.set('reverseHorizontalLookDirection', value);
        this.navigation.setReverseHorizontalLookDirection(value);
    };

    /**
     * Set or unset a view navigation option to reverse the default direction for vertical look operations.
     *
     * Not applicable to 2D.
     *
     *  Sets the preference in the UI
     *  @param {boolean} value - value of the option, true for reverse, false for default
     */
    Viewer3D.prototype.setReverseVerticalLookDirection = function (value) {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setReverseVerticalLookDirection is not applicable to 2D");
            return;
        }

        this.prefs.set('reverseVerticalLookDirection', value);
        this.navigation.setReverseVerticalLookDirection(value);
    };

    /**
     * Get the state of the view navigation option that requests the default direction for camera dolly (zoom) operations to be towards the camera pivot point.
     *
     *  Sets the preference in the UI
     *  @param {boolean} value - value of the option, true for towards the pivot, false for default
     */
    Viewer3D.prototype.setZoomTowardsPivot = function (value) {
        this.prefs.set('zoomTowardsPivot', value);
        this.navigation.setZoomTowardsPivot(value);
    };

    /**
     * Set or unset a view navigation option to allow the orbit controls to move the camera beyond the north and south poles (world up/down direction). In other words, when set the orbit control will allow the camera to rotate into an upside down orientation. When unset orbit navigation should stop when the camera view direction reaches the up/down direction.
     *
     * Not applicable to 2D.
     *
     *  Sets the preference in the UI
     *  @param {boolean} value - value of the option, true to allow orbiting past the poles.
     */
    Viewer3D.prototype.setOrbitPastWorldPoles = function (value) {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setOrbitPastWorldPoles is not applicable to 2D");
            return;
        }

        this.prefs.set('orbitPastWorldPoles', value);
        this.navigation.setOrbitPastWorldPoles(value);
    };

    /**
     * Set or unset a view navigation option which requests that mouse buttons be reversed from their default assignment. i.e. Left mouse operation becomes right mouse and vice versa.
     *
     *  Sets the preference in the UI
     *  @param {boolean} value - value of the option, true to request reversal of mouse button assignments.
     */
    Viewer3D.prototype.setUseLeftHandedInput = function (value) {
        this.prefs.set('leftHandedMouseSetup', value);
        this.navigation.setUseLeftHandedInput(value);
    };

    /**
     * Set visibility for a single layer, or for all layers.
     *
     * Not yet implemented for 3D.
     *
     * @param {?Array} nodes - An array of layer nodes, or a single layer node, or null for all layers
     * @param {boolean} visible - true to show the layer, false to hide it
     * @param {boolean=} [isolate] - true to isolate the layer
     */
    Viewer3D.prototype.setLayerVisible = function (nodes, visible, isolate) {
        if( this.model && !this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setLayerVisible is not yet implemented for 3D");
            return;
        }

        function getLayerIndexes(node) {

            if (node.isLayer) {
                return [node.index];
            }

            if (node.children) {
                var layerIndexes = [];
                var children = node.children;
                for (var i = 0; i < children.length; ++i) {
                    layerIndexes = layerIndexes.concat( getLayerIndexes(children[i]) );
                }
                return layerIndexes;            
            }

            return [];
        }

        var layersRoot = this.model.getLayersRoot();
        if (!layersRoot || 0 === layersRoot.childCount) {
            return;
        }

        if (nodes === null) {
            nodes = [layersRoot];
        }
        if (!Array.isArray(nodes)) {
            nodes = [nodes];
        }

        if (isolate) {
            // if we isolate, that means turn off everything to start.
            var allLayerIndices = getLayerIndexes(layersRoot);
            this.impl.setLayerVisible(allLayerIndices, false);
            visible = true; // force this because isolate + not visible doesn't make sense
        }

        // now set the visibility of the selected set
        var layerIndexes = [];
        for (var i = 0; i < nodes.length; ++i) {
            var nodeLayerIndices = getLayerIndexes(nodes[i]);
            layerIndexes = layerIndexes.concat( nodeLayerIndices );
        }
        this.impl.setLayerVisible(layerIndexes, visible);
        this.fireEvent({type: av.LAYER_VISIBILITY_CHANGED_EVENT});
    };

    /**
     * Returns true if the layer is visible.
     *
     * Not yet implemented for 3D.
     *
     * @param {Object} node - Layer node
     * @returns {boolean} true if the layer is visible
     */
    Viewer3D.prototype.isLayerVisible = function (node) {
        if( this.model && !this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.isLayerVisible is not yet implemented for 3D");
            return false;
        }

        return !!(node && node.isLayer && this.impl.isLayerVisible(node.index));
    };

    /**
     * Returns true if any layer is hidden.
     *
     * Not yet implemented for 3D.
     *
     * @returns {boolean} true if any layer is hidden
     */
    Viewer3D.prototype.anyLayerHidden = function () {
        if( this.model && !this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.anyLayerHidden is not yet implemented for 3D");
            return false;
        }

        var that = this;

        function anyLayerHidden(node) {
            if (node.isLayer) {
                return !that.impl.isLayerVisible(node.index);
            } else {
                var children = node.children;
                for (var i = 0; i < children.length; ++i) {
                    if (anyLayerHidden(children[i])) {
                        return true;
                    }
                }
            }
            return false;
        }

        var layersRoot = that.model.getLayersRoot();
        return !!(layersRoot && anyLayerHidden(layersRoot));
    };

    /**
     * If enabled, set ground shadow color
     *
     * Not applicable to 2D
     *
     * @param {THREE.Color} color
     */
    Viewer3D.prototype.setGroundShadowColor = function(color) {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setGroundShadowColor is not applicable to 2D");
            return;
        }

        this.impl.setGroundShadowColor(color);
    };

    /**
     * If enabled, set ground shadow alpha
     *
     * Not applicable to 2D
     *
     * @param {float} alpha
     */
    Viewer3D.prototype.setGroundShadowAlpha = function(alpha) {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setGroundShadowAlpha is not applicable to 2D");
            return;
        }

        this.impl.setGroundShadowAlpha(alpha);
    };

    /**
     * If enabled, set ground reflection color. This is reset to default when reflections toggled off.
     *
     * Not applicable to 2D
     *
     * @param {THREE.Color} color
     */
    Viewer3D.prototype.setGroundReflectionColor = function(color) {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setGroundReflectionColor is not applicable to 2D");
            return;
        }

        this.impl.setGroundReflectionColor(color);
    };

    /**
     * If enabled, set ground reflection alpha. This is reset to default when reflections toggled off.
     *
     * Not applicable to 2D
     *
     * @param {float} alpha
     */
    Viewer3D.prototype.setGroundReflectionAlpha = function(alpha) {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.setGroundReflectionAlpha is not applicable to 2D");
            return;
        }

        this.impl.setGroundReflectionAlpha(alpha);
    };

    /**
     * Returns a list of active cut planes
     *
     * Not applicable to 2D
     *
     * @return {THREE.Vector4[]} List of Vector4 plane representation {x:a, y:b, z:c, w:d}
     */
    Viewer3D.prototype.getCutPlanes = function() {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.getCutPlanes is not applicable to 2D");
            return [];
        }

        return this.impl.getCutPlanes();
    };

    /**
     * Apply a list of cut planes
     *
     * Not applicable to 2D
     *
     * @param {THREE.Vector4[]} planes - List of Vector4 plane representation: {x:a, y:b, z:c, w:d}
     * Plane general equation: ax + by + cz + d = 0 where a, b, and c are not all zero
     * Passing an empty list or null is equivalent to setting zero cut planes
     */
    Viewer3D.prototype.setCutPlanes = function(planes) {
        if( this.model && this.model.is2d() )
        {
            avp.logger.warn("Viewer3D.getCutPlanes is not applicable to 2D");
            return;
        }

        this.impl.setCutPlanes(planes);
    };

    /**
     * Captures the current screen image as Blob URL
     * Blob URL can be used like a regular image url (e.g., window.open, img.src, etc)
     * If width and height are 0, returns asynchronously and calls the callback with an image as Blob URL with dimensions equal to current canvas dimensions
     * If width and height are given, returns asynchronously and calls the callback with the resized image as Blob URL
     * If no callback is given, displays the image in a new window.<br>
     * See also [getScreenShotBuffer()]{@link Autodesk.Viewing.Viewer3D#getScreenShotBuffer}.
     * @param  {int}      [w]  width of the requested image
     * @param  {int}      [h]  height of the requested image
     * @param  {Function} [cb] callback
     * @return {DOMString}     screenshot image Blob URL, if no parameters are given
     */
    Viewer3D.prototype.getScreenShot = function(w, h, cb) {
        return this.impl.getScreenShot(w, h, cb);
    };

    /**
     * Alternative call to [getScreenShot()]{@link Autodesk.Viewing.Viewer3D#getScreenShot}
     * which internally uses additional steps (more processing) to generate the screenshot.
     * @param  {int}      [w]  width of the requested image
     * @param  {int}      [h]  height of the requested image
     * @param  {Function} [cb] callback
     */
    Viewer3D.prototype.getScreenShotBuffer = function (w, h, cb) {
        return this.impl.getScreenShotBuffer(w, h, cb);
    };

    /**
     * Sets the object context menu.
     * @param {?ObjectContextMenu=} [contextMenu]
     */
    Viewer3D.prototype.setContextMenu = function (contextMenu) {

        if (this.contextMenu) {

            // Hide the current context menu, just in case it's open right now.
            // This does nothing if the context menu is not open.
            //
            this.contextMenu.hide();
        }

        this.contextMenu = contextMenu || null; // to avoid undefined
    };

    /**
     * Activates the default context menu.<br>
     * Contains options Isolate, Hide selected, Show all objects, Focus and Clear selection.
     *
     * @returns {boolean} Whether the default context menu was successfully set (true) or not (false)
     */
    Viewer3D.prototype.setDefaultContextMenu = function() {

        var ave = Autodesk.Viewing.Extensions;
        if (ave && ave.ViewerObjectContextMenu) {
            this.setContextMenu(new ave.ViewerObjectContextMenu(this));
            return true;
        }
        return false;
    };

    Viewer3D.prototype.triggerContextMenu = function (event) {
        if (this.config && this.config.onTriggerContextMenuCallback) {
            this.config.onTriggerContextMenuCallback(event);
        }

        if (this.contextMenu) {
            this.contextMenu.show(event);
            return true;
        }
        return false;
    };

    Viewer3D.prototype.triggerSelectionChanged = function (dbId) {
        if (this.config && this.config.onTriggerSelectionChangedCallback) {
            this.config.onTriggerSelectionChangedCallback(dbId);
        }
    };

    Viewer3D.prototype.triggerDoubleTapCallback = function (event) {
        if (this.config && this.config.onTriggerDoubleTapCallback) {
            this.config.onTriggerDoubleTapCallback(event);
        }
    }

    Viewer3D.prototype.triggerSingleTapCallback = function (event) {
        if (this.config && this.config.onTriggerSingleTapCallback) {
            this.config.onTriggerSingleTapCallback(event);
        }
    }

    Viewer3D.prototype.initContextMenu = function() {

        // Disable the browser's default context menu by default, or if explicitly specified.
        //
        var disableBrowserContextMenu = !this.config || (this.config.hasOwnProperty("disableBrowserContextMenu") ? this.config.disableBrowserContextMenu : true);
        if (disableBrowserContextMenu) {
            this.onDefaultContextMenu = function (e) {
                e.preventDefault();
            };
            this.container.addEventListener('contextmenu', this.onDefaultContextMenu, false);
        }

        var self = this;

        function isRightClick(event) {
            var button = event.button;

            // Check for Firefox spoof: Control+LMB converted to RMB.
            // The "buttons" property in Firefox will include 1 for LMB and 2 for RMB.
            if( "buttons" in event ) {
                // For button down the 1 bit will be on indicating LMB.
                // For button up it's off so check the flag to see if we
                // switched the down event.
                if( self.__firefoxLMBfix && !(event.buttons & 1) ) { // Button up?
                    self.__firefoxLMBfix = false;
                    button = 0;
                    // avp.logger.log("FIREFOX UP!!!");
                }
                else if( (button === 2) && (event.buttons & 1) ) {
                    button = 0;    // Convert back to reality.
                    self.__firefoxLMBfix = true;
                    // avp.logger.log("FIREFOX SUX!!!");
                }
            }

            var useLeftHandedInput = self.navigation ? self.navigation.getUseLeftHandedInput() : false;
            var rightButton = useLeftHandedInput ? 0 : 2;

            if( button === rightButton )
                return true;

            /* See SPK-930 and SPK-928
             var isMac = (navigator.userAgent.search("Mac OS") !== -1);
             var leftButton = (rightButton === 2) ? 0 : 2;
             return isMac && event.ctrlKey && (event.button === leftButton);
             */
            return false;
        }

        var canvas = this.canvas || this.container;

        canvas.addEventListener( 'mousedown',
            function(event) {
                if (isRightClick(event)) {
                    self.startX = event.clientX;
                    self.startY = event.clientY;
                }
            } );

        canvas.addEventListener( 'mouseup',
            function ( event ) {
                if (isRightClick(event) && event.clientX === self.startX && event.clientY === self.startY) {
                    self.triggerContextMenu(event);
                }
                return true;
            }, false );
    };


    /**
     * Registers a new callback that modifies the context menu.
     * This allows extensions and others to add, remove, or change items in the context menu.
     * Extensions that call registerContextMenuCallback() should call unregisterContextMenuCallback() in their unload().
     * @param {string} id - Unique id to identify this callback. Used by unregisterContextMenuCallback().
     * @param {function(Array, Object)} callback - Will be called before the context menu is displayed.
     * @see Viewer.unregisterContextMenuCallback
     * @see ObjectContextMenu.buildMenu
     *
     * @example
     * // Here's an example that appends a new context menu item:
     *
     * viewer.registerContextMenuCallback('MyExtensionName', function (menu, status) {
 *     if (status.hasSelected) {
 *         menu.push({
 *             title: 'My new context menu item with selected objects',
 *             target: function () {
 *                 alert('Do something with selected objects');
 *         });
 *     } else {
 *         menu.push({
 *             title: 'My new context menu item, no selected objects',
 *             target: function () {
 *                 alert('Do something else');
 *         });
 *     }
 * });
 */
    Viewer3D.prototype.registerContextMenuCallback = function (id, callback) {
        this.contextMenuCallbacks[id] = callback;
    };

    /**
     * Unregisters an existing callback that modifies the context menu.
     * Extensions that call registerContextMenuCallback() should call unregisterContextMenuCallback() in their unload().
     * @param {string} id - Unique id to identify this callback.
     * @returns {boolean} true if the callback was unregistered successfully.
     * @see Viewer.registerContextMenuCallback
     */
    Viewer3D.prototype.unregisterContextMenuCallback = function (id) {
        if (id in this.contextMenuCallbacks) {
            delete this.contextMenuCallbacks[id];
            return true;
        }
        return false;
    };

    /**
     * Runs all registered context menu callbacks.
     * @param {Array} menu - Context menu items.
     * @param {Object} status - Information about nodes.
     * @see ObjectContextMenu.buildMenu
     * @private
     */
    Viewer3D.prototype.runContextMenuCallbacks = function (menu, status) {
        for (var id in this.contextMenuCallbacks) {
            if (this.contextMenuCallbacks.hasOwnProperty(id)) {
                this.contextMenuCallbacks[id](menu, status);
            }
        }
    };

    /**
     * Play animation if animation data is available as part of model data.
     * If the model data does not contain any animation, this function call is a no op.
     * @param  {Function} [callback] Callback function that would be invoked at each frame of the animation.
     * The callback function takes a single input value, with value range between 0 and 100, inclusive, with value
     * 100 indicates the animation has finished playing.
     * @example
     * Here is an example of callback function.
     * function(value) {
     *     if (value < 100)
     *         console.log("Animation progress: " + value + "%.");
     *     else
     *         console.log("Animation finished.");
     * }
     */
    Viewer3D.prototype.playAnimation = function (callback) {
        var animator = this.impl.keyFrameAnimator;
        if (animator) {
            animator.play(0, callback);
        }
    };

    /**
     * Join a live review session.
     *
     * @param {string} [sessionId] - The live review session id to join.
     */
    Viewer3D.prototype.joinLiveReview = function (sessionId) {
        if (!this.liveReviewClient) {
            this.liveReviewClient = new avp.LiveReviewClient(this);
        }

        var liveReviewClient = this.liveReviewClient;
        avp.loadDependency("lmv_io", "socket.io-1.3.5.js", function(){
            liveReviewClient.joinLiveReviewSession(sessionId);
        });
    };

    /**
     * Leave a live review session.
     */
    Viewer3D.prototype.leaveLiveReview = function () {
        if (this.liveReviewClient) {
            this.liveReviewClient.leaveLiveReviewSession();
        }
    };

    /**
     * Set model units
     * @param Model units
     */
    Viewer3D.prototype.setModelUnits = function(modelUnits) {
        if (this.model) {
            this.model.getData().overriddenUnits = modelUnits;
        }
    };

    /**
     * Calculates the pixel position in client space coordinates of a point in world space.<br>
     * See also
     * [clientToWorld()]{@link Autodesk.Viewing.Viewer3D#clientToWorld}.
     * @param {THREE.Vector3} point Point in world space coordinates.
     * @returns {THREE.Vector3} Point transformed and projected into client space coordinates. Z value is 0.
     */
    Viewer3D.prototype.worldToClient = function(point) {
        return this.impl.worldToClient(point);
    };

    /**
     * Given coordinates in pixel screen space it returns information of the underlying geometry node.
     * Hidden nodes will not be taken into account. Returns null if there is no geometry in the specified location.
     * For 2d models, it will return null outside the paper.<br>
     * See also
     * [worldToClient()]{@link Autodesk.Viewing.Viewer3D#worldToClient}.
     *
     * @param {Number} clientX - X coordinate where 0 is left
     * @param {Number} clientY - Y coordinate where 0 is top
     * @param {Boolean} [ignoreTransparent] - Ignores transparent materials
     * @returns {Object|null} contains point attribute. 3d models have additional attributes.
     */
    Viewer3D.prototype.clientToWorld = function(clientX, clientY, ignoreTransparent) {

        return this.impl.clientToWorld(clientX, clientY, ignoreTransparent);
    };

    /**
     * Expose if the model has topology information
     * Only applicable to 3D
     * @returns {boolean} value - Indicates whether the model has topology information.
     */
    Viewer3D.prototype.modelHasTopology = function() {

        if (this.model && this.model.getData().topology) {
            return true;
        }

        return false;
    };

    /**
     * Changes color of the selection overlay.
     * @example
     *  viewer.setSelectionColor(new THREE.Color(0xFF0000)); // red color
     * @param {THREE.Color} color
     */
    Viewer3D.prototype.setSelectionColor = function(color) {
        this.impl.setSelectionColor(color);
    };

    /**
     * Create ViewCube.
     */
    Viewer3D.prototype.createViewCube = function() {

        if (!this.viewCubeUi) {
            this.viewCubeUi = new avp.ViewCubeUi(this);
            this.viewCubeUi.create();
            this.displayViewCube(true);
        }
    };

    /**
     * Display ViewCube.
     * @param {boolean} display - Display or hide the ViewCube.
     */
    Viewer3D.prototype.displayViewCube = function(display) {

        if (this.viewCubeUi) {
            this.viewCubeUi.displayViewCube(display, false);
        }
    };

    /**
     * Display ViewCube.
     * @param {boolean} display - Display or hide the ViewCube with home and info buttons.
     */
    Viewer3D.prototype.displayViewCubeUI = function(display) {

        if (this.viewCubeUi) {
            this.viewCubeUi.setVisible(display);
        }
    };

    /**
     * Set the face of ViewCube and apply camera transformation according to it.
     * @param {string} face - The face name of ViewCube. The name can contain multiple face names,
     * the format should be `"[front/back], [top/bottom], [left/right]"`.
     */
    Viewer3D.prototype.setViewCube = function(face) {

        if (this.viewCubeUi && this.viewCubeUi.cube) {
            this.viewCubeUi.cube.cubeRotateTo(face);
        }
    };

    /**
     * Highlight an object with a theming color that is blended with the original object's material.
     * @param {number} dbId
     * @param {THREE.Vector4} color - (r, g, b, intensity), all in [0,1].
     * @param {Autodesk.Viewing.RenderModel} [model] - For multi-model support.
     */
    Viewer3D.prototype.setThemingColor = function(dbId, color, model) {
        // use default RenderModel by default
        model = model || this.model;

        model.setThemingColor(dbId, color);

        // we changed the scene to apply theming => trigger re-render
        this.impl.invalidate(true);
    };

    /**
     * Restore original colors for all themed shapes.
     * @param {Autodesk.Viewing.RenderModel} [model] - For multi-model support.
     */
    Viewer3D.prototype.clearThemingColors = function(model) {
        // use default RenderModel by default
        model = model || this.model;

        model.clearThemingColors();

        // we changed the scene to apply theming => trigger re-render
        this.impl.invalidate(true);
    }

    /**
     * Transfer model from this viewer to another one - including state of selection, ghosting, and theming.
     */
    Viewer3D.prototype.transferModel = function(modelId, viewer) {

        var model = this.impl.findModel(modelId);
        if (!model) {
            // unknown modeId
            return;
        }

        // collect all selected db ids for this model
        var selectedIds = [];
        this.getAggregateSelection(function(model, dbId) {
            if (model.id==modelId) {
                selectedIds.push(dbId);
            }
        });

        // collect isolated/hidden nodes
        var isolatedIds = this.impl.visibilityManager.getIsolatedNodes(model);
        var hiddenIds   = this.impl.visibilityManager.getHiddenNodes(model);

        // export all materials and textures to MaterialManager of the other viewer
        // Note: Getting the materials from MaterialManager directly is the safest way for consistent state between both viewers.
        // E.g., enumerating the materials of the RenderModel instead would not work for 2 reasons:
        //  a) If the model is still loading, some materials would get lost: SvfLoader adds all materials in onModelRootLoadDone() already.
        //     But, RenderModel only knows materials for meshes that have been already loaded.
        //  b) The material hashes are only known to MaterialManager
        var modelMaterials = this.impl.matman().exportModelMaterials(model);

        // remove model from this viewer
        this.impl.removeModel(model);

        // pass model to other viewer
        viewer.model = model;
        viewer.impl.addModel(model);

        // import materials to new viewer
        // Note that it is essential to do export/import of materials in separate steps:
        //  - Exporting materials must be done before removing the model. After removeModel(),
        //    MaterialManager would not contain the material of this model anymore.
        //  - Importing materials must be done after adding the model to make sure that everything is properly initialized.
        //    E.g., the layerTexture would not be initialized otherwise.
        viewer.impl.matman().importModelMaterials(modelMaterials);

        // if the other viewer had no model before, make sure that the loadSpinner disappears.
        if (viewer.loadSpinner) {
            viewer.loadSpinner.style.display = "None";
        }

        // link running loader to new viewer
        if (model.loader && model.loader.viewer3DImpl===this.impl) {
            model.loader.viewer3DImpl = viewer.impl;
        }

        // if model is still loading, the worker will call onLoadComplete later. If the model is still loaded,
        // we do it immediately.
        if (model.getData().loadDone) {
            viewer.impl.onLoadComplete(model);
        }

        // recover selection
        viewer.impl.selector.setSelection(selectedIds, model);

        // recover isolated/hidden nodes (Note that hiddenIds are only used if no node is isolated)
        if (isolatedIds.length!=0)      viewer.impl.visibilityManager.isolate(isolatedIds, model);
        else if (hiddenIds.length!=0)   viewer.impl.visibilityManager.hide(hiddenIds, model);
    }

Autodesk.Viewing.Viewer3D = Viewer3D;

})();
;
// Viewer3D offers public methods for developers to use.
// Viewer3DImpl is the implementation file for Viewer3D and is only used by Viewer3D.js
// 
// Viewer3D does things like parameter validation.
// Viewer3DImpl does the actual work, by interfacing with other internal components, such as the MaterialManager.

var av = Autodesk.Viewing,
    avp = Autodesk.Viewing.Private;

var ENABLE_DEBUG = avp.ENABLE_DEBUG || true;
var ENABLE_TRACE = avp.ENABLE_TRACE || true;

(function() {

"use strict";

//default parameters for WebGL initialization
av.InitParametersSetting = {
    canvas: null,
    antialias: false,
    alpha: false,
    premultipliedAlpha: false,
    preserveDrawingBuffer: true,
    stencil: false,
    depth: false,
    devicePixelRatio: null
};



/** @constructor */
function Viewer3DImpl(thecanvas, theapi)
{
    var _this = this;

    //Frame time cutoffs in milliseconds. We target the middle value,
    //but adjust the CPU-side work in the give min/max range
    //once we measure actual frame times (including async GPU work, system load, etc).
    //NOTE: These are doubled for mobile devices at construction time (end of this file).
    var MAX_FRAME_BUDGET = 1000 / 15,
        TARGET_FRAME_TIME = 1000 / 30,
        MIN_FRAME_BUDGET = 1000 / 120; //We aren't hoping for 120 fps -- this is just how often tick() gets called
                                     //not counting GPU latency, etc.

    var _phase = avp.RENDER_NORMAL;

    var _currentLightPreset = -1;
    var _oldLightPreset = -1;

    var _lastTickMoved = false;

    var _worldUp;
    var _worldUpName = "y";

    var _reqid, _needsResize, _newWidth, _newHeight, _materials;
    var _webglrender, _renderer;

    var _shadowMaps;

    // Default direction in world-space from which we get the most light from. Needed for shadow casting.
    // The default is only used if no direction is specified by light preset or model.
    var _shadowLightDirDefault = null; // {THREE.Vector3}
    var _shadowLightDir        = null; //

    var _needsClear = false,
        _needsRender = false,
        _overlayDirty = false;

    var _progressEvent = {type:Autodesk.Viewing.PROGRESS_UPDATE_EVENT, percent:0};

    var _sceneDirty = false;
    var _neededPresent = false; // True if previous frame needed to present.

    var _cameraUpdated;

    var _explodeScale = 0;

    var _lastBeginFrameTimeStamp = 0, _beginFrameAvg = 0;

    var _lastHighResTimeStamp = 0;

    var _frameTimeAvg = 1000.0 / 60.0;
    var _frameTimeSamples = 0;

    var _isLoading = true;  // turned off in onLoadComplete()

    var _groundShadow, _groundReflection;

    var _envMapBackground = false;

    var _modelQueue;

    var _AOsuppressed = false;
    var _turnAOonAndRender = false;

    var _lightsInitialized        = false;
    var _defaultLightIntensity    = 1.0;
    var _defaultDirLightColor     = null; // {THREE.Color}
    var _defaultAmbientColor      = null; //

    if (thecanvas) {
        setInterval(function() {
            // Only start reporting the framerate to ADP when there's been "enough" samples
            if (_isLoading || _frameTimeSamples < 60) {
                return;
            }
            _this.track({ name: 'fps', value: Number(_this.fps().toFixed(2)), aggregate: 'last' });
        }, 30000);
    }

    this.api = theapi;
    this.canvas = thecanvas;
    this.loader = null;

    //Slower initialization pieces can be delayed until after
    //we start loading data, so they are separated out here.
    this.initialize = function() {

        _worldUp = new THREE.Vector3(0,1,0);
        _modelQueue = new avp.RenderScene();

        //TODO: node webgl renderer
        _webglrender = createRenderer(thecanvas);
        if (!_webglrender && !av.isNodeJS) {
            return;
        }

        _renderer = new avp.RenderContext();
        _renderer.init(_webglrender, thecanvas ? thecanvas.clientWidth : 0, thecanvas ? thecanvas.clientHeight : 0);
        this.use2dInstancing = av.isMobileDevice() && this.glrenderer().supportsInstancedArrays();

        _materials = new avp.createMaterialManager(_webglrender);

        //this.camera = new THREE.CombinedCamera( w, h, VIEW_ANGLE, NEAR, FAR, NEAR, FAR);
        // this.camera = new THREE.PerspectiveCamera( VIEW_ANGLE, thecanvas.clientWidth/thecanvas.clientHeight, NEAR, FAR);
        // this.cameraChangedEvent = {type: Autodesk.Viewing.CAMERA_CHANGE_EVENT, camera: this.camera};
        //this.camera = new THREE.CombinedCamera( w, h, VIEW_ANGLE, NEAR, FAR, NEAR, FAR);
        avp.init_UnifiedCamera(THREE);
        this.camera = new av.UnifiedCamera(thecanvas ? thecanvas.clientWidth : 512, thecanvas ? thecanvas.clientHeight : 512);
        this.lightsOn = false;
        // we'll fill this in later, in initLights.
        this.lights = [];
        // pass in when lightsOn is false;
        this.no_lights = [];

        _defaultDirLightColor = new THREE.Color().setRGB(1,1,1);
        _defaultAmbientColor  = new THREE.Color().setRGB(1,1,1);

        // this.camera = this.unicam.getOrthographicCamera();
        this.cameraChangedEvent = this.camera.getCameraChangedEvent();

        _shadowLightDirDefault = new THREE.Vector3(1,1,1);
        _shadowLightDir        = new THREE.Vector3().copy(_shadowLightDirDefault);

        //This scene will just hold the camera and lights, while
        //we keep groups of progressively rendered geometry in
        //separate geometry scenes.
        this.scene = new THREE.Scene();
        this.sceneAfter = new THREE.Scene();
        this.sceneAfter.sortObjects = false;

        this.overlayScenes = {};

        this.selectionMaterial2d = null;

        this.selectionMaterialBase = new THREE.MeshPhongMaterial({color:0x6699ff, specular:0x080808, emissive:0x334c77, ambient:0, opacity:1.0, transparent:false});
        this.selectionMaterialTop = new THREE.MeshPhongMaterial({color:0x6699ff, specular:0x080808, emissive:0x334c77, ambient:0, opacity:0.15, transparent:true});
        this.selectionMaterialTop.packedNormals = true;
        this.selectionMaterialBase.packedNormals = true;
        createSelectionScene("selection", this.selectionMaterialBase, this.selectionMaterialTop);
        this.selectionMeshes = {};

        this.fadeMaterial = new THREE.MeshPhongMaterial({color:0xffffff, opacity:0.1, reflectivity: 0, transparent:true, depthWrite:false});
        this.fadeMaterial.packedNormals = true;
        _materials.addMaterial("__fadeMaterial__", this.fadeMaterial, true);

        this.highlightMaterial = new THREE.MeshPhongMaterial({color:0x6699ff, specular:0x080808, emissive:0x334c77, ambient:0, opacity:1.0, transparent:false});
        this.highlightMaterial.packedNormals = true;
        _materials.addMaterial("__highlightMaterial__", this.highlightMaterial, true);

        //Settings exposed to GUI:
        this.progressiveRender = true;
        this.swapBlackAndWhite = false;

        this.targetFrameBudget = TARGET_FRAME_TIME;
        if (av.isMobileDevice()) {
            MAX_FRAME_BUDGET *= 2;      // Increase to match TARGET_FRAME_TIME
            MIN_FRAME_BUDGET /= 2;      // GPUs are slower on mobile, so allow the frame budget to be smaller
            TARGET_FRAME_TIME *= 2;     // GPUs are slower on mobile use a longer target frame time
            this.targetFrameBudget /= 2;// The frame budget needs to be smaller because mobile GPUs are slower.
        }

        this.controls = {
            update: function(timeStamp) {
                this.camera.lookAt( this.camera.target );
                this.camera.updateProjectionMatrix();
                this.camera.dirty = false;
            },
            handleResize: function() {},
            recordHomeView: function() {},
            uninitialize: function() {}
        };

        this.selector = new avp.MultiModelSelector(this);

        this.visibilityManager = new avp.MultiModelVisibilityManager(this);

        this.showGhosting = true;
        this.showOverlaysWhileMoving = true;
        this.skipAOWhenMoving = false;

        this.keyFrameAnimator = null;
        this.zoomBoundsChanged = true;

        var cc = avp.LightPresets[avp.DefaultLightPreset].bgColorGradient;
        this.setClearColors(cc[0], cc[1], cc[2], cc[3], cc[4], cc[5]);

        _groundShadow = new av.Shaders.GroundShadow(_webglrender);
        _groundShadow.enabled = true;

        // TODO_NOP: hack register materials for cutplanes
        _materials.addMaterialNonHDR("groundShadowDepthMaterial", _groundShadow.getDepthMaterial());
        _materials.addOverrideMaterial("normalsMaterial", _renderer.getDepthMaterial());

        //just meant to do an initial clear to the background color we want.
        _renderer.beginScene(this.scene, this.camera, this.noLights, true);
        _renderer.composeFinalFrame(true);
    };


    function createRenderer(canvas) {

        if (!canvas)
            return null;

        //TODO: improve the pixel scale heuristics below
        var dpr = window.devicePixelRatio;
        if (!dpr) dpr = 1;

        //High density display -- turn off antialiasing since
        //it's not worth the slowdown in that case.
        //if (dpr >= 2.0)
        //    _settings.antialias = false;

        //Expose the pramaters to outside so that we could set these params on HTML.
        var params = av.InitParametersSetting;
        params.canvas=canvas;
        params.devicePixelRatio=dpr;

        var renderer = new avp.FireflyWebGLRenderer(params);

        if (!renderer.context)
            return null;

        renderer.autoClear = false;

        //Turn off scene sorting by THREE -- this is ok if we
        //do progressive draw in an order that makes sense
        //transparency-wise. If we start drawing using a frustum culling
        //r-tree or there are problems with transparency we'd have to turn on sorting.
        renderer.sortObjects = false;

        return renderer;
    }


    //Bridge between the render queue and render context
    //For passing pieces of model to the renderer during
    //timed progressive rendering, while also taking into account
    //the current rendering mode of the viewer
    function renderSomeCallback(scene) {

        //Ideally, here we only want the piece of the
        //render function that specifically renders geometries,
        //and none of the camera update stuff that we already do
        //once in beginProgressive() -- but this requires
        //some refactoring of THREE.WebGLRenderer.
        var phase = _phase;
        var wantColor = true;
        var wantSAO = phase == avp.RENDER_NORMAL;
        var wantID = _renderer.settings.idbuffer && phase != avp.RENDER_HIDDEN;

        if (phase == avp.RENDER_HIDDEN)
            scene.overrideMaterial = _this.fadeMaterial;
        else if (phase == avp.RENDER_HIGHLIGHTED)
            scene.overrideMaterial = _this.highlightMaterial;

        _renderer.renderScenePart(scene, wantColor, wantSAO, wantID);

        scene.overrideMaterial = null;

    }

    function updateFPS(highResTimeStamp) {
        _frameTimeSamples++;

        if (_lastHighResTimeStamp > 0)
            _frameTimeAvg = _frameTimeAvg * 0.8 + (highResTimeStamp - _lastHighResTimeStamp) * 0.2;

        if (_this.fpsCallback)
            _this.fpsCallback(_this.fps());
    }

    function updateAnimations(highResTimeStamp) {
        if (_this.keyFrameAnimator) {
            var delta = _lastHighResTimeStamp > 0 ? (highResTimeStamp - _lastHighResTimeStamp) / 1000 : 0;
            var updateFlags = _this.keyFrameAnimator.update(delta);
            if (updateFlags) {
                _this.sceneUpdated(true);
                if (updateFlags & _this.keyFrameAnimator.UPDATE_CAMERA)
                    return true;
            }
        }
        return false;
    }

    function updateCanvasSize() {
        if (_needsResize) {
            _this.camera.aspect = _newWidth/_newHeight;
            _this.camera.clientWidth = _newWidth;
            _this.camera.clientHeight = _newHeight;
            _renderer.setSize(_newWidth,_newHeight);
            _this.controls.handleResize();
            if (_groundReflection)
                _groundReflection.setSize(_newWidth, _newHeight);
            _this.invalidate(true, true, true);
            _needsResize = false;
            _this.api.fireEvent({
                type: av.VIEWER_RESIZE_EVENT,
                width: _newWidth,
                height: _newHeight
            });
        }
    }


    this.renderGroundShadow = function(target) {

        // If shadow maps are active, we don't use _groundShadow for the ground. Instead, the ground is
        // rendered using the shadow map as well.
        if (_shadowMaps) {
            if (_shadowMaps.state == avp.SHADOWMAP_VALID) {
                _shadowMaps.renderGroundShadow(_this.camera, target || _renderer.getColorTarget());
            }
        } else {
            _groundShadow.renderShadow(_this.camera, target || _renderer.getColorTarget());
            _groundShadow.rendered = true;
        }
    };

    function updateGroundTransform() {
        if (!_groundShadow.enabled && !_groundReflection || _this.is2d)
            return;

        var groundBox;
        if (_this.model && !_this.model.isLoadDone()) {
            groundBox = _this.model.getData().bbox;
        }
        else {
            groundBox = _this.getVisibleBounds(true, false);
        }
        if (!groundBox)
            return;

        _groundShadow.needClear = true;

        var camera = _this.camera;
        var bbox = groundBox.clone();

        var rightAxis = new THREE.Vector3(1, 0, 0);

        var shadowDir = _shadowLightDir.clone();

        // Transform bbox, rightAxis, and shadowDir using worldUpTransform. For the resulting box, we
        // can safely assume that y is the up-direction
        if (camera.worldUpTransform) {
            bbox.applyMatrix4(camera.worldUpTransform);
            rightAxis.applyMatrix4(camera.worldUpTransform);
            shadowDir.applyMatrix4(camera.worldUpTransform);
        }

        // expand the box downwards by 0.5%. The effect of this is just that the
        // ground plane does not touch the world box, but is slightly below it
        bbox.min.y -= 0.005 * (bbox.max.y - bbox.min.y);

        if (_shadowMaps) {
            _shadowMaps.expandByGroundShadow(bbox, shadowDir);
        }

        // get size and center
        var bsize   = bbox.size();
        var bcenter = bbox.center();

        // apply some adjustments specific for drop-shadow
        if (!_shadowMaps) {
            // add some horizontal margin so that burring is not clipped at the boundaries
            bsize.x *= 1.25;
            bsize.z *= 1.25;

            // expand to square, because the texture is squared as well
            bsize.x = bsize.z = Math.max(bsize.x, bsize.z);
        }

        // Rotate center back to world-coords.
        if (camera.worldUpTransform) {
            var worldUpInverse = new THREE.Matrix4().getInverse(camera.worldUpTransform);
            bcenter.applyMatrix4(worldUpInverse);

            // Note that we leave size vector as it is. I.e., only the center is transformed back to world-coords.
            // The size vector keeps as it is, i.e. the bbox defined by (center, size) is still aligned with
            // the rotated axes. In other worlds
            //  - size.x is the extent along worldUpTransform * (1,0,0) = rightAxis
            //  - size.y is the extent along worldUpTransform * (0,1,0) = camera.worldUp
            //  - size.z is the extent along worldUpTransform * (0,0,1)
        }

        _groundShadow.setTransform(
            bcenter,
            bsize,
            camera.worldup,
            rightAxis
        );

        if (_groundReflection) {
            var groundPos = (new THREE.Vector3()).subVectors(bcenter, camera.worldup.clone().multiplyScalar(bsize.y/2));
            _groundReflection.setTransform(groundPos, camera.worldup, bsize);
        }

        if (_shadowMaps) {
            _shadowMaps.setGroundShadowTransform(bcenter, bsize, camera.worldup, rightAxis);
        }
    }

    function updateScene(highResTimeStamp) {
        if (_sceneDirty) {
            updateGroundTransform();
            _sceneDirty = false;
        }
    }

    function updateOverlays(highResTimeStamp) {

        //Update the selection set cloned meshes
        for (var id in _this.selectionMeshes) {

            var m = _this.selectionMeshes[id];
            var fragList = m.model.getFragmentList();

            // If the proxy uses original geometry of the fragment, update its matrix.
            // If the geometry does not match, it is a consolidated or instanced mesh.
            // For these, the matrix is already baked into vertex buffer or
            // index buffer. We don't support animation for these.
            if (m.geometry === fragList.getGeometry(m.fragId)) {
                fragList.getWorldMatrix(m.fragId, m.matrix);
            }
        }

    }

    function invalidateShadowMap() {
        if (_shadowMaps) {
            _shadowMaps.state = avp.SHADOWMAP_NEEDS_UPDATE;
        }
    }

    /**
     * Progressive update of the shadow map:
     *
     *   a) For small models that can be rendered within a single frame, the shadow map will always be rendered first,
     *      so that shadows will not flicker on and off during animations, on scene changes, or when changing the light direction.
     *   b) For large models, seeing something is more important than shadows. Therefore, we render without shadows
     *      first and only do work on the shadow map if everything else is finished.
     *
     *  Whether we take a) or b) is determined on-the-fly: We use a) if we succeed to update the whole ShadowMap
     *  within a single frame time budget.
     *
     *   @param   {Number} frameRemaining - available frame time in milliseconds
     *   @returns {Number} remaining frame time
     */
    function updateShadowMaps(frameRemaining) {

        if (!_shadowMaps || !_this) {
            return frameRemaining;
        }

        var restartRender = (_needsRender || _needsClear);

        // Make sure that we never get stuck in avp.RENDER_SHADOWMAP phase. Either we proceed or we stop.
        if (_phase == avp.RENDER_SHADOWMAP) {

            // This case is only needed at the end of case b), where we need an extra phase of multiple frames to progressively
            // render the shadow map. If we are here, the following has happened in previous frames:
            //  - It was not possible to render the shadow map in the first frame.
            //  - Therefore, we had first rendered the scene without shadows. This phase has finished.
            //  - Finally, we started the progressive shadow map update.
            // Now, we either continue the update or we stop (if the camera has moved meanwhile).
            if (restartRender) {

                // If a re-render is required, stop deferred shadow-map work
                _phase = avp.RENDER_FINISHED;
                return frameRemaining;

            } else {

                // continue shadow map update as long as we have time
                frameRemaining = _shadowMaps.continueUpdate(_modelQueue, frameRemaining, _materials);

                // if we are done, trigger re-render to make shadows appear
                if (_shadowMaps.state == avp.SHADOWMAP_VALID) {

                    // signal that we don't need any more shadow-map update work
                    _phase = avp.RENDER_FINISHED;

                    // restart progressive rendering - this time with shadows
                    _needsClear  = true;
                    _needsRender = true;
                }
            }
        }

        // check if shadow map has been invalidated meanwhile
        // This section is always entered in the first frame if the shadow map is not available yet.
        if (_shadowMaps.state==avp.SHADOWMAP_NEEDS_UPDATE) {

            // start shadow map update. This call may end in two ways:
            //  - In case a), the shadowmap could already be finished within the startUpdate() call. Therefore, the
            //    shadow map will already be available and will be used in this frame.
            //    In this case, there is nothing more to do and all subsequent calls to updateShadowMap will
            //    do nothing.
            //  - in case b), the shadow map is not available. In this case, we first wait until the rendering
            //    without shadows is finished. (see next section)
            frameRemaining = _shadowMaps.startUpdate(_modelQueue, frameRemaining, _this.camera, _shadowLightDir, _materials);

        } else if (!restartRender) {

            // We just finished rendering without shadows and the camera has not moved in the meantime. Now, we have
            // have time to progressively render the shadow map.
            if (_phase == avp.RENDER_FINISHED && _shadowMaps.state==avp.SHADOWMAP_INCOMPLETE) {
                // Note that we have to restart the update, because the RenderQueue has been used for other
                // rendering phases in between. In theory, this could be optimized to preserve the results of the first
                // startUpdate() call. But it's safer and easier to just restart here.
                frameRemaining = _shadowMaps.startUpdate(_modelQueue, frameRemaining, _this.camera, _shadowLightDir, _materials);
                _phase = avp.RENDER_SHADOWMAP;
            }
        }
        return frameRemaining;
    }

    //Main animation loop -- update camera,
    //advance animations, render if needed.
    function tick(highResTimeStamp)
    {
        //Texture uploads of newly received textures
        var res = _materials.updateMaterials();
        _this.invalidate(res.needsClear, res.needsRender, res.overlayDirty);

        //Do animations -- this has to be done
        //before the scene update below
        var animationMoved = updateAnimations(highResTimeStamp);

        var controlsMoved = _this.controls.update(highResTimeStamp);

        var sceneChanged = _modelQueue && _modelQueue.update(highResTimeStamp);

        var moved = controlsMoved || animationMoved || _cameraUpdated || sceneChanged;

        //Did the window resize since last tick?
        var canvasSizeUpdated = _needsResize;
        if (_needsResize) updateCanvasSize();

        _needsClear = _needsClear || moved;
        _overlayDirty = _overlayDirty || moved;

        if (_overlayDirty)
            updateOverlays(highResTimeStamp);

        _overlayDirty = _overlayDirty || _renderer.overlayUpdate(highResTimeStamp);

        // ??? By adding on demand loading geometry, the progress of rendering now
        // ??? will proceed back and forth a few times.
        var signalProgressByRendering = _this.model && (_this.model.isLoadDone() ||
            (_this.model.myData.partPacksLoadDone === true));

        var frameBudget = _this.progressiveRender ? _this.targetFrameBudget : 1e10;
        var frameRemaining = frameBudget;
        var q = _modelQueue;

        //Has the geometry changed since the last frame.
        //Note this is not the same as just the camera moving, it indicates
        //that meshes have changed position, e.g. like during explode.
        if (_sceneDirty) {
            updateScene(highResTimeStamp);
        }

        // handle shadows
        frameRemaining = updateShadowMaps(frameRemaining);
        if (_shadowMaps && _phase == avp.RENDER_SHADOWMAP) {
            // if we are currently updating the shadow map, stop here to make
            // sure that only the shadow map update uses modelQueue.renderSome(..)
            // as long as the shadow update is in progress.
            return;
        }

        //Prepare the ground shadow
        var shadowDone = false;
        if (_groundShadow && !_this.is2d && !_isLoading) {
            shadowDone = _groundShadow.prepareGroundShadow(_this);
        }

        // If _needsClear is false at this point, nothing changed from outside. However, we might still
        // have to set _needsClear to true if the previous frame cannot be resumed. This happens when
        // when we rendered some transparent shapes before all opaque ones were rendered.
        var somethingChanged = _needsClear;
        var lastFrameValid = _modelQueue.frameResumePossible();
        _needsClear = _needsClear || !lastFrameValid;

        //Whether we will reset the render queue -- we could
        //do that without a screen clear in case we are just
        //loading new data without motion.
        if (_needsClear || _needsRender) {

            // Is SAO on? It should be turned off if we're moving and using smooth navigation.
            if ( moved && _this.skipAOWhenMoving && _renderer.settings.sao && !_AOsuppressed ) {
                // force SAO off in the renderer when performing smooth navigation, so that the normal/depth buffer
                // is not cleared *in future renders*, nor rendered to later on.
                _renderer.setAOEnabled(false);
                _AOsuppressed = true;
            }

            if (signalProgressByRendering)
                _this.signalProgress(0); //zero out the progress bar for when rendering begins

            //Measure actual frame time between two consecutive initial frames.
            //This is used to correct measured per-scene times to what they actually take
            //once the async processing of the graphics thread is taken into account.
            if (_lastBeginFrameTimeStamp > 0) {
                var delta = highResTimeStamp - _lastBeginFrameTimeStamp;
                _beginFrameAvg = 0.75 * _beginFrameAvg + 0.25 * delta;
            }
            _lastBeginFrameTimeStamp = highResTimeStamp;

            //Adjust frame time allowance based on actual frame rate,
            //but stay within the given boundaries.
            if (_beginFrameAvg < TARGET_FRAME_TIME && frameBudget < MAX_FRAME_BUDGET)
                _this.targetFrameBudget += 1;
            else if (_beginFrameAvg > TARGET_FRAME_TIME && frameBudget > MIN_FRAME_BUDGET)
                _this.targetFrameBudget -= 1;

            _this.updateCameraMatrices();

            _renderer.beginScene(_this.scene, _this.camera, _this.lightsOn ? _this.lights : _this.no_lights, _needsClear);

            if (moved || canvasSizeUpdated) {
                _this.api.fireEvent(_this.cameraChangedEvent);
            }

            //Render the ground shadow after screen clear
            if (shadowDone && !_groundReflection)
                _this.renderGroundShadow();

            if (q) {
                if (q.hasHighlighted()) {
                    //If we have objects in the render queue that are set
                    //to draw as "highlighted", render them first
                    _phase = avp.RENDER_HIGHLIGHTED;
                    q.reset(_this.camera, _phase, somethingChanged);
                } else {
                    // If nothing is highlighted just skip the highlighted phase
                    _phase = avp.RENDER_NORMAL;
                    q.reset(_this.camera, _phase, somethingChanged);
                }
            }
        } else {
            _lastBeginFrameTimeStamp = -1;
        }

        // process reflections after shadows, if it finishes it can render on top of reflections
        if (_groundReflection &&
            !_this.is2d &&
            !_isLoading) {

            var reflReady = _groundReflection.prepareGroundReflection(_this, _groundShadow, _needsClear);

            // if color pass already finished, non-progressive case
            if (reflReady) {
                if (_modelQueue.isDone()) {
                    // if ghosting, draw after refls are done (see below, ghosting is delayed if reflections are on)
                    if (_this.showGhosting && !_modelQueue.areAllVisible()) {
                        _phase = avp.RENDER_HIDDEN;
                        _modelQueue.reset(_this.camera, _phase);
                    }
                }
            }
        }

        var needsPresent = false;

        //Progressive render of the main scene
        //Render some meshes until we run out of time
        if (!q.isEmpty() && !q.isDone()) {

            needsPresent = true;

            //Render some geometry with the current render mode (highlighted, normal, or ghosted)
            frameRemaining = q.renderSome(renderSomeCallback, frameRemaining);

            //If we are done with the current render mode switch to the next mode and render some more,
            //if we have time
            if (q.isDone() && _phase === avp.RENDER_HIGHLIGHTED) {
                _phase = avp.RENDER_NORMAL;
                q.reset(_this.camera, _phase);

                // Allow the use of the remaining frame time to draw normal objects.
                frameRemaining = q.renderSome(renderSomeCallback, frameRemaining);
            }

            //If we are done with the current render mode switch to the next mode and render some more,
            //if we have time
            if (q.isDone()) {
                if (_phase === avp.RENDER_NORMAL &&
                    !q.areAllVisible() &&
                    _this.showGhosting)
                {
                    // delay render hidden until reflections are done
                    if (!_groundReflection || _groundReflection.finished) {
                        _phase = avp.RENDER_HIDDEN;
                        q.reset(_this.camera, _phase);

                        // Allow the use of the remaining time to draw ghosted objects.
                        frameRemaining = q.renderSome(renderSomeCallback, frameRemaining);
                    }
                }
                else
                {
                    //Progressive rendering done, switch render mode to "finished", and draw the .
                    _phase = avp.RENDER_FINISHED;
                    _renderer.renderScenePart(_this.sceneAfter, true, true, true);
                }

                if (signalProgressByRendering)
                    _this.signalProgress(100.0);

            } else {
                if (signalProgressByRendering)
                    _this.signalProgress(100.0 * q.getRenderProgress());
            }

            updateFPS(highResTimeStamp);
        }

        //Render selection highlight / pivot / HUD overlays and other overlay geometry
        //This is stuff that goes into the separate overlay render buffer
        if (_overlayDirty) {

            needsPresent = true;

            _renderer.renderScenePart(_this.sceneAfter, true, true, true);

            if ((!q.isEmpty() && q.isDone()) || _this.showOverlaysWhileMoving) {
                _this.renderOverlays();

                //During progressive rendering, we want to
                //continue rendering overlays until the queue is done
                //because adding more to the scene will affect the z buffer
                //which would change which parts of the overlays is visible.
                if (!q.isEmpty() && !q.isDone())
                    _overlayDirty = true;
            } else {
                _renderer.clearAllOverlays();
            }
        }

        //Decide if we want to run the ambient occlusion post-processing when we
        //present this frame. This depends on many things.
        var needsAO = true;

        if (_this.skipAOWhenMoving) {

            if (moved || !q.isDone()) {
                needsAO = false;
            } else if (_lastTickMoved) {

                //Finally, draw the AO pass, in case we skip AO pass when moving or progressive repaint.
                needsPresent = true;

                // if doing smooth navigation, prepare to turn AO back on if it was off
                if ( _AOsuppressed ) {
                    // if smooth navigation is on, and AO is on, then we'll need
                    // to do a full render (not just compose the final frame) in
                    // order to generate the normal/depth map.
                    _turnAOonAndRender = true;
                }
            }
        }

        // If non-resumable frames are enabled, rendering has to be restarted to render a full frame.
        // The effect of this would be that transparent shapes disappear whenever the camera stops -
        // until the frame is fully finished.
        // To avoid that, we do progressive rendering in the background until the frame is fully finished.
        // Until then, we keep the result of the last in-motion frame that still contained transparent objects.
        if (q.enableNonResumableFrames && _phase !== avp.RENDER_FINISHED && !moved) {
            needsPresent = false;
        }

        //Run post-processing and present to the front buffer
        if (needsPresent) {
            _renderer.composeFinalFrame(!needsAO);
        }

        if (_neededPresent !== needsPresent) {
            _neededPresent = needsPresent;
            _this.api.fireEvent({type: av.FINAL_FRAME_RENDERED_CHANGED_EVENT, value: {finalFrame: !needsPresent}});
        }

        _lastTickMoved = moved;
        _lastHighResTimeStamp = highResTimeStamp;


        // At the end of this tick, lets see whether need a re-render,
        // if page out started but failed, we need a re-run.
        if (q && q.needsRender()) {
            _needsRender = true;
            q.resetNeedsRender();
        }
        else {
            _needsRender = false;
        }

        _needsClear = false;
        _cameraUpdated = false;

        // if AO is to be turned back on, we'll need a full draw from the start.
        if ( _turnAOonAndRender ) {
            _turnAOonAndRender = false;
            // Turn AO back on. This could be done where _turnAOonAndRender was set to true, above, but
            // it's more maintainable to keep AO off until the very last moment.
            _renderer.setAOEnabled(true);
            _AOsuppressed = false;
            // signal that a full clear and render is needed, so that AO is generated.
            _this.invalidate(true, true);
        }
    }


    this.run = function() {
        //Begin the render loop (but delay first repaint until the following frame, so that
        //data load gets kicked off as soon as possible
        _reqid = 0;
        setTimeout(function(){
            (function animloop(highResTimeStamp) {
                _reqid = window.requestAnimationFrame(animloop);
                tick(highResTimeStamp);
            })();
        }, 1);
    };

    this.toggleProgressive = function(value) {
        this.progressiveRender = value;
        _needsClear = true;
    };

    this.toggleSwapBlackAndWhite = function(value) {
        this.swapBlackAndWhite = value;
        _renderer.toggleSwapBlackAndWhite(value);
        _needsClear = true;
    };

    this.toggleGhosting = function(value) {
        this.showGhosting = value;
        _needsClear = true;
    };

    this.toggleOverlaysWhileMoving = function(value) {
        this.showOverlaysWhileMoving = value;
    };

    this.togglePostProcess = function(useSAO, useFXAA) {
        _renderer.initPostPipeline(useSAO, useFXAA);
        this.fireRenderOptionChanged();
        _needsClear = true;
    };

    this.toggleCelShading = function(value) {
        _renderer.toggleCelShading(value);
        this.fireRenderOptionChanged();
        _needsClear = true;
    };

    this.toggleGroundShadow = function(value) {
        if (_groundShadow.enabled === value)
            return;

        _groundShadow.enabled = value;
        _groundShadow.clear();
        updateGroundTransform();
        this.fireRenderOptionChanged();
        this.invalidate(true, false, false);
    };

    this.setGroundShadowColor = function(color) {
        if (!_groundShadow.enabled) return;

        _groundShadow.setColor(color);
        this.invalidate(true, false, false);
    };

    this.setGroundShadowAlpha = function(alpha) {
        if (!_groundShadow.enabled) return;

        _groundShadow.setAlpha(alpha);
        this.invalidate(true, false, false);
    };

    this.toggleGroundReflection = function(enable) {
        if ((enable && !!_groundReflection) ||
            (!enable && !_groundReflection))
            return;

        if (enable) {
            _groundReflection = new av.Shaders.GroundReflection(_webglrender, this.canvas.clientWidth, this.canvas.clientHeight, { clearPass: _renderer.getClearPass() });
            _groundReflection.setClearColors(this.clearColorTop, this.clearColorBottom, av.isAndroidDevice() || av.isIOSDevice());
            _groundReflection.toggleEnvMapBackground(_envMapBackground);
            _groundReflection.setEnvRotation(_renderer.getEnvRotation());
            updateGroundTransform();
        }
        else {
            _groundReflection.cleanup();
            _groundReflection = undefined;
        }

        this.fireRenderOptionChanged();
        this.invalidate(true, false, false);
    };

    this.setGroundReflectionColor = function(color) {
        if (!_groundReflection) return;

        _groundReflection.setColor(color);
        this.invalidate(true, false, false);
    };

    this.setGroundReflectionAlpha = function(alpha) {
        if (!_groundReflection) return;

        _groundReflection.setAlpha(alpha);
        this.invalidate(true, false, false);
    };

    this.toggleEnvMapBackground = function(value) {
        _envMapBackground = value;
        _renderer.toggleEnvMapBackground(value);

        if (_groundReflection) {
            _groundReflection.toggleEnvMapBackground(value);
        }
        this.invalidate(true, true, false);
    };

    this.isEnvMapBackground = function() {
        return _envMapBackground;
    };

    this.toggleRenderPrism = function (value) {
        _materials.setRenderPrism(value);

        //TODO: support switching at run-time.
    };

    this.setOptimizeNavigation = function(value) {
        this.skipAOWhenMoving = value;
    };

    // If we have selection meshes, this function makes sure that they use exactly the same
    // geometry as we used in the main scene rendering. This is needed to avoid z-buffer artifacts
    // when using consolidation.
    function updateSelectionProxies() {
        for (var id in _this.selectionMeshes) {
            var proxy = _this.selectionMeshes[id];

            // Updating proxies is only relevant when using consolidtion. Otherwise, we always use the original
            // fragment geometry and can keep static proxy geometry.
            if (proxy.model && proxy.model.isConsolidated()) {
                proxy.model.updateRenderProxy(proxy, proxy.fragId);
            }
        }
    };

    this.renderOverlays = function() {

        updateSelectionProxies();

        //The overlays (selection, pivot, etc) get lighted using
        //the default lights, even if IBL is on
        var lightsOn = this.lightsOn;
        if (!lightsOn)
            this.toggleLights(true, true);

        var oldIntensity;
        if (this.dir_light1) {
            oldIntensity = this.dir_light1.intensity;
            this.dir_light1.intensity = 1;
        }

        _renderer.renderOverlays(this.overlayScenes, this.lightsOn ? this.lights : this.no_lights);

        if (!lightsOn)
            this.toggleLights(false, true);

        if (this.dir_light1)
            this.dir_light1.intensity = oldIntensity;

        _overlayDirty = false;
    };

    this.setLayerVisible = function (layerIndexes, visible) {
        this.matman().setLayerVisible(layerIndexes, visible);
        this.invalidate(true);
    };

    this.isLayerVisible = function (layerIndex) {
        return this.matman().isLayerVisible(layerIndex);
    };

    this.getVisibleLayerIds = function() {
        var data = this.model.getData();
        var lmap = data.layersMap;
        var visibleLayerIds = [];
        for (var layerIndex in lmap) {
            if ( this.isLayerVisible(layerIndex) ) {
                visibleLayerIds.push( lmap[layerIndex] ); // map from (index) into (id)
            }
        }
        return visibleLayerIds;
    };

    this.updateCameraMatrices = (function() {

        var tmpCameraMatrix;
        var tmpViewMatrix;
        var tmpBox;

        function init_three() {
            tmpCameraMatrix = new THREE.Matrix4();
            tmpViewMatrix = new THREE.Matrix4();
            tmpBox = new THREE.Box3();
        }

        return function() {

        if (!tmpBox)
            init_three();

        var camera = this.camera;

        //NOTE: This is not computing the same matrix as what we use for rendering,
        //in cases where we are in ORTHO mode and the camera is inside the model,
        //which would result in negative near plane. For the purposes of computing
        //the near/far planes, we have to skip the logic that adjusts the view matrix
        //based on the near/far planes. See UnifiedCamera.updateMatrix for the related
        //adjustment to the view matrix.
        tmpCameraMatrix.compose( camera.position, camera.quaternion, camera.scale );
        tmpViewMatrix.getInverse( tmpCameraMatrix );

        //TODO: Would be nice if this got called by the world up tool instead,
        //so that we don't have to update it every frame.
        if (camera.worldup)
            this.setWorldUp(camera.worldup);

        //Fix near and far to fit the current view
        if (this.model) {
            var worldBox = this.getVisibleBounds(true, _overlayDirty);
            tmpBox.copy(worldBox);

            //If reflection is on, then we need to double the worldBox size in the Y
            //direction, the reflection direction, otherwise the reflected view can be
            //clipped.
            if ( _groundReflection ) {
                // Increase bounding box to include ground reflection geometry. The idea
                // here is to extend the bounding box in the direction of reflection, based
                // on the "up" vector.
                var tmpVecReflect = new THREE.Vector3();
                tmpVecReflect.multiplyVectors( tmpBox.max, camera.worldup );
                var tmpVecMin = new THREE.Vector3();
                tmpVecMin.multiplyVectors( tmpBox.min, camera.worldup );
                tmpVecReflect.sub( tmpVecMin );
                // tmpVecReflect holds how much to increase the bounding box.
                // Negative values means the "up" vector is upside down along that axis,
                // so we increase the maximum bounds of the bounding box in this case.
                if ( tmpVecReflect.x >= 0.0 ) {
                    tmpBox.min.x -= tmpVecReflect.x;
                } else {
                    tmpBox.max.x -= tmpVecReflect.x;
                }
                if ( tmpVecReflect.y >= 0.0 ) {
                    tmpBox.min.y -= tmpVecReflect.y;
                } else {
                    tmpBox.max.y -= tmpVecReflect.y;
                }
                if ( tmpVecReflect.z >= 0.0 ) {
                    tmpBox.min.z -= tmpVecReflect.z;
                } else {
                    tmpBox.max.z -= tmpVecReflect.z;
                }
            }

            // Expand the bbox based on ground shadow. Note that the horizontal extent of the ground shadow
            // may be significantly larger for flat shadow light directions.
            if (_shadowMaps && _shadowMaps.groundShapeBox) {
                tmpBox.union(_shadowMaps.groundShapeBox);
            }

            //Transform the world bounds to camera space
            //to estimate the near/far planes we need for this frame
            tmpBox.applyMatrix4(tmpViewMatrix);

            //Expand the range by a small amount to avoid clipping when
            //the object is perfectly aligned with the axes and has faces at its boundaries.
            var sz = 1e-5 * (tmpBox.max.z - tmpBox.min.z);

            //TODO: expand for ground shadow. This just matches what the
            //ground shadow needs, but we need a better way to take into account
            //the ground shadow scene's bounds
            var expand = (tmpBox.max.y - tmpBox.min.y) * 0.5;

            var dMin = -(tmpBox.max.z+sz)-expand;
            var dMax = -(tmpBox.min.z-sz)+expand;

            //Camera is inside the model?
            if (camera.isPerspective)
                dMin = Math.max(dMin, Math.min(1, Math.abs(dMax - dMin) * 1e-4));
            else {
                //TODO:
                //Do nothing in case of ortho. While this "fixes" near plane clipping too early,
                //it effectively disallows moving through walls to go inside the object.
                //So we may need some heuristic based on how big we want the object to be
                //on screen before we let it clip out.
                //dMin = Math.max(dMin, 0);
            }

            //The whole thing is behind us -- nothing will display anyway?
            dMax = Math.max(dMax, dMin);

            camera.near = dMin;
            camera.far = dMax;
            camera.updateProjectionMatrix();

            //Update the line width scale with the
            //new pixels per unit scale
            var distance;
            if (this.model.is2d())
            {
                //Here we base pixel scale on the point at the center of the view.
                //However, this might not always be the most appropriate point,
                //e.g. at oblique angles or when the drawing is off to one side.
                //It might make more sense to base the scale on the distance of the
                //camera to the nearest part of the world bounding box, which requires
                //a more generic ray-aabb test.
                var groundPt = this.intersectGroundViewport(new THREE.Vector3(0,0,1));

                if (groundPt)
                    distance = camera.position.distanceTo(groundPt);
                else
                    distance = camera.position.distanceTo(worldBox.center()); //degenerate case: camera direction is parallel to the ground plane

                //NOTE: In case of ortho projection, we set FOV such that tan(fov/2) = 0.5,
                //so here we don't need separate code path for ortho.
                var pixelsPerUnit = _renderer.settings.deviceHeight / (2 * distance * Math.tan(THREE.Math.degToRad(camera.fov * 0.5)));

                //If we want to take into account devicePixelRatio for line weights (so that lines are not too thin)
                //we can do this here, but it's less esthetically pleasing:
                //pixelsPerUnit /= _webglrenderer.getPixelRatio();

                _materials.updatePixelScale(pixelsPerUnit);

                // AutoCAD drawings are commonly displayed with white lines on a black background. Setting reverse swaps (just)
                // these two colors.
                _materials.updateSwapBlackAndWhite(this.swapBlackAndWhite);
            } else {

                //If there is a cutting plane, get a point on that plane
                //for by the pixel scale computation.
                var cp = _materials.getCutPlanesRaw();

                var pt;
                if (cp && cp.length) {
                    var p = cp[0];

                    var dir = camera.target.clone().sub(camera.position).normalize();
                    var denominator = dir.dot(p);

                    if (denominator === 0)
                        pt = worldBox.center();
                    else {
                        var t = - ( camera.position.clone().dot( p ) + p.w ) / denominator;
                        pt = worldBox.clampPoint(dir.multiplyScalar(t).add(camera.position));
                    }
                } else {
                    pt = worldBox.center();
                }

                distance = camera.position.distanceTo(pt);

                //NOTE: In case of ortho projection, we set FOV such that tan(fov/2) = 0.5,
                //so here we don't need separate code path for ortho.
                var pixelsPerUnit = _renderer.settings.deviceHeight / (2 * distance * Math.tan(THREE.Math.degToRad(camera.fov * 0.5)));

                _materials.updatePixelScale(pixelsPerUnit);
            }

        }
    }
    })();

    this.initLights = function()
    {
        this.dir_light1 = new THREE.DirectionalLight(_defaultDirLightColor, _defaultLightIntensity);

        this.dir_light1.position.set( -1, 0, 1 );

        //Note this color will be overridden by various light presets
        this.amb_light = new THREE.AmbientLight(_defaultAmbientColor);

        // Set this list only once, so that we're not constantly creating and deleting arrays each frame.
        // See https://www.scirra.com/blog/76/how-to-write-low-garbage-real-time-javascript for why.
        // use this.no_lights empty array if no lights are needed.
        this.lights = [this.dir_light1, this.amb_light];

        //We do not add the lights to any scene, because we need to use them
        //in multiple scenes during progressive render.
        //this.scene.add(this.amb_light);

        // Attach the light to the camera, so that the light direction is applied in view-space.
        // Note:
        //
        //  1. For directional lights, the direction where the light comes from is determined by
        //     lightPosition - targetPosition, both in in world-space.
        //  2. The default target of dir lights is the world origin.
        //  3. Transforming the light object only affects the light position, but has no effect on the target.
        //
        // The goal is to rotate the lightDir with the camera, but keep it independent
        // of the camera position. Due to 3. above, we must also attach the light's target object to the camera.
        // Otherwise, the camera position would incorrectly be added to the light direction.
        this.camera.add(this.dir_light1);
        this.camera.add(this.dir_light1.target);

        _lightsInitialized = true;
    };

    this.toggleLights = function(state, isForOverlay) {

        //This can happen during initial construction
        if (!this.amb_light)
            return;

        // Don't create or remove arrays, as that's bad to do during rendering.
        // Instead, later use lightsOn to decide which array to use.
        this.lightsOn = state;

        //Update the light colors based on the current preset
        var preset = avp.LightPresets[_currentLightPreset];
        var ac = preset.ambientColor;
        var dc = preset.directLightColor;

        ac = ac || _defaultAmbientColor.toArray();
        dc = dc || _defaultDirLightColor.toArray();

        if (this.lightsOn) {
            if (isForOverlay && this.amb_light)
                this.amb_light.color.setRGB(dc[0]*0.5,dc[1]*0.5,dc[2]*0.5);
            else if (this.amb_light) {
                this.amb_light.color.setRGB(ac[0],ac[1],ac[2]);
            }

            if (this.dir_light1) {
                this.dir_light1.color.setRGB(dc[0],dc[1],dc[2]);
            }
        }
        else
        {
            //Restores the ambient for the main scene after drawing overlays
            if (this.amb_light && isForOverlay)
                this.amb_light.color.setRGB(ac[0],ac[1],ac[2]);
        }
    };

    //Forces the view controller to update when the camera
    //changes programmatically (instead of via mouse events).
    this.syncCamera = function(syncWorldUp)
    {
        this.camera.updateProjectionMatrix();

        if( syncWorldUp )
            this.setWorldUp( this.api.navigation.getWorldUpVector() );

        _cameraUpdated = true;
    };


    this.setViewFromFile = function(model, skipTransition) {

        var camera;

        var defaultCamera = model.getDefaultCamera();

        if (defaultCamera) {

            camera = defaultCamera;

        } else {

            //Model has no default view. Make one up based on the bounding box.

            camera = {};

            var bbox = model.getBoundingBox();
            var size = bbox.size();
            camera.target = bbox.center();

            if (!model.is2d())
            {
                camera.isPerspective = true;
                camera.fov = this.camera.fov;
                camera.up = this.camera.up.clone();

                camera.position = camera.target.clone();
                camera.position.z += 1.5 * Math.max(size.x, size.y, size.z);
            }
            else {
                camera.isPerspective = false;

                var pageAspect = size.x / size.y;
                var screenAspect = this.camera.aspect;

                //Fit the page to the screen
                if (screenAspect > pageAspect)
                    camera.orthoScale = size.y;
                else
                    camera.orthoScale = size.x / screenAspect;

                //2D case -- ground plane / up vector is Z
                camera.up = new THREE.Vector3(0,0,1);

                camera.position = camera.target.clone();
                camera.position.z += camera.orthoScale;

                //This is to avoid freaking out the camera / controller with co-linear up and direction
                camera.target.y += 1e-6 * size.y;

            }

        }

        this.setViewFromCamera(camera, skipTransition);
    };

    //Camera is expected to have the properties of a THREE.Camera.
    this.adjustOrthoCamera = function(camera) {

        //Sometimes (Revit) the camera target is unspecified/infinite
        //for ortho. So we pick target and distance such that
        //initial view and orbit is about right
        if (!camera.isPerspective && this.model) {
            var bbox = this.model.getBoundingBox();
            var size = bbox.size();

            var at = camera.target.clone().sub(camera.position);
            if (at.length() > 1000 * size.length()) {
                //We will try to set a target point that is a similar
                //distance away as camera->bbox center, but is in the
                //direction of the at vector (which is not necessarily looking at the center)
                var dist = camera.position.distanceTo(bbox.center());
                camera.target.copy(camera.position).add(at.normalize().multiplyScalar(dist));
            }
            else {
                //TODO: UnifiedCamera does not actually look at the orthoScale property. It bases
                //the ortho projection on value derived from the position-target distance and an
                //assumed field of view. Here we apply the inverse so that the initial view is
                //right, without affecting the initial orbit target.
                camera.position.copy(camera.target).add(at.normalize().multiplyScalar(-camera.orthoScale));
            }
        }
    };

    /**
     * Switches to a new view based on a given camera. If the current orbiting mode is constrained,
     * the up vector may be adjusted.
     *
     * @param {THREE.Camera} camera Input camera.
     * @param {boolean} skipTransition Switch to the view immediately instead of transitioning.
     */
    this.setViewFromCamera = function(camera, skipTransition)
    {
        this.adjustOrthoCamera(camera);

        // If the current orbiting mode is unconstrained (the 'freeorbit' tool),
        // use exact camera settings, otherwise (the 'orbit' tool) snap the up vector to a world axis.
        // Note that 'freeorbit' vs. 'orbit' tools are active even when the FusionOrbit extension is used.
        var useExactCamera = this.controls.isToolActivated('freeorbit');

        var upVectorArray = this.model ? this.model.getUpVector() : null;

        //HACK for local testing copy of SaRang
        if (this.model && this.model.getData().basePath.indexOf("SaRang") != -1)
            upVectorArray = [0,0,1];

        var worldUp;
        if (upVectorArray) {
            worldUp = new THREE.Vector3().fromArray(upVectorArray);
        } else {
            worldUp = useExactCamera ? camera.up.clone() : av.Navigation.snapToAxis(camera.up.clone());
        }

        if (useExactCamera) {
            if (this.api.prefs)
                this.api.prefs.set('fusionOrbitConstrained', worldUp.equals(camera.up));
        } else {
            camera.up = worldUp;
        }

        var navapi = this.api.navigation;
        if ( navapi) {
            if (!skipTransition) {
                this.camera.isPerspective = camera.isPerspective;
                if (useExactCamera) {
                    navapi.setRequestTransitionWithUp(true, camera.position, camera.target, camera.fov, camera.up, worldUp);
                } else {
                    var up = navapi.computeOrthogonalUp(camera.position, camera.target);
                    navapi.setRequestTransitionWithUp(true, camera.position, camera.target, camera.fov, up, worldUp);
                }
            } else {
                //This code path used during initial load -- it sets the view directly
                //without doing a transition. Transitions require that the camera is set explicitly

                var tc = this.camera;
                tc.up.copy(camera.up);
                tc.position.copy(camera.position);
                tc.target.copy(camera.target);
                if( camera.isPerspective ) {
                    tc.fov = camera.fov;
                }
                else {
                    tc.saveFov = camera.fov;    // Stash original fov
                    tc.fov = av.UnifiedCamera.ORTHO_FOV;
                }
                tc.isPerspective = camera.isPerspective;
                tc.orthoScale = camera.orthoScale;
                tc.dirty = true;

                navapi.setWorldUpVector(useExactCamera ? worldUp : tc.up);
                navapi.setView(tc.position, tc.target);
                navapi.setPivotPoint(tc.target);

                this.syncCamera(true);
            }
        }
        _cameraUpdated = true;
    };

    this.setViewFromViewBox = function(model, viewbox, name, skipTransition)
    {
        if (!model.is2d()) {
            return;
        }


        var camera = {};

        var bbox = model.getBoundingBox();

        var box = {
            width: viewbox[2] - viewbox[0],
            height: viewbox[3] - viewbox[1]
        };
        box.aspect = box.width / box.height;
        box.centerX = viewbox[0] + box.width / 2;
        box.centerY = viewbox[1] + box.height / 2;

        var screenAspect = this.camera.aspect;

        //Fit the viewbox to the screen
        if (screenAspect > box.aspect)
            camera.orthoScale = box.height;
        else
            camera.orthoScale = box.width / screenAspect;

        camera.isPerspective = false;
        camera.position = new THREE.Vector3(box.centerX, box.centerY, bbox.center().z + camera.orthoScale);
        camera.target = new THREE.Vector3(box.centerX, box.centerY, bbox.center().z);
        camera.target.y += 1e-6 * box.height;

        camera.up = new THREE.Vector3(0,0,1);

        this.setViewFromCamera(camera, skipTransition);
    };

    this.setWorldUp = function(upVector) {

        if (_worldUp.equals(upVector))
            return;

        _worldUp.copy(upVector);

        // get the (max) up axis and sign
        var maxVal = Math.abs(upVector.x);
        _worldUpName = "x";
        if (Math.abs(upVector.y) > maxVal) {
            _worldUpName = "y";
            maxVal = Math.abs(upVector.y);
        }
        if (Math.abs(upVector.z) > maxVal) {
            _worldUpName = "z";
        }

        var getRotation = function(vFrom, vTo) {
            var rotAxis = (new THREE.Vector3()).crossVectors(vTo, vFrom).normalize();  // not sure why this is backwards
            var rotAngle = Math.acos(vFrom.dot(vTo));
            return (new THREE.Matrix4()).makeRotationAxis(rotAxis, rotAngle);
        };

        var identityUp = new THREE.Vector3(0,1,0);
        _this.camera.worldUpTransform = getRotation(identityUp, upVector);

        this.sceneUpdated(false);
    };


    this.addModel = function(model)
    {
        if (!model)
            return;

        //Is it the first model being loaded into the scene?
        var isOverlay = !!this.model;
        var is2d = model.is2d();

        var diagonalLength = 0;
        if (!this.model) {
            this.model = model;

            _renderer.setUnitScale(model.getUnitScale());

            // Compute a rough size for the model, so that we can set a reasonable AO radius.
            // This simple approach is reasonable for mechanical models, but is probably too
            // large a value for architectural models, where the viewer is inside the model
            // and so the model itself is relatively large compared to the viewer.
            var bbox = model.getData().bbox;
            diagonalLength = bbox.size().length();
        }

        //Create a render list for progressive rendering of the
        //scene fragments
        _modelQueue.addModel(model);
        this.selector.addModel(model);
        this.visibilityManager.addModel(model);

        if (is2d)
        {
            //In case of a 2D drawing
            //initialize the common line shader
            //and the layers texture

            var data = model.getData();
            _materials.initLayersTexture(data.layerCount, data.layersMap);

            var idMatName = _materials.create2DMaterial(model, { useInstancing: this.use2dInstancing }, true, false, function() { _this.invalidate(false, true, false); });
            var idMaterial = _materials.findMaterial(model, idMatName);

            _renderer.enter2DMode(idMaterial);

            if (!isOverlay) {
                this.is2d = true;

                //Rememeber the light preset so we can restore is
                //when we unload the 2d sheet -- the light preset for 2d
                //is not persisted.
                _oldLightPreset = _currentLightPreset;
                this.setLightPreset(avp.DefaultLightPreset2d);

                var svf = model.getData();
                if (svf.hidePaper) {
                    var bg = svf.bgColor;
                    var r = (bg>>16)&0xff;
                    var g = (bg >>8)&0xff;
                    var b = bg&0xff;
                    this.setClearColors(r,g,b,r,g,b );
                }
            }
        }

        if (this.api.navigation) {
            this.api.navigation.setIs2D(is2d && !isOverlay);
            this.api.setActiveNavigationTool(); // use default nav tool

            // For leaflet, restrict 2D navigation, so that we cannot zoom/pan away from the image
            // and stop zoom-in when reaching max resolution.
            var modelData = model.getData();
            if (modelData.isLeaflet) {
                this.api.navigation.setConstraints2D(modelData.bbox, modelData.maxPixelPerUnit);
            }
            else {
                // If it is not a leaflet model, clear constrain 2d. 
                // Otherwise, it will leak to the next model that viewer could open up.
                this.api.navigation.setConstraints2D();
            }
        }


        if (!isOverlay) {
            this.setViewFromFile(model, true);
            this.controls.recordHomeView();
        }

        // grab the environment preset data from the file.
        if (!is2d && !this.setLightPresetFromFile(model)) {
            //When switching from a 2D sheet back to a 3D view,
            //we restore the environment map that was used for the
            //last 3D view displayed. The operation is delayed until here
            //so that switching between 2D sheets does not incur this unnecessary overhead.
            if (_oldLightPreset >= 0) {
                this.setLightPreset(_oldLightPreset, true);
                _oldLightPreset = -1;
            } else {
                this.setLightPreset(_currentLightPreset, false);
            }
        }

        // however, we override the AO radius, as we want to
        // set our own scaled version
        if ( diagonalLength > 0 ) {
            // 10 works well as a default for most models, including
            // architectural scenes. Surprising! But, for small models,
            // where for some reason the model is not in "human-sized units",
            // 0.05 says the ambient occlusion should extend 5% of the
            // diagonal length of the model.
            // The 10 here should match the SAOShader.js radius of 10.
            _renderer.setAOOptions(Math.min(10.0,0.05*diagonalLength));
        }

        this.fireRenderOptionChanged();
        this.invalidate(true);
    };

    this.getSvfMaterialId = function (fragId) {
        return this.model.getFragmentList().getSvfMaterialId(fragId);
    };

    this.getMaterials = function() { return _materials; };


    //Creates a THREE.Mesh representation of a fragment. Currently this is only
    //used as vehicle for activating a fragment instance for rendering once its geometry is received
    //or changing the fragment data (matrix, material). So, it's mostly vestigial.
    this.setupMesh = function(model, threegeom, materialId, matrix) {

        var svf = model.getData();

        var m = {
            geometry: threegeom,
            matrix: matrix,
            isLine: threegeom.isLines,
            isPoint: threegeom.isPoints,
            is2d: threegeom.is2d
        };

        // Check if this geometry is to be rendered with a line mesh
        if ( threegeom.isLines || threegeom.isPoints ) {
            // Check to see if there are vertex colors
            var vertexColors = !!threegeom.attributes.color;
            // Create a new LineBasicMaterial with vertexColors true/false depending on above
            //TODO: this material also needs to be added to the materials set, but first
            //make sure this will not cause line display side effects.

            var material;
            if (threegeom.isPoints) {
                material = new THREE.PointCloudMaterial(
                    {
                        vertexColors: vertexColors,
                        size: threegeom.pointSize
                    }
                );
            } else {
                material = new THREE.LineBasicMaterial({ vertexColors: vertexColors });
            }

            // If there are no vertex colors, default to the material color
            if(!vertexColors){
                var svfmat = _materials.findMaterial(model, materialId);
                material.color = svfmat.color;
            }

            // Save in material so we can map back from material to SVF id.
            material.svfMatId = materialId;

            //Register it with material manager so that cutplanes get updated
            _materials.addMaterialNonHDR(svf.basePath + materialId + "_line_" + material.id, material);

            // Use line mesh
            m.material = material;

            svf.hasLines = true;
        } else {
            var material = _materials.findMaterial(model, materialId);

            if (material) // Save in material so we can map back from material to SVF id.
                material.svfMatId = materialId;

            _materials.applyGeometryFlagsToMaterial(material, threegeom);

            m.material = material;
        }

        return m;
    };

    function _initAnim(model) {

        var svf = model.getData();
        // Init animations
        function initAnimations() {
            if (svf.animations) {
                _this.keyFrameAnimator = new avp.KeyFrameAnimator(_this, svf.animations.duration);
                for (var a in svf.animations.animations) {
                    _this.keyFrameAnimator.add(svf.animations.animations[a]);
                }
                _this.keyFrameAnimator.goto(0);
                _this.api.fireEvent({ type: av.ANIMATION_READY_EVENT });
            }
            _this.api.removeEventListener(av.OBJECT_TREE_CREATED_EVENT, initAnimations);
        }
        // init animations after object tree created and geometry loaded
        if (model.isObjectTreeCreated()) {
            initAnimations();
        } else {
            _this.api.addEventListener(av.OBJECT_TREE_CREATED_EVENT, initAnimations);
        }

    }

    this.onDemandLoadComplete = function(model) {
        // This one will be called on an SVF file with the on demand loading enabled.
        // Quite similar as onLoadComplete, but with some difference,
        // Do not notify scene update as it will trigger a whole new render again, which doesn't
        // make sense in this scenario.

        _isLoading = false;
        
        this.signalProgress(100);
        this.invalidate(false, true);

        var svf = model.getData();
        if (svf.hasLines) {
            _materials.togglePolygonOffset(true);
        }

        // Init animations
        _initAnim(model);

        // Fire the event so we know the on demand requested geometry are loaded done.
        this.api.fireEvent({
            type: av.GEOMETRY_LOADED_EVENT,
            model: model,
            onDemandLoad: true
        });
    }

    // Gets called by the active Loader
    this.onLoadComplete = function (model)
    {
        _isLoading = false;

        this.signalProgress(100);

        this.sceneUpdated(false);

        //In the case of 2d drawing, initialize the dbIds texture
        //to be used for selection highlighting. Initially,
        //nothing is highlighted
        if (this.is2d) {
            this.selectionMaterial2d = _materials.init2DSelectionMaterial(model, this.use2dInstancing, function() { _this.invalidate(false, true, false); });
            this.createOverlayScene("selection2d", this.selectionMaterial2d);
        }

        var svf = model.getData();

        var geomList = _modelQueue.getGeometryList();
        if (geomList) {
            _modelQueue.getGeometryList().printStats();
        }

        //If the model has line geometries
        //set polygon offset on the solid materials
        //so that we avoid z-fighting between solids and
        //their outlines.
        if (svf.hasLines) {
            _materials.togglePolygonOffset(true);
        }

        // Init animations
        _initAnim(model);

        if (!model.hasGeometry()) {
            avp.logger.warn("Loaded model has not geometry.");
        }

        // Fire the event so we know the geometry is done loading.
        this.api.fireEvent({
            type: av.GEOMETRY_LOADED_EVENT,
            model: model
        });
    };

    this.signalProgress = function(percent)
    {
        if (_progressEvent.percent === percent)
            return;
        _progressEvent.percent = percent;
        this.api.fireEvent(_progressEvent);
    };

    this.resize = function(w, h) {
        _needsResize = true;
        _newWidth = w;
        _newHeight = h;
    };


    this.unloadModel = function(model) {

        if (!this.removeModel(model)) {
            // model not found
            return;
        }

        if (model.loader)
            model.loader.dtor();
    };

    /** Removes a model from this viewer, but (unlike unload) keeps the RenderModel usable,
     *  so that it can be added to this or other viewers later.
     *   @param {RenderModel}
     *   @returns {bool} True if the model was known and has been successfully removed.
     */
    this.removeModel = function(model) {

        if (!_modelQueue.removeModel(model)) {
            return false;
        }

        if (this.keyFrameAnimator) {
            this.keyFrameAnimator.destroy();
            this.keyFrameAnimator = null;
        }

        // Note that this just discards the GPU resources, not the model itself.
        model.dtor(this.glrenderer());

        _materials.cleanup(model);

        this.selector.removeModel(model);
        this.visibilityManager.removeModel(model);

        if (model === this.model) {
            this.model = null;

            if (!_modelQueue.isEmpty())
                this.model = _modelQueue.getModels()[0];
        }

        this.api.fireEvent({type: av.MODEL_UNLOADED_EVENT, model: model});

        this.invalidate(true, true, true);

        return true;
    };

    this.unloadCurrentModel = function() {
        //Before loading a new model, restore states back to what they
        //need to be when loading a new model. This means restoring transient
        //changes to the render state made when entering 2d mode,
        //like light preset, antialias and SAO settings,
        //and freeing GL objects specific to the old model.
        if (this.is2d) {
            this.is2d = undefined;
            this.selectionMaterial2d = null;
            this.removeOverlayScene("selection2d");
            _renderer.exit2DMode();

            //Restore the state, but do not actually switch it here, because
            //we don't want to spend the time on it
            //when switching from 2d to 2d. See corresponding
            //logic in addModel().
            _currentLightPreset = _oldLightPreset;
        }

        _renderer.beginScene(this.scene, this.camera, this.lightsOn ? this.lights : this.no_lights, true);
        _renderer.composeFinalFrame(true);

        // Destruct any ongoing loaders, in case the loading starts, but the model root hasn't created yet.
        if (this.loaders) {
            this.loaders.forEach(function(loader) {
                loader.dtor();
            });
            this.loaders = [];
        }

        var models = _modelQueue.getModels();
        for (var i=models.length-1; i>=0; i--)
            this.unloadModel(models[i]);
    };

    var createSelectionScene = function(name, materialPre, materialPost) {
        materialPre.depthWrite = false;
        materialPre.depthTest = true;
        materialPre.side = THREE.DoubleSide;

        materialPost.depthWrite = false;
        materialPost.depthTest = true;
        materialPost.side = THREE.DoubleSide;

        // make selection material support instanced geometry
        avp.addInstancingSupport(materialPre);
        avp.addInstancingSupport(materialPost);

        _this.createOverlayScene(name, materialPre, materialPost);
    };

    this.createOverlayScene = function(name, materialPre, materialPost, camera) {
        if (materialPre) {
            _materials.addOverrideMaterial(name+"_pre", materialPre);
        }

        if (materialPost) {
            _materials.addOverrideMaterial(name+"_post", materialPost);
        }

        var s = new THREE.Scene();
        s.__lights = this.scene.__lights;
        this.overlayScenes[name] = {
            scene : s,
            camera: camera,
            materialPre : materialPre,
            materialPost : materialPost
        };
    };

    this.removeOverlayScene = function (name) {

        var overlay = this.overlayScenes[name];
        if (overlay) {
            delete this.overlayScenes[name];
            this.invalidate(false, false, true);
        }
    };

    this.addOverlay = function(overlayName, mesh) {
        this.overlayScenes[overlayName].scene.add(mesh);
        this.invalidate(false, false, true);
    };

    this.addMultipleOverlays = function(overlayName, meshes) {
        for (var i in meshes) {
            if (!meshes.hasOwnProperty(i)) continue;
            this.addOverlay(overlayName, meshes[i]);
        }
    };

    this.removeOverlay = function(overlayName, mesh) {
        if (this.overlayScenes[overlayName]) {
            this.overlayScenes[overlayName].scene.remove(mesh);
            this.invalidate(false, false, true);
        }
    };

    this.removeMultipleOverlays = function(overlayName, meshes) {
        for (var i in meshes) {
            if (!meshes.hasOwnProperty(i)) continue;
            this.removeOverlay(overlayName, meshes[i]);
        }
    };

    this.clearOverlay = function(overlayName) {

        if (!this.overlayScenes[overlayName])
            return;

        var scene = this.overlayScenes[overlayName].scene;
        var obj, i;
        for (i = scene.children.length - 1; i >= 0; --i) {
            obj = scene.children[ i ];
            if (obj) {
                scene.remove(obj);
            }
        }

        this.invalidate(false, false, true);
    };

    this.setClearColors = function(r,g,b, r2, g2, b2) {
        this.clearColorTop = new THREE.Vector3(r/255.0,g/255.0,b/255.0);
        this.clearColorBottom = new THREE.Vector3(r2/255.0,g2/255.0,b2/255.0);

        //If we are using the background color as environment also,
        //create an environment map texture from the new colors
        if (!_materials._reflectionMap || _materials._reflectionMap.isBgColor) { // TODO: don't access internal members of matman
            var cubeMap = _materials.setCubeMapFromColors(this.clearColorTop, this.clearColorBottom);
            _renderer.setCubeMap(cubeMap);
            this.invalidate(true);
        }

        _renderer.setClearColors(this.clearColorTop, this.clearColorBottom);
        if (_groundReflection) _groundReflection.setClearColors(this.clearColorTop, this.clearColorBottom, av.isAndroidDevice() || av.isIOSDevice());
        _needsClear = true;
        this.fireRenderOptionChanged();
    };

    //Similar to THREE.Box3.setFromObject, but uses the precomputed bboxes of the
    //objects instead of doing it per vertex.
    var _box3;
    function computeObjectBounds(dst, object) {

        _box3 = _box3 || new THREE.Box3();

        object.updateMatrixWorld( true );

        object.traverse( function ( node ) {

            var geometry = node.geometry;

            if (geometry !== undefined && geometry.visible) {

                if (!geometry.boundingBox)
                    geometry.computeBoundingBox();

                _box3.copy(geometry.boundingBox);
                _box3.applyMatrix4(node.matrixWorld);
                dst.union(_box3);
            }

        } );
    }

    function getOverlayBounds() {
        var bounds = new THREE.Box3();
        var overlays = _this.overlayScenes;

        for (var key in overlays) {
            if (!overlays.hasOwnProperty(key))
                continue;

            computeObjectBounds(bounds, overlays[key].scene);
        }

        //Also add the root scene -- people add overlays there too
        computeObjectBounds(bounds, _this.scene);

        return bounds;
    }

    this.getVisibleBounds = function(includeGhosted, includeOverlays) {
        var result = new THREE.Box3();
        if (!_modelQueue.isEmpty()) {
            computeObjectBounds(result, this.scene);
            result = _modelQueue.getVisibleBounds(includeGhosted).union(result);

            if (includeOverlays) {
                result = getOverlayBounds().union(result);
            }
        }
        return result;
    };

    this.getFitBounds = function( ignoreSelection )
    {
        var bounds;

        // If there is a valid selection, use its bounds
        if( !ignoreSelection && this.selector !== null) {
            bounds = this.selector.getSelectionBounds();
        }

        // Otherwise, if there is a valid isolation, use its bounds
        if(!bounds || bounds.empty()) {
            bounds = this.getVisibleBounds();
        }
        //console.log("  getFitBounds bounds are " + + bounds.min.x +", "+ bounds.min.y + " to " + bounds.max.x +", "+ bounds.max.y);

        return bounds;
    };

    this.getRenderProxy = function(model, fragId) {
        //currently there is a single model so the mapping
        //of fragId to render mesh is 1:1.
        return model.getFragmentList().getVizmesh(fragId);
    };

    this.getFragmentProxy = function(model, fragId) {
        return new avp.FragmentPointer(model.getFragmentList(), fragId);
    };

    this.getRenderProxyCount = function(model) {
        return model.getFragmentList().getCount();
    };

    this.getRenderProxyDbIds = function(model, fragId) {
        return model.getFragmentList().getDbIds(fragId);
    };

    this.isWholeModelVisible = function(model) {
        return _modelQueue ? _modelQueue.areAllVisible() : true;
    };

    this.highlightObjectNode = function(model, dbId, value, simpleHighlight) {

        if (model.is2d()) {
            _materials.highlightObject2D(dbId, value); //update the 2d object id texture
            this.invalidate(false, false, true);
        }

        var scope = this;
        var it = model.getData().instanceTree;

        //TODO: There can be instance tree in the case of 2D drawing, but
        //we do not currently populate the node tree with the virtual fragment ids
        //that map 2d objects to 2d consolidated meshes, hence the use of dbId2fragId in the else condition
        if (it && !model.is2d()) {

            it.enumNodeFragments(dbId, function(fragId) {
                scope.highlightFragment(model, fragId, value, simpleHighlight);
            }, false);

        } else {
            var fragId = dbId;

            if (model.is2d())
                fragId = model.getData().fragments.dbId2fragId[dbId];

            if (Array.isArray(fragId))
                for (var i=0; i<fragId.length; i++)
                    scope.highlightFragment(model, fragId[i], value, simpleHighlight);
            else
                scope.highlightFragment(model, fragId, value, simpleHighlight);

        }

    };

    this.highlightFragment = function(model, fragId, value, simpleHighlight) {

        var mesh = this.getRenderProxy(model, fragId);

        if (!mesh)
            return;

        //And also add a mesh to the overlays in case we need that.
        //For 2D that is always the case, while for 3D it's done
        //for "fancy" single-selection where we draw an outline for the object
        //as post-processing step.
        var useOverlay = !simpleHighlight || mesh.is2d;

        var highlightId = model.id + ":" + fragId;

        if (useOverlay) {
            var overlayName = model.is2d() ? "selection2d" : "selection";

            if (value)
            {
                var selectionProxy = new THREE.Mesh(mesh.geometry, mesh.material);
                selectionProxy.matrix.copy(mesh.matrixWorld);
                selectionProxy.matrixAutoUpdate = false;
                selectionProxy.matrixWorldNeedsUpdate = true;

                selectionProxy.frustumCulled = false;
                selectionProxy.model = model;
                selectionProxy.fragId = fragId;

                this.addOverlay(overlayName, selectionProxy);

                this.selectionMeshes[highlightId] = selectionProxy;
            }
            else
            {
                if (this.selectionMeshes[highlightId]) {
                    this.removeOverlay(overlayName, this.selectionMeshes[highlightId]);
                    delete this.selectionMeshes[highlightId];
                }
            }
        }

        if (!useOverlay || !value) {
            //Case where highlighting was done directly in the primary render queue
            //and we need to repaint to clear it. This happens when multiple
            //nodes are highlighted using e.g. right click in the tree view
            if (model.setHighlighted(fragId, value)) //or update the vizflags in the render queue for 3D objects
                this.invalidate(true);
        }
    };

    this.explode = function(scale) {

        if(scale == _explodeScale)
            return;

        _explodeScale = scale;

        _modelQueue.explode(scale);

        //force a repaint and a clear
        this.sceneUpdated(true);

        this.api.fireEvent({type:av.EXPLODE_CHANGE_EVENT, scale: scale});
    };

    /**
     * Gets the last applied explode scale
     */
    this.getExplodeScale = function()
    {
        return _explodeScale;
    };


    /* simple function to set the brightness of the ghosting.
     * Simply sets another colour that is better for brighter environments
     */
    this.setGhostingBrightness = function(darkerFade)
    {
        if (darkerFade) {
            this.fadeMaterial.color = new THREE.Color(0x101010);
        }
        else {
            this.fadeMaterial.color =  new THREE.Color(0xffffff);
        }
        this.fadeMaterial.needsUpdate = true;
    };


    this.setLightPreset = function(index, force)
    {
        // make sure that lights are created
        if (!_lightsInitialized) {
            this.initLights();
        }

        if (_currentLightPreset == index && !force)
            return;

        // Reset index in cases the index out of range.
        // This could happen, if we update the light preset list and user
        // has a local web storage which stores the last accessed preset index which is potentially
        // out of range with respect to the new preset list.
        if (index < 0 || avp.LightPresets.length <= index) {
            index = avp.DefaultLightPreset;
        }

        _currentLightPreset = index;
        var preset = avp.LightPresets[index];
        if (preset && preset.path) {
            var pathPrefix = "res/environments/" + preset.path;
            var reflPath = avp.getResourceUrl(pathPrefix + "_mipdrop." + (preset.type || "") + ".dds");
            var irrPath =  avp.getResourceUrl(pathPrefix + "_irr." + (preset.type || "") + ".dds");

            var irrMap = _materials.setIrradianceMap(irrPath, preset.E_bias, function() { _this.invalidate(true); });
            var cubeMap = _materials.setCubeMap(reflPath, preset.E_bias, function(map) {
                _this.invalidate(true);
                if (!map) {
                    _materials.setCubeMapFromColors(_this.clearColorTop, _this.clearColorBottom);
                }
            });
            _renderer.setCubeMap(cubeMap);

            //Set exposure that the environment was baked with.
            //This has to be known at baking time and is applied
            //by the shader.
            _materials.setEnvExposure(-preset.E_bias);
            _renderer.setEnvExposure(-preset.E_bias);

            this.setTonemapExposureBias(preset.E_bias);
            this.setTonemapMethod(preset.tonemap);

            this.setGhostingBrightness(preset.darkerFade);
        }
        else {
            _materials.setIrradianceMap(null);
            var cubeMap = _materials.setCubeMap(null);
            _renderer.setCubeMap(cubeMap);
            _materials.setEnvExposure(0);
            _renderer.setEnvExposure(0);

            this.setTonemapExposureBias(0);
            this.setTonemapMethod(0);

            this.setGhostingBrightness(false);

            this.invalidate(true);
        }


        //To begin with, get the SAO defaults from the shader uniforms definition
        //Note the scaling we apply to inverse scaling done by the setAOOptions API internally.
        //This is not pretty....
        var saoRadius = av.Shaders.SAOShader.uniforms.radius.value;
        var saoIntensity = av.Shaders.SAOShader.uniforms.intensity.value;

        //Check if the preset overrides the SAO settings
        if (preset.hasOwnProperty("saoRadius"))
            saoRadius = preset.saoRadius;
        if (preset.hasOwnProperty("saoIntensity"))
            saoIntensity = preset.saoIntensity;
        _renderer.setAOOptions(saoRadius, saoIntensity);

        //if the light preset has a specific background color, set that
        var c = preset.bgColorGradient;
        if (!c)
            c = avp.BackgroundPresets["Custom"];
        this.setClearColors(c[0], c[1], c[2], c[3], c[4], c[5]);

        var lightIntensity = _defaultLightIntensity;
        if (preset.lightMultiplier !== null && preset.lightMultiplier !== undefined) {
            lightIntensity = preset.lightMultiplier;
        }

        // init primary light direction used for shadows
        _shadowLightDir.copy(_shadowLightDirDefault);
        if (preset.lightDirection) {
            // The presets describe the direction away from the light, while _shadowLightDir
            // is the direction pointing to the light.
            _shadowLightDir.fromArray(preset.lightDirection).negate();
        }

        // changing the shadow light direction invalidates the shadow-map
        if (_shadowMaps) {
            invalidateShadowMap();
        }

        if (this.dir_light1) {
            this.dir_light1.intensity = lightIntensity;

            if (preset.lightDirection) {
                this.dir_light1.position.set( -preset.lightDirection[0], -preset.lightDirection[1], -preset.lightDirection[2] );
            }

        }

        _materials.setEnvRotation(preset.rotation || 0.0);
        _renderer.setEnvRotation(preset.rotation || 0.0);

        if (_groundReflection) _groundReflection.setEnvRotation(preset.rotation || 0.0);

        // toggle lights on/off based on lightMultiplier
        this.toggleLights(lightIntensity !== 0.0);

        this.invalidate(true, false, true);

        this.fireRenderOptionChanged();
    };

    this.setLightPresetFromFile = function(model)
    {
        if (!model || model.is2d()) {
            return false;
        }

        var style = model.getMetadata('renderEnvironmentStyle', 'value', null);
        if ((style === null) || (style ===""))
            return false;

        // TODO add more control for environments
        // the user cannot set anything expect the style from current UI
        // currently only the style can be selected.
        // TODO We cannot control these values so comment out for now
        var grndReflection = model.getMetadata('renderEnvironmentGroundReflection', 'value', null);
        if (grndReflection !== null) {
            if (this.api.prefs.hasTag('groundReflection', 'ignore-producer')) {
                avp.logger.debug('setLightPresetFromFile(): groundReflection is locked. No changes.');
            } else {
                this.api.prefs.tag('no-storage', 'groundReflection');
                this.api.setGroundReflection(grndReflection);
            }
        }

        var grndShadow = model.getMetadata('renderEnvironmentGroundShadow', 'value', null);
        if (grndShadow !== null) {
            if (this.api.prefs.hasTag('groundShadow', 'ignore-producer')) {
                avp.logger.debug('setLightPresetFromFile(): groundShadow is locked. No changes.');
            } else {
                this.api.prefs.tag('no-storage', 'groundShadow');
                this.api.setGroundShadow(grndShadow);
            }
        }
        var ambientShadows = model.getMetadata('renderEnvironmentAmbientShadows', 'value', null);
        if (ambientShadows !== null) {
            if (this.api.prefs.hasTag('ambientShadows', 'ignore-producer')) {
                avp.logger.debug('setLightPresetFromFile(): ambientShadows is locked. No changes.');
            } else {
                this.api.prefs.tag('no-storage', 'ambientShadows');
                // kludgey, but maintains previous API linking these two different algorithms together
                this.api.setQualityLevel(ambientShadows, _renderer.getAntialiasing());
            }
        }
        var displayLines = model.getMetadata('renderEnvironmentDisplayLines', 'value', null);
        if (displayLines !== null) {
            if (this.api.prefs.hasTag('lineRendering', 'ignore-producer')) {
                avp.logger.debug('setLightPresetFromFile(): lineRendering is locked. No changes.');
            } else {
                this.api.prefs.tag('no-storage', 'lineRendering');
                this.api.hideLines(!displayLines);
            }
        }
        var displayPoints = model.getMetadata('renderEnvironmentDisplayPoints', 'value', null);
        if (displayPoints !== null) {
            if (this.api.prefs.hasTag('pointRendering', 'ignore-producer')) {
                avp.logger.debug('setLightPresetFromFile(): pointRendering is locked. No changes.');
            } else {
                this.api.prefs.tag('no-storage', 'pointRendering');
                this.api.hidePoints(!displayPoints);
            }
        }


        var preset = avp.LightPresets.filter(function(lightPreset){
            return lightPreset.name === style;
        });
        preset = preset[0] || null;
        if (preset) {
            if (this.api.prefs.hasTag('lightPreset', 'ignore-producer')) {
                avp.logger.debug('setLightPresetFromFile(): lightPreset is locked. No changes.');
            } else {
                this.api.prefs.tag('no-storage', 'lightPreset');

                // Create an env based on an existing preset
                // and add it at the end of the official list
                var env = avp.ModelSettingsEnvironment;
                if (!env) {
                    env = avp.ModelSettingsEnvironment = {};
                    avp.LightPresets.push(env);
                }

                // Copy existing Preset into custom Model-Loaded preset
                avp.copyLightPreset(preset, env);

                // Override Name for use in UI
                env.name = '(Custom: Model defined)'; // TODO: Localize

                // Override Environment Exposure Values
                var exposureBias = model.getMetadata('renderEnvironmentExposureBias', 'value', null);
                var exposureBase = model.getMetadata('renderEnvironmentExposureBase', 'value', null);
                if (exposureBias !== null && exposureBase !== null ) {
                    env.E_bias = exposureBias + exposureBase;
                }

                // Override Environment Background Color
                // Note that there's a specific preset for background color
                var bgColor = model.getMetadata('renderEnvironmentBackgroundColor', 'value', null);
                if (this.api.prefs.hasTag('backgroundColorPreset', 'ignore-producer')) {
                    avp.logger.debug('setLightPresetFromFile(): backgroundColorPreset is locked. No changes.');
                } else if (bgColor) {
                    env.bgColorGradient = [
                        255.0 * bgColor[0], 255.0 * bgColor[1], 255.0 * bgColor[2],
                        255.0 * bgColor[0], 255.0 * bgColor[1], 255.0 * bgColor[2]
                    ];
                }

                // Override Environment Rotation
                var envRotation = model.getMetadata('renderEnvironmentRotation', 'value', null); //assumed radians
                if (envRotation !== null) {
                    env.rotation = envRotation;
                }

                var i = avp.LightPresets.indexOf(env);
                this.api.setLightPreset(i);
            }
        }

        var bgEnvironment = model.getMetadata('renderEnvironmentBackgroundFromEnvironment', 'value', null);
        if (bgEnvironment !== null) {
            if (this.api.prefs.hasTag('envMapBackground', 'ignore-producer')) {
                avp.logger.debug('setLightPresetFromFile(): envMapBackground is locked. No changes.');
            } else {
                this.api.prefs.tag('no-storage', 'envMapBackground');
                this.api.setEnvMapBackground(bgEnvironment);
            }
        }

        // Important to return the model defined preset
        return preset;
    };


    this.setTonemapMethod = function (index) {

        if (index == _renderer.getToneMapMethod())
            return;

        _renderer.setTonemapMethod(index);
        _materials.setTonemapMethod(index);

        this.fireRenderOptionChanged();
        this.invalidate(true);
    };

    this.setTonemapExposureBias = function (bias) {

        if (bias == _renderer.getExposureBias())
            return;

        _renderer.setTonemapExposureBias(bias);
        _materials.setTonemapExposureBias(bias);

        this.fireRenderOptionChanged();
        this.invalidate(true);
    };


    /**
     * Unloads model, frees memory, as much as possible.
     */
    this.dtor = function() {
        window.cancelAnimationFrame(_reqid);

        this.unloadCurrentModel();

        // this.controls is uninitialized by Viewer3D, since it was initialized there
        this.controls = null;
        this.canvas = null;

        this.loader = null;

        this.selector.dtor();
        this.selector = null;

        this.model = null;
        this.visibilityManager = null;

        _modelQueue = null;
        _renderer = null;
        _materials.dtor();
        _materials = null;
    };

    this.hideLines = function(hide){
        if (_modelQueue && !_modelQueue.isEmpty()) {
            _modelQueue.hideLines(hide);
            this.sceneUpdated(true);
            return true;
        }
        return false;
    };

    this.hidePoints = function(hide){
        if (_modelQueue && !_modelQueue.isEmpty()) {
            _modelQueue.hidePoints(hide);
            this.sceneUpdated(true);
            return true;
        }
        return false;
    };

    this.getCutPlanes = function() {
        return _materials.getCutPlanes();
    };

    this.setCutPlanes = function(planes) {
        _materials.setCutPlanes(planes);
        this.sceneUpdated();
        this.api.fireEvent({type:av.CUTPLANES_CHANGE_EVENT, planes: planes});
    };

    this.fireRenderOptionChanged = function() {

        //If SAO is changing and we are using multiple
        //render targets in the main material pass, we have
        //to update the materials accordingly.
        _materials.toggleMRTSetting(_renderer.mrtFlags());

        this.api.fireEvent({type:av.RENDER_OPTION_CHANGED_EVENT});
    };

    this.viewportToRay = function(vpVec, ray) {
        var camera = this.camera;

        // set two vectors with opposing z values
        vpVec.z = -1.0;
        var end = new THREE.Vector3( vpVec.x, vpVec.y, 1.0 );
        vpVec = vpVec.unproject(camera);
        end = end.unproject( camera );

        // find direction from vector to end
        end.sub( vpVec ).normalize();

        if (!ray)
            ray = new THREE.Ray();

        ray.set(!camera.isPerspective ? vpVec : camera.position, end);

        return ray;
    };

    // Add "meshes" parameter, after we get meshes of the object using id buffer,
    // then we just need to ray intersect this object instead of all objects of the model.
    this.rayIntersect = function(ray, ignoreTransparent, dbIds, modelIds) {
        var result = _modelQueue.rayIntersect(ray.origin, ray.direction, ignoreTransparent, dbIds, modelIds);

        if (this.sceneAfter.children.length) {
            var raycaster = new THREE.Raycaster(ray.origin, ray.direction, this.camera.near, this.camera.far);
            var intersects = [];
            avp.VBIntersector.intersectObject(this.sceneAfter, raycaster, intersects, true);

            if (intersects.length) {
                if (!result || intersects[0].distance < result.distance) {
                    result = intersects[0];
                }
            }
        }

        if (!result)
            return null;

        var fragId = result.fragId,
            intersectPoint = result.point,
            face = result.face,
            model = result.model;

        var dbId = result.dbId;
        if (dbId === undefined && fragId !== undefined /* 0 is a valid fragId */) {

            dbId = model.getFragmentList().getDbIds(fragId);
            var instanceTree = model.getData().instanceTree;

            if (!instanceTree) {
                //Case where there is no object tree hierarchy. Create a 'virtual' node
                //with node Id = fragment Id, so that selection works like
                //each scene fragment is a scene node by itself.
                dbId = fragId;
            }
        }

        return { dbId: dbId, fragId: fragId, "intersectPoint":intersectPoint, "face":face, "model":model };
    };

    this.castRayViewport = function() {

        var _ray;

        // Add "meshes" parameter, after we get meshes of the object using id buffer,
        // then we just need to ray intersect this object instead of all objects of the model.
        return function (vpVec, ignoreTransparent, dbIds, modelIds) {

            _ray = _ray || new THREE.Ray();

            if (!_modelQueue) {
                return {};
            }

            this.viewportToRay(vpVec, _ray);

            return this.rayIntersect(_ray, ignoreTransparent, dbIds, modelIds);
        };

    }();

    this.clientToViewport = function (clientX, clientY)
    {
        var rect = _this.canvas.getBoundingClientRect();
        return new THREE.Vector3(
            ((clientX + 0.5) / rect.width) * 2 - 1,
           -((clientY + 0.5) / rect.height) * 2 + 1, 1 );
    };

    this.viewportToClient = function (viewportX, viewportY)
    {
        var rect = _this.canvas.getBoundingClientRect();
        return new THREE.Vector3(
            (viewportX + 1) * 0.5 * rect.width  - 0.5,
            (viewportY - 1) *-0.5 * rect.height - 0.5, 0 );
    };

    this.castRay = function (clientX, clientY, ignoreTransparent) {
        // Use the offsets based on the client rectangle, which is relative to the browser's client
        // rectangle, unlike offsetLeft and offsetTop, which are relative to a parent element.
        //
        return this.castRayViewport(this.clientToViewport(clientX, clientY),ignoreTransparent);
    };


    this.intersectGroundViewport = function(vpVec) {

        var camera = this.camera;

        var worldUp = "z";

        //In 2D mode, the roll tool can be used to change the orientation
        //of the sheet, which will also set the world up vector to the new orientation.
        //However, this is not what we want in case of a 2d sheet -- its ground plane is always Z.
        //TODO: It's not clear if checking here or in setWorldUp is better. Also I don't see
        //a way to generalize the math in a way to make it work without such check (e.g. by using camera up only).
        if (!this.is2d) {
            worldUp = _worldUpName;
        }

        var vector = vpVec;

        // set two vectors with opposing z values
        vector.z = -1.0;
        var end = new THREE.Vector3( vector.x, vector.y, 1.0 );
        vector = vector.unproject( camera );
        end = end.unproject( camera );

        // find direction from vector to end
        end.sub( vector ).normalize();

        var dir = end;

        //Is the direction parallel to the ground plane?
        //Then we fail.
        if (Math.abs(dir[worldUp]) < 1e-6)
            return null;

        var rayOrigin;
        if (camera.isPerspective) {
            rayOrigin = camera.position;
        }
        else {
            rayOrigin = vector;
        }

        var baseElev = this.model ? this.model.getBoundingBox().min[worldUp] : 0;

        var distance = (baseElev - rayOrigin[worldUp]) / dir[worldUp];

        //2D drawing, intersect the plane
        dir.multiplyScalar(distance);
        dir.add(rayOrigin);

        return dir;
    };

    this.intersectGround = function(clientX, clientY) {
        return this.intersectGroundViewport(this.clientToViewport(clientX, clientY));
    };


    this.hitTestViewport = function(vpVec, ignoreTransparent) {

        var result;

        if (_this.is2d) {

            var dbId;
            var ids = [];
            if (av.isMobileDevice()) {
                // Set the detection area to 44*44 pixel rectangle according to Apple's iOS Human Interface Guidelines
                dbId = _renderer.idAtPixels(vpVec.x, vpVec.y, 45, ids);
            }
            else {
                // Set the detection area to 5*5 pixel search rectangle
                dbId = _renderer.idAtPixels(vpVec.x, vpVec.y, 5, ids);
            }

            if (dbId <= 0)
                return null;

            //Note this function will destructively modify vpVec,
            //so it's unusable after that.
            var point = this.intersectGroundViewport(vpVec);

            var model = _modelQueue.findModel(ids[1]) || _this.model;

            //var node = dbId ? { dbId : dbId, fragIds : _this.model.getData().fragments.dbId2fragId[dbId] } : null;
            result = {
                intersectPoint : point,
                dbId : dbId,
                fragId : model.getData().fragments.dbId2fragId[dbId],
                model : model
            };
        }
        else {

            result = this.castRayViewport(vpVec, ignoreTransparent);

        }

        return result;
    };


    this.hitTest = function(clientX, clientY, ignoreTransparent) {

        return _this.hitTestViewport(this.clientToViewport(clientX, clientY), ignoreTransparent);

    };

    this.snappingHitTestViewport = function(vpVec, ignoreTransparent) {

        var result;

        if (_this.is2d) {

            var dbId;
            if (av.isMobileDevice()) {
                //Set the detection area to 44*44 pixel rectangle according to Apple's iOS Human Interface Guidelines
                //Notice: The amount of pixels per line should correspond to pixelSize in setDetectRadius of Snapper.js,
                //the shape of detection area is square in idAtPixels, but circle in snapper, should make their areas match roughly.
                dbId = _renderer.idAtPixels(vpVec.x, vpVec.y, 45);
            }
            else {
                //Notice: The amount of pixels per line should correspond to pixelSize in setDetectRadius of Snapper.js,
                //the shape of detection area is square in idAtPixels, but circle in snapper, should make their areas match roughly.
                dbId = _renderer.idAtPixels(vpVec.x, vpVec.y, 17);
            }

            // Need to do hitTest in snapping when dbId = 0
            if (dbId < 0)
                return null;

            //Note this function will destructively modify vpVec,
            //so it's unusable after that.
            var point = this.intersectGroundViewport(vpVec);

            // get fragment ID if there is a fragment list
            var fragments = _this.model.getData().fragments;
            var fragId    = (fragments ? fragments.dbId2fragId[dbId] : -1);

            //var node = dbId ? { dbId : dbId, fragIds : _this.model.getData().fragments.dbId2fragId[dbId] } : null;
            result = { intersectPoint : point, dbId : dbId, fragId : fragId };

            if (dbId) {
                //result.node = ... get the node for the dbId here
            }

        }
        else {

            var dbId = _renderer.idAtPixel(vpVec.x, vpVec.y);

            result = this.castRayViewport(vpVec, ignoreTransparent, dbId > 0 ? [dbId] : null);

        }

        return result;
    };

    // Used for snapping
    // firstly, find the intersect object using pre-computed ID buffer
    // secondly, find the intersect point and face using intersection test
    this.snappingHitTest = function(clientX, clientY, ignoreTransparent) {

        return this.snappingHitTestViewport(this.clientToViewport(clientX, clientY), ignoreTransparent);
    };

    //Used for rollover highlighting using pre-computed ID buffer
    //Currently only the 2D code path can do this.
    this.rolloverObjectViewport = function(vpVec) {

        //Not supported for 3d.
        //if (!this.is2d)
        //    return;

        if (_renderer.rolloverObjectViewport(vpVec.x, vpVec.y))
            this.invalidate(false, false, true);
    };

    this.rolloverObject = function(clientX, clientY) {

        if (!this.rolloverDisabled)
            this.rolloverObjectViewport(this.clientToViewport(clientX, clientY));
    };

    this.disableRollover = function(disable) {

        this.rolloverDisabled = disable;
    };

    this.rolloverObjectNode = function(dbId) {

        var dbIds = [];
        var it = _this.model.getData().instanceTree;

        if (it) {

            it.enumNodeChildren(dbId, function(childId) {
                dbIds.push(childId);
            }, true);

            // Sort the array to get the dbIds range, it should exclude the first node which
            // is local root, since its dbId may not be serial number like its descendants.
            if (dbIds.length > 1) {
                var temp = dbIds.shift();
                dbIds.sort(function(a,b) {return a-b;});
                dbIds.unshift(temp);
            }

        }
        else {
            dbIds.push(dbId);
        }

        if (_renderer.rolloverObjectViewport(null, null, dbIds))
            this.invalidate(false, false, true);
    };

    // https://github.com/ebidel/filer.js/blob/master/src/filer.js
    function dataURLToBlob(dataURL) {
        var BASE64_MARKER = ';base64,';
        var parts, contentType, raw;
        if (dataURL.indexOf(BASE64_MARKER) == -1) {
            parts = dataURL.split(',');
            contentType = parts[0].split(':')[1];
            raw = decodeURIComponent(parts[1]);

            return new Blob([raw], {type: contentType});
        }

        parts = dataURL.split(BASE64_MARKER);
        contentType = parts[0].split(':')[1];
        raw = window.atob(parts[1]);
        var rawLength = raw.length;

        var uInt8Array = new Uint8Array(rawLength);

        for (var i = 0; i < rawLength; ++i) {
            uInt8Array[i] = raw.charCodeAt(i);
        }

        return new Blob([uInt8Array], {type: contentType});
    }

    //this function get a blob object
    this.getScreenShotBuffer = function (w, h, cb) {
        _renderer.presentBuffer();
        var blobobj = _this.canvas.toDataURL("image/png");

        var flip = av.isSafari();
        if (flip) {
            w = w ? w : _newWidth;
            h = h ? h : _newHeight;
        }

        if (!w || !h)
            return blobobj;

        // calc resize and center
        var nw, nh, nx = 0, ny = 0;
        if (w > h || (_newWidth / _newHeight < w / h)) {
            nw = w;
            nh = _newHeight / _newWidth * w;
            ny = h / 2 - nh / 2;
        }
        else {
            nh = h;
            nw = _newWidth / _newHeight * h;
            nx = w / 2 - nw / 2;
        }

        var blobURL = window.URL.createObjectURL(dataURLToBlob(_this.canvas.toDataURL("image/png")));
        // new image from blobURL
        var img = new Image();
        img.src = blobURL;

        // create working canvas
        var tmpCanvas = document.createElement("canvas");
        var ctx = tmpCanvas.getContext("2d");
        tmpCanvas.width = w;
        tmpCanvas.height = h;

        // draw image on canvas
        img.onload = function () {
            if (flip) {
                ctx.translate(0, nh);
                ctx.scale(1,-1);
            }
            ctx.drawImage(img, nx, ny, nw, nh);
            var newobj = tmpCanvas.toDataURL("image/png");
            var newBlobURL = window.URL.createObjectURL(dataURLToBlob(tmpCanvas.toDataURL("image/png")));
            if (cb)
                cb(newobj);
            else
                window.open(newBlobURL);
        };
    };

    // we use Blob URL, Chrome crashes when opening dataURL that is too large
    // https://developer.mozilla.org/en-US/docs/Web/API/URL/createObjectURL
    this.getScreenShot = function(w, h, cb) {

        function reframeBlob(blobURL, w, h, flip, cb) {

            if (!flip && (!w || !h)) {
                cb && cb(blobURL);
            } else {
                // calc resize and center
                var nw, nh, nx = 0, ny = 0;
                if (w > h || (_newWidth/_newHeight < w/h)) {
                    nw = w;
                    nh = _newHeight/_newWidth * w;
                    ny = h/2 - nh/2;
                }
                else {
                    nh = h;
                    nw = _newWidth/_newHeight * h;
                    nx = w/2 - nw/2;
                }

                // new image from blobURL
                var img = new Image();
                img.src = blobURL;

                // create working canvas
                var tmpCanvas = document.createElement("canvas");
                var ctx = tmpCanvas.getContext("2d");
                tmpCanvas.width = w;
                tmpCanvas.height = h;

                // draw image on canvas
                img.onload = function() {
                    if (flip) {
                        ctx.translate(0, nh);
                        ctx.scale(1,-1);
                    }
                    ctx.drawImage(img, nx, ny, nw, nh);
                    var newBlobURL = window.URL.createObjectURL(dataURLToBlob(tmpCanvas.toDataURL("image/png")));
                    if (cb) {
                        cb(newBlobURL);
                    } else {
                        window.open(newBlobURL);
                    }
                };
            }
        }

        _renderer.presentBuffer();
        var blobURL = window.URL.createObjectURL(dataURLToBlob(_this.canvas.toDataURL("image/png")));

        // It seems there is not a better way to detect if the resulting image needs to be flipped.
        var flip = av.isSafari();
        if (flip) {
            w = w ? w : _newWidth;
            h = h ? h : _newHeight;
        }

        reframeBlob(blobURL, w, h, flip, cb);
    };

    //This accessor is only used for debugging purposes a.t.m.
    this.modelQueue = function() { return _modelQueue; };

    this.glrenderer = function() { return _webglrender; };

    this.renderer = function() { return _renderer; };

    // only for debugging purposes
    this.shadowMaps = function() { return _shadowMaps; }

    this.worldUp = function() { return _worldUp; };
    this.worldUpName = function() { return _worldUpName; };

    this.setUserRenderContext = function(ctx) {
        _renderer = (ctx) ? ctx : new avp.RenderContext();
        _renderer.init(_webglrender, this.canvas.clientWidth, this.canvas.clientHeight);
        _renderer.setClearColors(this.clearColorTop, this.clearColorBottom);
        this.invalidate(true);
        this.sceneUpdated(false); //to reset world boxes needed by new RenderContext for shadows, etc
    };

    this.invalidate = function(needsClear, needsRender, overlayDirty) {
        _needsClear = _needsClear || needsClear;
        _needsRender = _needsRender || needsRender;
        _overlayDirty = _overlayDirty || overlayDirty;
    };

    this.sceneUpdated = function(objectsMoved) {

        this.invalidate(true, false, true);

        // Mark the scene bounds for update
        if (_modelQueue && objectsMoved){
            _modelQueue.invalidateVisibleBounds();
            this.zoomBoundsChanged = true;
        }

        _sceneDirty = true;

        invalidateShadowMap();
    };

    this.currentLightPreset = function() { return _currentLightPreset; };

    this.matman = function() { return _materials; };

    this.fps = function() { return 1000.0 / _frameTimeAvg; };

    this.setFPSTargets = function(min, target, max) {
        MAX_FRAME_BUDGET = 1000 / max;
        MIN_FRAME_BUDGET = 1000 / min;
        TARGET_FRAME_TIME = 1000 / target;
        this.targetFrameBudget = av.isMobileDevice() ? TARGET_FRAME_TIME / 4 : TARGET_FRAME_TIME;
    };

    //========================================================================


    // Record fragments transformation in explode mode for RaaS rendering
    //this.fragTransformConfig = [];

    this.track = function(event) {
        avp.logger.track(event);
    };

    this.worldToClient = function(point) {
        var p = new THREE.Vector4(point.x, point.y, point.z, 1);
        p.applyMatrix4(this.camera.matrixWorldInverse);
        p.applyMatrix4(this.camera.projectionMatrix);

        // Don't want to mirror values with negative z (behind camera)
        if (p.w > 0)
        {
            p.x /= p.w;
            p.y /= p.w;
            p.z /= p.w;
        }

        return this.viewportToClient(p.x, p.y);
    };

    this.clientToWorld = function(clientX, clientY, ignoreTransparent) {

        var result = null;
        var model = this.model;
        var modelData = model.getData();

        if (model.is2d()) {

            var collision = this.intersectGround(clientX, clientY);
            if (collision) {
                collision.z = 0;
                var bbox = modelData.bbox;
                if (modelData.hidePaper || bbox.containsPoint(collision)) {
                    result = {
                        point: collision,
                        model: model
                    };
                }
            }
        } else {

            // hitTest handles multiple scenes
            result = this.hitTest(clientX, clientY, ignoreTransparent);
            if (result) {
                result.point = result.intersectPoint; // API expects attribute point to have the return value too.
            }
        }

        return result;
    };

    /**
     *
     * @param {THREE.Color} color
     */
    this.setSelectionColor = function(color) {
        this.selectionMaterialBase.color.set(color);
        this.selectionMaterialTop.color.set(color);
        this.invalidate(false, false, true);
    };

    // Update the viewport Id for the first selection in 2d measure
    this.updateViewportId = function(vpId) {
        _materials.updateViewportId(vpId);
        this.invalidate(true);
    };

    /**
     *  @param   {number} id
     *  @returns {RenderModel|null}
     */
    this.findModel = function(modelId) {
        return _modelQueue.findModel(modelId);
    };

    /**
     *  For shadow casting, we assume a single directional light. Shadow light direction is the direction
     *  that this light comes from, i.e., shadows are casted to the opposite direction.
     *  This function changes the direction and triggers a shadow update.
     *
     *  Note that the directional light source is only assumed for shadow casting. The actual lighting usually comes from
     *  several directions when using environment lighting, but we need a fixed direction for shadow mapping.
     *
     *   @param {THREE.Vector3} lightDir - direction in world space
     */
    this.setShadowLightDirection = function(lightDir) {
        _shadowLightDir.copy(lightDir);
        invalidateShadowMap();
        this.invalidate(true, false, false);

        // update ground transform to make sure that the ground shape is large enough
        // to make the whole shadow visible.
        updateGroundTransform();
    };

    /**
     *  The result is either returned as a new vector or written to 'target' (if specified)
     *  @param [THREE.Vector3} [target]
     *  @returns {THREE.Vector3} Either target object or new Vector3 instance.
     */
    this.getShadowLightDirection = function(target) {
        var dir = (target ? target : new THREE.Vector3());
        dir.copy(_shadowLightDir);
        return dir;
    };

    /**
     * @param {Bool} enable
     * Note that viewer must be initialized first.
     */
    this.toggleShadows = function(enable) {
        if (!!_shadowMaps == !!enable) {
            // no change
            return;
        }

        if (enable) {
            _shadowMaps = new avp.ShadowMaps(_webglrender);
        } else {
            _shadowMaps.cleanup(_materials);
            _shadowMaps = null;
        }

        // adjust ground plane box.
        updateGroundTransform();

        this.invalidate(true, true, false);
    };

    this.showTransparencyWhenMoving = function(enabled) {
        _modelQueue.enableNonResumableFrames = enabled;
    };


    this.fitToView = function(objectIds, model, immediate) {
        
        model = model || this.model;
        immediate = immediate || false;

        if (!model || !model.isLoadDone())
            return false;

        var theEvent = { 
            type: av.FIT_TO_VIEW_EVENT,
            nodeIdArray: objectIds,
            immediate: immediate,
            model: model 
        };

        var that = this;
        var _fit = function(){
            var fitTo = null;
            if( Array.isArray(objectIds) && (objectIds.length > 0) )
            {
                var bounds = new THREE.Box3();
                var box = new THREE.Box3();

                var instanceTree = model.getInstanceTree();
                var fragList = model.getFragmentList();

                for (var i=0; i<objectIds.length; i++) {
                    instanceTree.enumNodeFragments(objectIds[i], function(fragId) {
                        fragList.getWorldBounds(fragId, box);
                        bounds.union(box);
                    }, true);
                }

                if( !bounds.empty() )
                    fitTo = bounds;
            }
            if( !fitTo || fitTo.empty() )
                fitTo = that.getFitBounds();

            that.api.navigation.fitBounds(immediate, fitTo);
            that.api.fireEvent( theEvent );
        };

        // This doesn't guarantee that an object tree will be created but it will be pretty likely
        if (objectIds && objectIds.length > 0) {
            if (model.is2d()) {
                // objectIds list is array of dbids. Go through list and find bounds.

                /*
                FragmentList.dbid2fragId[dbid] will return the fragment id or an array of fragment ids
                that contain geometry for the dbid.
                Loop through the fragments and get the geometry for each fragment.
                Create a VertexBufferReader using the geometry.
                Use the VertexBufferReader to find the geometry for a dbid.

                To find the geometry we use VertexBufferReader.enumGeomsForObject(dbid, callback).
                It uses a callback object to enumerate geometry for a dbid. The callback object needs these
                optional functions:

                onLineSegment(x0, y0, x1, y1, viewport_id)
                onCircularArc(centerX, centerY, startAngle, endAngle, radius, viewport_id)
                onEllipticalArccenterX, centerY, startAngle, endAngle, major, minor, tilt, viewport_id)
                onTriangleVertex(x, y, viewport_id)
                etc.

                We use the VertexBufferReader to loop through the geometry in the
                buffer looking for the dbid.
                */

                var bounds = new THREE.Box3();
                // move this next one up into the calling method
                var bc = new BoundsCallback(bounds);

                var dbId2fragId = model.getData().fragments.dbId2fragId;

                for (var i=0; i<objectIds.length; i++) {
                    var fragIds = dbId2fragId[objectIds[i]];
                    // fragId is either a single vertex buffer or an array of vertex buffers
                    if (Array.isArray(fragIds)) {
                        for (var j=0; j<fragIds.length; j++) {
                            // go through each vertex buffer, looking for the object id
                            this.find2DBounds(fragIds[j], objectIds[i], bc);
                        }
                    } else if (typeof fragIds === 'number') {
                        // go through the specific vertex buffer, looking for the object id
                        this.find2DBounds(fragIds, objectIds[i], bc);
                    }
                }
                // should have some real box at this point; check
                if ( !bounds.empty()) {
                    //console.log("selected bounds are " + bounds.min.x +", "+ bounds.min.y + " to " + bounds.max.x +", "+ bounds.max.y);
                    this.api.navigation.fitBounds(immediate, bounds);
                    this.api.fireEvent( theEvent );
                    return;             
                }
            } else {
                // 3D content
                var propertyDB = model.getData().propertydb,
                    propertyDBFileExists = propertyDB && propertyDB.attrs.length > 0;

                if (propertyDBFileExists) {
                    model.getObjectTree(function(){
                        _fit();
                    });
                    return;
                }
            }
        }

        // If there was no selected set, see what the bounds are of the visible layers.
        // no bounds found, so for 2D instead look at visible layers
        var viewState = this.api.viewerState.getState();
        var object2D = viewState.objectSet[0];
        if (model.is2d() && !object2D.allLayers) {
            var bounds = new THREE.Box3();
            // move this next one up into the calling method
            var bc = new BoundsCallback(bounds);

            var frags = model.getData().fragments;
            // go through all fragments' geometry objects and see if any are on visible layers
            for (var i=0; i<frags.length; i++) {
                this.find2DLayerBounds(i, bc);
            }
        
            // should have some real box at this point; check
            if ( !bounds.empty()) {
                //console.log("layer bounds are " + bounds.min.x +", "+ bounds.min.y + " to " + bounds.max.x +", "+ bounds.max.y);
                this.api.navigation.fitBounds(immediate, bounds);
                this.api.fireEvent( theEvent );
                return;                 
            }
        }

        // Fallback, fit to the model bounds
        this.api.navigation.fitBounds(immediate, this.getFitBounds(true));
        this.api.fireEvent( theEvent );
    };

    /**
     * @private
     */
    this.find2DBounds = function(fragId, dbId, bc)
    {
        var mesh = this.getRenderProxy(this.model, fragId);

        var vbr = new avp.VertexBufferReader(mesh.geometry);
        vbr.enumGeomsForObject(dbId, bc);
    }

    /**
     * @private
     */
    this.find2DLayerBounds = function(fragId, bc)
    {
        var mesh = this.getRenderProxy(this.model, fragId);

        var vbr = new avp.VertexBufferReader(mesh.geometry);

        var visibleLayerIds = this.getVisibleLayerIds();
        vbr.enumGeomsForVisibleLayer(visibleLayerIds, bc);
    }

    /**
     * Helper class for fitToView() 
     * @private
     */
    function BoundsCallback(bounds) {
        this.bounds = bounds;
        // workspace, so we don't reallocate this each time
        this.point = new THREE.Vector4();
        this.point.z = 0.0;
        this.point.w = 1.0; // it's a point, not a vector
    }

    BoundsCallback.prototype.onTriangleVertex = function(cx, cy, vpId) {
        this.point.x = cx;
        this.point.y = cy;
        this.bounds.expandByPoint( this.point );
    };

    BoundsCallback.prototype.onLineSegment = function(x1, y1, x2, y2, vpId) {
        this.onTriangleVertex( x1, y1 );
        this.onTriangleVertex( x2, y2 );
    };

    BoundsCallback.prototype.onCircularArc = function(cx, cy, start, end, radius, vpId) {
        this.onEllipticalArc(cx, cy, start, end, radius, radius, 0.0, vpId);
    };

    BoundsCallback.prototype.onEllipticalArc = function(cx, cy, start, end, major, minor, tilt, vpId) {
        if ( tilt == 0.0 ) {
            // does start and end make a full ellipse?
            if ( (start <= 0) && (end >= 2.0 * Math.PI - 0.00001) ) {
                // full way around, simply treat it like a rectangle
                this.onTexQuad(cx, cy, 2*major, 2*minor, tilt, vpId);
            } else {
                // Not a full ellipse. We take the start and end points and also figure
                // out the four "compass rose" points that are between these two locations.
                // The start and end locations often exist as separate vertices so would
                // already be included, but for some line types they may not exist, so we
                // include them here.
                this.point.x = cx + Math.cos(start)*major;
                this.point.y = cy + Math.sin(start)*minor;
                this.bounds.expandByPoint( this.point );
                this.point.x = cx + Math.cos(end)*major;
                this.point.y = cy + Math.sin(end)*minor;
                this.bounds.expandByPoint( this.point );

                // now check each NESW compass point, i.e., middle of each edge
                if ( start > end ) {
                    // add right edge
                    this.point.x = cx + major;
                    this.point.y = cy ;
                    this.bounds.expandByPoint( this.point );
                    // make start < end for the rest of the tests
                    start -= 2.0 * Math.PI;
                }
                if ( start < 0.5 * Math.PI && end > 0.5 * Math.PI ) {
                    // add top edge
                    this.point.x = cx ;
                    this.point.y = cy + minor;
                    this.bounds.expandByPoint( this.point );
                }
                if ( start < Math.PI && end > Math.PI ) {
                    // add left edge
                    this.point.x = cx - major;
                    this.point.y = cy;
                    this.bounds.expandByPoint( this.point );
                }
                if ( start < 1.5 * Math.PI && end > 1.5 * Math.PI ) {
                    // add bottom edge
                    this.point.x = cx ;
                    this.point.y = cy - minor;
                    this.bounds.expandByPoint( this.point );
                }
            }
        } else {
            // Has a tilt.
            // From what we see, you should never reach here, as tilted ellipses are actually
            // always tessellated. So, we do a fallback: call the onTexQuad with the rotation.
            // This call will be a pretty good approximation, putting a rotated bounding box
            // around the whole ellipse. For more accuracy you would need to tessellate the
            // ellipse and get its points (especially if you don't have a full ellipse).
            this.onTexQuad(cx, cy, 2*major, 2*minor, tilt, vpId)

            // does start and end make a full ellipse?
            //if ( (start <= 0) && (end >= 2.0 * Math.PI - 0.00001) ) {
            //}
        }
    };

    // Currently this case does not actually come up, as textured quads, i.e., images, are
    // not something that can be selected, from what data I have tried. So I have not spent
    // any time on the rotated case.
    // TODO: this code is only partially tested: I had problems getting a selectable raster
    // object in a DWG convert to an F2D.
    BoundsCallback.prototype.onTexQuad = function(centerX, centerY, width, height, rotation, vpId) {
        var halfWidth = 0.5 * width;
        var halfHeight = 0.5 * width;
        if (rotation == 0.0) {
            this.onTriangleVertex( centerX - halfWidth, centerY - halfHeight );
            this.onTriangleVertex( centerX + halfWidth, centerY + halfHeight );
        } else {
            // A more complex rectangle, rotated. Take the four corners and rotate each
            // around the center.
            var rmtx = new THREE.Matrix4();  // Matrix3() does not have enough helper methods
            var mtx = new THREE.Matrix4();
            // Take a rectangle centered at the origin, rotate it, translate it to the final
            // position. Each corner is added to the bounds.
            rmtx.makeRotationZ(rotation);
            // put it into the final position:
            mtx.makeTranslation(centerX, centerY, 0.0);
            mtx.multiply(rmtx);

            for (var i = 0; i < 4; i++) {
                this.point.x = (((i%2)==1)?halfWidth:-halfWidth);
                this.point.y = ((i>=2)?halfHeight:-halfHeight);
                this.point.applyMatrix4(mtx);
                this.bounds.expandByPoint( this.point );
            }
        }
    };

    BoundsCallback.prototype.onOneTriangle = function(x1, y1, x2, y2, x3, y3, vpId) {
        this.onTriangleVertex( x1, y1 );
        this.onTriangleVertex( x2, y2 );
        this.onTriangleVertex( x3, y3 );
    };

}

Viewer3DImpl.prototype.constructor = Viewer3DImpl;

avp.Viewer3DImpl = Viewer3DImpl;

})();
;

(function() {

"use strict";

/**
 * The FileLoaderManager manages a set of file loaders available to the viewer.
 * Register, retrieve, and unregister your file loaders using the singleton theFileLoader.
 *
 * @constructor
 */
var FileLoaderManager = function () {
    var fileLoaders = {};

    /**
     * Registers a new file loader with the given id.
     *
     * @param {String} fileLoaderId - The string id of the file loader.
     * @param {String[]} fileExtensions - The array of supported file extensions. Ex: ['stl', 'obj']
     * @param {Function} fileLoaderClass - The file loader constructor.
     * @returns {Boolean} - True if the file loader was successfully registered.
     */
    function registerFileLoader(fileLoaderId, fileExtensions, fileLoaderClass) {
        if (!fileLoaders[fileLoaderId]) {
            fileLoaders[fileLoaderId] = {
                loader: fileLoaderClass,
                extensions: fileExtensions
            };
            return true;
        }
        return false;
    }

    /**
     * Returns the file loader for a given ID.
     *
     * @param {String} fileLoaderId - The string id of the file loader.
     * @returns {Function?} - The file loader constructor if one was registered; null otherwise.
     */
    function getFileLoader(fileLoaderId) {
        if (fileLoaders[fileLoaderId]) {
            return fileLoaders[fileLoaderId].loader;
        }
        return null;
    }

    /**
     * Unregisters an existing file loader with the given id.
     *
     * @param {String} fileLoaderId - The string id of the file loader.
     * @returns {Boolean} - True if the file loader was successfully unregistered.
     */
    function unregisterFileLoader(fileLoaderId) {
        if (fileLoaders[fileLoaderId]) {
            delete fileLoaders[fileLoaderId];
            return true;
        }
        return false;
    }

    /**
     * Returns a file loader that supports the given extension.
     *
     * @param {String} fileExtension - The file extension.
     *
     * @returns {Function?} - The file loader constructor if one is found; null otherwise.
     */
    function getFileLoaderForExtension(fileExtension) {
        fileExtension = fileExtension ? fileExtension.toLowerCase() : "";
        for (var fileLoaderId in fileLoaders) {
            var fileLoader = fileLoaders[fileLoaderId];
            if (fileLoader) {
                for (var i = 0; i < fileLoader.extensions.length; i++) {
                    if (fileLoader.extensions[i].toLowerCase() === fileExtension) {
                        return fileLoader.loader;
                    }
                }
            }
        }

        return null;
    }

    return {
        registerFileLoader: registerFileLoader,
        getFileLoader: getFileLoader,
        getFileLoaderForExtension: getFileLoaderForExtension,
        unregisterFileLoader: unregisterFileLoader
    };
};

var av = Autodesk.Viewing;
av.FileLoaderManager = new FileLoaderManager();

})();;

(function() {

var lmv = Autodesk.LMVTK;
var av = Autodesk.Viewing,
    avp = av.Private;

// Fall back to console logging in workers
avp.logger = avp.logger || console;

avp.workerMain = function(loadContext) {

    if(!loadContext.hasOwnProperty('operation')) {
        return;
    }

    //Initialize the path that contains the requested
    //file. It's the root for other relative paths referenced
    //by the base file.
    loadContext.basePath = "";
    if (loadContext.url) {
        var lastSlash = loadContext.url.lastIndexOf("/");
        if (lastSlash != -1)
            loadContext.basePath = loadContext.url.substr(0, lastSlash+1);
    }

    // Create the default failure callback.
    //
    loadContext.raiseError = function() {
        loadContext.worker.raiseError.apply(loadContext.worker, arguments);
    };
    loadContext.onFailureCallback = avp.ViewingService.defaultFailureCallback.bind(loadContext);

    var op = loadContext.operation;
    switch (op) {

        case "LOAD_GEOMETRY":       lmv.doGeomLoad(loadContext);          break;
        case "LOAD_SVF":            lmv.doLoadSvf(loadContext);           break;
        case "LOAD_SVF_CONTD":      lmv.doLoadSvfContinued(loadContext);  break;
        case "GET_PROPERTIES":      lmv.doPropertyGet(loadContext);       break;
        case "SEARCH_PROPERTIES":   lmv.doPropertySearch(loadContext);    break;
        case "BUILD_EXTERNAL_ID_MAPPING": lmv.doBuildExternalIdMapping(loadContext); break;
        case "GET_OBJECT_TREE":     lmv.doObjectTreeParse(loadContext);   break;
        case "PARSE_F2D":           lmv.doParseF2D(loadContext);          break;
        case "PARSE_F2D_FRAME":     lmv.doParseF2DFrame(loadContext);     break;
        case "STREAM_F2D":          lmv.doStreamF2D(loadContext);         break;
        case "DECOMPRESS_DELTA":    lmv.doDecompressDelta(loadContext);   break; //FUSION_SPECIFIC
        case "POPULATE_CACHE":      lmv.doPopulateCache(loadContext);     break;
        case "DECODE_ENVMAP":       lmv.doDecodeEnvmap(loadContext);      break;
    }

}


})();
;

var lmv = Autodesk.LMVTK;
var av = Autodesk.Viewing,
    avp = av.Private;

function MainWorker() {

	var self = this;

	var listeners = this.listeners = [];

	this.addEventListener = function(eventType, callback) {
		if (eventType !== "message")
			console.error("Expected 'message' event type for worker thread.");
		listeners.push(callback);
	};

	this.addEventListenerWithIntercept = function(callback) {
		listeners.push(callback);
	};

	this.clearAllEventListenerWithIntercept = function() {
		listeners = [];
	};

	this.terminate = function() {
		listeners = [];
	};

	this.postMessage = function(data) {
		//make result compatible with web worker message event
		var e = { data: data };

		for (var i=0; i<listeners.length; i++)
			listeners[i](e);
	};

	//Web worker dispatcher function -- received a message
	//from the main thread and calls the appropriate handler
	this.doOperation = function(e) {

		var loadContext = e;
		loadContext.worker = this;

		avp.workerMain(loadContext);

	};

	this.raiseError = function(code, msg, args) {
		self.postMessage({ "error": { "code": code, "msg": msg, "args": args }});
	};

	// Shared by all workers to output debug message on console of main thread.
	this.debug = function(msg) {
		self.postMessage({debug : 1, message : msg});
	};
}

avp.createWorker = function() {
	return new MainWorker();
};

avp.createWorkerWithIntercept = function() {
	return avp.createWorker();
};

avp.initWorkerScript = function(successCB, errorCB) {
	if (successCB)
		successCB();
};
;


(function(){

"use strict";

var av = Autodesk.Viewing,
    avp = av.Private;

var NUM_WORKER_THREADS = av.isNodeJS ? 10 : (av.isMobileDevice() ? 2 : 6);
var WORKER_LOAD_GEOMETRY = "LOAD_GEOMETRY";
var WORKER_LOAD_SVF = "LOAD_SVF";
var WORKER_LOAD_SVF_CONTD = "LOAD_SVF_CONTD";


// Paging proxy object to manage on demand loading and paging logic, 
// that is specific to the model loaded by svf loader.
var SvfPagingProxy = function(options) {

    var _extendObject = function(target, source) {
        for (var prop in source) {
            if (source.hasOwnProperty(prop)) {
                target[prop] = source[prop];
            }
        }
    };

    // Options of control memory management.
    this.options = {
 
        pageOutPercentage: avp.PAGEOUT_PERCENTAGE,
        maxQueuedGeomPFForLoading: WGS.MAX_QUEUED_GEOM_PF_FOR_LOADING,
        pixelCullingEnable: WGS.pixelCullingEnable,
        pixelCullingThreshold: WGS.PIXEL_CULLING_THRESHOLD,
        onDemandLoading: avp.onDemandLoading,
        pageOutGeometryEnabled: avp.pageOutGeometryEnabled,

        minPackFiles: WGS.MIN_PACK_FILES,
        maxPackFiles: WGS.MAX_PACK_FILES,

        // This one just for testing.
        forceOnDemandLoading: WGS.forceOnDemandLoading
    };
    _extendObject(this.options, options);

    // If reach limit, then stop loading any further pack files.
    this.reachLimit    = false;
    // the geom ids map, is a dictionary that key is the geometry id,
    // and value is an index to an array that record the traversed count
    // for that geometry.
    // ??? The reason that doesn't use the object to record the count but
    // ??? use the indirect arry is due to PERFORMANCE. 
    // ??? Because, if the JS object properties' value are changed frequently,
    // ??? the performance will hurt a whole lot.
    this.geomidsmap    = {};
    this.geomTravCount = [];

    // Variables for recording loaded or loading or queued pack files.
    this.loadedPacks = {};
    this.loadedPackslength = 0;
    this.loadingPacks = [];
    this.queuedPacks = [];

    // read from options, and passed by the loader.
    this.totalPackFiles = this.options.totalPackFiles;
    this.loadPackFileImpl = this.options.loadPackFileImpl;
    this.cancelLoadPackImpl = this.options.cancelLoadPackImpl;

    var _resumeNextFrame = false;


    // Return true of false, whether on demand loading enabled.
    // This mainly controls how the geometries referenced by the fagments
    // are going to load. 
    //
    // If false, then geometry pack files will load in sequence all at once.
    // if true, then only those geometry pack files that are request to render,
    //          can they start to load *on demand*
    this.onDemandLoadingEnabled = function() {
        // On demand loading will be controlled by two factors.
        // 1. A global switch that enable/disable this behavior.
        // 2. The fragment counts that only large number of fragments allow to on demand loading
        //     so that can control memory consumption.

        if (this.options.onDemandLoading && this.loadPackFileImpl) {
            if (this.options.forceOnDemandLoading) {
                return true;
            }

            return this.totalPackFiles > this.options.maxPackFiles;
        }

        return false;
    };

    this.pageOutGeometryEnabled = function() {
        return this.options.pageOutGeometryEnabled && this.onDemandLoadingEnabled();
    };

    this.pixelCullingEnable = function() {
        return this.options.pixelCullingEnable;
    };

    this.pixelCullingThreshold = function() {
        return this.options.pixelCullingThreshold;
    }

    this.loadPackFile = function(packId) {
        // If on demand loading is disabled, disallow load pack file arbitrarily.
        if (!this.onDemandLoadingEnabled() || this.reachLimit) {
          return false;
        }
        
        this.loadPackFileImpl(packId);

        return true;
    };

    this.unloadPackFile = function(packId, geomsList) {
        // If on demand loading is disabled, can't unload on runtime.
        if (!this.onDemandLoadingEnabled()) {
          return false;
        }
        
        if (!this.loadedPacks[packId] || !geomsList) {
            return false;
        }
        
        var idx = -1;
        // Remove all geometries comming from this pack file
        geomsList.geoms.forEach(function(geom) {
            if (geom && geom.packId == packId) {
                geomsList.removeGeometry(geom.svfid);
            }
        });
        
        // Then, remove the record and decrease the count.
        delete this.loadedPacks[packId];
        this.loadedPackslength--;
        
        return true;
        
    };

    this.onPackFileLoaded = function(data) {
        if (!data) {
            return;
        }
        
        // Record the pack file loaded.
        var packId = data.packId;
        if (!this.loadedPacks[packId]) {
            var count = data.meshes.length;
            
            this.loadedPacks[packId] = {
                count: count,
                travsed: 0,
                culled: 0
            };
            
            this.loadedPackslength++;
        }
        
        var id = this.loadingPacks.indexOf(packId);
        if (id != -1) {
            this.loadingPacks.splice(id, 1);
        }
        
        if (this.loadedPackslength > this.options.maxPackFiles) {
            avp.logger.warn("More pack files being loaded than the max count: " + this.loadedPackslength);
        }
    };

    this.onPackFileLoading = function(packId) {
        this.loadingPacks.push(packId);
    };

    this.onProcessReceivedMesh = function(geometry, numInstances) {

        var geomId = geometry.svfid;
        if (this.onDemandLoadingEnabled() && numInstances > 1 &&
            this.geomidsmap[geomId] == null) {
            this.geomidsmap[geomId] = this.geomTravCount.length;
            this.geomTravCount.push(0);
        }
    };

    this.loadedPackFileCount = function() {
        return this.loadedPackslength;
    };

    this.preparedPackFilesCount = function() {
        return this.queuedPacks.length + this.loadingPacks.length + this.loadedPackFileCount();
    };

    this.reset = function() {

        // Reset the record of geometry travsed or culled count.
        var loadedPacks = this.loadedPacks;
        for (var p in loadedPacks) {
            loadedPacks[p].travsed = 0;
            loadedPacks[p].culled = 0;
        }
        
        if (this.cancelLoadPackImpl && 
            this.loadingPacks.length > 0 && 
            this.loadedPackslength >= this.options.maxPackFiles) {
                
            // Cancel any on going geometry loading, as it is probably no longer
            // immediately used by the following rendering as scene or camera 
            // changed.
            this.cancelLoadPackImpl();
        }
        
        this.loadingPacks.length = 0;
        this.queuedPacks.length = 0;
    };

    this.geomPacksMissingLastFrame = function() {
        return this.queuedPacks;
    }

    this.addGeomPackMissingLastFrame = function(packId) {

        if (this.pageOutGeometryEnabled()) {
            // Not too many loaded + loading + queued.
            if (this.preparedPackFilesCount() >= this.options.maxPackFiles) {
                this.reachLimit = true;
                return false;
            }
            
            // Not too many queued.
            if (this.queuedPacks.length >= this.options.maxQueuedGeomPFForLoading) {
                return false;
            }
        }

        // Otherwise, schedule a futher loading
        if(this.queuedPacks.indexOf(packId) == -1) {
            this.queuedPacks.push(packId);
        }
        
        return true;
    };

    this.needResumeNextFrame = function() {
        return _resumeNextFrame;
    }

    this.pageOut = function(iterationDone, forcePageOut, geomList) {

        _resumeNextFrame = false;
        var pageStatus = WGS.PAGEOUT_SUCCESS;

        // Only try to page out at the end of iteration of scene travseral,
        // which is to guarantee the geometries loaded from pack files get 
        // all used (either traversed or culled.)
        if (!iterationDone) {
            return pageStatus;
        }

        // This page out will page geometries on a pack file basis
        var count = this.loadedPackFileCount();
        if (count && (this.reachLimit || count > this.options.maxPackFiles)) {

            var loadedPacks = this.loadedPacks;
            var loadedPackIds = Object.keys(loadedPacks);
            
            loadedPackIds.sort(function(a, b) {
                var wa = loadedPacks[a].culled * 0.7 + loadedPacks[a].travsed * 0.3;
                var wb = loadedPacks[b].culled * 0.7 + loadedPacks[b].travsed * 0.3;
                return wa < wb;
            })
            
            var maxp = this.options.maxPackFiles;
            var count = Math.ceil(this.options.pageOutPercentage * maxp);

            // Then, unload pack files 
            var num = 0;
            loadedPackIds.every(function(id) {
                var v = loadedPacks[id].culled + loadedPacks[id].travsed;
                if (v > 0) {
                    this.unloadPackFile(id, geomList);
                    num++;
                }
                
                return num < count;
            }.bind(this));
            
            if (forcePageOut && num == 0) {
                this.unloadPackFile(loadedPackIds[0], geomList);
                num++;
                avp.logger.log("A force page out occur.");
            }

            if (num == 0) {
                pageStatus = WGS.PAGEOUT_FAIL;
                this.reachLimit = true;
            }
            else {
                this.reachLimit = false;
                _resumeNextFrame = true;
            }

            avp.logger.log("[On Demand Loading] Unload pack files count: " + num);
            if (window && window.gc) {
                window.gc();
            }
            
            return pageStatus;
        }

        // resume on missing geom for next frame.
        _resumeNextFrame = _resumeNextFrame || this.queuedPacks.length > 0;

        return pageStatus;
    };

    this.onGeomTraversed = function(geometry) {
        var packId = geometry.packId;
        var geomId = geometry.svfid;

        // Only record it for paging if the pack file is allowed to be paged out.
        if (packId >= this.options.minPackFiles) {
            var geomTraversed = true;
            
            var mapIdx = this.geomidsmap[geomId];
            if (mapIdx != null) {
                // increase counter of traversed geometry instances
                this.geomTravCount[mapIdx]++;

                geomTraversed = geometry.instanceCount == this.geomTravCount[mapIdx];
            }

            if (geomTraversed) {
                this.loadedPacks[packId].travsed++;
            }
        }

    };

    this.onGeomCulled = function(geometry) {
        if (!geometry) {
            return;
        }

        var packId = geometry.packId;
        var geomId = geometry.svfid;

        // Only record it for paging if the pack file is allowed to be paged out.
        if (packId >= this.options.minPackFiles) {
            var mapIdx = this.geomidsmap[geomId];

            if (mapIdx != null) {
                // ??? multiple geometry instance, may have some traversed
                // ??? and some culled. The culled one is also marked as traversed count,
                // ??? so this geometry may be counted as either culled or traversed,
                // ??? that is ok so far.
                this.geomTravCount[mapIdx]++;

                if (geometry.instanceCount == this.geomTravCount[mapIdx]) {
                    this.loadedPacks[packId].culled++;
                }
            }
            else {
                this.loadedPacks[packId].culled++;

            }
        }
        
    };
};



/** @constructor */
var SvfLoader = function (parent) {
    this.viewer3DImpl = parent;
    this.next_pack = 0;
    this.loading = false;
    this.loadedPacksCount = 0;
    this.loadedPacks = [];
    this.tmpMatrix = new THREE.Matrix4();
    this.tmpBox = new THREE.Box3();

    this.logger = avp.logger;
    this.loadTime = 0;
    this.domainParam = (av.getUseCredentials() && !av.isNodeJS) ? ("domain=" + encodeURIComponent(window.location.origin)) : "";

};

SvfLoader.prototype.dtor = function () {
    // Cancel all potential process on loading a file.

    // 1. init worker script can be cancelled. 
    // 
    if (this.initWorkerScriptToken) {
        this.initWorkerScriptToken.cancel();
        this.initWorkerScriptToken = null;
        avp.logger.debug("SVF loader dtor: on init worker script.");
    }

    // 2. load model root (aka. svf) can be cancelled. 
    //
    if (this.svfWorker) {
        this.svfWorker.clearAllEventListenerWithIntercept();
        this.svfWorker.terminate();
        this.svfWorker = null;
        avp.logger.debug("SVF loader dtor: on svf worker.");
    }

    // 3. load geometry pack files can be cancelled.
    // 
    if (this.pack_workers) {
        for (var i=0; i<this.pack_workers.length; i++) {
            this.pack_workers[i].clearAllEventListenerWithIntercept();
            this.pack_workers[i].terminate();
        }
        this.pack_workers = null;
        avp.logger.debug("SVF loader dtor: on geom worker.");
    }

    // 4. load property can be cancelled.
    // 
    if (this.svf && this.svf.propWorker) {
        this.svf.propWorker.dtor();
        this.svf.propWorker = null;
    }

    // and clear metadata.
    this.viewer3DImpl = null;
    this.logger = null;
    this.domainParam = null;
    this.tmpMatrix = null;
    this.tmpBox = null;

    this.next_pack = 0;
    this.loading = false;
    this.loadedPacksCount = 0;
    this.loadedPacks = [];
    this.loadTime = 0;
    this.pagingProxy = null;
};

SvfLoader.prototype.isValid = function() {
    return this.viewer3DImpl != null;
}

//Maps a relative resource path (like a pack file or texture)
//to an absolute URL (possibly signed).
avp.pathToURL = function(path) {

    if (path.indexOf("://") !== -1 ||
        path.indexOf("urn:") === 0) {
        return path;
    }

    if (typeof window === "undefined")
        return path;

    var rootRelPath = window.location.pathname;
    //chop off the index.html part
    var lastSlash = rootRelPath.lastIndexOf("/");
    rootRelPath = rootRelPath.substr(0, lastSlash+1);
    var absPath = window.location.protocol + "//" + window.location.host + rootRelPath + path;
    return absPath;
};

function _addLoadingFile(viewerImpl, svfLoader) {
    if (!viewerImpl.loaders) {
        viewerImpl.loaders = [];
    }
    viewerImpl.loaders.push(svfLoader);
};

function _removeLoadingFile(viewerImpl, svfLoader) {
    if (viewerImpl.loaders) {
        var idx = viewerImpl.loaders.indexOf(svfLoader);
        if (idx >= 0) {
            viewerImpl.loaders.splice(idx, 1);
        }
    }
};

SvfLoader.prototype.loadFile = function(path, options, onSuccess, onError, onWorkerStart) {
    if (!this.viewer3DImpl) {
        avp.logger.log("SVF loader was already destructed. So no longer usable.");
        return false;
    }

    if (this.loading) {
        avp.logger.log("Loading of SVF already in progress. Ignoring new request.");
        return false;
    }

    // Mark it as loading now.
    this.loading = true;
    _addLoadingFile(this.viewer3DImpl, this);

    var index = path.indexOf('urn:');
    if (index != -1) {
        // Extract urn:adsk.viewing:foo.bar.whateverjunks out of the path URL and bind it to logger.
        // From now on, we can send logs to viewing service, and logs are grouped by urn to make Splunk work.
        path = decodeURIComponent(path);
        var urn = path.substr(index, path.substr(index).indexOf('/'));
        avp.logger.log("Extracted URN: " + urn);

        // Extract urn(just base64 code)
        var _index = urn.lastIndexOf(':');
        this.svfUrn = urn.substr(_index + 1);
    } else {
        this.svfUrn = path;
    }

    this.sharedDbPath = options.sharedPropertyDbPath;

    this.currentLoadPath = path;
    var lastSlash = this.currentLoadPath.lastIndexOf("/");
    if (lastSlash != -1)
        this.basePath = this.currentLoadPath.substr(0, lastSlash+1);

    this.acmSessionId = options.acmSessionId;

    this.queryParam = this.domainParam;
    if (this.acmSessionId) {
        if (this.queryParam)
            this.queryParam += "&";
        this.queryParam += "acmsession=" + this.acmSessionId;
    }

    this.options = options;
    var scope = this;

    this.initWorkerScriptToken = avp.initWorkerScript(function() {
        scope.loadSvfCB(path, options, onSuccess, onError, onWorkerStart);
    });

    return true;
};


/**
 * Define this to manipulate the manifest before it is used.
 * Must be either undefined or a function that takes exactly one argument, the manifest.
 *
 * I.e.: Autodesk.Viewing.Private.SvfLoader.prototype.interceptManifest = function(manifest) { <your code> };
 *
 */
SvfLoader.prototype.interceptManifest = undefined;

SvfLoader.prototype.loadSvfCB = function(path, options, onSuccess, onError, onWorkerStart) {
    this.t0 = new Date().getTime();
    this.firstPixelTimestamp = null;
    this.failedToLoadSomeGeometryPacks = null;
    var first = true;

    var scope = this;
    var msg = {
        url: avp.pathToURL(path),
        basePath: this.currentLoadPath,
        objectIds : options.ids,
        globalOffset : options.globalOffset,
        placementTransform : options.placementTransform,
        applyRefPoint: options.applyRefPoint,
        queryParams : this.queryParam,
        bvhOptions : options.bvhOptions || {isWeakDevice : av.isMobileDevice()},
        applyScaling: options.applyScaling,
        loadInstanceTree: options.loadInstanceTree
    };

    if (avp.memoryOptimizedSvfLoading) {
      msg.perfOpt = {
        memoryOptimizedSvfLoading: avp.memoryOptimizedSvfLoading,
        forceMemoryOptimizedMode: avp.forceMemoryOptimizedModeOnSvfLoading
      }
    }

    // When using consolidation, a too fine-grained bvh would eliminate the performance gain.
    // To avoid that, we use larger default settings when activating consolidation.
    //
    // Doing this for consolidation only is done to minimize the scope of potential side effects whenever consolidation is not used.
    // It might generally be useful to increase these values, but this requires more investigation of potential performance impact first.
    if (options.useConsolidation && !options.bvhOptions) {
        msg.bvhOptions["frags_per_leaf_node"] = 256;
        msg.bvhOptions["max_polys_per_node"]  = 50000;
    }

    var w = this.svfWorker = avp.createWorkerWithIntercept();

    var onSVFLoad = function (ew) {
        var cleaner = function() {
            w.clearAllEventListenerWithIntercept();
            w.terminate();
            scope.svfWorker = null;
            w = null;
        };

        if (first && onWorkerStart) {
            first = false;
            onWorkerStart();
        }

        if (ew.data && ew.data.manifest) {

            scope.interceptManifest(ew.data.manifest);
            msg.operation = WORKER_LOAD_SVF_CONTD;
            msg.manifest = ew.data.manifest;
            w.doOperation(msg);
        } else if (ew.data && ew.data.svf) {
            //Decompression is done.
            var svf = scope.svf = ew.data.svf;

            if (scope.failedToLoadSomeGeometryPacks) {
                // Report a warning. It is not a fatal error.
                if (onError)
                    onError( scope.failedToLoadSomeGeometryPacks.code, scope.failedToLoadSomeGeometryPacks.msg);
                scope.failedToLoadSomeGeometryPacks = null;
            }

            scope.onModelRootLoadDone(svf);

            if (onSuccess)
                onSuccess(scope.model);

            scope.viewer3DImpl.api.fireEvent({type:av.MODEL_ROOT_LOADED_EVENT, svf:svf, model:scope.model});

            scope.svf.loadDone = false;

            var isGltf = false;
            if (scope.svf.metadata && scope.svf.metadata.gltf) {
                isGltf = true;
            }

            if (!isGltf) {
                var numGeomPacks = svf.geompacks.length;

                if (numGeomPacks == 0) {
                    scope.onGeomLoadDone();
                }
                else {
                    
                    if (scope.model.getFragmentList().onDemandLoadingEnabled()) {
                        // On demand loading is enabled, then
                        // Defer to launch jobs for loading some geometry packs,
                        // until the viewer really need them.
                        avp.logger.debug("[On Demand Loading]: Enabled.");
                        scope.loadedPacksCount = 0;
                    }
                    else {
                        // On demand loading is disabled, then
                        // Require loading immediately
                        if (numGeomPacks) {
                            var count = Math.min(numGeomPacks, NUM_WORKER_THREADS);
                            for (var i=0; i<count; i++) {
                                var pf = svf.geompacks[scope.next_pack++];
                                pf.loading = true;
                                if (av.isNodeJS) {
                                    scope.loadGeometryPack(pf.id, pf.uri);
                                } else {
                                    (function(pf) {
                                        setTimeout(function() {scope.loadGeometryPack(pf.id, pf.uri);}, i * 200);
                                    })(pf);
                                }
                            }
                        }
                    }
                }
            }

            if (ew.data.progress == 1) {
                scope.loading = false;
                cleaner();
            }

            if (!svf.fragments.polygonCounts)
                svf.fragments.polygonCounts = new Int32Array(svf.fragments.length);
            else {
            }

            // Set bvh to svf, if it is posted with svf together.
            if (ew.data.bvh) {
                scope.svf.bvh = ew.data.bvh;
                scope.model.setBVH(new avp.NodeArray(scope.svf.bvh.nodes, scope.svf.bvh.useLeanNodes), scope.svf.bvh.primitives, scope.options.bvhOptions);
                scope.viewer3DImpl.invalidate(false, true);
            }

        } else if (ew.data && ew.data.bvh) {
            //Spatial index was done by the worker:
            if (!scope.svf.bvh) {
                scope.svf.bvh = ew.data.bvh;
                scope.model.setBVH(new avp.NodeArray(scope.svf.bvh.nodes, scope.svf.bvh.useLeanNodes), scope.svf.bvh.primitives, scope.options.bvhOptions);
                scope.viewer3DImpl.invalidate(false, true);
            }
            scope.loading = false;
            cleaner();
        } else if (ew.data && ew.data.mesh) {
            //GLTF loader sends meshes from the main loader thread
            scope.processReceivedMesh(ew.data);

            if (ew.data.progress === 1) {
                scope.onGeomLoadDone();
                scope.loading = false;
                cleaner();
            }
        } else if (ew.data && ew.data.progress) {
            if (ew.data.progress == 1) {
                scope.loading = false;
                cleaner();
            }
        } else if (ew.data && ew.data.error) {
            scope.loading = false;
            cleaner();
            if (onError)
                onError(ew.data.error.code, ew.data.error.msg, ew.data.error.args.httpStatus, ew.data.error.args.httpStatusText);
        } else if (ew.data && ew.data.debug) {
            avp.logger.debug(ew.data.message);
        } else {
            avp.logger.error("SVF download failed.");
            //Download failed.
            scope.loading = false;
            cleaner();
        }
    };

    w.addEventListenerWithIntercept(onSVFLoad);

    msg.operation = WORKER_LOAD_SVF;
    msg.interceptManifest = !!this.interceptManifest;
    w.doOperation(avp.initLoadContext(msg));

    return true;
};

SvfLoader.prototype.cancelGeometryPackLoading = function() {
    
    // Cancel any ongoing geometry pack file loading.
    if (!this.pack_workers || !this.isValid()) {
        return;
    }
    
    for (var i=0; i<this.pack_workers.length; i++) {
        if (this.svf) {
            this.svf.geompacks[this.pack_workers[i].packId].loading = false;
        }
        this.pack_workers[i].queued = 0;
        this.pack_workers[i].clearAllEventListenerWithIntercept();
        this.pack_workers[i].terminate();
    }
    
    this.pack_workers = null;
};

SvfLoader.prototype.loadGeometryPackOnDemand = function (packId) {

    // If loader is already destructed, do nothing.
    if(!this.svf || !this.isValid()) {
        return;
    }

    // Do nothing if the geometry pack file is already in loading.
    var pf = this.svf.geompacks[packId];
    if (pf.loading) {
        return ;
    }

    // Record the time on first on demand geometry pack file loading request
    if (!this.t0) {
        this.t0 = new Date().getTime();
    }

    var pp = this.pagingProxy;
    var i;
    var scope = this;

    var onMeshLoad = function (ew) {
        if (ew.data && ew.data.meshes) {
            
            pp.onPackFileLoaded(ew.data);
            
            var meshes = ew.data.meshes;

            var mdata = {
                packId: ew.data.packId,
                meshIndex: 0,
                mesh:null
            };

            for (var i=0; i<meshes.length; i++) {
                var mesh = meshes[i];

                if (!mesh)
                    continue;

                mdata.meshIndex = i;
                mdata.mesh = mesh;

                scope.processReceivedMesh(mdata);
            }

            if (ew.data.progress >= 1.0) {
                scope.pack_workers[ew.data.workerId].queued -= 1;
                scope.svf.geompacks[ew.data.packId].loading = false;

                // Are all workers done?
                var isdone = true;
                for (var j = 0; j < scope.pack_workers.length; j++) {
                    if (scope.pack_workers[j].queued != 0) {
                        isdone = false;
                        break;
                    }
                }

                if (scope.loadedPacks.indexOf(ew.data.packId) == -1) {
                    // Recored which pack has been loaded.
                    scope.loadedPacks.push(ew.data.packId);
                }

                if (isdone && scope.model.geomPacksMissingLastFrame().length == 0) {
                    scope.onDemandGeomLoadDone();
                }
                else {
                    scope.viewer3DImpl.invalidate(false, true);
                }
            }
        } else if (ew.data && ew.data.progress) {
            scope.pack_workers[ew.data.workerId].queued -= 1;
            scope.loadedPacksCount++;

            // This load is done, then can start next one.
            var pf = null, packId;
            var missingPacks = scope.model.geomPacksMissingLastFrame();
            for(i = 0; i < missingPacks.length; ++i) {
                packId = missingPacks[i];
                pf = scope.svf.geompacks[packId];
                if(!pf.loading) {
                    break;
                }
            }

            // Find one that hasn't been loaded.
            if (pf && !pf.loading) {
                missingPacks.splice(i, 1);
                scope.loadGeometryPackOnDemand(packId);
            }

            scope.viewer3DImpl.signalProgress(100 * scope.loadedPacks.length / scope.svf.geompacks.length);

        } else if (ew.data && ew.data.debug) {
            avp.logger.debug(ew.data.message);
        } else if (ew.data && ew.data.error) {
            scope.failedToLoadSomeGeometryPacks = {code:ew.data.error.code, msg:ew.data.error.msg};
        } else {
            //Download failed.
            scope.pack_workers[ew.data.workerId].queued -= 2;
            scope.svf.geompacks[ew.data.packId].loading = false;
        }
    };

    // Initialize pack workers if it is not ready yet.
    if (!this.pack_workers) {
        this.pack_workers = [];

        var numWorkers = pp.options.maxPackFiles < NUM_WORKER_THREADS ? pp.options.maxPackFiles : NUM_WORKER_THREADS;

        for (i = 0; i < numWorkers; i++) {
            var wr = avp.createWorkerWithIntercept();
            wr.addEventListenerWithIntercept(onMeshLoad);

            wr.queued = 0;
            this.pack_workers.push(wr);
        }
    }

    //Find the least busy worker
    var which = 0;
    var queued = this.pack_workers[0].queued;
    for (i = 1; i < this.pack_workers.length; i++) {
        if (this.pack_workers[i].queued < queued) {
            which = i;
            queued = this.pack_workers[i].queued;
        }
    }

    // If worker is busy queue this reqest for next try.
    if (queued > 1 || pp.preparedPackFilesCount() >= pp.options.maxPackFiles) {
        
        // All workers are busy, then queue it for next try.
        if (!this.model.addGeomPackMissingLastFrame(packId)) {
            // If failed to add, it means that it is too many queued.
            // then restart render.
            this.viewer3DImpl.invalidate(false, true);
            //avp.logger.debug("[On Demand Loading] Re-render on too many geom pack file requests.");
        }

        return;
    }

    var w, workerId;
    var path = pf.uri;
    w = this.pack_workers[which];
    w.queued += 2;
    w.packId = packId;
    workerId = which;

    pp.onPackFileLoading(packId);
    
    pf.loading = true;
    scope.svf.partPacksLoadDone = false; // Still loading geometry pack files.

    avp.logger.debug("[On Demand Loading] Loading Geometry Pack file: " + packId);

    //Pass unzip job to the worker
    var reqPath = avp.pathToURL(this.svf.basePath + path);
    var xfer = { "operation":WORKER_LOAD_GEOMETRY,
                 "url": reqPath,
                 "packId": parseInt(packId), /* mesh IDs treat the pack file id as integer to save on storage in the per-fragment arrays */
                 "workerId": workerId,
                 "packNormals": this.options.packNormals,
                 "skipAssetCallback": true,
                 "queryParams" : this.queryParam };

    w.doOperation(avp.initLoadContext(xfer)); // Send data to our worker.
};


SvfLoader.prototype.loadGeometryPack = function (packId, path) {
    var w;
    var workerId;
    var i, j;
    var scope = this;
    
    // If loader is already destructed, do nothing.
    if(!this.svf || !this.isValid()) {
        return;
    }

    var onMeshLoad = function (ew) {
        if (ew.data && ew.data.meshes) {

            var meshes = ew.data.meshes;

            var mdata = {
                packId: ew.data.packId,
                meshIndex: 0,
                mesh:null
            };

            for (var i=0; i<meshes.length; i++) {
                var mesh = meshes[i];

                if (!mesh)
                    continue;

                mdata.meshIndex = i;
                mdata.mesh = mesh;

                scope.processReceivedMesh(mdata);
            }

            //Is the worker done loading the geom pack?
            if (ew.data.progress >= 1.0) {
                scope.pack_workers[ew.data.workerId].queued -= 1;

                scope.loadedPacksCount++;
                scope.viewer3DImpl.signalProgress(100 * scope.loadedPacksCount / scope.svf.geompacks.length);

                //Are all workers done?
                var isdone = true;
                for (j = 0; j < scope.pack_workers.length; j++) {
                    if (scope.pack_workers[j].queued != 0) {
                        isdone = false;
                        break;
                    }
                }

                if (isdone) {
                    for (j = 0; j < scope.pack_workers.length; j++) {
                        scope.pack_workers[j].clearAllEventListenerWithIntercept();
                        scope.pack_workers[j].terminate();
                    }
                    scope.pack_workers = null;
                }

                if (scope.svf.fragments.numLoaded == scope.svf.fragments.length) { //all workers are done?
                    scope.onGeomLoadDone();
                }
            }
        } else if (ew.data && ew.data.progress) {
            //download is done, queue the next download
            scope.pack_workers[ew.data.workerId].queued -= 1;

            if (scope.next_pack < scope.svf.geompacks.length) {

                var pf = null;
                var missingPacks = scope.model.geomPacksMissingLastFrame();
                for(i = 0; i < missingPacks.length; ++i) {
                    pf = scope.svf.geompacks[missingPacks[i]];
                    if(pf && !pf.loading) {
                        break;
                    }
                }

                if(!pf || pf.loading) {
                    while(scope.next_pack < scope.svf.geompacks.length) {
                        pf = scope.svf.geompacks[scope.next_pack++];
                        if(!pf.loading) {
                            break;
                        }
                    }
                }

                if(pf && !pf.loading) {
                    pf.loading = true;
                    scope.loadGeometryPack(pf.id, pf.uri);
                }
                else {
                    scope.viewer3DImpl.modelQueue().enforceBvh = false;
                    scope.svf.fragments.packIds = null; // not needed anymore
                }
            }
        } else if (ew.data && ew.data.debug) {
            avp.logger.debug(ew.data.message);
        } else if (ew.data && ew.data.error) {
            scope.failedToLoadSomeGeometryPacks = {code:ew.data.error.code, msg:ew.data.error.msg};
        } else {
            //Download failed.
            scope.pack_workers[ew.data.workerId].queued -= 2;
        }
    };

    var pw = this.pack_workers;
    if (!pw) {
        pw = this.pack_workers = [];
    }

    //If all workers are busy and we are allowed to create more, then create a new one
    if (pw.length < NUM_WORKER_THREADS) {
        var allBusy = true;
        for (var i=0; i<pw.length; i++) {
            if (pw.queued === 0) {
                allBusy = false;
                break;
            }
        }

        if (allBusy) {
            var wr = avp.createWorkerWithIntercept();
            wr.addEventListenerWithIntercept(onMeshLoad);

            wr.queued = 0;
            pw.push(wr);
        }
    }

    //Find the least busy worker
    var which = 0;
    var queued = pw[0].queued;
    for (i = 1; i < pw.length; i++) {
        if (pw[i].queued < queued) {
            which = i;
            queued = pw[i].queued;
        }
    }
    w = pw[which];
    w.queued += 2;
    workerId = which;


    //Pass unzip job to the worker
    var reqPath = avp.pathToURL(this.svf.basePath + path);
    var xfer = { "operation":WORKER_LOAD_GEOMETRY,
                 "url": reqPath,
                 "packId": parseInt(packId), /* mesh IDs treat the pack file id as integer to save on storage in the per-fragment arrays */
                 "workerId": workerId,
                 "packNormals": this.options.packNormals,
                 "queryParams" : this.queryParam };

    w.doOperation(avp.initLoadContext(xfer)); // Send data to our worker.
};

SvfLoader.prototype.checkCull = function (frags, idx, frustum) {

    var box = this.tmpBox;
    frags.getWorldBounds(idx, box);
    if (!frustum.intersectsBox(box)) {
        return true;
    }
    else {
        var area = frustum.projectedArea(box);
        area *= frustum.areaConv;
        if (area < frustum.areaCullThreshold) {
            return true;
        }
    }
    return false;
};

SvfLoader.prototype.processReceivedMesh = function(mdata) {

    //Find all fragments that instance this mesh
    var meshid = mdata.packId + ":" + mdata.meshIndex;

    var svf = this.svf;
    var fragments = svf.fragments;
    var rm = this.model;

    var fragIndexes = fragments.mesh2frag[meshid];
    if (fragIndexes === undefined) {
        avp.logger.warn("Mesh " + meshid + " was not referenced by any fragments.");
        return;
    }
    if (!Array.isArray(fragIndexes))
        fragIndexes = [fragIndexes];

    // Let's do a culling when process the received meshes,
    // which cull those won't be rendered in current frame.
    // 
    // ??? TODO: look at this later, may not needed.
    // if (avp.cullGeometryOnLoading) {
    //     var culled = true;
    //     for (var i=0; i<fragIndexes.length; ++i) {
    //         // Do not cull the first FRAGS_PERSISTENT_COUNT fragments.
    //         if (fragIndexes[i] < avp.FRAGS_PERSISTENT_COUNT) {
    //             culled = false;
    //             break;
    //         }

    //         culled = culled && this.checkCull(rm.getFragmentList(), fragIndexes[i], this.viewer3DImpl.modelQueue().frustum());
    //         if (!culled)
    //             break;
    //     }
    //     if (culled) {
    //         // Discard this mesh directly.
    //         mdata.mesh = null;
    //         mdata = null;
    //         return;
    //     }
    // }

    //Convert the received mesh to THREE buffer geometry
    avp.BufferGeometryUtils.meshToGeometry(mdata);
    mdata.geometry.packId = mdata.packId;
    
    var numInstances = fragIndexes.length;

    //Reuse previous index of this geometry, if available
    var idx = rm.getFragmentList().getGeometryId(fragIndexes[0]);
    var geomId = rm.getGeometryList().addGeometry(mdata.geometry, numInstances, idx);

    // This is to record how many instances this geometry has,
    // and the number of instances have been rendered in one frame.
    this.pagingProxy.onProcessReceivedMesh(mdata.geometry, numInstances);

    var ib = mdata.geometry.attributes['index'].array || mdata.geometry.ib;
    var polyCount = ib.length / 3;

    //For each fragment, add a mesh instance to the renderer
    for (var i=0; i<fragIndexes.length; i++) {
        var fragId = 0|fragIndexes[i];

        //We get the matrix from the fragments and we set it back there
        //with the activateFragment call, but this is to maintain the
        //ability to add a plain THREE.Mesh -- otherwise it could be simpler
        rm.getFragmentList().getOriginalWorldMatrix(fragId, this.tmpMatrix);

        var materialId = fragments.materials[fragId].toString();

        if (fragments.polygonCounts)
            fragments.polygonCounts[fragId] = polyCount;

        var m = this.viewer3DImpl.setupMesh(this.model, mdata.geometry, materialId, this.tmpMatrix);

        //If there is a placement transform, we tell activateFragment to also recompute the
        //world space bounding box of the fragment from the raw geometry model box, for a tighter
        //fit compared to what we get when loading the fragment list initially.
        rm.activateFragment(fragId, m, !!svf.placementTransform);
    }

    if (!this.model.getFragmentList().onDemandLoadingEnabled()) {
        //don't need this mapping anymore.
        fragments.mesh2frag[meshid] = null;
    }

    //Repaint and progress reporting
    fragments.numLoaded += fragIndexes.length;

    //repaint every once in a while -- more initially, less as the load drags on.
    var geomList = rm.getGeometryList();
    if (geomList.geomPolyCount > svf.nextRepaintPolys) {
        //avp.logger.log("num loaded " + numLoaded);
        this.firstPixelTimestamp = this.firstPixelTimestamp || Date.now();
        svf.numRepaints ++;
        svf.nextRepaintPolys += 10000 * Math.pow(1.5, svf.numRepaints);
        this.viewer3DImpl.invalidate(false, true);
    }

};


SvfLoader.prototype.onModelRootLoadDone = function(svf) {

    // Root model loading is done, and loader now is attached to model,
    // so can remove the direct reference to it from viewer impl.
    _removeLoadingFile(this.viewer3DImpl, this);
    
    svf.geomMemory = 0;
    svf.fragments.numLoaded = 0;
    svf.meshCount = 0;
    svf.gpuNumMeshes = 0;
    svf.gpuMeshMemory = 0;

    svf.nextRepaintPolys = 0;
    svf.numRepaints = 0;

    svf.urn = this.svfUrn;
    svf.acmSessionId = this.acmSessionId;

    svf.basePath = this.basePath;

    svf.loadOptions = this.options;

    var t1 = Date.now();
    this.loadTime += t1 - this.t0;
    avp.logger.log("SVF load: " + (t1 - this.t0));

    // Create the API Model object and its render proxy
    var model = this.model = new av.Model(svf);
    model.loader = this;

    // Let's set the options through for each model that control how memory saving mode start,
    // which decide how to load geometry pack files, and whether paging out if needed.
    // And assume the performance tuning options passed through viewer's config.
    var memPerfOpts = this.viewer3DImpl.api.config ? 
                      (this.viewer3DImpl.api.config.memPerfOpts || {}) : 
                      {};

    // So, for now do not support on paging for multiple models. 
    if (this.viewer3DImpl.modelQueue().getModels().length > 0) {
        // If already a model loaded into viewer, then disable paging for the other ones.
        memPerfOpts.pageOutGeometryEnabled = false;
    }

    memPerfOpts.totalPackFiles = svf.geompacks.length;
    memPerfOpts.loadPackFileImpl = this.loadGeometryPackOnDemand.bind(this);
    memPerfOpts.cancelLoadPackImpl = this.cancelGeometryPackLoading.bind(this);
    this.pagingProxy = new SvfPagingProxy(memPerfOpts);

    model.initialize(this.pagingProxy);

    //For 3D models, we can start loading the property database as soon
    //as we know the fragment list which contains the fragId->dbId map.
    //We would not load property db when we are on mobile device AND on demand loading is on (which
    //implies the model is not 'normal' in terms of its size.). This is only a temp solution that
    //allow big models loads on mobile without crash. Without property db loading selection could break.
    var shouldLoadPropertyDb = !(this.model.getFragmentList().onDemandLoadingEnabled() && (av.isMobileDevice()));
    if (shouldLoadPropertyDb && !this.options.skipPropertyDb) {
        this.loadPropertyDb();
    }

    var numMaterials = this.viewer3DImpl.matman().convertMaterials(model);
    if (this.viewer3DImpl.matman().hasTwoSidedMaterials()) {
        this.viewer3DImpl.renderer().toggleTwoSided(true);
    }

    this.t0 = t1;

    //The BBox object loses knowledge of its
    //type when going across the worker thread boundary...
    svf.bbox = new THREE.Box3().copy(svf.bbox);
    if (svf.modelBox)
        svf.modelBox = new THREE.Box3().copy(svf.modelBox);

    if (svf.refPointTransform) {
        svf.refPointTransform = new LmvMatrix4(true).copy(svf.refPointTransform);
    }
    if (svf.placementTransform) {
        svf.placementTransform = new LmvMatrix4(true).copy(svf.placementTransform);
    }

    //Camera vectors also lose their prototypes when they
    //cross the thread boundary...
    if (svf.cameras) {
        for (var i = 0; i < svf.cameras.length; i++) {
            var camera = svf.cameras[i];
            camera.position = new THREE.Vector3().copy(camera.position);
            camera.target = new THREE.Vector3().copy(camera.target);
            camera.up = new THREE.Vector3().copy(camera.up);
        }
    }

    //If the textures are likely to come from the Protein CDN
    //load them in parallel with the geometry packs
    if (svf.proteinMaterials && PROTEIN_ROOT && PRISM_ROOT) {
        this.viewer3DImpl.matman().loadTextures(this.model);
    }

    avp.logger.log("scene bounds: " + JSON.stringify(svf.bbox));

    var metadataStats = {
        category: "metadata_load_stats",
        urn: svf.urn,
        has_topology: !!svf.topology,
        has_animations: !!svf.animations,
        cameras: svf.cameras ? svf.cameras.length : 0,
        lights: svf.lights ? svf.lights.length : 0,
        materials: numMaterials,
        is_mobile: av.isMobileDevice()
    };
    if (svf.topologyTooBig) {
        metadataStats.has_topology = true; // File does actually have topology, as far as tracking goes.
        metadataStats.topologyTooBig = true;
    }
    avp.logger.track(metadataStats);

    this.viewer3DImpl.signalProgress(5);
    this.viewer3DImpl.invalidate(false, false);
};

SvfLoader.prototype.addTransparencyFlagsToMaterials = function(mats) {
    for(var id in mats) {
        var mat = mats[id];
        var userAssets = mat["userassets"];
        //TODO: for GLTF materials, userAssets does not exist
        if (userAssets) {
            var innerMats = mat["materials"];
            var innerMat = innerMats[userAssets[0]];
            mat.transparent = innerMat["transparent"];
        }
    }
};

SvfLoader.prototype.makeBVH = function(svf) {
    var t0 = performance.now();
    var mats = svf.materials ? svf.materials["materials"] : null;
    if (mats)
        this.addTransparencyFlagsToMaterials(mats);
    svf.bvh = new avp.BVHBuilder(svf.fragments, mats);
    svf.bvh.build(this.options.bvhOptions || {isWeakDevice : av.isMobileDevice()});
    var t1 = performance.now();
    avp.logger.log("BVH build time: " + (t1 - t0));
};

SvfLoader.prototype.onDemandGeomLoadDone = function() {
    
    // Launch the texture loads only on those materials that are required by current rendered geometries.
    if (!this.svf.proteinMaterials || !PROTEIN_ROOT || !PRISM_ROOT) { 
        // TODO:
    }

    // Time for loading part of the on-demanded geometries.
    var t1 = Date.now();
    var msg = "[On Demand Loading] On demand requested geometries load time: " + (t1 - this.t0);

    avp.logger.log(msg);

    // Track the on demand geom load stats.
    var modelStats = {
        category: "on_demand_geom_load_stats",
        is_f2d: false,
        has_prism: this.viewer3DImpl.matman().hasPrism,
        load_time: (t1 - this.t0),
        geometry_size: this.model.getGeometryList().geomMemory,
        meshes_count: this.model.getGeometryList().geoms.length,
        fragments_count: this.model.getFragmentList().getCount(),
        load_pack_count: this.loadedPacksCount,
        urn: this.svfUrn
    };
    avp.logger.track(modelStats, true);

    // TODO: send recorded assets to ios. 

    // clear the start time, which can be set again if on demand loading geometry again.
    this.t0 = null; 

    this.loadedPacksCount = 0;
    this.svf.partPacksLoadDone = true;
    this.viewer3DImpl.onDemandLoadComplete(this.model);
};

SvfLoader.prototype.onGeomLoadDone = function() {
    this.svf.loadDone = true;

    //launch the texture loads in case that was not done already
    if (!this.svf.proteinMaterials || !PROTEIN_ROOT || !PRISM_ROOT) {
        this.viewer3DImpl.matman().loadTextures(this.model);
    }

    // We need to keep a copy of the original fragments
    // transforms in order to restore them after explosions, etc.
    // the rotation/scale 3x3 part.
    // TODO: consider only keeping the position vector and throwing out
    //
    //delete this.svf.fragments.transforms;

    // Release that won't be used. the on demand loading won't call this anyway.
    this.svf.fragments.entityIndexes = null;
    this.svf.fragments.mesh2frag = null;

    var t1 = Date.now();
    var msg = "Fragments load time: " + (t1 - this.t0);
    this.loadTime += t1 - this.t0;

    var firstPixelTime = this.firstPixelTimestamp - this.t0;
    msg += ' (first pixel time: ' + firstPixelTime + ')';

    //If there is a post-transform, the BVH has to be computed after
    //all the world transforms/boxes are updated
    if (!this.svf.bvh || this.svf.placementTransform) {
        this.makeBVH(this.svf);
        this.model.setBVH(this.svf.bvh.nodes, this.svf.bvh.primitives, this.options.bvhOptions);
    }
    avp.logger.log(msg);

    // Run optional consolidation step
    if (this.options.useConsolidation) {
        // TODO: I don't really like to access the viewer and (even worse) the renderer here. But for the
        //       consolidation, we need it to know whether we can use instancing and to dispose individual fragemnts
        //       from GPU to make space for the consolidated ones.
        var glRenderer = this.viewer3DImpl.glrenderer();

        this.model.consolidate(this.viewer3DImpl.getMaterials(), this.options.consolidationMemoryLimit, glRenderer);
    }

    var modelStats = {
        category: "model_load_stats",
        is_f2d: false,
        has_prism: this.viewer3DImpl.matman().hasPrism,
        load_time: this.loadTime,
        geometry_size: this.model.getGeometryList().geomMemory,
        meshes_count: this.model.getGeometryList().geoms.length,
        fragments_count: this.model.getFragmentList().getCount(),
        urn: this.svfUrn
    };
    if (firstPixelTime > 0) {
        modelStats['first_pixel_time'] = firstPixelTime; // time [ms] from SVF load to first geometry rendered
    }
    avp.logger.track(modelStats, true);

    function sendMessage(data){
        var aMessage = {'command':'assets', data: data};
        if (av.isBrowser)
            window.webkit.messageHandlers.callbackHandler.postMessage(aMessage);
    }

    if (avp.assets) {
        // Callback to ios.
        if (av.isBrowser && window.webkit) {
            sendMessage(avp.assets);
            avp.assets = null;
        }
    }

    this.currentLoadPath = null;

    this.viewer3DImpl.onLoadComplete(this.model);
};

SvfLoader.prototype.loadPropertyDb = function() {
    this.svf.propWorker = new avp.PropDbLoader(this.sharedDbPath, this.model, this.viewer3DImpl.api);
    this.svf.propWorker.load();
};

avp.SvfLoader = SvfLoader;
avp.SvfPagingProxy = SvfPagingProxy;

av.FileLoaderManager.registerFileLoader("svf", ["svf", "gltf", "glb"], avp.SvfLoader);


})();
;

(function(){

"use strict";

var av = Autodesk.Viewing,
    avp = av.Private;

var WORKER_PARSE_F2D = "PARSE_F2D";
var WORKER_STREAM_F2D = "STREAM_F2D";
var WORKER_PARSE_F2D_FRAME = "PARSE_F2D_FRAME";

// Paging proxy object to manage on demand loading and paging logic, 
// that is specific to the model loaded by svf loader.
var F2DPagingProxy = function(loader, options) {

    var _extendObject = function(target, source) {
        for (var prop in source) {
            if (source.hasOwnProperty(prop)) {
                target[prop] = source[prop];
            }
        }
    };

    var _loader = loader;

    // Options of control memory management.
    this.options = {

        max2DPersistentBufferCount: avp.MAX_2D_PERSISTENT_BUFFER_COUNT,
        pageOutCount2D: avp.PAGE_OUT_COUNT_2D,
        pageOutGoal2D: avp.PAGE_OUT_GOAL_2D,
        instancingFactor: 1,
        pixelCullingEnable: WGS.pixelCullingEnable,
        pixelCullingThreshold: WGS.PIXEL_CULLING_THRESHOLD,
        onDemandLoading: avp.onDemandLoading,
        pageOutGeometryEnabled: avp.pageOutGeometryEnabled,

        // This one just for testing.
        forceOnDemandLoading: WGS.forceOnDemandLoading
    };
    _extendObject(this.options, options);
    this.options.max2DPersistentBufferCount *= this.options.instancingFactor;
    this.options.pageOutCount2D *= this.options.instancingFactor;
    this.options.pageOutGoal2D *= this.options.instancingFactor;
    this.options.pageOutGeometryEnabled = this.options.onDemandLoading; // On demand loading forces page out
    this.options.fragsPersistentCont = 0;         // Only keep first fragment, because it draws the paper and has less popping
    this.options.fragsPersistentMaxCount = this.options.max2DPersistentBufferCount;    // One buffer is one fragment
    this.options.geomCountLimit = 0 | this.options.pageOutCount2D;

    // Initialize members used by on demand loading
    var _pendingBuffers = [];
    var _pendingCount = 0;
    var _lastBufferPending = -1;
    var _lastTraversed = -1;
    var _maxRequest = -1;
    var _canceled = 0;
    var _bufferCount = 0;
    var _finalFrame = false;
    var _culledGeom = [];

    // Viewer API - these methods are used by the viewer to handler
    // on demand loading and paging out geometry

    // Return true of false, whether on demand loading enabled.
    // This controls how the geometry buffers are going to load. 
    //
    // If false, then geometry buffers will load in sequence all at once.
    // if true, then only those geometry buffers that are request to render,
    //          can they start to load *on demand*
    this.onDemandLoadingEnabled = function() {
        return this.options.onDemandLoading;
    };

    this.pageOutGeometryEnabled = function() {
        return this.options.onDemandLoading;
    };

    this.pixelCullingEnable = function() {
        return this.options.pixelCullingEnable;
    };

    this.pixelCullingThreshold = function() {
        return this.options.pixelCullingThreshold;
    }

    this.loadPackFile = function(bufferId) {
        if (!this.onDemandLoadingEnabled())
            return false;

        // Request out of range
        if (bufferId < 0 || (_finalFrame && bufferId >= _bufferCount))
            return false;

        if (bufferId > _maxRequest)
            _maxRequest = bufferId;

        // If this buffer hasn't been requested, then check for
        // out of sequence ordering and mark it as requested.
        if (!_pendingBuffers[bufferId]) {
            // reset if we get a request out of order
            if (bufferId <= _lastBufferPending)
                this.reset();
            // Mark as pending
            _pendingBuffers[bufferId] = true;
        }

        // request more buffers to draw.
        var numGeomsInMemory = 0;
        if (_loader.model) {
            var geoms = _loader.model.getGeometryList();
            if (geoms) {
                numGeomsInMemory = geoms.numGeomsInMemory; 
            }
        }

        var nextReq = _lastBufferPending;
        while (numGeomsInMemory + _pendingCount < this.options.max2DPersistentBufferCount) {
            // Anything left to request
            if (++nextReq >= _pendingBuffers.length)
                break;     // No
            if (_pendingBuffers[nextReq]) {
                // Need to request this one
                _lastBufferPending = nextReq;
                ++_pendingCount;
                _loader.parsingWorker.doOperation({operation:WORKER_PARSE_F2D_FRAME,
                                                  bufferId: nextReq });
            }
        }

        return true;
    };

    this.reset = function() {
        // we need to cancel the parsing worker.
        _loader.parsingWorker.doOperation({operation:WORKER_PARSE_F2D_FRAME,
                                           cancel: true });
        _pendingBuffers.length = 0;
        _lastBufferPending = -1;
        _lastTraversed = -1;
        _pendingCount = 0;
        _culledGeom.length = 0;
        _maxRequest = _bufferCount - 1;
        ++_canceled;
    };

    this.addGeomPackMissingLastFrame = function(packId) {
        return true;// Shouldn't be called
    };

    this.needResumeNextFrame = function() {
        return false;
    }

    this.pageOut = function(iterationDone, forcePageOut, geomList) {
        // If over the limit, start page out
        var num = geomList.numGeomsInMemory;
        if (num > this.options.geomCountLimit) {
            var i = 0; // tmp (see below)

            // Goal is to page out to limit - limit * percent
            var remaining = 0 | (num - this.options.pageOutGoal2D);

            // Step 1: Remove untraversed geometries first
            var removeGeoms = _culledGeom.splice(0, remaining);
            remaining = remaining - removeGeoms.length;
            removeGeoms.forEach(function(geomId) {
                // remove culled geom
                geomList.removeGeometry(geomId);
            });

            // Step 2: If not enough, continue to remove geometries aren't about to be traversed.
            if (remaining > 0) {
                for (i = geomList.geoms.length; --i >= 0; ) {
                    if (i <= this.options.fragsPersistentCont)
                        break;
                    if ((i <= _lastTraversed || i > _lastBufferPending)
                        && geomList.removeGeometry(i) > 0 && --remaining <= 0)
                        break;
                }
            }

            // below tracks numGeomsInMemory instead. If forcePageOut is set, 
            // this could mean that we enter step 3. and remove relevant geometry, 
            // even if _culledGeom and traversedGeoms might still contain better candidates.
            // However, this method is currently only culled with frorcePageOut if 
            // calling without didn't help at all. (see this.frameUpdatePaging)

            // Step 3: If existing geometries are still over the limitation, and force page out enabled,
            //         run through the whole list and page out as much as needed.
            num = geomList.numGeomsInMemory - this.options.geomCountLimit;
            if (forcePageOut && num > 0) {
                for (i = _lastBufferPending; i >= 0; --i) {
                    if (i <= this.options.fragsPersistentCont)
                        break;
                    if (geomList.removeGeometry(i) > 0 && --num <= 0)
                        break;
                }
                //THREE.log("[On Demand Loading] A force page out occur. ");
            }

            // When starting chrome with this JS flag: --js-flags="--expose-gc", then window.gc is defined and
            // can be used for doing a force GC. This is useful for testing purpose.
            if (window && window.gc) {
                window.gc();
            }
        }

        // If the iterator is finished and the file is still loading then
        // we request more buffers. This how buffers initially get loaded
        if (iterationDone && !_finalFrame) {
            var bufferCount = this.options.fragsPersistentMaxCount - geomList.numGeomsInMemory;
            if (bufferCount > 0) { 
                var bufferId = _maxRequest;
                while (--bufferCount >= 0)
                    this.loadPackFile(++bufferId);
            }
        }

        return WGS.PAGEOUT_SUCCESS;
    };

    this.onGeomTraversed = function(geometry) {
        // TODO Paging: refactor this to the proxy object of 2d loader.
        //              2d doesn't have multiple instance geometry, so 
        //              just record it as traversed.
        _lastTraversed = geometry.svfid - 1;
    };

    this.onGeomCulled = function(geometry) {
        // TODO Paging: refactor this to the proxy object of 2d loader.
        if (this.onDemandLoadingEnabled() && geometry) {
            _culledGeom.push(geometry.svfid - 1);
        }
    };

    this.onMeshReceived = function(mesh, mindex) {
        // Accept all meshes if not on demand loading
        if (!this.onDemandLoadingEnabled())
            return true;

        // If on demand loading don't process any meshes that are requested
        // These can get queued after canceling all of the meshes.
        if (_canceled != 0 || !_pendingBuffers[mindex])
            return false;

        // Keep track of the buffer count
        if (mindex >= _bufferCount)
            _bufferCount = mindex + 1;

        // Keep track of pending buffers
        _pendingBuffers[mindex] = false;
        --_pendingCount;

        // If on demand loading then we need to invalidate for each mesh
        // to insure that the visibility flags are correctly updated.
        _loader.viewer3DImpl.invalidate(false, true);
        return true;
    };

    this.onFinalFrame = function() {
        // Remove pending requests that are outside of the buffer counting
        // and decrement the pending count
        if (this.onDemandLoadingEnabled()) {
            _finalFrame = true;                
            _pendingBuffers.splice(_bufferCount, _pendingBuffers.length).forEach( function(pending) {
                if (pending)
                    --_pendingCount;
            });
        }
    };

    this.cancelAcknowledged = function() {
        --_canceled;
    }
};

/** @constructor */
function F2DLoader(parent) {
    this.viewer3DImpl = parent;
    this.loading = false;
    this.tmpMatrix = new THREE.Matrix4();

    this.logger = avp.logger;
    this.loadTime = 0;
    this.domainParam = (av.getUseCredentials() && !av.isNodeJS) ? ("domain=" + encodeURIComponent(window.location.origin)) : "";
    this.useInstancing = this.viewer3DImpl.use2dInstancing;
}

F2DLoader.prototype.dtor = function () {
    // Cancel all potential process on loading a file.

    // 1. init worker script can be cancelled. 
    // 
    if (this.initWorkerScriptToken) {
        this.initWorkerScriptToken.cancel();
        this.initWorkerScriptToken = null;
        avp.logger.debug("F2D loader dtor: on init worker script.");
    }

    // 2. Streaming F2D data can be cancelled. 
    if (this.streamingWorker) {
        this.streamingWorker.terminate();
        this.streamingWorker = null;
        avp.logger.debug("F2D loader dtor: on streaming worker.");
    }

    // 3. Parsing F2D geometry can be cancelled.
    if (this.parsingWorker) {
        this.parsingWorker.terminate();
        this.parsingWorker = null;
        avp.logger.debug("F2D loader dtor: on parsing worker.");
    }

    // 4. Property loading can be cancelled.
    if (this.svf && this.svf.propWorker) {
        this.svf.propWorker.dtor();
        this.svf.propWorker = null;
    }   

    // And clear metadata.
    this.viewer3DImpl = null;
    this.loading = false;
    this.tmpMatrix = null;
    this.logger = null;
    this.domainParam = null;
    this.loadTime = 0;

    this.svf = null;
    this.options = null;
    this.pagingProxy = null;
};

F2DLoader.prototype.isValid = function() {
    return this.viewer3DImpl != null;
}

function _addLoadingFile(viewerImpl, f2dLoader) {
    if (!viewerImpl.loaders) {
        viewerImpl.loaders = [];
    }
    viewerImpl.loaders.push(f2dLoader);
};

function _removeLoadingFile(viewerImpl, f2dLoader) {
    if (viewerImpl.loaders) {
        var idx = viewerImpl.loaders.indexOf(f2dLoader);
        if (idx >= 0) {
            viewerImpl.loaders.splice(idx, 1);
        }
    }
};

F2DLoader.prototype.loadFile = function(path, options, onSuccess, onError, onWorkerStart) {
    if (!this.viewer3DImpl) {
        avp.logger.log("F2D loader was already destructed. So no longer usable.");
        return false;
    }

    if (this.loading) {
        avp.logger.log("Loading of F2D already in progress. Ignoring new request.");
        return false;
    }

    // Mark it as loading now.
    this.loading = true;
    _addLoadingFile(this.viewer3DImpl, this);

    var index = path.indexOf('urn:');
    if (index != -1) {
        // Extract urn:adsk.viewing:foo.bar.whateverjunks out of the path URL and bind it to logger.
        // From now on, we can send logs to viewing service, and logs are grouped by urn to make Splunk work.
        path = decodeURIComponent(path);
        var urn = path.substr(index, path.substr(index).indexOf('/'));
        avp.logger.log("Extracted URN: " + urn);

        // Extract urn(just base64 code)
        var _index = urn.lastIndexOf(':');
        this.svfUrn = urn.substr(_index + 1);
    } else {
        this.svfUrn = path;
    }

    this.sharedDbPath = options.sharedPropertyDbPath;
    this.currentLoadPath = path;
    this.acmSessionId = options.acmSessionId;

    this.queryParam = this.domainParam;
    if (this.acmSessionId) {
        if (this.queryParam)
            this.queryParam += "&";
        this.queryParam += "acmsession=" + this.acmSessionId;
    }

    this.options = options;

    if (this.options.placementTransform) {
        //NOTE: The scale of the placement transform is not always sufficient to
        //determine the correct scale for line widths. This is because when a 2D model (in inches) is
        //loaded into a 3d scene in feet, the transform includes all the scaling needed to get into feet
        //but the model space line weight for the drawing is relative to the drawing itself, so an extra
        //factor of 12 would be needed in such case to cancel out the 1/12 needed for inch->foot.
        //This could probably be automatically derived, but in an error prone way, so I'm leaving it
        //up to the application layer that does the model aggregation to pass in the right model scale as an option.
        this.modelScale = this.options.modelScale || this.options.placementTransform.getMaxScaleOnAxis();
    } else {
        this.modelScale = this.options.modelScale || 1;
    }

    this.isf2d = true;
    var scope = this;
    
    // Get memory performance options
    var memPerfOpts = this.memPerfOpts = this.viewer3DImpl.api.config ? 
                                         (this.viewer3DImpl.api.config.memPerfOpts || {}) : 
                                         {};
    if (!memPerfOpts.hasOwnProperty("max2DPersistentBufferCount") || memPerfOpts.max2DPersistentBufferCount <= 0)
        memPerfOpts.max2DPersistentBufferCount = avp.MAX_2D_PERSISTENT_BUFFER_COUNT;
    // If instancing buffer are 1/4 the normal size, so increase the max
    memPerfOpts.instancingFactor = this.useInstancing ? 4 : 1;
    if (!memPerfOpts.hasOwnProperty("forceOnDemandLoading"))
        memPerfOpts.forceOnDemandLoading = WGS.forceOnDemandLoading;
    if (!memPerfOpts.hasOwnProperty("onDemandLoading"))
        memPerfOpts.onDemandLoading = avp.onDemandLoading;
    if (!memPerfOpts.hasOwnProperty("pageOutGeometryEnabled"))
        memPerfOpts.pageOutGeometryEnabled = avp.pageOutGeometryEnabled;
    if (!memPerfOpts.hasOwnProperty("pixelCullingEnable"))
        memPerfOpts.pixelCullingEnable = WGS.pixelCullingEnable;

    this.initWorkerScriptToken = avp.initWorkerScript(function() {
        scope.loadFydoCB(path, options, onSuccess, onError, onWorkerStart);
    });
    
    return true;
};


F2DLoader.prototype.loadFydoCB = function(path, options, onSuccess, onError, onWorkerStart) {
    this.t0 = Date.now();

    var svfPath = avp.pathToURL(path);

    // Streaming worker as data producer that generates fydo frame streams.
    this.streamingWorker = avp.createWorker();
    // Parsing worker as data consumer that consumes fydo frame streams and generate meshes.
    this.parsingWorker = avp.createWorker();
    var scope = this;
    var first = true;

    var terminateParser = function() {
        // The parse worker is only terminated when the loader is destroyed when we
        // are doing on demand loading. It is needed to supply buffers on demand.
        if (!scope.memPerfOpts.onDemandLoading) {
            scope.parsingWorker.terminate();
            scope.parsingWorker = null;
        }
    }

    var onStream = function (ew) {

        if (!scope.isValid()) {
            return;
        }

        // Determine whether the current model should use on demand loading.
        // This can only be calculated after the metadata is read. We estimate
        // the number of vertex buffers we need to hold the data and turn it on
        // if there are too many.
        var shouldLoadOnDemand = function(metadata, isMobile) {
            if (metadata) {
                var stats = metadata.geom_metrics;
                // Start counting segments, because most things are done as segments
                var verts = (stats.arcs + stats.circ_arcs) * 3; // 3 segments for arcs - 1 for the arc and 2 for caps
                verts += stats.circles; // 1 segment for a circle
                verts += (stats.pline_points - (stats.plines || 0)); // 1 segment for each line segment, stats.plines not always present
                verts += stats.rasters;   // 1 segment for each raster
                verts += (stats.ptri_indices / 3) * 3; // max 3 per triangle for antialiased edges
                // 4 verts per segment without instancing, 1 with, but the buffer
                // size is cut by a factor of 4 with instancing, which we adjust
                // max2DPersistentBufferCount to compensate for. So, we always
                // want to multiply by 4
                // TODO: Needs to keep this consistent with F2D parser
                verts *= 4;
                verts += stats.ptri_points;     // verts in poly triangles
                var verts_per_buffer = isMobile ? 16383 : 32767;
                verts /= verts_per_buffer;
                // TODO: get this from the loader
                var memPerfOpts = scope.memPerfOpts;
                if (memPerfOpts.onDemandLoading && !memPerfOpts.forceOnDemandLoading
                    && verts < memPerfOpts.max2DPersistentBufferCount * memPerfOpts.instancingFactor) {
                    memPerfOpts.onDemandLoading = false;
                    memPerfOpts.pageOutGeometryEnabled = false;
                }
            }
            return scope.memPerfOpts.onDemandLoading;
        };

        if (first && onWorkerStart) {
            first = false;
            onWorkerStart();
        }

        if (ew.data && ew.data.type == "F2DBLOB") {
            shouldLoadOnDemand(ew.data.metadata, av.isMobileDevice());
            var msg = { operation:WORKER_PARSE_F2D,
                data: ew.data.buffer,
                metadata: ew.data.metadata,
                manifest: ew.data.manifest,
                basePath: ew.data.basePath,
                f2dLoadOptions: {
                    modelSpace : options.modelSpace,
                    bgColor: options.bgColor,
                    isMobile: av.isMobileDevice(),
                    useInstancing: scope.useInstancing,
                    onDemandLoading: scope.memPerfOpts.onDemandLoading
                },
                url: svfPath
                };
            scope.parsingWorker.doOperation(msg, [msg.data]);
            scope.streamingWorker.terminate();
            scope.streamingWorker = null;

        } else if (ew.data && ew.data.type == "F2DSTREAM") {
            shouldLoadOnDemand(ew.data.metadata, av.isMobileDevice());
            var msg = { operation:WORKER_PARSE_F2D_FRAME,
                        data: ew.data.frames,
                        url: svfPath,
                        f2dLoadOptions: {
                            modelSpace : options.modelSpace,
                            bgColor: options.bgColor,
                            isMobile: av.isMobileDevice(),
                            useInstancing: scope.useInstancing,
                            onDemandLoading: scope.memPerfOpts.onDemandLoading
                        }
                      };

            //first frame
            if (ew.data.metadata) {
                msg.metadata = ew.data.metadata;
                msg.manifest = ew.data.manifest;
            }

            //last frame?
            if (ew.data.finalFrame)
                msg.finalFrame = true;

            if (ew.data.progress)
                scope.viewer3DImpl.signalProgress(100*ew.data.progress);

            scope.parsingWorker.doOperation(msg, msg.data ? [msg.data] : undefined);

            if (ew.data.finalFrame) {
                scope.streamingWorker.terminate();
                scope.streamingWorker = null;
            }
        } else if (ew.data && ew.data.type == "F2DAssetURL") {
            avp.assets = avp.assets.concat(ew.data.urls);
        } else if (ew.data && ew.data.assetRequest) {
            avp.assets.push(ew.data.assetRequest);
        } else if (ew.data && ew.data.progress) {
            //just ignore progress-only message, it's only needed by the initial worker start notification above
        } else if (ew.data && ew.data.debug) {
            avp.logger.debug(ew.data.message);
        } else if (ew.data && ew.data.error) {
            scope.loading = false;
            scope.streamingWorker.terminate();
            scope.streamingWorker = null;
            if (onError)
                onError.call(this, ew.data.error.code, ew.data.error.msg, ew.data.error.args.httpStatus, ew.data.error.args.httpStatusText);
        } else {
            avp.logger.error("F2D download failed.");
            scope.loading = false;
            scope.streamingWorker.terminate();
            scope.streamingWorker = null;
        }
    };



    var onParse = function (ew) {

        if (!scope.isValid()) {
            return;
        }
        
        if (first && onWorkerStart) {
            first = false;
            onWorkerStart();
        }

        if (ew.data && ew.data.f2d) {
            var f = scope.svf = ew.data.f2d;

            terminateParser();
            
            avp.logger.info("Num polylines: " + f.numPolylines);
            avp.logger.info("Line segments: " + f.numLineSegs);
            avp.logger.info("Circular arcs: " + f.numCircles);
            avp.logger.info("Ellipitcal arcs:" + f.numEllipses);
            avp.logger.info("Plain triangles:" + f.numTriangles);
            avp.logger.info("Total # of op codes generated by fydo.parse: " + f.opCount);

            scope.onModelRootLoadDone(scope.svf);

            if (onSuccess)
                onSuccess(scope.model);

            scope.viewer3DImpl.api.fireEvent({type:av.MODEL_ROOT_LOADED_EVENT, svf:scope.svf, model:scope.model});
            

            for (var i=0; i < f.meshes.length; i++) {
                scope.processReceivedMesh2D(f.meshes[i], i);
            }

            f.meshes = null;

            scope.onGeomLoadDone();

            scope.loading = false;

        }  else if (ew.data && ew.data.f2dframe) {
            var baseIndex = 0;

            if (!ew.data.meshes) {
                //First message from the worker
                scope.svf = ew.data.f2dframe;
                baseIndex = ew.data.baseIndex;
            } else {
                //Update the world box and current mesh index
                //on subsequent messages from the worker.
                var bbox = ew.data.bbox;
                scope.svf.bbox = new THREE.Box3(bbox.min, bbox.max);
                baseIndex = ew.data.baseIndex;
            }

            var f = scope.svf;

            if (!f.fragments || !f.fragments.initialized) {
                //First message from the worker,
                //initialize the load states, fragment lists, etc.
                scope.onModelRootLoadDone(f);

                if (onSuccess) {
                    onSuccess(scope.model);
                }
                scope.viewer3DImpl.api.fireEvent({type:av.MODEL_ROOT_LOADED_EVENT, svf:f, model:scope.model});

            }

            if (ew.data.meshes && ew.data.meshes.length)
            {
                for (var i = 0; i < ew.data.meshes.length; i++) {
                    scope.processReceivedMesh2D(ew.data.meshes[i], baseIndex+i);
                }
            }

            if (ew.data.finalFrame) {
                //Update the F2D properties which are accumulated
                //while reading the F2D stream.
                var cumulativeProps = ew.data.cumulativeProps;
                for (var p in cumulativeProps) {
                    f[p] = cumulativeProps[p];
                }

                scope.onGeomLoadDone();

                scope.loading = false;

                terminateParser();

                if (this.pagingProxy)
                    this.pagingProxy.onFinalFrame();
            }

        } else if (ew.data && ew.data.progress) {
            //just ignore progress-only message, it's only needed by the initial worker start notification above
        } else if (ew.data && ew.data.debug) {
            avp.logger.debug(ew.data.message);
        } else if (ew.data && ew.data.canceled && scope.pagingProxy) {
            scope.pagingProxy.cancelAcknowledged();
        } else if (ew.data && ew.data.error) {
            scope.loading = false;
            terminateParser();

            avp.logger.error("Error while parsing F2d: " + JSON.stringify(ew.data.error.args));

            // TODO: in debug model, viewer3d.html does not have any on error callback.
            // So, any errors would be swallowed, instead of reported back.
            // Is this intended? We should at least print the stack on console to help make our life easier.
            if (onError)
                onError.call(this, ew.data.error.code, ew.data.error.msg, ew.data.error.args.httpStatus, ew.data.error.args.httpStatusText);
        } else {
            avp.logger.error("F2D download failed.");
            //Download failed.
            scope.loading = false;
            terminateParser();
        }
    };

    this.streamingWorker.addEventListener('message', onStream, false);
    this.parsingWorker.addEventListener('message', onParse, false);

    var msg = { operation:WORKER_STREAM_F2D,
        url: svfPath,
        objectIds : options.ids,
        queryParams : this.queryParam };  // For CORS caching issue.

    this.streamingWorker.doOperation(avp.initLoadContext(msg));

    return true;
};



F2DLoader.prototype.processReceivedMesh = function(mdata) {

    //Find all fragments that instance this mesh
    var meshid = mdata.packId + ":" + mdata.meshIndex;

    var svf = this.svf;
    var fragments = svf.fragments;

    var fragIndexes = fragments.mesh2frag[meshid];
    if (fragIndexes === undefined) {
        avp.logger.warn("Mesh " + meshid + " was not referenced by any fragments.");
        return;
    }
    if (!Array.isArray(fragIndexes))
        fragIndexes = [fragIndexes];

    //Convert the received mesh to THREE buffer geometry
    avp.BufferGeometryUtils.meshToGeometry(mdata);

    var numInstances = fragIndexes.length;

    var rm = this.model;
    
    //Reuse previous index of this geometry, if available
    var geomId = rm.getGeometryList().addGeometry(mdata.geometry, numInstances, mdata.meshIndex + 1);

    var ib = mdata.geometry.attributes['index'].array || mdata.geometry.ib;
    var polyCount = ib.length / 3;

    //For each fragment, add a mesh instance to the renderer
    for (var i=0; i<fragIndexes.length; i++) {
        var fragId = 0|fragIndexes[i];

        //We get the matrix from the fragments and we set it back there
        //with the activateFragment call, but this is to maintain the
        //ability to add a plain THREE.Mesh -- otherwise it could be simpler
        rm.getFragmentList().getOriginalWorldMatrix(fragId, this.tmpMatrix);

        if (this.options.placementTransform) {
            this.tmpMatrix = new THREE.Matrix4().multiplyMatrices(this.options.placementTransform, this.tmpMatrix);
        }

        var materialId = fragments.materials[fragId].toString();

        if (fragments.polygonCounts)
            fragments.polygonCounts[fragId] = polyCount;

        var m = this.viewer3DImpl.setupMesh(this.model, mdata.geometry, materialId, this.tmpMatrix);
        rm.activateFragment(fragId, m);
    }

    //don't need this mapping anymore.
    fragments.mesh2frag[meshid] = null;

    //Repaint and progress reporting
    fragments.numLoaded += fragIndexes.length;

    var numLoaded = fragments.numLoaded;
};

F2DLoader.prototype.processReceivedMesh2D = function(mesh, mindex) {

    if (this.pagingProxy && !this.pagingProxy.onMeshReceived(mesh, mindex))
        return;

    var mdata = { mesh: mesh, is2d: true, packId : "0", meshIndex: mindex };

    var meshId = "0:" + mindex;

    var frags = this.svf.fragments;

    //Remember the list of all dbIds referenced by this mesh.
    //In the 2D case this is 1->many (1 frag = many dbIds) mapping instead of
    // 1 dbId -> many fragments like in the SVF 3D case.
    var dbIds = Object.keys(mdata.mesh.dbIds).map(function(item){return parseInt(item);});
    frags.fragId2dbId[mindex] = dbIds;

    //TODO: dbId2fragId is not really necessary if we have a good instance tree for the 2D drawing (e.g. Revit, AutoCAD)
    //so we can get rid of this mapping if we can convert Viewer3DImpl.highlightFragment to use the same logic for 2D as for 3D.
    for (var j=0; j<dbIds.length; j++) {
        var dbId = dbIds[j];
        var fragIds = frags.dbId2fragId[dbId];
        if (Array.isArray(fragIds))
             fragIds.push(mindex);
        else if (typeof fragIds !== "undefined") {
            frags.dbId2fragId[dbId] = [fragIds, mindex];
        }
        else {
            frags.dbId2fragId[dbId] = mindex;
        }
    }

    frags.mesh2frag[meshId] = mindex;
    mesh.material.modelScale = this.modelScale;
    var viewer = this.viewer3DImpl;
    frags.materials[mindex] = this.viewer3DImpl.matman().create2DMaterial(this.model, mesh.material, false, false, function() { viewer.invalidate(false, true, false); });

    frags.length++;

    this.processReceivedMesh(mdata);

};

F2DLoader.prototype.onModelRootLoadDone = function(svf) {

    // Root model loading is done, and loader now is attached to model,
    // so can remove the direct reference to it from viewer impl.
    _removeLoadingFile(this.viewer3DImpl, this);


    //In the 2d case we create and build up the fragments mapping
    //on the receiving end.
    svf.fragments = {};
    svf.fragments.mesh2frag = {};
    svf.fragments.materials = [];
    svf.fragments.fragId2dbId = [];
    svf.fragments.dbId2fragId = [];
    svf.fragments.length = 0;
    svf.fragments.initialized = true;


    svf.geomMemory = 0;
    svf.fragments.numLoaded = 0;
    svf.meshCount = 0;
    svf.gpuNumMeshes = 0;
    svf.gpuMeshMemory = 0;

	svf.nextRepaintPolys = 10000;
	svf.numRepaints = 0;

    svf.urn = this.svfUrn;
    svf.acmSessionId = this.acmSessionId;

    svf.basePath = "";
    var lastSlash = this.currentLoadPath.lastIndexOf("/");
    if (lastSlash != -1)
        svf.basePath = this.currentLoadPath.substr(0, lastSlash+1);

    svf.loadOptions = this.options;

    var t1 = Date.now();
    this.loadTime += t1 - this.t0;
    avp.logger.log("SVF load: " + (t1 - this.t0));

    this.t0 = t1;

    //The BBox object loses knowledge of its
    //type when going across the worker thread boundary...
    svf.bbox = new THREE.Box3().copy(svf.bbox);

    //Create the API Model object and its render proxy
    var model = this.model = new av.Model(svf);
    model.loader = this;

    // Let's set the options through for each model that control how memory saving mode start,
    // which decide how to load geometry pack files, and whether paging out if needed.
    // And assume the performance tuning options passed through viewer's config.
    var memPerfOpts = this.memPerfOpts;

    // So, for now do not support on paging for multiple models. 
    if (this.viewer3DImpl.modelQueue().getModels().length > 0) {
        // If already a model loaded into viewer, then disable paging for the other ones.
        memPerfOpts.pageOutGeometryEnabled = false;
    }

    memPerfOpts.pageOutPercentage = memPerfOpts.pageOutPercentage > 0 && memPerfOpts.pageOutPercentage < 1 ?
                                    memPerfOpts.pageOutPercentage : 
                                    avp.PAGEOUT_PERCENTAGE
    if (memPerfOpts.onDemandLoading || memPerfOpts.pixelCullingEnable)
        this.pagingProxy = new F2DPagingProxy(this, memPerfOpts);

    model.initialize(this.pagingProxy);

    //We would not load property db when we are on mobile device AND on demand loading is on (which
    //implies the model is not 'normal' in terms of its size.). This is only a temp solution that
    //allow big models loads on mobile without crash. Without property db loading selection could break.
    var shouldLoadPropertyDb = !(this.model.getFragmentList().onDemandLoadingEnabled() && (av.isMobileDevice()));
    if (shouldLoadPropertyDb && !this.options.skipPropertyDb) {
        this.svf.propWorker = new avp.PropDbLoader(this.sharedDbPath, this.model, this.viewer3DImpl.api);
    }

    avp.logger.log("scene bounds: " + JSON.stringify(svf.bbox));

    var metadataStats = {
        category: "metadata_load_stats",
        urn: svf.urn,
        layers: svf.layerCount
    };
    avp.logger.track(metadataStats);

    this.viewer3DImpl.signalProgress(5);
    this.viewer3DImpl.invalidate(false, false);
};


F2DLoader.prototype.onGeomLoadDone = function() {
    this.svf.loadDone = true;

    // Don't need these anymore
    this.svf.fragments.entityIndexes = null;
    if (!this.memPerfOpts.onDemandLoading)
        this.svf.fragments.mesh2frag = null;

    var t1 = Date.now();
    var msg = "Fragments load time: " + (t1 - this.t0);
    this.loadTime += t1 - this.t0;

    //Load the property database after all geometry is loaded (2D case). For 2D,
    //the fragId->dbId mapping is only fully known once geometry is loaded, as
    //it's built on the fly.
    //TODO: As an optimization we can split the property db logic into two calls -- one to load the files
    //in parallel with the geometry and a second to do the processing.
    if (!this.options.skipPropertyDb)
        this.loadPropertyDb();

    avp.logger.log(msg);

    var modelStats = {
        category: "model_load_stats",
        is_f2d: true,
        has_prism: this.viewer3DImpl.matman().hasPrism,
        load_time: this.loadTime,
        geometry_size: this.model.getGeometryList().geomMemory,
        meshes_count: this.model.getGeometryList().geoms.length,
        urn: this.svfUrn
    };
    avp.logger.track(modelStats, true);

    function sendMessage(data){
        if (av.isBrowser) {
            var handler = window.webkit.messageHandlers.callbackHandler;
            // We add doOperation() function, but on some implementation
            // of the WebWorker, setting a new property on it is not allowed
            // so we fallback onto the wrapped function
            
            // The post message operation has to be called on the instance of handler.
            if (handler.doOperation) {
               handler.doOperation({'command':'assets', data: data});
            }
            else if (handler.postMessage) {
               handler.postMessage({'command':'assets', data: data});
            }

        }
    }

    if (avp.assets) {
        // Callback to ios.
        if (av.isBrowser && window.webkit) {
            sendMessage(avp.assets);
            avp.assets = null;
        }
    }

    this.currentLoadPath = null;
    this.isf2d = undefined;

    this.viewer3DImpl.onLoadComplete(this.model);
};


F2DLoader.prototype.loadPropertyDb = function() {
    if (this.svf.propWorker)
        this.svf.propWorker.load();
};


avp.F2DLoader = F2DLoader;
avp.F2DPagingProxy = F2DPagingProxy;

av.FileLoaderManager.registerFileLoader("f2d", ["f2d"], avp.F2DLoader);


})();
;

(function() {

    "use strict";

    var av = Autodesk.Viewing,
        avp = av.Private;

    var WORKER_GET_PROPERTIES = "GET_PROPERTIES";
    var WORKER_SEARCH_PROPERTIES = "SEARCH_PROPERTIES";
    var WORKER_BUILD_EXTERNAL_ID_MAPPING = "BUILD_EXTERNAL_ID_MAPPING";
    var WORKER_GET_OBJECT_TREE = "GET_OBJECT_TREE";
    var WORKER_ATTRIBUTES_MAP = "ATTRIBUTES_MAP";

    var PropDbLoader = function(sharedDbPath, model, eventTarget) {

        this.sharedDbPath = sharedDbPath;

        this.propWorker = null;

        this.eventTarget = eventTarget || new av.EventDispatcher();

        this.model = model;
        this.svf = model && model.getData();

        //Sigh -- see SvfLoader for similar stuff
        var domainParam = (av.getUseCredentials() && !av.isNodeJS) ? ("domain=" + encodeURIComponent(window.location.origin)) : "";

        this.queryParam = domainParam;
        if (this.svf && this.svf.acmSessionId) {
            if (this.queryParam)
                this.queryParam += "&";
            this.queryParam += "acmsession=" + this.svf.acmSessionId;
        }
    };

    PropDbLoader.prototype.dtor = function() {
        if (this.propWorker && !this.sharedDbPath) {
            this.propWorker.clearAllEventListenerWithIntercept();
            this.propWorker.terminate();
            this.propWorker = null;
        }
    };



    //Cache of property workers per property database path.
    //Many bubbles (Revit, AutoCAD) share the same property database
    //across all viewables, so we can reuse the same worker for all
    //sheets. This is particularly important for gigantic Revit property databases.
    var propWorkerCache = {};

    var PROPDB_CB_COUNTER = 1;
    var PROPDB_CALLBACKS = {};

    function propertyWorkerCallback(e) {

        var data = e.data;

        if (data && data.debug) {
            avp.logger.debug(data.message);
            return;
        }

        if (data.cbId) {
            var cbs = PROPDB_CALLBACKS[data.cbId];

            if (data && data.error) {
                if (cbs[1])
                    cbs[1](data.error);
            } else {
                if (cbs[0])
                    cbs[0](data.result);
            }

            delete PROPDB_CALLBACKS[data.cbId];
        }

    }

    function registerWorkerCallback(onSuccess, onError) {
        var cbId = PROPDB_CB_COUNTER++;

        PROPDB_CALLBACKS[cbId] = [onSuccess, onError];

        return cbId;
    }

    PropDbLoader.prototype.processLoadResult = function(result) {
        var scope = this;

        if (result.instanceTreeStorage) {

            var nodeAccess = new avp.InstanceTreeAccess(result.instanceTreeStorage, result.rootId, result.instanceBoxes);

            scope.instanceTree = new avp.InstanceTree(nodeAccess, result.objectCount, result.maxTreeDepth);

            //For backwards compatibility, svf.instanceTree has to be set also
            if (scope.svf) {
                scope.svf.instanceTree = scope.instanceTree;
            }
        } else if (result.instanceTree) {
            //Case of fake glTF instance tree
            //TODO: the glTF instance tree would have to be converted or warpped inside an avp.InstanceTree
            //in order to be usable by the UI.
            avp.logger.warn("glTF instance tree not supported");

            scope.hasObjectProperties = result.objectCount;
        }
        else if (result.objectCount) {

            //Case where there is no object tree, but objects
            //do still have properties. This is the case for F2D drawings.
            scope.hasObjectProperties = result.objectCount;

            if (scope.svf) {
                scope.svf.hasObjectProperties = result.objectCount;
            }
        }

        scope.eventTarget.fireEvent({
            type: av.OBJECT_TREE_CREATED_EVENT,
            svf:scope.svf,
            model:scope.model,
            target: scope
        });

    };

    PropDbLoader.prototype.processLoadError = function(error) {

        var scope = this;

        scope.propertyDbError = error;

        scope.eventTarget.fireEvent({
            type: av.OBJECT_TREE_UNAVAILABLE_EVENT,
            svf:scope.svf,
            model:scope.model,
            target: scope
        });
    };


    PropDbLoader.prototype.load = function() {
        var scope = this;

        //In the case of glTF, the instance tree is immediately available, loaded
        //together with the geometry payload ("the svf")
        if (this.svf && this.svf.instanceTree && this.svf.instanceBoxes) {
            //Need this call to be async, because some state required
            //by object tree load event handlers is not yet initialized
            //when the PropDbLoader.load() is called (in particular, viewer.model is not assigned at that point)
            setTimeout(function() { scope.processLoadResult(scope.svf); },0);
            return;
        }

        var onObjectTreeRead = function(result) {

            scope.processLoadResult(result);

            //If any other instance of PropDbLoader tried to load
            //the same property database while we were also loading it,
            //notify it with the result also.
            var cacheable = !!scope.sharedDbPath;
            var cached = cacheable && propWorkerCache[scope.sharedDbPath];
            if (cached && cached.waitingLoaders) {
                for (var i=0; i<cached.waitingLoaders.length; i++) {
                    cached.waitingLoaders[i].processLoadResult(result);
                }
                cached.waitingLoaders = null;
                cached.workerResult = result;
            }
        };

        var onObjectTreeError = function(error) {
            scope.processLoadError(error);

            //If any other instance of PropDbLoader tried to load
            //the same property database while we were also loading it,
            //notify it with the result also.
            var cacheable = !!scope.sharedDbPath;
            var cached = cacheable && propWorkerCache[scope.sharedDbPath];
            if (cached && cached.waitingLoaders) {
                for (var i=0; i<cached.waitingLoaders.length; i++) {
                    cached.waitingLoaders[i].processLoadError(error);
                }
                cached.waitingLoaders = null;
                cached.workerError = error;
            }

        };

        //See if we already loaded this property database once
        var cacheable = !!this.sharedDbPath;
        var cached = cacheable && propWorkerCache[this.sharedDbPath];

        if (cached) {
            avp.logger.log("Using cached property worker for ", this.sharedDbPath);
            this.propWorker = cached;
        } else {

            this.propWorker = avp.createWorkerWithIntercept();
            this.propWorker.addEventListenerWithIntercept(propertyWorkerCallback);

            if (cacheable) {
                propWorkerCache[this.sharedDbPath] = this.propWorker;
            }
        }

        var cbId = registerWorkerCallback(onObjectTreeRead, onObjectTreeError);

        var reqPath;
        if (this.svf && this.svf.propertydb.values.length) {
            reqPath = avp.pathToURL(this.svf.basePath);
        } else {
            //If there is a shared db path and there is no
            //per-SVF specific property database, use the shared one
            reqPath = this.sharedDbPath;
            avp.logger.log("Using shared property db: " + reqPath);
        }

        var xfer = { "operation":WORKER_GET_OBJECT_TREE,
                     "url": reqPath,
                     "propertydb" : (this.svf && this.svf.propertydb) || { attrs : [], avs: [], ids: [], values: [], offsets: [] },
                     "fragToDbId": this.svf && this.svf.fragments.fragId2dbId, //the 1:1 mapping of fragment to dbId we got from the SVF or the 1:many we built on the fly for f2d
                     "fragBoxes" : this.svf && this.svf.fragments.boxes, //needed to precompute bounding box hierarchy for explode function (and possibly others)
                     cbId: cbId,
                     queryParams : this.queryParam };

        this.propWorker.doOperation(avp.initLoadContext(xfer)); // Send data to our worker.

    };


    PropDbLoader.prototype.asyncPropertyOperation = function(opArgs, success, fail) {

        var scope = this;

        if (scope.instanceTree || scope.hasObjectProperties) {

            opArgs.cbId = registerWorkerCallback(success, fail);

            this.propWorker.doOperation(opArgs); // Send data to our worker.
        } else if (scope.propertyDbError) {
            if (fail)
                fail(scope.propertyDbError);
        } else {
            var onEvent = function(e) {
                scope.eventTarget.removeEventListener(av.OBJECT_TREE_CREATED_EVENT, onEvent);
                scope.eventTarget.removeEventListener(av.OBJECT_TREE_UNAVAILABLE_EVENT, onEvent);
                if (scope.instanceTree || scope.hasObjectProperties || scope.propertyDbError)
                    scope.asyncPropertyOperation(opArgs, success, fail);
                else if (fail)
                    fail({code:av.UNKNOWN_FAILURE, msg:"Failed to load properties"}); //avoid infinite recursion.
            };
            scope.eventTarget.addEventListener(av.OBJECT_TREE_CREATED_EVENT, onEvent);
            scope.eventTarget.addEventListener(av.OBJECT_TREE_UNAVAILABLE_EVENT, onEvent);
        }
    };


    PropDbLoader.prototype.getProperties = function(dbId, onSuccess, onError) {

        this.asyncPropertyOperation(
            {
                "operation":WORKER_GET_PROPERTIES,
                "dbId": dbId
            },
            onSuccess, onError
        );
    };

    /**
     * Bulk property retrieval with property name filter.
     * dbIds -- array of object dbIds to return properties for.
     * propFilter -- array of property names to retrieve values for. If empty, all properties are returned.
     * ignoreHidden -- ignore hidden properties
     */
    PropDbLoader.prototype.getBulkProperties = function(dbIds, propFilter, onSuccess, onError, ignoreHidden) {

        this.asyncPropertyOperation(
            {
                "operation":WORKER_GET_PROPERTIES,
                "dbIds": dbIds,
                "propFilter": propFilter,
                "ignoreHidden": ignoreHidden
            },
            onSuccess, onError
        );
    };


    PropDbLoader.prototype.searchProperties = function(searchText, attributeNames, onSuccess, onError, completeInfo) {

        this.asyncPropertyOperation(
            {
                "operation": WORKER_SEARCH_PROPERTIES,
                "searchText": searchText,
                "attributeNames" : attributeNames,
                "completeInfo": completeInfo
            },
            onSuccess, onError
        );
    };


    PropDbLoader.prototype.getExternalIdMapping = function(onSuccess, onError) {

        this.asyncPropertyOperation(
            {
                "operation": WORKER_BUILD_EXTERNAL_ID_MAPPING
            },
            onSuccess, onError
        );
    };


    PropDbLoader.prototype.getObjectTree = function(onSuccess, onError) {
        var scope = this;

        if (scope.instanceTree) {
            onSuccess(scope.instanceTree);
        } else if (scope.propertyDbError || 'hasObjectProperties' in scope) {
            if (onError)
                onError(scope.propertyDbError);
        } else {
            // Property Db has been requested; waiting for worker to complete //
            var listener = function() {
                scope.eventTarget.removeEventListener(av.OBJECT_TREE_CREATED_EVENT, listener);
                scope.eventTarget.removeEventListener(av.OBJECT_TREE_UNAVAILABLE_EVENT, listener);
                scope.getObjectTree(onSuccess, onError);
            };
            scope.eventTarget.addEventListener(av.OBJECT_TREE_CREATED_EVENT, listener);
            scope.eventTarget.addEventListener(av.OBJECT_TREE_UNAVAILABLE_EVENT, listener);
        }
    };

    avp.PropDbLoader = PropDbLoader;

})();
;
(function() {

var av = Autodesk.Viewing,
    avp = av.Private;

    var endpoint = "";
    var useCredentials = false;
    var needsBubble = false;
    var isViewingV1 = true; // false to use derivativeservice/v2/

    av.HTTP_REQUEST_HEADERS = {};

    av.getApiEndpoint = function() {
        return endpoint;
    };

    av.setApiEndpoint = function(val, bubbleManifest, isV1) {
        endpoint = val;
        needsBubble = bubbleManifest;
        isViewingV1 = isV1;

        if (!isViewingV1) {
            needsBubble = false; // /v2/ doesn't support the /bubbles/ url-route
        }
    };

    av.getViewingUrl = function(root) {
        if (isViewingV1)
            return (root || endpoint) + '/viewingservice/v1';
        else
            return (root || endpoint) + '/derivativeservice/v2';
    };

    av.getUseCredentials = function() {
        return useCredentials;
    };

    av.setUseCredentials = function(val) {
        useCredentials = val;
    };

    av.getManifestApi = function(root) {
        var base = av.getViewingUrl(root);
        if (needsBubble) 
            return base + "/bubbles/";  // Only applies to /v1/ accessed from viewing.api
        else if (isViewingV1)
            return base + '/';
        else
            return base + '/manifest/';
    };

    av.getItemApi = function(root) {
        if (isViewingV1)
            return av.getViewingUrl(root) + "/items/";
        else
            return av.getViewingUrl(root) + "/derivatives/";
    };

    av.getThumbnailApi = function(root) {
        return av.getViewingUrl(root) + "/thumbnails/";
    };

    av.makeOssPath = function(root, bucket, object) {
        return (root || endpoint) + "/oss/v2/buckets/" + bucket + "/objects/" + encodeURIComponent(decodeURIComponent(object));
    }

})();
;

(function() {

var av = Autodesk.Viewing,
    avp = av.Private;

    var global = av.getGlobal();

    global.PROTEIN_ROOT = null;
    global.PRISM_ROOT = null;
    global.LOCALIZATION_REL_PATH = "";
    global.LMV_VIEWER_VERSION = "@build_version@";  // Gets replaced with content from deployment/package.json
    global.LMV_VIEWER_PATCH = "@build_number@";// Gets replaced with build number from TeamCity
    global.LMV_BUILD_TYPE = "@build_type@"; // Either Development, Staging or Production
    global.LMV_RESOURCE_VERSION = null;
    global.LMV_RESOURCE_ROOT = "";
    global.LMV_THIRD_PARTY_COOKIE = undefined;

    if (LMV_VIEWER_VERSION.charAt(0) === 'v'){
        // remove prefixed 'v'
        // Required due to TeamCity build pipeline (LMV-1361)
        LMV_VIEWER_VERSION = LMV_VIEWER_VERSION.substr(1);
    }


    global.stderr = function() {
        console.warn('"stderr" is deprecated; please use "Autodesk.Viewing.Private.logger" instead');
    };

    avp.env = null;
    // GUID of the current active document item.
    avp.docItemId = null;

    avp.token = {
        accessToken : null,
        getAccessToken : null,
        tokenRefreshInterval : null
    };

    // ??? Loading options, put it as global configs and default to be false.
    // ??? This will control whether use a different package reader with 
    // ??? less memory consumption for 'large' models.
    avp.memoryOptimizedSvfLoading = false;
    // This force to enable a memory optimized mode for svf loading. 
    // (for testing purpose only)
    avp.forceMemoryOptimizedModeOnSvfLoading = false;

    // A list of resources that record the URL and necessary auxilary information (such as ACM headers and / or
    // session id) required to get the resource. This bag of collection will be passed from JS to native code so
    // all viewer consumable resources could be downloaded on native side for offline viewing.
    // avp.assets = isAndroidDevice() ? [] : null;
    avp.assets = [];
    // Set viewer in offline mode if set to true. In offline mode, viewer would ignore all URNs in bubble JSON
    // and assume the viewables are laid out in local file system path relative to the bubble.json.
    avp.offline = false;
    // Offline resource prefix specified by viewer consumer (e.g. IOS web view). Used as prefix to concatenate with
    // each resource relative path to form the absolute path of each resource.
    avp.offlineResourcePrefix = null;

    var LmvEndpoints = {
        local: {
            RTC:        ['https://rtc-dev.api.autodesk.com:443', 'https://lmv.autodesk.com:443'] //port # is required here.
        },
        dev: {
            RTC:        ['https://rtc-dev.api.autodesk.com:443', 'https://lmv.autodesk.com:443']
        },
        stg: {
            RTC:        ['https://rtc-stg.api.autodesk.com:443', 'https://lmv.autodesk.com:443']
        },
        prod: {
            RTC:        ['https://rtc.api.autodesk.com:443', 'https://lmv.autodesk.com:443']
        }
    };

    var ViewingApiUrls = {
        local: "",
        dev: "https://viewing-dev.api.autodesk.com",
        stg: "https://viewing-staging.api.autodesk.com",
        prod: "https://viewing.api.autodesk.com"
    };

    var DevApiUrls = {
        local: "",
        dev: "https://developer-dev.api.autodesk.com",
        stg: "https://developer-stg.api.autodesk.com",
        prod: "https://developer.api.autodesk.com"
    };

    // The apps on https://developer.autodesk.com had to be created under an ADS account... Ask for brozp
    var AdpConfigs = {
        stg: { CLIENT_ID: 'lmv-stag', CLIENT_KEY: 'kjemi1rwAgsqIqyvDUtc9etPD6MsAzbV', ENDPOINT: 'https://ase-stg.autodesk.com' },
        prod: { CLIENT_ID: 'lmv-prod', CLIENT_KEY: 'iaoUM2CRGydfn703yfPq4MAogZi8I5u4', ENDPOINT: 'https://ase.autodesk.com' }
    };

    avp.EnvironmentConfigurations = {
        Local: {
            ROOT:       '',
            LMV:        LmvEndpoints["local"]
        },
        Development: {
            ROOT:       ViewingApiUrls["dev"],
            LMV:        LmvEndpoints["dev"],
            bubbleManifest: true
        },
        Staging: {
            ROOT:       ViewingApiUrls["stg"],
            LMV:        LmvEndpoints["stg"],
            bubbleManifest: true
        },
        Production: {
            ROOT:       ViewingApiUrls["prod"],
            LMV:        LmvEndpoints["prod"],
            bubbleManifest: true
        },
        AutodeskDevelopment: {
            ROOT:       DevApiUrls["dev"],
            LMV:        LmvEndpoints["dev"]
        },
        AutodeskStaging: {
            ROOT:       DevApiUrls["stg"],
            LMV:        LmvEndpoints["stg"]
        },
        AutodeskProduction: {
            ROOT:       DevApiUrls["prod"],
            LMV:        LmvEndpoints["prod"]
        }
    };


    avp.initializeEnvironmentVariable = function (options) {
        var env;

        // Use the enviroment that was explicitly specified.
        //
        if (options && options.env) {
            env = options.env;
        }

        // If not available, check if the environment was specified in the query parameters.
        //
        if (!env) {
            env = avp.getParameterByName("env");
        }

        if (options && options.offlineResourcePrefix) {
            avp.offlineResourcePrefix = options.offlineResourcePrefix;
        }

        if (options && options.offline && options.offline === "true") {
            avp.offline = true;
        }

        // If still not available, try to resolve the environment based on the url.
        //
        if (!env) {
            switch (window.location.hostname) {
                case "viewing-dev.api.autodesk.com" :
                    env = 'Development';
                    break;
                case "viewing-staging.api.autodesk.com" :
                    env = 'Staging';
                    break;
                case "viewing.api.autodesk.com" :
                    env = 'Production';
                    break;
                case "developer-dev.api.autodesk.com" :
                    env = 'AutodeskDevelopment';
                    break;
                case "developer-stg.api.autodesk.com" :
                    env = 'AutodeskStaging';
                    break;
                case "developer.api.autodesk.com" :
                    env = 'AutodeskProduction';
                    break;

                case "localhost.autodesk.com" :
                    env = 'Local';
                    break;
                case "" : // IP addresses on Chrome.
                    env = 'Local';
                    break;
                case "127.0.0.1" :
                    env = 'Local';
                    break;
                default:
                    env = 'AutodeskProduction';
            }
        }

        if (avp.ENABLE_TRACE) {
            if (typeof window !== "undefined")
                console.log("Host name : " + window.location.hostname);
            console.log("Environment initialized as : " + env);
        }
        avp.env = env;
    };

    avp.initializeServiceEndPoints = function (options) {

        var endpoint = options.endpoint;
        var bubbleManifest = options.bubbleManifest;
        var isV1 = !options.useDerivativeServiceV2;
        if (!endpoint) {
            var config = avp.EnvironmentConfigurations[avp.env];
            endpoint = config['ROOT'];
            bubbleManifest = config.bubbleManifest && isV1;
        }
        // TODO: This design (or lack thereof) has outgrown the feature set
        av.setApiEndpoint(endpoint, bubbleManifest, isV1);

        if (av.isNodeJS)
            return;

        //Derive the root for static viewer resources based on the
        //location of the main viewer script
        var libList = [
            "viewer3D.js",
            "viewer3D.min.js",
            "firefly.js",
            "firefly.min.js"
        ];
        if (options && options.hasOwnProperty('libraryName'))
            libList.push(options.libraryName);

        var root;
        var scriptUrl;

        // TODO_NOP: this doesn't work for Polymer / Web Components
        for (var i=0; i<libList.length; i++) {
            var script = avp.getScript(libList[i]);
            scriptUrl = script ? script.src : "";
            var idx = scriptUrl.indexOf(libList[i]);
            if (idx >= 0) {
                root = scriptUrl.substr(0, idx);
                break;
            }
        }

        //Derive any custom version request
        LMV_RESOURCE_VERSION = "v" + LMV_VIEWER_VERSION;

        var version = avp.getParameterByNameFromPath("v", scriptUrl);
        if (version && version.length && version != LMV_RESOURCE_VERSION) {
            console.warn("Version string mismatch between requested and actual version: " + version + " vs. " + LMV_RESOURCE_VERSION + ". Using " + version);
            LMV_RESOURCE_VERSION = version;
        } else if (!version || !version.length) {
            LMV_RESOURCE_VERSION = null;
            console.info("No viewer version specified, will implicitly use " + LMV_VIEWER_VERSION);
        }

        LMV_RESOURCE_ROOT = root || LMV_RESOURCE_ROOT;
    };


    avp.initLoadContext = function(inputObj) {

        inputObj = inputObj || {};

        inputObj.auth = av.getUseCredentials();
        inputObj.endpoint = av.getApiEndpoint();

        if (!inputObj.headers)
            inputObj.headers = {};

        for (var p in av.HTTP_REQUEST_HEADERS) {
            inputObj.headers[p] = av.HTTP_REQUEST_HEADERS[p];
        }

        return inputObj;
    };

    avp.refreshCookie = function(token, onSuccess, onError) {

        var xhr = new XMLHttpRequest();
        xhr.onload = onSuccess;
        xhr.onerror = onError;
        xhr.ontimeout = onError;

    // We support two set token end points, the native VS end point and the wrapped apigee end point.
        if (avp.env.indexOf('Autodesk') === 0) {
            // This really sucks, as Apigee end points use different naming pattern than viewing service.
            var url = avp.EnvironmentConfigurations[avp.env].ROOT;

            xhr.open("POST", url + "/utility/v1/settoken", true);
            xhr.setRequestHeader("Content-Type", "application/x-www-form-urlencoded");
            xhr.withCredentials = true;

            xhr.send("access-token=" + token);

            // Here we control whether to go through IE 11's authentication code path or not.
            if (av.isIE11) {
                avp.accessToken = token;
            }
        }
        else {
            var token =
            {
                "oauth": {
                    "token": token
                }
            };

            // console.log("auth token : " + JSON.stringify(token));

            xhr.open("POST", av.getViewingUrl() + "/token", true);
            xhr.setRequestHeader("Content-Type", "application/json");
            xhr.withCredentials = true;

            xhr.send(JSON.stringify(token));
        }

    };

    // Refresh the token in request header, in case that the third party cookie is disabled
    avp.refreshRequestHeader = function(token) {

        av.HTTP_REQUEST_HEADERS["Authorization"] = "Bearer " + token;

    };

    avp.refreshToken = function(token, onSuccess, onError) {

        // Store the token, it will be used when third-party cookies are disabled
        avp.token.accessToken = token;

        // At the beginning, try to store the token in cookie
        if (LMV_THIRD_PARTY_COOKIE === undefined) {
            avp.refreshCookie(token, onSuccess, onError);
        } else {
            doTokenRefresh();
        }

        // if third-party cookies are enabled in browser, then put token in cookie
        // if not, put token into request header
        function doTokenRefresh() {

            if (LMV_THIRD_PARTY_COOKIE) {

                avp.refreshCookie(token, onSuccess, onError);

            } else {

                avp.refreshRequestHeader(token);
                onSuccess();

            }
        }

    };

    avp.initializeAuth = function (onSuccessCallback, options) {

        var shouldInitializeAuth = options ? options.shouldInitializeAuth : undefined;
        if (shouldInitializeAuth === undefined) {
            var p = avp.getParameterByName("auth");
            shouldInitializeAuth = (p.toLowerCase() !== "false");
        }

        //Skip Auth in case we are serving the viewer locally
        if (avp.env == "Local" || !shouldInitializeAuth) {
            setTimeout(onSuccessCallback, 0);
            av.setUseCredentials((typeof options.useCredentials !== "undefined") ? options.useCredentials : false);
            return av.getUseCredentials();
        }

        //For Node.js, we will use the Authorization header instead of cookie
        if (av.isNodeJS)
            LMV_THIRD_PARTY_COOKIE = false;

        av.setUseCredentials((typeof options.useCredentials !== "undefined") ? options.useCredentials : true);

        var accessToken;
        if (options && options.getAccessToken) {
            function onGetAccessToken(token /* access token value. */, expire /* expire time, in seconds. */) {
                accessToken = token;
                avp.refreshToken(accessToken, avp.token.tokenRefreshInterval ? null /* If this is a token refresh call,
                 don't invoke the onSuccessCallback which will loadDocument and so on. */
                    : onSuccessCallback);
                var interval = expire - 60; // Refresh 1 minute before token expire.
                if (interval <= 0) {
                    // We can't get a precise upper bound if the token is such a short lived one (expire in a minute),
                    // so just use the original one.
                    interval = expire;
                }
                avp.token.tokenRefreshInterval = interval * 1000;
                setTimeout(function() {options.getAccessToken(onGetAccessToken)}, avp.token.tokenRefreshInterval);
            }
            avp.token.getAccessToken = options.getAccessToken;

            accessToken = options.getAccessToken(onGetAccessToken);

            //Backwards compatibility with the old synchronous API
            if (typeof accessToken == "string" && accessToken) {
                avp.refreshToken(accessToken, onSuccessCallback);
            }

        } else if (options && options.accessToken) {
            accessToken = options.accessToken;
            avp.refreshToken(accessToken, onSuccessCallback);
        } else {
            accessToken = avp.getParameterByName("accessToken");
            if (!accessToken) {
                accessToken = "9AMaRKBoPCIBy61JmQ8OLLLyRblS";
                avp.logger.warn("Warning : no access token is provided. Use built in token : " + accessToken);
            }
            avp.refreshToken(accessToken, onSuccessCallback);
        }

        //TODO: this seems like a pointless thing to return
        return av.getUseCredentials();
    };

    avp.initializeLogger = function (options) {

        var loggerConfig = {
            eventCallback: options ? options.eventCallback : undefined
        };

        avp.logger.initialize(loggerConfig);

        // ADP is opt-out
        if (options && options.hasOwnProperty('useADP') && options.useADP == false) {
            return;
        }
        //Also bail on ADP if we are a node module
        if (av.isNodeJS)
            return;

        // Load Autodesk Data Platform client
        // (and if we're in RequireJS environment, use its APIs to avoid problems)
        var url = 'https://ase-cdn.autodesk.com/adp/v1.0.3/js/adp-web-analytics-sdk.min.js';
        var callback = function() {
            if (typeof (Adp) === 'undefined') {
                avp.logger.warn('Autodesk Data Platform SDK not found');
                return;
            }

            var adpConfig;
            switch (LMV_BUILD_TYPE) {
                case 'Production': adpConfig = AdpConfigs['prod']; break;
                default: adpConfig = AdpConfigs['stg']; break;
            }
            var facets = {
                product: {
                    name: 'LMV',
                    line_name: 'LMV',
                    key: adpConfig.CLIENT_ID,
                    id: adpConfig.CLIENT_KEY,
                    id_provider: 'appkey',
                    build_id: LMV_VIEWER_VERSION + '.' + LMV_VIEWER_PATCH,
                    build_tag: LMV_BUILD_TYPE
                }
            };
            var config = {
                server: adpConfig.ENDPOINT,
                enable_geo_data: false,
                enable_browser_data: true,
                enable_session_messages: true
            };
            avp.logger.adp = new Adp(facets, config);
        };

        if (typeof requirejs !== 'undefined') {
            requirejs([url], function(adp) {
                window['Adp'] = adp;
                callback();
            });
        } else {
            avp.loadDependency('Adp', url, callback);
        }
    };

    avp.initializeProtein = function () {

        //For local work, don't redirect texture requests to the CDN,
        //because local ones will load much faster, presumably.
        if (avp.ENABLE_DEBUG && avp.env == "Local" && !av.getUseCredentials() /* when auth is true, the viewer is operating under
        local mode but connect to remote server to get data. */)
            return;

        // In offline mode, viewer will get the texture from the locally cached SVF data sets, instead pinging texture
        // CDN.
        // TODO: this will break when translators stop including Protein into SVF.
        if (avp.offline) {
            return;
        }

        var xhr1 = new XMLHttpRequest();
        xhr1.open("GET", "https://raas-assets.autodesk.com/StaticContent/BaseAddress?family=protein", true);
        xhr1.responseType = "json";

        xhr1.onload = function (e) {
            var res = xhr1.response.url;
            if (res && res.length) {
                res = res.replace("http://", "https://");
                PROTEIN_ROOT = res + "/";
                avp.logger.info("Protein root is: " + PROTEIN_ROOT);
            }
        };

        xhr1.send();

        var xhr2 = new XMLHttpRequest();
        xhr2.open("GET", "https://raas-assets.autodesk.com/StaticContent/BaseAddress?family=prism", true);
        xhr2.responseType = "json";

        xhr2.onload = function (e) {
            var res = xhr2.response.url;
            if (res && res.length) {
                res = res.replace("http://", "https://");
                PRISM_ROOT = res + "/";
                avp.logger.info("Prism root is: " + PRISM_ROOT);
            }
        };

        //xhr.onerror = ;
        //xhr.ontimeout = ;

        xhr2.send();
    };

// Returns the query parameter value from window url
    avp.getParameterByName = function (name) {
        if (typeof window === "undefined") {
            return "";
        }
        return avp.getParameterByNameFromPath(name, window.location.href);
    };

// return value of parameter from a url
    avp.getParameterByNameFromPath = function (name, url) {
        name = name.replace(/[\[]/, "\\\[").replace(/[\]]/, "\\\]");
        var regexS = "[\\?&]" + name + "=([^&#]*)";
        var regex = new RegExp(regexS);
        var results = regex.exec(url);
        if (results == null)
            return "";
        else
            return decodeURIComponent(results[1].replace(/\+/g, " "));
    };

    avp.urlIsApiViewingOrDev = function(url) {
                // Dev API endpoints
        return  url.indexOf('developer.api.autodesk.com') !== -1 ||
                url.indexOf('developer-stg.api.autodesk.com') !== -1 ||
                url.indexOf('developer-dev.api.autodesk.com') !== -1 ||
                // Viewing API endpoints
                url.indexOf('viewing.api.autodesk.com') !== -1 ||
                url.indexOf('viewing-staging.api.autodesk.com') !== -1 ||
                url.indexOf('viewing-dev.api.autodesk.com') !== -1;
    };

// Return a default document URN for demo purpose.
    avp.getDemoDocumentURN = function () {
        var documentId;

        switch (avp.env) {
            case "Development" :
                //documentId = "urn:dXJuOmFkc2sub2JqZWN0czpvcy5vYmplY3Q6Y29sdW1idXMvTWljaGFlbF9IYW5kLV8tYjE0MDk3ODQxNzcwMDZSQ0Nhci5kd2Y";
                documentId = "urn:dXJuOmFkc2suYTM2MGJldGFkZXY6ZnMuZmlsZTplbnRlcnByaXNlLmxtdnRlc3QuRFM1YTczMFFUYmYwMDIyZDA3NTFhYmE5MjZlZDZkMjJlZDY0P3ZlcnNpb249MQ==";
                break;
            case "Staging" :
                documentId = "urn:dXJuOmFkc2suczM6ZGVyaXZlZC5maWxlOlZpZXdpbmdTZXJ2aWNlVGVzdEFwcC91c2Vycy9NaWNoYWVsX0hhbicvTU0zNTAwQXNzZW1ibHkuZHdm";
                break;
            case "Production" :
                documentId = "FIXME";
                break;
            default:
                //documentId = "urn:dXJuOmFkc2suczM6ZGVyaXZlZC5maWxlOlZpZXdpbmdTZXJ2aWNlVGVzdEFwcC91c2Vycy9NaWNoYWVsX0hhbmAvUkMgQ2FyLmR3Zg"
                documentId = "https://lmv.rocks/viewer/data/gears/output/bubble.json";
        }

        return documentId;
    };

    avp.setLanguage = function (language, callback) {

        var options = {
            lng: language,
            resGetPath: 'res/locales/__lng__/__ns__.json',
            ns: {
                namespaces: ['allstrings'],
                defaultNs: 'allstrings'
            },
            fallbackLng: "en",
            debug: false
        };

        LOCALIZATION_REL_PATH = "res/locales/" + language + "/";
        Autodesk.Viewing.i18n.init(options, function (t) {
            Autodesk.Viewing.i18n.clearDebugLocString(); //Calls localize as well
            if (callback) {
                callback();
            }
        });
    };

    avp.initializeLocalization = function (options) {
        // Initialize language for localization. The corresponding string files
        // will be downloaded.
        var language = (options && options.language) || navigator.language;

        // use iso scheme (ab/ab-XY)
        var tags = language.split('-');
        language = tags.length > 1 ? tags[0].toLowerCase() + '-' + tags[1].toUpperCase() : tags[0].toLowerCase();

        // check supported language tags and subtags
        var supportedTags = ["cs", "de", "en", "es", "fr", "it", "ja", "ko", "pl", "pt-BR", "ru", "tr", "zh-HANS", "zh-HANT"];
        if (supportedTags.indexOf(language) === -1) {
            if (language.indexOf("zh-CN") > -1) language = "zh-HANS";
            else if (language.indexOf("zh-TW") > -1) language = "zh-HANT";
            else if (tags.length > 1 && supportedTags.indexOf(tags[0]) > -1) language = tags[0];
            else language = "en";
        }

        // Uncomment below to default to english
        //language = "en";
        avp.setLanguage(language);
    };

    avp.initializeUserInfo = function (options) {
        if (!options || !options.userInfo) return;
        avp.setUserName(options.userInfo.name);
        if (options.comment2Token) {
            avp.comment2Token = options.comment2Token;
        }
    };


// TODO:  This is here for now, until we find a better place for it.
//
    /**
     * Returns the first source url found containing the given script name.
     * @private
     * @param {string} scriptName - Script name.
     * @returns {HTMLScriptElement} The script element whose source location matches the input parameter.
     */
    avp.getScript = function (scriptName) {
        scriptName = scriptName.toLowerCase();
        var scripts = document.getElementsByTagName('SCRIPT');
        if (scripts && scripts.length > 0) {
            for (var i = 0; i < scripts.length; ++i) {
                if (scripts[i].src && scripts[i].src.toLowerCase().indexOf(scriptName) !== -1) {
                    return scripts[i];
                }
            }
        }
        return null;
    };

    /**
     * Returns the full url of a resource with version.
     * The version will be determined from the LMV_VIEWER_VERSION variable.
     * @private
     * @param {string} resourceRelativePath - The path of the resource relative to LMV_RESOURCE_ROOT.
     * @returns {string} The full resource path.
     */
    avp.getResourceUrl = function (resourceRelativePath) {
        var version = LMV_RESOURCE_VERSION;
        return LMV_RESOURCE_ROOT + resourceRelativePath + (version ? ('?v=' + version) : '');
    };

    /**
     * Loads a script (e.g. an external library JS) and calls the callback once loaded.
     * Used for delayed loading of required libraries. Accepts both relative and absolute URLs.
     */
    avp.loadDependency = function(libNamespace, libName, callback) {
        if (typeof window[libNamespace] == "undefined") {
            var s = document.createElement("SCRIPT");
            s.src = libName.indexOf('://') > 0 ? libName : avp.getResourceUrl(libName);
            document.head.appendChild(s);
            if (callback)
                s.onload = callback;
        }
        else if (callback)
            callback();
    };


    /**
     * Helper class for initializing the viewer runtime.
     *
     * Includes:
     *  - End points of cloud services the viewer uses, like viewing service and search service.
     *  - Authentication and authorization cookie settings on the client side.
     *  - Misc runtime environment variables and viewer configurations parameters.
     *
     * @constructor
     * @param {object} options - The options object contains configuration parameters used to do initializations. If no
     * access token or authentication callback is provided, the Initializer will fall back
     * on an access token provided in the URL query string, or a previous access token stored in
     * the cookie cache, if available.
     * @param {string} [options.env] - Can be "Development", "Staging" or "Production", for viewers running without PAAS
     * endpoints. Can be "AutodeskDevelopment", "AutodeskStaging", or "AutodeskProduction"
     * for viewers running with PAAS endpoints.
     * @param {function} [options.getAccessToken] - An function that provides an access token asynchronously.
     * The function signature is `getAccessToken(onSuccess)`, where onSuccess is a callback that getAccessToken
     * function should invoke when a token is granted, with the token being the first input parameter for the
     * onSuccess function, and the token expire time (in seconds) being the second input parameter for the
     * function. Viewer relies on both getAccessToken and the expire time to automatically renew token, so
     * it is critical that getAccessToken must be implemented as described here.
     * @param {boolean} [options.useADP] - Whether to report analytics to ADP. True by default.
     * @param {string} [options.accessToken] - An access token.
     * @param {string} [options.webGLHelpLink] - A link to a help page on webGL if it's disabled.
     * @param {string} [options.language] - Preferred language code as defined in RFC 4646, such as "en", "de", "fr", etc.
     * If no language is set, viewer will pick it up from the browser. If language is not as defined in RFC,
     * viewer will fall back to "en" but the behavior is undefined.
     * @param {function} callback - A method the client executes when initialization is finished.
     * @example
     *  var options = {
     *     env: "Production",
     *     language: "en",
     *     webGLHelpLink: "http://my.webgl.help.link",
     *     getAccessToken: function(onSuccess) {
     *         var accessToken, expire;
     *         // Code to retrieve and assign token value to
     *         // accessToken and expire time in seconds.
     *         onSuccess(accessToken, expire);
     *     }
     *  };
     *  var callback = function() {
     *     alert("initialization complete");
     *  };
     *  Autodesk.Viewing.Initializer(options, callback);
     * @category Core
     */
    Autodesk.Viewing.Initializer = function (options, callback) {

        if (av.isNodeJS) {

            avp.initializeEnvironmentVariable(options);
            avp.initializeServiceEndPoints(options);
            avp.initializeLogger(options);
            //avp.initializeProtein(); //TODO:NODE

            //init_three_dds_loader(); //TODO:NODE
            //init_three_pvr_loader(); //TODO:NODE
            avp.initializeAuth(callback, options);

        } else {

            avp.WEBGL_HELP_LINK = options ? options.webGLHelpLink : null;
            avp.initializeEnvironmentVariable(options);
            avp.initializeServiceEndPoints(options);
            avp.initializeLogger(options);
            avp.initializeProtein();

            function init() {
                avp.initializeLegacyNamespaces(false);

                //Temporarily silence THREE.warn due to new builds of Chrome producing oodles of shader compile warnings.
                THREE.warn = avp.logger.warn.bind(avp.logger);

                init_three_dds_loader();
                init_three_pvr_loader();
                avp.initializeAuth(callback, options);
                avp.initializeLocalization(options);
                avp.initializeUserInfo(options);
            }

            //Kick off a request for the web worker script, so it loads in parallel with three.js
            avp.initWorkerScript();

            //Load three.js & wgs.js, then continue initialization
            avp.loadDependency('THREE', 'three.min.js', function() {
                avp.loadDependency('WGS', 'wgs.js', init);
            });
        }
    };

})();
;

(function() {

var https = require('https');
var events = require('events');

function AdskAuth(endpoint, key, secret) {

    events.EventEmitter.call(this);

    this.endpoint = endpoint;
    this.key = key;
    this.secret = secret;
    this.currentToken = null;
    this.timeoutId = undefined;
}

AdskAuth.Event = {
    TOKEN_REFRESH: "tokenRefresh",
    TOKEN_ERROR: "tokenError"
};

AdskAuth.prototype.__proto__ = events.EventEmitter.prototype;

AdskAuth.prototype.getTokenString = function() {
    return this.currentToken.access_token;
};

AdskAuth.prototype.refreshToken = function(callback) {

    var self = this;

    //If we are called explicitly, cancel any pending
    //self-refresh.
    if (this.timeoutId)
        clearTimeout(this.timeoutId);

	var dataString = "client_id=" + this.key
					+ "&client_secret=" + this.secret
					+ "&grant_type=client_credentials"
					+ "&scope=data:read data:write bucket:create bucket:update bucket:read";

    var headers = {
        "Content-Type": "application/x-www-form-urlencoded"
    };

	var options = {
  		host: this.endpoint,
  		port: 443,
  		path: "/authentication/v1/authenticate",
  		method: "POST",
  		headers: headers,

  		// only for dev!
  		rejectUnauthorized: false,
        requestCert: true,
        agent: false
	};

	var req = https.request(options, function(res) {
  		res.setEncoding("utf8");
  		var responseString = "";

  		res.on("data", function (data) {
    		responseString += data;
  		});

  		res.on("end", function() {

            if (res.statusCode == 200) {

                var token = JSON.parse(responseString);

                self.currentToken = token;

                console.log("Got a token: " + token.access_token);

                //Schedule a token refresh a few seconds before
                //the current token expires.
                var timeout = (token.expires_in - 5) * 1000;
                if (timeout > 0)
                    self.timeoutId = setTimeout(function () {
                            self.refreshToken(callback);
                        }
                        , timeout);

                if (callback) callback(null, token);

                self.emit(AdskAuth.Event.TOKEN_REFRESH, token);

            } else {

                console.log("Token fetch failed.", res.statusCode, responseString);

                if (callback)
                    callback(res.statusCode, null);

                self.emit(AdskAuth.Event.TOKEN_ERROR, res.statusCode);

                //If token get fails, try again in a few seconds.
                //TODO: Make the timing variable
                self.timeoutId = setTimeout(function () {
                    self.refreshToken(callback);
                }, 5000);

            }
    	});
    });

    req.write(dataString);
    req.end();
};


exports.AdskAuth = AdskAuth;


})();;
(function() {

var https   = require('https');
var fs      = require('fs');
var zlib    = require('zlib');
var temp    = require('temp');
var path    = require('path');
var crypto  = require('crypto');
var mkdirp  = require('mkdirp');

var OSSAPI  = '/oss/v2/buckets';

var _config = undefined; // initialized in the Oss constructor

function tryToParseJSON(str) {
    try {
        return JSON.parse(str);
    } catch(err) {
        return str;
    }
}

function calculateChecksum(fileName, callback) {
    var shasum = crypto.createHash('sha1');

    var s = fs.ReadStream(fileName);
    s.on('data',  function(d) { shasum.update(d);                     });
    s.on('end',   function()  { callback(null, shasum.digest('hex')); });
    s.on('error', function(e) { callback(e);                          });
}

/**
 * * Utilities for interacting with the OSS storage service.
 * * https://wiki.autodesk.com/display/saascore/OSS+REST+API+v+1.0%2C+v+2.0
 */
function Oss(host, getTokenString, route) {
    _config = {
        host:           host,
        getTokenString: getTokenString,
        route:          route || OSSAPI
    };
}

function setupRequest(method, path) {
    return {
        host:                  _config.host,
        port:                  '443',
        method:                method,
        path:                  _config.route + (path ? ('/' + path) : ''),
        headers: {
            'authorization':   'Bearer ' + _config.getTokenString()
        }
    };
}

function handleJsonResponse(res, callback) {
    res.setEncoding('utf8');

    var chunks = [];
    res.on("data", function(chunk) {
        chunks.push(chunk);
    });

    res.on("end", function() {
        var str = chunks.join("");
        var result = tryToParseJSON(str);
        if(res.statusCode == 200) {
            callback(null, result);
        } else {
            var error = {
                statusCode:     res.statusCode,
                statusMessage:  res.statusMessage,
                error:          result
            };
            callback(error);
        }
    });
}

function requestJsonResult(options, postData, callback) {
    options.headers['accept'] = 'application/json';                                         // we expect to receive json data
    if(postData) { options.headers['content-type'] = 'application/json'; }                  // we are sending json data in the body

    var req = https.request(options, function(res) { handleJsonResponse(res, callback); }); // init the HTTP request

    req.on('error', callback);                                                              // error handling is simple
    if(postData) { req.write(JSON.stringify(postData)); }                                   // post the json data to the body (if any)
    req.end();                                                                              // finish the request
}

Oss.prototype.setupRequest = setupRequest;

Oss.prototype.createBucket = function(bucket, policy, callback) {
    var content = {
        bucketKey: bucket,
        allow:     [ ],
        policyKey: policy || 'persistent'
    };

    console.log('oss: create bucket: %s', JSON.stringify(content));

    var options = setupRequest('POST', '');
    requestJsonResult(options, content, callback);
};

Oss.prototype.deleteBucket = function(bucket, callback) {
    console.log('oss: delete bucket: %s', bucket);

    var options = setupRequest('DELETE', bucket);
    requestJsonResult(options, null, callback);
};

Oss.prototype.listBuckets = function(callback) {
    console.log('oss: list buckets');

    var options = setupRequest('GET', '');
    requestJsonResult(options, null, callback);
};

Oss.prototype.listObjects = function(bucket, prefix, callback ) {

    console.log('oss: listing objects in %s', bucket);

    var items = [];

    var requestPage = function(startAt) {
        var query = 'limit=100';
        if(prefix) {
            query += '&beginsWith='+encodeURIComponent(prefix);
        }
        if(startAt) {
            query += '&startAt='+encodeURIComponent(startAt);
        }

        //console.log('Querying page...', query);

        var options = setupRequest('GET', bucket + '/objects?' + query);

        requestJsonResult(options, null, function(error, success) {
            if(success) {
                items = items.concat(success.items);
                if(success.next) {
                    requestPage(success.items.pop().objectKey);
                } else {
                    callback(null, items);
                }
            } else {
                callback(error);
            }
        });
    };
    requestPage();
};

Oss.prototype.getBucketDetails = function(bucket, callback) {
    console.log('oss: get bucket details: %s', bucket);

    var options = setupRequest('GET', bucket + '/details');
    requestJsonResult(options, null, callback);
};


Oss.prototype.uploadData = function(bucket, fileKey, data, contentType, callback) {
    console.log('oss: upload data to: %s/%s [%s bytes]', bucket, fileKey, data.length);

    // post the data
    var options = setupRequest('PUT', bucket + '/objects/' + encodeURIComponent(fileKey));
    options.headers['accept']           = 'application/json';
    options.headers['content-type']     = contentType || 'application/stream';
    options.headers['content-length']   = data.length;

    var req = https.request(options, function(res) { handleJsonResponse(res, callback); });
    req.on('error', callback);
    req.write(data);
    req.end();
};

Oss.prototype.uploadFile = function(bucket, fileName, fileKey, callback) {
    fileKey = fileKey || path.basename(fileName);

    var rstream;
    try {
        rstream = fs.createReadStream(fileName);
    } catch(error) {
        callback(error);
        return;
    }

    //Gzip before sending
    //TODO: OSS seems to not like that
    var tmpname = temp.path();

    // ensure that the temp file gets deleted in any case
    // by adding the delete operation to the callback
    var callbackWrap = function(err, success) {
        fs.unlink(tmpname);             // delete the temp file first
        if (callback)
            callback(err, success);    // and then callback the original callback
    };

    //rstream.pipe(zlib.createGzip()).pipe(fs.createWriteStream(tmpname)).on('finish', function() {
    rstream.pipe(fs.createWriteStream(tmpname)).on('finish', function() {

        //Annoyingly, OSS wants the Content-Length up front
        fs.stat(tmpname, function(err, stats) {
            if (err) { callbackWrap(err); return; }

            console.log('oss: upload file to: %s/%s, from: "%s" [%s bytes]', bucket, fileKey, fileName, stats.size);

            var options = setupRequest('PUT', bucket + '/objects/' + encodeURIComponent(fileKey));
            options.headers['accept']           = 'application/json';
            options.headers['content-type']     = 'application/stream';
            options.headers['content-length']   = stats.size;
            //options.headers['content-encoding'] = 'gzip';

            var req = https.request(options, function(res) { handleJsonResponse(res, callbackWrap); });
            req.on('error', callbackWrap);
            fs.createReadStream(tmpname).pipe(req).on('finish', function() { req.end(); });
        });
    });
};

Oss.prototype.updateFile = function(bucket, fileName, fileKey, callback) {
    fileKey = fileKey || path.basename(fileName);

    var scope = this;

    this.getObjectDetails(bucket, fileKey, function(error, details) {
        if (error) {
            // file does not exist yet => upload it
            scope.uploadFile(bucket, fileName, fileKey, callback);
            return;
        }

        calculateChecksum(fileName, function(err, sha1) {
            if(err) { callback(err); return; }

            if (sha1 !== details.sha1) {
                console.log('oss: file exits, but SHA1 differs: %s/%s, %s (local file) vs. %s (oss)', bucket, fileKey, sha1, details.sha1);
                scope.uploadFile(bucket, fileName, fileKey, callback);
            } else {
                console.log('oss: file with same key and hash already exists, skipping upload: %s/%s: %s', bucket, fileKey, sha1);
                callback(null, details);
            }
        });
    })
};


Oss.prototype.downloadStream = function(bucket, fileKey, wstream, callback) {
    console.log('oss: download data from: %s/%s', bucket, fileKey);

    var options = setupRequest('GET', bucket + '/objects/' + encodeURIComponent(fileKey));
    options.headers['accept-encoding'] = 'gzip'; // we can deal with gzipped content

    var req = https.request(options, function(res) {
        if (res.statusCode !== 200) {
            callback(res.statusCode);
            return;
        }

        var out = res;
        if(res.headers['content-encoding'] === 'gzip') {
            out = out.pipe(zlib.createGunzip());
        }

        out.pipe(wstream).on('finish', function() { callback(null, res.statusCode); });
    });

    req.on('error', callback);
    req.end();
};

Oss.prototype.downloadFile = function(bucket, fileKey, fileName, callback) {
    fileName = fileName || fileKey;

    console.log('oss: download file from: %s/%s as: "%s"', bucket, fileKey, fileName);

    try {
        mkdirp.sync(path.dirname(fileName));
        var wstream = fs.createWriteStream(fileName);
        this.downloadStream(bucket, fileKey, wstream, function(err, success) {
            wstream.close();
            callback(err, success);
        });
    } catch(err) {
        callback(err);
    }
};

Oss.prototype.getObjectDetails = function(bucket, fileKey, callback) {
    console.log('oss: get details for: %s/%s', bucket, fileKey);

    var options = setupRequest('GET', bucket + '/objects/' + encodeURIComponent(fileKey) + '/details');
    requestJsonResult(options, null, callback);
};

Oss.prototype.signObject = function(bucket, fileKey, minutes, access, callback) {
    console.log("Signing " + fileKey);

    var body = {
        minutesExpiration: minutes||60
    };

    var options = setupRequest('POST',
        bucket + '/objects/' + encodeURIComponent(fileKey) + '/signed?access=' + (access||'read')
    );
    options.headers['content-type'] = 'application/json';

    requestJsonResult(options, body, callback);
};


Oss.prototype.deleteObject = function(bucket, fileKey, callback) {
    console.log('oss: delete object: %s/%s', bucket, fileKey);

    var options = setupRequest('DELETE', bucket + '/objects/' + encodeURIComponent(fileKey));
    requestJsonResult(options, null, callback);
};

Oss.prototype.grantAccess = function(bucket, consumer_key, access, callback) {
    access = access || 'read';
    console.log('oss: grant %s access to %s to %s.', access, bucket, consumer_key);

    var options = setupRequest('POST', bucket + '/grant');
    options.headers['content-type'] = 'application/json';

    var body = {
        allow: [{
            authId: consumer_key,
            access: access
        }]
    };
    requestJsonResult(options, body, callback);
};

exports.Oss = Oss;

})();;

(function() {

var https = require('https');
var zlib = require('zlib');
var zip = require('node-zip');
var path = require('path');
var mkdirp = require('mkdirp');
var fs = require('fs');

//var crypto = require('crypto');


var _endpoint,
	_a,
	_oss;

var DSAPI = '/derivativeservice/v2/';

function setupRequest(method, path) {
	var req = {
		  host: _endpoint,
		  port: '443',
		  method: method,
		  path: DSAPI + (path || ''),
		  headers: { }
	};

	if (_a) {
		req.headers['Authorization'] = 'Bearer ' + _a.getTokenString();
	}

	if (method === 'GET') {
		req.headers['Accept-Encoding'] = 'gzip, deflate';
	}

	return req;
}

function setupResponseStream(response, dontUnzip) {
	var stream = response;
	if (!dontUnzip && response.headers['content-encoding'] == 'gzip') {
		stream = response.pipe(zlib.createGunzip());
	}
	return stream;
}

function concatStream(stream, callback) {
	var chunks = [];

	stream.on("data", function(chunk) {
		chunks.push(chunk);
	});

	stream.on("end", function() {
		if (chunks.length) {
			if (typeof chunks[0] === "string")
				callback(null, chunks.join(""));
			else
				callback(null, Buffer.concat(chunks));
		} else {
			callback(null, null);
		}

	});

	stream.on("error", function(e) {
		callback(e);
	});
}

function responseAsJSON(response, callback) {

	var stream = setupResponseStream(response);

	stream.setEncoding('utf8');

	concatStream(stream, function(error, str) {
		//console.log("_"+str+"_");
		var result;

		if (!error) {
			try {
				result = JSON.parse(str);
			} catch(e) {
				console.log(str, e);
			}
		}

		callback(result);
	});
}

var encodeUrn = function(urn) {
	return new Buffer(urn)
			.toString('base64')
				.replace(/\+/g, '-') // Convert '+' to '-'
                .replace(/\//g, '_') // Convert '/' to '_'
                .replace(/=+$/, ''); // Remove ending '='
};


var decodeUrn = function(urn) {
	urn = urn.replace(/-/g, '+').replace(/_/g, '/');

	while (urn.length % 4)
		urn += '=';

	return new Buffer(urn, 'base64').toString();
};

var openWriteStream = function(outFile) {
	var wstream;
	if (outFile) {
		try {
			mkdirp.sync(path.dirname(outFile));
			wstream = fs.createWriteStream(outFile);
		} catch(e) {
		}
	}

	return wstream;
};


function Ds(endpoint, auth, oss) {
	_endpoint = endpoint;
	_a = auth;

    if (oss) {
        _oss = oss;
    } else {
    	//this makes sure OSS is loaded either from relartive path
    	//or when running as part of the amalgamated node module.
    	var Oss = exports.Oss || require('../oss/oss').Oss;
    	_oss = new Oss(_endpoint, function() { return _a.getTokenString(); } );
    }
}


Ds.prototype.register = function(urn, from, force, channel, callback) {
	var isDesignDescription = false;

	if (!urn) {
		if (typeof from == 'string')
			urn = from;
		else if (from && from.designDescription) {
			isDesignDescription = true;
		}
		else {
			callback("Design URN not specified.", null);
			return;
		}
	} else {
		isDesignDescription = (from && from.designDescription);
	}

	var payload;

	var registerType = {
		"thumbnail" : {},
		"2dviewing" : {},
		"3dviewing" : {
			//"building_shell" : true,
			//"buildingShell" : true,
			//"enable_spd" : 'true'
		}
	};



	if (isDesignDescription)
		payload = {
			design: encodeUrn(urn),
			designDescription: from,
			registerType: registerType,
			channel: channel || undefined
		};
	else
		payload = {
			design : encodeUrn(urn),
			from: encodeUrn(from),
			registerType: registerType,
			channel: channel || undefined
		};

	var payloadStr = JSON.stringify(payload);

	console.log(payloadStr);

	var post_options = setupRequest('POST', 'registration');

	post_options.headers["Content-Type"] = "application/json; charset=utf-8";
	post_options.headers["Content-Length"] =  Buffer.byteLength(payloadStr, 'utf8');
	if (force)
		post_options.headers["x-ads-force"] = "true";

	var post_req = https.request(post_options, function(response) {
		responseAsJSON(response, function(result) {

			if (response.statusCode == 200 || (response.statusCode == 201 && !force))
				if (callback)
					callback(null, result);
			else {
				//if (response.statusCode == 400) {
					console.log("Bad request: ", response.statusCode, JSON.stringify(payload));
				//}
				if (callback)
					callback(result);
			}
		});
	});

	post_req.on('error', function(e) {
		callback(e, null);
	});
	post_req.write(payloadStr);
	post_req.end();
};

Ds.prototype.getManifest = function(urn, manifestContent, subGuid, callback) {
	var encodedUrn = ((urn.indexOf("urn:") === 0) ? encodeUrn(urn) : urn);
	var path = 'manifest/' + encodedUrn;

	if (manifestContent)
		path += '/' + manifestContent; // "all" or "status"

	if (subGuid)
		path += '?guid=' + subGuid;

	var post_options = setupRequest('GET', path, true);

	var post_req = https.request(post_options, function(response) {
		if (response.statusCode == 200) {
			responseAsJSON(response, function(result) {
				result.urn = encodedUrn; //Store back the urn of the bubble into the bubble, for ease of use
				callback(null, result);
			});
		} else {
			var extraInfo = response.headers['x-ads-troubleshooting'];
			callback(response.statusCode + (extraInfo ? ": " + extraInfo : ""));
		}
	});

	post_req.on('error', function(e) {
		callback(e, null);
	});
	post_req.end();
};

Ds.prototype.unregister = function(urn, callback) {
	var encodedUrn = ((urn.indexOf("urn:") === 0) ? encodeUrn(urn) : urn);
	var path = 'registration/' + encodedUrn;
	var options = setupRequest('DELETE', path);

	var req = https.request(options, function(response) {
		responseAsJSON(response, function(result) {
			if (response.statusCode == 200) {
				callback(null, result);
			} else {
				callback(result ? result : response.statusCode);
			}
		});
	});

	req.on('error', function(e) {
		callback(e, null);
	});
	req.end();
};


Ds.prototype.getItem = function(itemUrn, outFile, callback) {

	// Go directly to OSS when we can
	/*
	if(itemUrn.startsWith('urn:adsk.objects')) {
		// it's stored on OSS, go get it there
		var urnParts = itemUrn.split(':');
		var path = urnParts[urnParts.length - 1];
		var firstPathSlash = path.indexOf('/');
		var bucketName = path.substring(0,firstPathSlash);
		var objectKey = path.substring(firstPathSlash + 1);   // OSS stores the object with %2F!
		_oss.downloadFile(bucketName, objectKey, outFile, callback);
		return;
	}
	*/

	var urlpath = 'derivatives/' + encodeURIComponent(itemUrn);

	var post_options = setupRequest('GET', urlpath);

	var post_req = https.request(post_options, function(response) {

		//Don't write blanks
		if (response.statusCode !== 200) {
			callback(response.statusCode);
			return;
		}

		var wstream = openWriteStream(outFile);

		//skip unzipping of items to make the downloaded content compatible with viewer debugging
		//TODO: may be this should be a command line option?
		var stream = setupResponseStream(response, true);

		if (wstream && response.statusCode == 200) {
			stream.pipe(wstream).on('finish', function () {
				callback(null, response.statusCode);
			}).on('error', callback);
		} else {
			if (!outFile && response.statusCode === 200) {
				concatStream(stream, callback);
			} else {
				//Read the error messsage text from the stream
				concatStream(stream, function(error, str) {
					callback(response.statusCode + " : " + str.toString('utf8'));
				});
			}

		}
	});

	post_req.on('error', function(e) {
		callback(e, null);
	});
	post_req.end();
};


Ds.prototype.getThumbnail = function(urn, guid, outFile, callback) {
	var sz = 400;
	var urlpath = "thumbnails/" + ((urn.indexOf("urn:") === 0) ? encodeUrn(urn) : urn) + "?guid=" + encodeURIComponent(guid) + "&role=rendered" + "&width=" + sz + "&height=" + sz;

	var post_options = setupRequest('GET', urlpath);

	var post_req = https.request(post_options, function(response) {

		var wstream = openWriteStream(outFile);

		var stream = setupResponseStream(response);

		if (wstream && response.statusCode == 200) {
			stream.pipe(wstream).on('finish', function () {
				callback(null, response.statusCode);
			}).on('error', callback);
		} else {
			if (!outFile && response.statusCode === 200) {
				concatStream(stream, callback);
			} else {
				//Read the error messsage text from the stream
				concatStream(stream, function(error, str) {
					callback(response.statusCode + " : " + str.toString('utf8'));
				});
			}

		}
	});

	post_req.on('error', function(e) {
		callback(e, null);
	});
	post_req.end();
};

Ds.prototype.getSupportedFormats = function(callback) {
	var options = setupRequest('GET', "supported");
	var req = https.request(options, function(response) {
		responseAsJSON(response, function(result) {
			if (response.statusCode == 200)
				callback(null, result);
			else
				callback(result);
		});
	});

	req.on('error', function(e) {
		callback(e, null);
	});
	req.end();
};

Ds.prototype.getChannelMapping = function(callback) {
	var options = setupRequest('GET', "configuration/channel-mapping");
	var req = https.request(options, function(response) {
		responseAsJSON(response, function(result) {
			if (response.statusCode == 200)
				callback(null, result);
			else
				callback(result);
		});
	});

	req.on('error', function(e) {
		callback(e, null);
	});
	req.end();
};

Ds.prototype.getDesignDescription = function(urn, callback) {
	var path = 'designdescription/' + encodeUrn(urn);
	var post_options = setupRequest('GET', path);

	var post_req = https.request(post_options, function(response) {
		responseAsJSON(response, function(result) {
			if (response.statusCode == 200)
				callback(null, result);
			else
				callback(result);
		});
	});

	post_req.on('error', function(e) {
		callback(e, null);
	});
	post_req.end();
};


function extractPathsFromGraphicsUrn(urn, result) {

	//This needs to be done for encoded OSS URNs, because the paths
	//in there are url encoded and lose the / character.
	urn = decodeURIComponent(urn);

	var basePath = urn.slice(0, urn.lastIndexOf("/") + 1);
	var localPath = basePath.slice(basePath.indexOf("/")+1);
	var urnBase = basePath.slice(0, basePath.indexOf("/"));

	//For supporting compound bubbles, we need to prefix
	//by sub-urn as well, otherwise files might clash.
	//var localPrefix = urnBase ? crypto.createHash('md5').update(urnBase).digest("hex") + "/" : "";
	var localPrefix = "";

	result.urn = urn;
	result.basePath = basePath;
	result.localPath = localPrefix + localPath;
	result.rootFileName = urn.slice(urn.lastIndexOf("/") + 1);
}


Ds.prototype.listAllDerivativeFiles = function(bubble, callback) {
	var ds = this;

	//First get all the root derivative files from the bubble
	var res = [];
	(function traverse(node) {

		if (
			    node.role === "Autodesk.CloudPlatform.PropertyDatabase"
			||  node.role === "Autodesk.CloudPlatform.DesignDescription"
			||  node.role === "Autodesk.CloudPlatform.IndexableContent"
			||  node.role === "graphics"
			||  node.role === "raas"
			||  node.role === "pdf"
			||  node.role === "leaflet-zip"
			||  node.role === "preview"
			||  node.role === "lod"
		) {
			var item = { mime: node.mime };
			extractPathsFromGraphicsUrn(node.urn, item);

			//Optionally replace the path in the source bubble by the local path
			//for use as local bubbles in the viewer
			node.urn = "$file$/" + item.localPath + item.rootFileName;
			res.push(item);
		}

		if (node.type === "geometry") {
			//Why would we be sane and use real booleans??
			if (node.hasThumbnail === "true") {
				var item = {mime: "thumbnail", urn: bubble.urn, guid: node.guid};
				item.localPath = "thumbnails/";

				node.thumbnailUrn = "$file$/" + "thumbnails/" + item.guid + ".png";
				res.push(item);
			}

			if (node.intermediateFile && node.children) {
				//We will derive the full intermediate file path from the child F2D node
				var f2dNode;

				for (var i=0; i<node.children.length; i++) {
					if (node.children[i].mime === "application/autodesk-f2d") {
						f2dNode = node.children[i];
						break;
					}
				}

				if (f2dNode) {

					var f2dUrl = f2dNode.urn;
					var idx = f2dUrl.indexOf(bubble.urn);
					var baseUrl = f2dUrl.substr(0, idx + bubble.urn.length);

					var item = {mime: "application/octet-stream", urn: bubble.urn, guid: node.guid};

					//Construct the full urn path, similar to how it's stored for the SVF geometry items
					var intPath = "/" + node.intermediateFile;
					if (baseUrl.indexOf('urn:adsk.objects') === 0)
						intPath = encodeURIComponent(intPath);
					var fullPath = baseUrl + intPath;

					extractPathsFromGraphicsUrn(fullPath, item);

					res.push(item);

				}

			}

		}

		if (node.children) {
			node.children.forEach(function(child) {
				traverse(child);
			});
		}

	})(bubble, "");

	console.log("Manifests to process: ", res.length);

	if(res.length === 0) {
		callback(null, { list: [], totalSize: 0 });
		return;
	}

	var current = 0;
	var done = 0;
	var estSize = 0;
	var countedPropDb = {};


	var processOne = function() {

		function onProgress() {
			done++;
			console.log("Manifests done ", done);
			if (done === res.length) {
				var result = {
					list:res,
					totalSize: estSize
				};
				callback(null, result);
			} else {
				setTimeout(processOne, 0);
			}
		}

		if (current >= res.length)
			return;

		var rootItem = res[current++];

		var basePath;
		var files = rootItem.files = [];

		if (rootItem.mime !== "thumbnail") {
			basePath = rootItem.basePath;
		}

		if (rootItem.mime === "application/autodesk-db") {

			//The file list for property database files is fixed,
			//no need to go to the server to find out
			files.push("objects_attrs.json.gz");
			files.push("objects_vals.json.gz");
			files.push("objects_avs.json.gz");
			files.push("objects_offs.json.gz");
			files.push("objects_ids.json.gz");

			onProgress();
		} else if (rootItem.mime === "thumbnail") {

			rootItem.files.push(rootItem.guid + ".png");
			onProgress();

		} else if (rootItem.mime === "application/autodesk-svf") {

			var svfPath = rootItem.urn.slice(basePath.length);
			files.push(svfPath);

			//Closure to capture loop-variant variable for the getItem callback
			(function() {
				var myItem = rootItem;

				ds.getItem(rootItem.urn, null, function(error, success) {

					if (success) {
						var manifest;
						try {
							var pack = new zip(success, {base64: false, checkCRC32: true});
							success = pack.files["manifest.json"].asNodeBuffer();
							manifest = JSON.parse(success.toString("utf8"));
						} catch (e) {
							console.log(e.message);
						}

						if (manifest && manifest.assets) {
							for (var j=0; j<manifest.assets.length; j++) {
								var asset = manifest.assets[j];

								//Skip SVF embedded resources
								if (asset.URI.indexOf("embed:/") === 0)
									continue;

								//Skip non-local property db files
								//Those are listed explicitly in the bubble as property database role
								//so we will get them anyway
								if (asset.URI.indexOf("../") === 0) {

									//To get a correct bubble size estimate,
									//we get the property db file sizes from the SVF manifest,
									//because they are not available in the bubble itself.
									//It's ugly, but such is bubble life.
									//Also, this number seems to be the uncompressed size of the property db files,
									//so it's an overestimate, and we divide by 4 to get a more reasonable one.
									if (!countedPropDb[rootItem.basePath]) {
										estSize += asset.size / 4;
									}

									continue;
								}

								estSize += asset.size;
								myItem.files.push(asset.URI);
							}
						}

						countedPropDb[rootItem.basePath] = 1;
					}

					onProgress();
				});
			})();

		} else if (rootItem.mime === "application/autodesk-f2d") {

			files.push("manifest.json.gz");
			var manifestPath = basePath + "manifest.json.gz";

			//Closure to capture loop-variant variable for the getItem callback
			(function() {
				var myItem = rootItem;
				ds.getItem(manifestPath, null, function(error, success) {
					if (success) {
						estSize += success.length;

						var manifest;
						try {
							if (success[0] === 0x1f && success[1] === 0x8b) {
								success = zlib.gunzipSync(success);
							}
							manifest = JSON.parse(success.toString("utf8"));
						} catch (e) {
							console.log(e.message);
						}

						if (manifest && manifest.assets) {
							for (var j=0; j<manifest.assets.length; j++) {
								var asset = manifest.assets[j];

								//Skip non-local property db files
								//Those are listed explicitly in the bubble as property database role
								//so we will get them anyway
								if (asset.URI.indexOf("../") === 0)
									continue;

								estSize += asset.size;
								myItem.files.push(asset.URI);
							}
						}
					}

					onProgress();
				});
			})();

		} else {
			//All other files are assumed to be just the file listed in the bubble
			files.push(rootItem.rootFileName);
			onProgress();
		}
	};

	//Kick off 6 parallel jobs
	for (var k=0; k<6; k++)
		processOne();
};

Ds.prototype.downloadAllDerivativeFiles = function(fileList, destDir, callback) {
	var self = this;

	var succeeded = 0;
	var failed = 0;

	var flatList = [];

	for (var i=0; i<fileList.length; i++) {
		var item = fileList[i];
		for (var j=0; j<item.files.length; j++) {

			var flatItem = {
				basePath : item.basePath,
				localPath : destDir + item.localPath,
				fileName : item.files[j]
			};

			if (item.urn) {
				flatItem.urn = item.urn;
				flatItem.guid = item.guid;
				flatItem.mime = item.mime;
			}

			flatList.push(flatItem);
		}
	}

	if(flatList.length === 0) {
		callback(failed, succeeded);
		return;
	}

	var current = 0;
	var done = 0;

	var downloadOneItem = function() {

		if (current >= flatList.length)
			return;

		var fi = flatList[current++];

		var downloadComplete = function(error, success) {

			done++;

			if (error) {
				failed++;
				console.log("Failed to download file.", fi.localPath + fi.fileName, error);
			}
			else {
				succeeded++;
				console.log("Downloaded", fi.localPath + fi.fileName);
			}

			console.log("Progress:", (100 * (failed + succeeded) / flatList.length) | 0, "%");

			if (done === flatList.length) {
				callback(failed, succeeded);
			} else {
				setTimeout(downloadOneItem, 0);
			}

		};

		if (fi.mime && fi.mime === "thumbnail")
			self.getThumbnail(fi.urn, fi.guid, fi.localPath + fi.fileName, downloadComplete);
		else {
			self.getItem(fi.basePath + fi.fileName, fi.localPath + fi.fileName, downloadComplete);
		}

	};

	//Kick off 10 parallel jobs
	for (var k=0; k<10; k++)
		downloadOneItem();

};

Ds.encodeUrn = encodeUrn;
Ds.decodeUrn = decodeUrn;

exports.Ds = Ds;

})();
;
//Functional wrapper around a bubble manifest json providing common functionality needed by Fluent

(function() {

"use strict";

var nextId = 1;

function checkForPropertyDb(item) {
	if (item.mime == "application/autodesk-db" && item.urn) {
		//Of course, OSS is a storage system that mangles paths because why not,
		//so it needs special handling to extract the property database path
		if (item.urn.indexOf("urn:adsk.objects:os.object") === 0)
			return item.urn.substr(0, item.urn.lastIndexOf("%2F")+3);
		else
			return item.urn.substr(0, item.urn.lastIndexOf("/")+1);
	}
	return null;
}


/**
 * Wrapper and helper for "bubble" data.
 *
 * _Bubble_ is a container of various 2D or 3D viewables (and additional data)
 * that may be generated from a single seed file. The bubble is a JSON structure
 * of nodes that have different roles, for example, they may represent sheets,
 * nested 2D/3D geometry, etc.
 *
 * This class wraps the internal representation of the bubble
 * and adds a couple of helper methods.
 *
 * @constructor
 * @memberof Autodesk.Viewing
 * @alias Autodesk.Viewing.BubbleNode
 * @param {object} rawNode Raw node from the bubble JSON.
 * @param {object} [parent] Parent node from the bubble JSON.
 * @category Core
 */
function BubbleNode(rawNode, parent) {

	this.parent = parent;

	//Just an integer ID for use in runtime hashmaps
	this.id = nextId++;

	//TODO: do we need to clone the data into outselves, or just keep pointer as is
	//would be a waste of space to copy...
	this.data = rawNode;

	//Now do some postprocessing / precomputation of things we will need
    //TODO: are there nodes with type==geometry where role isn't 3d nor 2d?
	this.isLeaf = (rawNode.type === "geometry" && (rawNode.role === "3d" || rawNode.role === "2d" || rawNode.role === "lod"));

	if (Array.isArray(rawNode.children)) {
		this.children = [];

		//Recurse
		var len = rawNode.children.length;

		for(var i=0; i < len; i++) {
			this.children[i] = new BubbleNode(rawNode.children[i], this);
		}

		//Some more postprocessing / precomputation of things we will need
		//Some properties are determined by specific children. Look for those.
		for (var i=0; i<len; i++) {
			//Find the node's shared property db path -- if there is one, it's one of the children
			var path = checkForPropertyDb(rawNode.children[i]);
			if (path)
				this.sharedPropertyDbPath = path;

			//Check if a child geometry is an LOD model
			//TODO: expect a change in the extractor to put the lod role in the node itself
			//so this check will be made on item instead of its children eventually.
			if (rawNode.children[i].role === "lod")
				this.lodNode = this.children[i];
		}
	}
}

/**
 * @returns {Autodesk.Viewing.BubbleNode} Top-most bubble node.
 */
BubbleNode.prototype.getRootNode = function() {

	if (this.parent)
        return this.parent.getRootNode();

	return this;
};

/**
 * Finds shared property DB if there is one.
 *
 * @returns {?string} Shared property DB path, or null.
 */
BubbleNode.prototype.findPropertyDbPath = function() {

	if (this.sharedPropertyDbPath)
		return this.sharedPropertyDbPath;

	if (this.parent)
		return this.parent.findPropertyDbPath();

	return null;
};

// Deprecated. Avoid using this from the outside.
BubbleNode.prototype._raw = function() {
	return this.data;
};

/**
 * @returns {string} Node name.
 */
BubbleNode.prototype.name = function() {
	return this.data.name;
};

/**
 * @returns {string} Node GUID.
 */
BubbleNode.prototype.guid = function() {
	return this.data.guid;
};

/**
 * Retrieves the URN of the node or its closest ancestor.
 *
 * @param {boolean} searchParent If URN is not available for this node,
 * search through its ancestors, too.
 * @returns {string} Viewable URN.
 */
BubbleNode.prototype.urn = function(searchParent) {

	var urn = this.data.urn;

	if (!searchParent)
		return urn;

	var n = this.parent;
	while (!urn && n) {
		urn = n.data.urn;
		n = n.parent;
	}

	return urn;
};

/**
 * Retrieves value of a node tag.
 *
 * @param {string} tag Tag name.
 * @returns {*} Tag value.
 */
BubbleNode.prototype.getTag = function(tag) {
	return (this.data.tags ? this.data.tags : this.data)[tag];
};

/**
 * Sets node tag value.
 *
 * @param {string} tag Tag name.
 * @param {*} value Tag value.
 */
BubbleNode.prototype.setTag = function(tag, value) {
	if (this.data.tags)
		this.data.tags[tag] = value;
	else
		this.data[tag] = value;
};

/** @returns {boolean} Is this a geometry leaf node. */
BubbleNode.prototype.isGeomLeaf = function() {
	return this.isLeaf;
};

/** @returns {boolean} Is this a viewable node. */
BubbleNode.prototype.isViewable = function() {
	return this.data.role === "viewable";
};

/** @returns {boolean} Is this an LOD node. */
BubbleNode.prototype.getLodNode = function() {
	return this.lodNode;
};

/** @returns {boolean} Is this a geometry node. */
BubbleNode.prototype.isGeometry = function() {
	return this.data.type === "geometry";
};

/** @returns {boolean} Is this a 2D node. */
BubbleNode.prototype.is2D = function() {
	return this.data.role === "2d";
};

/** @returns {boolean} Is this a 3D node. */
BubbleNode.prototype.is3D = function() {
	return this.data.role === "3d";
};

/** @returns {boolean} Is this a 2D geometry node. */
BubbleNode.prototype.is2DGeom = function() {
	return this.isGeometry() && this.is2D();
};

/** @returns {boolean} Is this a 3D geometry node. */
BubbleNode.prototype.is3DGeom = function() {
	return this.isGeometry() && this.is3D();
};

/** @returns {object} Placement transform of the node. */
BubbleNode.prototype.getPlacementTransform = function() {
	return this.data.placement;
};

/** @returns {boolean} Is this a metadata node. */
BubbleNode.prototype.isMetadata = function() {
	//Certain nodes are not relevant for display purposes,
	//as they contain no graphics and provide extra information for
	//the graphics nodes.
	if (this.data.role) {
		if (this.data.role.indexOf("Autodesk.CloudPlatform.DesignDescription") !== -1)
			return true;
		if (this.data.role === "Autodesk.CloudPlatform.PropertyDatabase")
			return true;
	}

	return false;
};

/**
 * @returns {?Autodesk.Viewing.BubbleNode} First parent in the hierarchy that is a viewable.
 */
BubbleNode.prototype.findViewableParent = function() {

	var p = this;
	while (p && !p.isViewable())
		p = p.parent;

	return p;
};

/**
 * @returns {?Autodesk.Viewing.BubbleNode} First parent in the hierarchy that is a 2D or 3D geometry.
 */
BubbleNode.prototype.findParentGeom2Dor3D = function() {

	var p = this;
	while (p && !p.is2DGeom() && !p.is3DGeom())
		p = p.parent;

	return p;
};

/**
 * Looks for the viewable root path in this node and all its children.
 * @returns {?string} Viewable root path, or null.
 */
BubbleNode.prototype.getViewableRootPath = function() {

	if (!this.isGeomLeaf())
		return null;

	var mime = this.is2D() ? "application/autodesk-f2d" : "application/autodesk-svf";

	var items = this.search({mime:mime});

	if (items && items.length) {
		var path = items[0].data.urn;
		return path;
	}

	return null;
};

/**
 * Returns first node from the bubble matching a GUID.
 *
 * Note that some GUIDs in the bubble are not unique, you have to be sure
 * you are looking for a GUID that is unique if you want correct result
 * from this function. Otherwise use the generic search.
 *
 * @param {string} guid Node GUID.
 * @returns {?Autodesk.Viewing.BubbleNode} Matching bubble node, or null.
 */
BubbleNode.prototype.findByGuid = function(guid) {
	var item = null;

	this.traverse(function(node) {
		if (node.data.guid === guid) {
			item = node;
			return true;
		}
	});

	return item;
};

/**
 * Finds nodes from the bubble matching one or more properties.
 *
 * @param {object} propsToMatch Filter criteria - matching nodes must have
 * the same properties and values.
 * @returns {?(Autodesk.Viewing.BubbleNode[])} Matching nodes, or null.
 */
BubbleNode.prototype.search = function(propsToMatch) {

	var result = [];

	this.traverse(function(node) {
		var found = true;
		for (var p in propsToMatch) {
			if (!node.data.hasOwnProperty(p) || node.data[p] !== propsToMatch[p]) {
				found = false;
				break;
			}
		}
		if (found)
			result.push(node);
	});

	return result.length ? result : null;
};

/**
 * Finds nodes from the bubble matching one or more tags.
 *
 * @param {object} tagsToMatch Filter criteria - matching nodes must have
 * the same tags and values.
 * @returns {?(Autodesk.Viewing.BubbleNode[])} Matching nodes, or null.
 */
BubbleNode.prototype.searchByTag = function(tagsToMatch) {

	var result = [];

	this.traverse(function(node) {
		var found = true;
		for (var p in tagsToMatch) {
			if (node.getTag(p) !== tagsToMatch[p]) {
				found = false;
				break;
			}
		}
		if (found)
			result.push(node);
	});

	return result.length ? result : null;
};

/**
 * Recursively traverses the bubble, calling a callback function for each node,
 * for as long as the callback function keeps returning false.
 *
 * @param {function} cb Callback function, accepts a bubble node as an argument,
 * and returns true if the traversal should be terminated.
 * @returns {boolean} Result of the last callback invokation.
 */
BubbleNode.prototype.traverse = function(cb) {

	//Allow the callback to exit early if it meets
	//some internal condition and returns true.
	if (cb(this)) return true;

	if (this.children) {

		for (var i=0; i<this.children.length; i++) {

			if (this.children[i].traverse(cb))
				return true;

		}

	}

	return false;
};

/*
 * Returns the Revit Level/Floor of this bubble node.
 *
 * Only relevant for 2d sheets coming from Revit at the moment.
 */
BubbleNode.prototype.getLevel = function() {
    // Eventually Revit should tag the bubble nodes with this value,
    // currently it's just a guess done by Fluent.guessObjectLevels().
	var level = this.getTag("level");

	//TODO: for now, return the first level if a sheet shows multiple levels,
	//since the UI code can't handle it.
	if (Array.isArray(level))
		return level[0];

	return level;
};

//BubbleNode search patterns for often used nodes (yes, they are confusing, hence pre-defined to
//help you not go insane).
BubbleNode.MODEL_NODE =         { "role":"3d", "type":"geometry" };
BubbleNode.GEOMETRY_SVF_NODE =  { "role":"graphics", "mime": "application/autodesk-svf" };
BubbleNode.SHEET_NODE =         { "role":"2d", "type":"geometry" };
BubbleNode.GEOMETRY_F2D_NODE =  { "role":"graphics", "mime": "application/autodesk-f2d" };
BubbleNode.VIEWABLE_NODE =      { "role":"viewable" };


Autodesk.Viewing.BubbleNode = BubbleNode;


})();
;
Autodesk.Viewing.Private.initializeLegacyNamespaces(false);
exports.THREE = THREE;
exports.WGS = WGS;